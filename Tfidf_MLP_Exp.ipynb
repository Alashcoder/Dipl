{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qZWi2EEQW80d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import sklearn\n",
    "import torchmetrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1MV3_19KY_wN"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('main_dataset.csv',  encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "T-Y-10uCZIwm",
    "outputId": "5c31d972-8598-431c-d766-bc0baab289f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>на работе был полный пиддес :| и так каждое за...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Коллеги сидят рубятся в Urban terror, а я из-з...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@elina_4post как говорят обещаного три года жд...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Желаю хорошего полёта и удачной посадки,я буду...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Обновил за каким-то лешим surf, теперь не рабо...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  label\n",
       "0   1  на работе был полный пиддес :| и так каждое за...    0.0\n",
       "1   2  Коллеги сидят рубятся в Urban terror, а я из-з...    1.0\n",
       "2   3  @elina_4post как говорят обещаного три года жд...    0.0\n",
       "3   4  Желаю хорошего полёта и удачной посадки,я буду...    0.0\n",
       "4   5  Обновил за каким-то лешим surf, теперь не рабо...    0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jonptviKZMYi",
    "outputId": "555f9ba9-b590-4213-876a-f11609d6a788"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'after' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m after \u001b[38;5;241m=\u001b[39m \u001b[43mafter\u001b[49m\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'after' is not defined"
     ]
    }
   ],
   "source": [
    "after = after.dropna(subset=['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(after, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "#Создание экземпляра TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "#Преобразование текстов в матрицу TF-IDF\n",
    "tfidf_matrix_train_df = vectorizer.fit_transform(train_df['text'])\n",
    "\n",
    "#Преобразование разреженной матрицы в формат CSR\n",
    "tfidf_csr_train_df = csr_matrix(tfidf_matrix_train_df)\n",
    "\n",
    "# Преобразование формата разреженной матрицы в формат COO\n",
    "tfidf_coo_train_df = tfidf_csr_train_df.tocoo().astype(np.float32)\n",
    "\n",
    "# Преобразование матрицы TF-IDF в разреженный тензор PyTorch\n",
    "tfidf_tensor_train_df = torch.sparse.FloatTensor(torch.LongTensor([tfidf_coo_train_df.row.tolist(), tfidf_coo_train_df.col.tolist()]),\n",
    "                                        torch.FloatTensor(tfidf_coo_train_df.data))\n",
    "\n",
    "# Вывод тензора TF-IDF\n",
    "print(tfidf_tensor_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "#Удаление строк с пропущенными значениями в столбце 'text'\n",
    "after = after.dropna(subset=['text'])\n",
    "\n",
    "#Создание экземпляра TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "#Преобразование текстов в матрицу TF-IDF\n",
    "tfidf_matrix_test_df = vectorizer.fit_transform(test_df['text'])\n",
    "\n",
    "#Преобразование разреженной матрицы в формат CSR\n",
    "tfidf_csr_test_df = csr_matrix(tfidf_matrix_test_df)\n",
    "\n",
    "# Преобразование формата разреженной матрицы в формат COO\n",
    "tfidf_coo_test_df = tfidf_csr_test_df.tocoo().astype(np.float32)\n",
    "\n",
    "# Преобразование матрицы TF-IDF в разреженный тензор PyTorch\n",
    "tfidf_tensor_test_df = torch.sparse.FloatTensor(torch.LongTensor([tfidf_coo_test_df.row.tolist(), tfidf_coo_test_df.col.tolist()]),\n",
    "                                        torch.FloatTensor(tfidf_coo_test_df.data))\n",
    "\n",
    "# Вывод тензора TF-IDF\n",
    "print(tfidf_tensor_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=list()\n",
    "for i in train_df['label']:\n",
    "    y_train_list.append(i)\n",
    "y_train=torch.tensor(y_train_list)\n",
    "y_train.unsqueeze_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=list()\n",
    "for i in train_df['label']:\n",
    "    y_train_list.append(i)\n",
    "y_train=torch.tensor(y_train_list)\n",
    "y_train.unsqueeze_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tfidf_tensor_train_df\n",
    "x_test = tfidf_tensor_test_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.to_dense()\n",
    "x_test = x_test.to_dense()\n",
    "x_train = x_train.narrow(1, 0, 1000) \n",
    "x_test = x_test.narrow(1, 0, 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Word2Vec_MLP_Experiment_#1 (Base)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_MK1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP_MK1, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "#         out=torch.round(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk1=MLP_MK1(1000,300,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    dev = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     dev=torch.device('cuda:0')\n",
    "# else: dev=torch.device('cpu:0')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.to(dev)\n",
    "x_test=x_test.to(dev)\n",
    "y_train=y_train.to(dev)\n",
    "y_test=y_test.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk1=Mk1.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(Mk1.parameters(), lr=0.001)\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "f1_score = torchmetrics.functional.f1_score\n",
    "accuracy = torchmetrics.functional.accuracy\n",
    "diagdf=pd.DataFrame(columns=['Epoch','loss','F1-score','accuracy'])\n",
    "for epoch in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    pred = Mk1.forward(x_train.float())\n",
    "    l = loss(pred, y_train) # squeeze the predicted tensor\n",
    "    l.backward()\n",
    "    f1= f1_score(pred, y_train, task='binary')\n",
    "    acc=accuracy(pred, y_train, task='binary')\n",
    "    data={'Epoch':epoch,'loss':l.item(),'F1-score':f1.item(),'accuracy':acc.item()}\n",
    "    diagdf = pd.concat([diagdf, pd.DataFrame(data, index=[epoch])], ignore_index=True)\n",
    "    optimizer.step()\n",
    "    print('Epoch: ', epoch+1, ', Loss: ', l.item(),'  f1-score:', f1.item(),\"  accuracy:\", acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# построение графика loss\n",
    "plt.plot(diagdf['Epoch'], diagdf['loss'], label='loss')\n",
    "\n",
    "# построение графика F1-score\n",
    "plt.plot(diagdf['Epoch'], diagdf['F1-score'], label='F1-score')\n",
    "\n",
    "# построение графика accuracy\n",
    "plt.plot(diagdf['Epoch'], diagdf['accuracy'], label='accuracy')\n",
    "\n",
    "# добавление заголовка графика\n",
    "plt.title('Графики loss, F1-score и accuracy')\n",
    "\n",
    "# добавление подписей к осям\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Значение')\n",
    "\n",
    "# добавление легенды\n",
    "plt.legend()\n",
    "\n",
    "# отображение графика\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test1=Mk1.forward(x_test.float())\n",
    "pred_test_binarized1 = (pred_test1 > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.to('cpu'), pred_test_binarized1.to('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Word2Vec_MLP_Experiment_#2</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>epochs: 10000 -> 5050, hidden_size: 200 -> 300, lr: 0.0001 -> 0.001</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# nn.Linear() можно указать точные значения для \"input_size, hidden_size\"\n",
    "# вместо nn.ReLU() можно посмотреть Sigmoid, tangensoid, etc.\n",
    "# попробовать добавить еще Layers (fc3, fc4, etc.)\n",
    "class MLP_MK2(nn.Module): #изменить название\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP_MK2, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size) #если добавлять или изменять, то не забыть поменять название\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x) #если добавлять или изменять, то не забыть поменять название\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk2=MLP_MK2(1000,300,1) #изменить название переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    dev = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     dev=torch.device('cuda:0')\n",
    "# else: dev=torch.device('cpu:0')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.to(dev)\n",
    "x_test=x_test.to(dev)\n",
    "y_train=y_train.to(dev)\n",
    "y_test=y_test.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk2=Mk2.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"lr\" - learning rate (чем больше \"epoch\", тем меньше \"lr\")\n",
    "optimizer = torch.optim.Adam(Mk2.parameters(), lr=0.001) #изменить название переменной\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "f1_score = torchmetrics.functional.f1_score\n",
    "accuracy = torchmetrics.functional.accuracy\n",
    "diagdf1=pd.DataFrame(columns=['Epoch','loss','F1-score','accuracy']) #изменить название переменной\n",
    "# можно изменить количество \"epoch\"\n",
    "for epoch in range(5050):\n",
    "    optimizer.zero_grad()\n",
    "    pred = Mk2.forward(x_train.float()) #изменить название переменной\n",
    "    l = loss(pred, y_train) # squeeze the predicted tensor\n",
    "    l.backward()\n",
    "    f1= f1_score(pred, y_train, task='binary')\n",
    "    acc=accuracy(pred, y_train, task='binary')\n",
    "    data={'Epoch':epoch,'loss':l.item(),'F1-score':f1.item(),'accuracy':acc.item()}\n",
    "    diagdf1 = pd.concat([diagdf1, pd.DataFrame(data, index=[epoch])], ignore_index=True) #изменить название переменной\n",
    "    optimizer.step()\n",
    "    print('Epoch: ', epoch+1, ', Loss: ', l.item(),'  f1-score:', f1.item(),\"  accuracy:\", acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagdf изменить название везде\n",
    "# построение графика loss\n",
    "plt.plot(diagdf1['Epoch'], diagdf1['loss'], label='loss')\n",
    "\n",
    "# построение графика F1-score\n",
    "plt.plot(diagdf1['Epoch'], diagdf1['F1-score'], label='F1-score')\n",
    "\n",
    "# построение графика accuracy\n",
    "plt.plot(diagdf1['Epoch'], diagdf1['accuracy'], label='accuracy')\n",
    "\n",
    "# добавление заголовка графика\n",
    "plt.title('Графики loss, F1-score и accuracy')\n",
    "\n",
    "# добавление подписей к осям\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Значение')\n",
    "\n",
    "# добавление легенды\n",
    "plt.legend()\n",
    "\n",
    "# отображение графика\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test2=Mk2.forward(x_test.float())\n",
    "pred_test_binarized2 = (pred_test2 > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.to('cpu'), pred_test_binarized2.to('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Word2Vec_MLP_Experiment_#3</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>layers + 1, epochs: 5050 -> 2000, hidden_size: 300 -> 150, lr: 0.001</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# nn.Linear() можно указать точные значения для \"input_size, hidden_size\"\n",
    "# вместо nn.ReLU() можно посмотреть Sigmoid, tangensoid, etc.\n",
    "# попробовать добавить еще Layers (fc3, fc4, etc.)\n",
    "class MLP_MK3(nn.Module): #изменить название\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP_MK3, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size) #если добавлять или изменять, то не забыть поменять название\n",
    "        self.tanh = nn.Tanh()\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x) #если добавлять или изменять, то не забыть поменять название\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.tanh(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk3=MLP_MK3(1000,150,1) #изменить название переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    dev = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     dev=torch.device('cuda:0')\n",
    "# else: dev=torch.device('cpu:0')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.to(dev)\n",
    "x_test=x_test.to(dev)\n",
    "y_train=y_train.to(dev)\n",
    "y_test=y_test.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk3=Mk3.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"lr\" - learning rate (чем больше \"epoch\", тем меньше \"lr\")\n",
    "optimizer = torch.optim.Adam(Mk3.parameters(), lr=0.001) #изменить название переменной\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "f1_score = torchmetrics.functional.f1_score\n",
    "accuracy = torchmetrics.functional.accuracy\n",
    "diagdf2=pd.DataFrame(columns=['Epoch','loss','F1-score','accuracy']) #изменить название переменной\n",
    "# можно изменить количество \"epoch\"\n",
    "for epoch in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    pred = Mk3.forward(x_train.float()) #изменить название переменной\n",
    "    l = loss(pred, y_train) # squeeze the predicted tensor\n",
    "    l.backward()\n",
    "    f1= f1_score(pred, y_train, task='binary')\n",
    "    acc=accuracy(pred, y_train, task='binary')\n",
    "    data={'Epoch':epoch,'loss':l.item(),'F1-score':f1.item(),'accuracy':acc.item()}\n",
    "    diagdf2 = pd.concat([diagdf2, pd.DataFrame(data, index=[epoch])], ignore_index=True) #изменить название переменной\n",
    "    optimizer.step()\n",
    "    print('Epoch: ', epoch+1, ', Loss: ', l.item(),'  f1-score:', f1.item(),\"  accuracy:\", acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagdf изменить название везде\n",
    "# построение графика loss\n",
    "plt.plot(diagdf2['Epoch'], diagdf2['loss'], label='loss')\n",
    "\n",
    "# построение графика F1-score\n",
    "plt.plot(diagdf2['Epoch'], diagdf2['F1-score'], label='F1-score')\n",
    "\n",
    "# построение графика accuracy\n",
    "plt.plot(diagdf2['Epoch'], diagdf2['accuracy'], label='accuracy')\n",
    "\n",
    "# добавление заголовка графика\n",
    "plt.title('Графики loss, F1-score и accuracy')\n",
    "\n",
    "# добавление подписей к осям\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Значение')\n",
    "\n",
    "# добавление легенды\n",
    "plt.legend()\n",
    "\n",
    "# отображение графика\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test3=Mk3.forward(x_test.float())\n",
    "pred_test_binarized3 = (pred_test3 > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.to('cpu'), pred_test_binarized3.to('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Word2Vec_MLP_Experiment_#4</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>epochs: 2000 -> 5000, lr: 0.001 -> 0.0001</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# nn.Linear() можно указать точные значения для \"input_size, hidden_size\"\n",
    "# вместо nn.ReLU() можно посмотреть Sigmoid, tangensoid, etc.\n",
    "# попробовать добавить еще Layers (fc3, fc4, etc.)\n",
    "class MLP_MK4(nn.Module): #изменить название\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP_MK4, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size) #если добавлять или изменять, то не забыть поменять название\n",
    "        self.tanh = nn.Tanh()\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x) #если добавлять или изменять, то не забыть поменять название\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.tanh(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk4=MLP_MK4(1000,150,1) #изменить название переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    dev = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     dev=torch.device('cuda:0')\n",
    "# else: dev=torch.device('cpu:0')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.to(dev)\n",
    "x_test=x_test.to(dev)\n",
    "y_train=y_train.to(dev)\n",
    "y_test=y_test.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk4=Mk4.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"lr\" - learning rate (чем больше \"epoch\", тем меньше \"lr\")\n",
    "optimizer = torch.optim.Adam(Mk4.parameters(), lr=0.0001) #изменить название переменной\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "f1_score = torchmetrics.functional.f1_score\n",
    "accuracy = torchmetrics.functional.accuracy\n",
    "diagdf3=pd.DataFrame(columns=['Epoch','loss','F1-score','accuracy']) #изменить название переменной\n",
    "# можно изменить количество \"epoch\"\n",
    "for epoch in range(5000):\n",
    "    optimizer.zero_grad()\n",
    "    pred = Mk4.forward(x_train.float()) #изменить название переменной\n",
    "    l = loss(pred, y_train) # squeeze the predicted tensor\n",
    "    l.backward()\n",
    "    f1= f1_score(pred, y_train, task='binary')\n",
    "    acc=accuracy(pred, y_train, task='binary')\n",
    "    data={'Epoch':epoch,'loss':l.item(),'F1-score':f1.item(),'accuracy':acc.item()}\n",
    "    diagdf3 = pd.concat([diagdf3, pd.DataFrame(data, index=[epoch])], ignore_index=True) #изменить название переменной\n",
    "    optimizer.step()\n",
    "    print('Epoch: ', epoch+1, ', Loss: ', l.item(),'  f1-score:', f1.item(),\"  accuracy:\", acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagdf изменить название везде\n",
    "# построение графика loss\n",
    "plt.plot(diagdf3['Epoch'], diagdf3['loss'], label='loss')\n",
    "\n",
    "# построение графика F1-score\n",
    "plt.plot(diagdf3['Epoch'], diagdf3['F1-score'], label='F1-score')\n",
    "\n",
    "# построение графика accuracy\n",
    "plt.plot(diagdf3['Epoch'], diagdf3['accuracy'], label='accuracy')\n",
    "\n",
    "# добавление заголовка графика\n",
    "plt.title('Графики loss, F1-score и accuracy')\n",
    "\n",
    "# добавление подписей к осям\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Значение')\n",
    "\n",
    "# добавление легенды\n",
    "plt.legend()\n",
    "\n",
    "# отображение графика\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test4=Mk4.forward(x_test.float())\n",
    "pred_test_binarized4 = (pred_test4 > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.to('cpu'), pred_test_binarized4.to('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Word2Vec_MLP_Experiment_#5</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>layers: -1, activation functions: Sigmoid() and Tanh(), epochs: 2000, hidden_size: 200, lr: 0.0001 -> 0.001</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# nn.Linear() можно указать точные значения для \"input_size, hidden_size\"\n",
    "# вместо nn.ReLU() можно посмотреть Sigmoid, tangensoid, etc.\n",
    "# попробовать добавить еще Layers (fc3, fc4, etc.)\n",
    "class MLP_MK5(nn.Module): #изменить название\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP_MK5, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size) #если добавлять или изменять, то не забыть поменять название\n",
    "        self.tanh1 = nn.Tanh()\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x) #если добавлять или изменять, то не забыть поменять название\n",
    "        out = self.sigmoid1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.tanh1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk5=MLP_MK5(1000,200,1) #изменить название переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    dev = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     dev=torch.device('cuda:0')\n",
    "# else: dev=torch.device('cpu:0')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.to(dev)\n",
    "x_test=x_test.to(dev)\n",
    "y_train=y_train.to(dev)\n",
    "y_test=y_test.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk5=Mk5.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"lr\" - learning rate (чем больше \"epoch\", тем меньше \"lr\")\n",
    "optimizer = torch.optim.Adam(Mk5.parameters(), lr=0.001) #изменить название переменной\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "f1_score = torchmetrics.functional.f1_score\n",
    "accuracy = torchmetrics.functional.accuracy\n",
    "diagdf4=pd.DataFrame(columns=['Epoch','loss','F1-score','accuracy']) #изменить название переменной\n",
    "# можно изменить количество \"epoch\"\n",
    "for epoch in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    pred = Mk5.forward(x_train.float()) #изменить название переменной\n",
    "    l = loss(pred, y_train) # squeeze the predicted tensor\n",
    "    l.backward()\n",
    "    f1= f1_score(pred, y_train, task='binary')\n",
    "    acc=accuracy(pred, y_train, task='binary')\n",
    "    data={'Epoch':epoch,'loss':l.item(),'F1-score':f1.item(),'accuracy':acc.item()}\n",
    "    diagdf4 = pd.concat([diagdf4, pd.DataFrame(data, index=[epoch])], ignore_index=True) #изменить название переменной\n",
    "    optimizer.step()\n",
    "    print('Epoch: ', epoch+1, ', Loss: ', l.item(),'  f1-score:', f1.item(),\"  accuracy:\", acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagdf изменить название везде\n",
    "# построение графика loss\n",
    "plt.plot(diagdf4['Epoch'], diagdf4['loss'], label='loss')\n",
    "\n",
    "# построение графика F1-score\n",
    "plt.plot(diagdf4['Epoch'], diagdf4['F1-score'], label='F1-score')\n",
    "\n",
    "# построение графика accuracy\n",
    "plt.plot(diagdf4['Epoch'], diagdf4['accuracy'], label='accuracy')\n",
    "\n",
    "# добавление заголовка графика\n",
    "plt.title('Графики loss, F1-score и accuracy')\n",
    "\n",
    "# добавление подписей к осям\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Значение')\n",
    "\n",
    "# добавление легенды\n",
    "plt.legend()\n",
    "\n",
    "# отображение графика\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test5=Mk5.forward(x_test.float())\n",
    "pred_test_binarized5 = (pred_test5 > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.to('cpu'), pred_test_binarized5.to('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Word2Vec_MLP_Experiment_#6</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>layer + 1, epochs: 2000 -> 10000, lr: 0.0001 -> 0.001, hidden_size: 200 -> 300</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# nn.Linear() можно указать точные значения для \"input_size, hidden_size\"\n",
    "# вместо nn.ReLU() можно посмотреть Sigmoid, tangensoid, etc.\n",
    "# попробовать добавить еще Layers (fc3, fc4, etc.)\n",
    "class MLP_MK6(nn.Module): #изменить название\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP_MK6, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size) #если добавлять или изменять, то не забыть поменять название\n",
    "        self.tanh = nn.Tanh()\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x) #если добавлять или изменять, то не забыть поменять название\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.tanh(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk6=MLP_MK6(1000,300,1) #изменить название переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    dev = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     dev=torch.device('cuda:0')\n",
    "# else: dev=torch.device('cpu:0')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.to(dev)\n",
    "x_test=x_test.to(dev)\n",
    "y_train=y_train.to(dev)\n",
    "y_test=y_test.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk6=Mk6.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"lr\" - learning rate (чем больше \"epoch\", тем меньше \"lr\")\n",
    "optimizer = torch.optim.Adam(Mk6.parameters(), lr=0.001) #изменить название переменной\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "f1_score = torchmetrics.functional.f1_score\n",
    "accuracy = torchmetrics.functional.accuracy\n",
    "diagdf5=pd.DataFrame(columns=['Epoch','loss','F1-score','accuracy']) #изменить название переменной\n",
    "# можно изменить количество \"epoch\"\n",
    "for epoch in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    pred = Mk6.forward(x_train.float()) #изменить название переменной\n",
    "    l = loss(pred, y_train) # squeeze the predicted tensor\n",
    "    l.backward()\n",
    "    f1= f1_score(pred, y_train, task='binary')\n",
    "    acc=accuracy(pred, y_train, task='binary')\n",
    "    data={'Epoch':epoch,'loss':l.item(),'F1-score':f1.item(),'accuracy':acc.item()}\n",
    "    diagdf5 = pd.concat([diagdf5, pd.DataFrame(data, index=[epoch])], ignore_index=True) #изменить название переменной\n",
    "    optimizer.step()\n",
    "    print('Epoch: ', epoch+1, ', Loss: ', l.item(),'  f1-score:', f1.item(),\"  accuracy:\", acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagdf изменить название везде\n",
    "# построение графика loss\n",
    "plt.plot(diagdf5['Epoch'], diagdf5['loss'], label='loss')\n",
    "\n",
    "# построение графика F1-score\n",
    "plt.plot(diagdf5['Epoch'], diagdf5['F1-score'], label='F1-score')\n",
    "\n",
    "# построение графика accuracy\n",
    "plt.plot(diagdf5['Epoch'], diagdf5['accuracy'], label='accuracy')\n",
    "\n",
    "# добавление заголовка графика\n",
    "plt.title('Графики loss, F1-score и accuracy')\n",
    "\n",
    "# добавление подписей к осям\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Значение')\n",
    "\n",
    "# добавление легенды\n",
    "plt.legend()\n",
    "\n",
    "# отображение графика\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test6=Mk6.forward(x_test.float())\n",
    "pred_test_binarized6 = (pred_test6 > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.to('cpu'), pred_test_binarized6.to('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Word2Vec_MLP_Experiment_#7</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>layers - 2, epochs: 10000, lr: 0.001</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# nn.Linear() можно указать точные значения для \"input_size, hidden_size\"\n",
    "# вместо nn.ReLU() можно посмотреть Sigmoid, tangensoid, etc.\n",
    "# попробовать добавить еще Layers (fc3, fc4, etc.)\n",
    "class MLP_MK7(nn.Module): #изменить название\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MLP_MK7, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, output_size)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "#         self.fc3 = nn.Linear(hidden_size, output_size) #если добавлять или изменять, то не забыть поменять название\n",
    "#         self.tanh = nn.Tanh()\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x) #если добавлять или изменять, то не забыть поменять название\n",
    "#         out = self.relu(out)\n",
    "#         out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "#         out = self.fc3(out)\n",
    "#         out = self.tanh(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk7=MLP_MK7(1000,1) #изменить название переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    dev = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     dev=torch.device('cuda:0')\n",
    "# else: dev=torch.device('cpu:0')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.to(dev)\n",
    "x_test=x_test.to(dev)\n",
    "y_train=y_train.to(dev)\n",
    "y_test=y_test.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk7=Mk7.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"lr\" - learning rate (чем больше \"epoch\", тем меньше \"lr\")\n",
    "optimizer = torch.optim.Adam(Mk7.parameters(), lr=0.001) #изменить название переменной\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "f1_score = torchmetrics.functional.f1_score\n",
    "accuracy = torchmetrics.functional.accuracy\n",
    "diagdf6=pd.DataFrame(columns=['Epoch','loss','F1-score','accuracy']) #изменить название переменной\n",
    "# можно изменить количество \"epoch\"\n",
    "for epoch in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    pred = Mk7.forward(x_train.float()) #изменить название переменной\n",
    "    l = loss(pred, y_train) # squeeze the predicted tensor\n",
    "    l.backward()\n",
    "    f1= f1_score(pred, y_train, task='binary')\n",
    "    acc=accuracy(pred, y_train, task='binary')\n",
    "    data={'Epoch':epoch,'loss':l.item(),'F1-score':f1.item(),'accuracy':acc.item()}\n",
    "    diagdf6 = pd.concat([diagdf6, pd.DataFrame(data, index=[epoch])], ignore_index=True) #изменить название переменной\n",
    "    optimizer.step()\n",
    "    print('Epoch: ', epoch+1, ', Loss: ', l.item(),'  f1-score:', f1.item(),\"  accuracy:\", acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagdf изменить название везде\n",
    "# построение графика loss\n",
    "plt.plot(diagdf6['Epoch'], diagdf6['loss'], label='loss')\n",
    "\n",
    "# построение графика F1-score\n",
    "plt.plot(diagdf6['Epoch'], diagdf6['F1-score'], label='F1-score')\n",
    "\n",
    "# построение графика accuracy\n",
    "plt.plot(diagdf6['Epoch'], diagdf6['accuracy'], label='accuracy')\n",
    "\n",
    "# добавление заголовка графика\n",
    "plt.title('Графики loss, F1-score и accuracy')\n",
    "\n",
    "# добавление подписей к осям\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Значение')\n",
    "\n",
    "# добавление легенды\n",
    "plt.legend()\n",
    "\n",
    "# отображение графика\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test7=Mk7.forward(x_test.float())\n",
    "pred_test_binarized7 = (pred_test7 > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.to('cpu'), pred_test_binarized7.to('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Word2Vec_MLP_Experiment_#8</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>layers: 1, epochs: 20000, lr: 0.001 -> 0.0001</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# nn.Linear() можно указать точные значения для \"input_size, hidden_size\"\n",
    "# вместо nn.ReLU() можно посмотреть Sigmoid, tangensoid, etc.\n",
    "# попробовать добавить еще Layers (fc3, fc4, etc.)\n",
    "class MLP_MK8(nn.Module): #изменить название\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MLP_MK8, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, output_size)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "#         self.fc3 = nn.Linear(hidden_size, output_size) #если добавлять или изменять, то не забыть поменять название\n",
    "#         self.tanh = nn.Tanh()\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x) #если добавлять или изменять, то не забыть поменять название\n",
    "#         out = self.relu(out)\n",
    "#         out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "#         out = self.fc3(out)\n",
    "#         out = self.tanh(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk8=MLP_MK8(1000,1) #изменить название переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    dev = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     dev=torch.device('cuda:0')\n",
    "# else: dev=torch.device('cpu:0')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.to(dev)\n",
    "x_test=x_test.to(dev)\n",
    "y_train=y_train.to(dev)\n",
    "y_test=y_test.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk8=Mk8.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"lr\" - learning rate (чем больше \"epoch\", тем меньше \"lr\")\n",
    "optimizer = torch.optim.Adam(Mk8.parameters(), lr=0.0001) #изменить название переменной\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "f1_score = torchmetrics.functional.f1_score\n",
    "accuracy = torchmetrics.functional.accuracy\n",
    "diagdf7=pd.DataFrame(columns=['Epoch','loss','F1-score','accuracy']) #изменить название переменной\n",
    "# можно изменить количество \"epoch\"\n",
    "for epoch in range(20000):\n",
    "    optimizer.zero_grad()\n",
    "    pred = Mk8.forward(x_train.float()) #изменить название переменной\n",
    "    l = loss(pred, y_train) # squeeze the predicted tensor\n",
    "    l.backward()\n",
    "    f1= f1_score(pred, y_train, task='binary')\n",
    "    acc=accuracy(pred, y_train, task='binary')\n",
    "    data={'Epoch':epoch,'loss':l.item(),'F1-score':f1.item(),'accuracy':acc.item()}\n",
    "    diagdf7 = pd.concat([diagdf7, pd.DataFrame(data, index=[epoch])], ignore_index=True) #изменить название переменной\n",
    "    optimizer.step()\n",
    "    print('Epoch: ', epoch+1, ', Loss: ', l.item(),'  f1-score:', f1.item(),\"  accuracy:\", acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagdf изменить название везде\n",
    "# построение графика loss\n",
    "plt.plot(diagdf7['Epoch'], diagdf7['loss'], label='loss')\n",
    "\n",
    "# построение графика F1-score\n",
    "plt.plot(diagdf7['Epoch'], diagdf7['F1-score'], label='F1-score')\n",
    "\n",
    "# построение графика accuracy\n",
    "plt.plot(diagdf7['Epoch'], diagdf7['accuracy'], label='accuracy')\n",
    "\n",
    "# добавление заголовка графика\n",
    "plt.title('Графики loss, F1-score и accuracy')\n",
    "\n",
    "# добавление подписей к осям\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Значение')\n",
    "\n",
    "# добавление легенды\n",
    "plt.legend()\n",
    "\n",
    "# отображение графика\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test8=Mk8.forward(x_test.float())\n",
    "pred_test_binarized8 = (pred_test8 > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.to('cpu'), pred_test_binarized8.to('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Word2Vec_MLP_Experiment_#9</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>layers: 1, epochs: 20000, lr: 0.0001 -> 0.001</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# nn.Linear() можно указать точные значения для \"input_size, hidden_size\"\n",
    "# вместо nn.ReLU() можно посмотреть Sigmoid, tangensoid, etc.\n",
    "# попробовать добавить еще Layers (fc3, fc4, etc.)\n",
    "class MLP_MK9(nn.Module): #изменить название\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MLP_MK9, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, output_size)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "#         self.fc3 = nn.Linear(hidden_size, output_size) #если добавлять или изменять, то не забыть поменять название\n",
    "#         self.tanh = nn.Tanh()\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x) #если добавлять или изменять, то не забыть поменять название\n",
    "#         out = self.relu(out)\n",
    "#         out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "#         out = self.fc3(out)\n",
    "#         out = self.tanh(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk9=MLP_MK9(1000,1) #изменить название переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    dev = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     dev=torch.device('cuda:0')\n",
    "# else: dev=torch.device('cpu:0')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.to(dev)\n",
    "x_test=x_test.to(dev)\n",
    "y_train=y_train.to(dev)\n",
    "y_test=y_test.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk9=Mk9.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"lr\" - learning rate (чем больше \"epoch\", тем меньше \"lr\")\n",
    "optimizer = torch.optim.Adam(Mk9.parameters(), lr=0.001) #изменить название переменной\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "f1_score = torchmetrics.functional.f1_score\n",
    "accuracy = torchmetrics.functional.accuracy\n",
    "diagdf8=pd.DataFrame(columns=['Epoch','loss','F1-score','accuracy']) #изменить название переменной\n",
    "# можно изменить количество \"epoch\"\n",
    "for epoch in range(20000):\n",
    "    optimizer.zero_grad()\n",
    "    pred = Mk9.forward(x_train.float()) #изменить название переменной\n",
    "    l = loss(pred, y_train) # squeeze the predicted tensor\n",
    "    l.backward()\n",
    "    f1= f1_score(pred, y_train, task='binary')\n",
    "    acc=accuracy(pred, y_train, task='binary')\n",
    "    data={'Epoch':epoch,'loss':l.item(),'F1-score':f1.item(),'accuracy':acc.item()}\n",
    "    diagdf8 = pd.concat([diagdf8, pd.DataFrame(data, index=[epoch])], ignore_index=True) #изменить название переменной\n",
    "    optimizer.step()\n",
    "    print('Epoch: ', epoch+1, ', Loss: ', l.item(),'  f1-score:', f1.item(),\"  accuracy:\", acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagdf изменить название везде\n",
    "# построение графика loss\n",
    "plt.plot(diagdf8['Epoch'], diagdf8['loss'], label='loss')\n",
    "\n",
    "# построение графика F1-score\n",
    "plt.plot(diagdf8['Epoch'], diagdf8['F1-score'], label='F1-score')\n",
    "\n",
    "# построение графика accuracy\n",
    "plt.plot(diagdf8['Epoch'], diagdf8['accuracy'], label='accuracy')\n",
    "\n",
    "# добавление заголовка графика\n",
    "plt.title('Графики loss, F1-score и accuracy')\n",
    "\n",
    "# добавление подписей к осям\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Значение')\n",
    "\n",
    "# добавление легенды\n",
    "plt.legend()\n",
    "\n",
    "# отображение графика\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test9=Mk9.forward(x_test.float())\n",
    "pred_test_binarized9 = (pred_test9 > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.to('cpu'), pred_test_binarized9.to('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Word2Vec_MLP_Experiment_#10</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>layers: 1+3, epochs: 10000, lr: 0.0001</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# nn.Linear() можно указать точные значения для \"input_size, hidden_size\"\n",
    "# вместо nn.ReLU() можно посмотреть Sigmoid, tangensoid, etc.\n",
    "# попробовать добавить еще Layers (fc3, fc4, etc.)\n",
    "class MLP_MK10(nn.Module): #изменить название\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP_MK10, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, 200)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc3 = nn.Linear(200, 100) #если добавлять или изменять, то не забыть поменять название\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.fc4 = nn.Linear(100, output_size) #если добавлять или изменять, то не забыть поменять название\n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x) #если добавлять или изменять, то не забыть поменять название\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.sigmoid1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk10=MLP_MK10(1000,300,1) #изменить название переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    dev = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     dev=torch.device('cuda:0')\n",
    "# else: dev=torch.device('cpu:0')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.to(dev)\n",
    "x_test=x_test.to(dev)\n",
    "y_train=y_train.to(dev)\n",
    "y_test=y_test.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk10=Mk10.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"lr\" - learning rate (чем больше \"epoch\", тем меньше \"lr\")\n",
    "optimizer = torch.optim.Adam(Mk10.parameters(), lr=0.0001) #изменить название переменной\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "f1_score = torchmetrics.functional.f1_score\n",
    "accuracy = torchmetrics.functional.accuracy\n",
    "diagdf9=pd.DataFrame(columns=['Epoch','loss','F1-score','accuracy']) #изменить название переменной\n",
    "# можно изменить количество \"epoch\"\n",
    "for epoch in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    pred = Mk10.forward(x_train.float()) #изменить название переменной\n",
    "    l = loss(pred, y_train) # squeeze the predicted tensor\n",
    "    l.backward()\n",
    "    f1= f1_score(pred, y_train, task='binary')\n",
    "    acc=accuracy(pred, y_train, task='binary')\n",
    "    data={'Epoch':epoch,'loss':l.item(),'F1-score':f1.item(),'accuracy':acc.item()}\n",
    "    diagdf9 = pd.concat([diagdf9, pd.DataFrame(data, index=[epoch])], ignore_index=True) #изменить название переменной\n",
    "    optimizer.step()\n",
    "    print('Epoch: ', epoch+1, ', Loss: ', l.item(),'  f1-score:', f1.item(),\"  accuracy:\", acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagdf изменить название везде\n",
    "# построение графика loss\n",
    "plt.plot(diagdf9['Epoch'], diagdf9['loss'], label='loss')\n",
    "\n",
    "# построение графика F1-score\n",
    "plt.plot(diagdf9['Epoch'], diagdf9['F1-score'], label='F1-score')\n",
    "\n",
    "# построение графика accuracy\n",
    "plt.plot(diagdf9['Epoch'], diagdf9['accuracy'], label='accuracy')\n",
    "\n",
    "# добавление заголовка графика\n",
    "plt.title('Графики loss, F1-score и accuracy')\n",
    "\n",
    "# добавление подписей к осям\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Значение')\n",
    "\n",
    "# добавление легенды\n",
    "plt.legend()\n",
    "\n",
    "# отображение графика\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test10=Mk10.forward(x_test.float())\n",
    "pred_test_binarized10 = (pred_test10 > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.to('cpu'), pred_test_binarized10.to('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
