{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qZWi2EEQW80d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import sklearn\n",
    "import torchmetrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1MV3_19KY_wN"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('main_dataset.csv',  encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "T-Y-10uCZIwm",
    "outputId": "5c31d972-8598-431c-d766-bc0baab289f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>на работе был полный пиддес :| и так каждое за...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Коллеги сидят рубятся в Urban terror, а я из-з...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@elina_4post как говорят обещаного три года жд...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Желаю хорошего полёта и удачной посадки,я буду...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Обновил за каким-то лешим surf, теперь не рабо...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  label\n",
       "0   1  на работе был полный пиддес :| и так каждое за...    0.0\n",
       "1   2  Коллеги сидят рубятся в Urban terror, а я из-з...    1.0\n",
       "2   3  @elina_4post как говорят обещаного три года жд...    0.0\n",
       "3   4  Желаю хорошего полёта и удачной посадки,я буду...    0.0\n",
       "4   5  Обновил за каким-то лешим surf, теперь не рабо...    0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jonptviKZMYi",
    "outputId": "555f9ba9-b590-4213-876a-f11609d6a788"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "k7tjF34Ka1W4",
    "outputId": "b0aa29ee-a3f1-4417-ffb1-be61da20efc5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>на работе был полный пиддес :| и так каждое за...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Коллеги сидят рубятся в Urban terror, а я из-з...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@elina_4post как говорят обещаного три года жд...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Желаю хорошего полёта и удачной посадки,я буду...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Обновил за каким-то лешим surf, теперь не рабо...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  label\n",
       "0   1  на работе был полный пиддес :| и так каждое за...    0.0\n",
       "1   2  Коллеги сидят рубятся в Urban terror, а я из-з...    1.0\n",
       "2   3  @elina_4post как говорят обещаного три года жд...    0.0\n",
       "3   4  Желаю хорошего полёта и удачной посадки,я буду...    0.0\n",
       "4   5  Обновил за каким-то лешим surf, теперь не рабо...    0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "FLFjjgTOctwh",
    "outputId": "b3d84997-b104-4bc3-de39-1a8d27e63d28"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15870</th>\n",
       "      <td>15871</td>\n",
       "      <td>Вонючий совковый скот прибежал и ноет. А вот и...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15871</th>\n",
       "      <td>15872</td>\n",
       "      <td>А кого любить? Гоблина тупорылого что-ли? Или ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15872</th>\n",
       "      <td>15873</td>\n",
       "      <td>Посмотрел Утомленных солнцем 2. И оказалось, ч...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15873</th>\n",
       "      <td>15874</td>\n",
       "      <td>КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15874</th>\n",
       "      <td>15875</td>\n",
       "      <td>До сих пор пересматриваю его видео. Орамбо кст...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  label\n",
       "15870  15871  Вонючий совковый скот прибежал и ноет. А вот и...    1.0\n",
       "15871  15872  А кого любить? Гоблина тупорылого что-ли? Или ...    1.0\n",
       "15872  15873  Посмотрел Утомленных солнцем 2. И оказалось, ч...    0.0\n",
       "15873  15874  КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...    1.0\n",
       "15874  15875  До сих пор пересматриваю его видео. Орамбо кст...    0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqgRumQGcxxc",
    "outputId": "0e13df21-081b-4d8f-e3cf-4466e09868ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.unique of 0        на работе был полный пиддес :| и так каждое за...\n",
       "1        Коллеги сидят рубятся в Urban terror, а я из-з...\n",
       "2        @elina_4post как говорят обещаного три года жд...\n",
       "3        Желаю хорошего полёта и удачной посадки,я буду...\n",
       "4        Обновил за каким-то лешим surf, теперь не рабо...\n",
       "                               ...                        \n",
       "15870    Вонючий совковый скот прибежал и ноет. А вот и...\n",
       "15871    А кого любить? Гоблина тупорылого что-ли? Или ...\n",
       "15872    Посмотрел Утомленных солнцем 2. И оказалось, ч...\n",
       "15873    КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...\n",
       "15874    До сих пор пересматриваю его видео. Орамбо кст...\n",
       "Name: text, Length: 15875, dtype: object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xurlS8Nyem67"
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0Ue-PVWce0oq",
    "outputId": "29a5c55f-7dae-4070-fbd2-fe87bca122e3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>на работе был полный пиддес :| и так каждое за...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Коллеги сидят рубятся в Urban terror, а я из-з...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@elina_4post как говорят обещаного три года жд...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Желаю хорошего полёта и удачной посадки,я буду...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Обновил за каким-то лешим surf, теперь не рабо...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  label\n",
       "0   1  на работе был полный пиддес :| и так каждое за...    0.0\n",
       "1   2  Коллеги сидят рубятся в Urban terror, а я из-з...    1.0\n",
       "2   3  @elina_4post как говорят обещаного три года жд...    0.0\n",
       "3   4  Желаю хорошего полёта и удачной посадки,я буду...    0.0\n",
       "4   5  Обновил за каким-то лешим surf, теперь не рабо...    0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KajWFhWfjSrS",
    "outputId": "a77a8e01-a9c2-4906-f658-bfd81cdb72d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15875 entries, 0 to 15874\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   id      15875 non-null  int64  \n",
      " 1   text    15875 non-null  object \n",
      " 2   label   15875 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 372.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z6btZkkLhj4g",
    "outputId": "26c3afb4-b4db-465b-fa91-84399a400f76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gKdBA2ZSh2rf",
    "outputId": "f953110b-0a31-4ac7-c4d6-b6fbf7bb1973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UyZYKVAblLzQ",
    "outputId": "bc847523-c603-4581-ebb9-812aa192090e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>    15875\n",
      "Name: text, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['text'].apply(type).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8zfy03Wkg5g",
    "outputId": "24dd6a3b-69b5-47f5-8a11-82f6f28e666b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stop-words in c:\\users\\admin\\anaconda3\\envs\\op11\\lib\\site-packages (2018.7.23)\n"
     ]
    }
   ],
   "source": [
    "!pip install stop-words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Ok_7iVJdgbpA"
   },
   "outputs": [],
   "source": [
    "import stop_words\n",
    "#stop_words_russian = set(stopwords.words('russian'))\n",
    "stop_words_russian = stop_words.get_stop_words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "9XQeumC_i2n5"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convert non-string values to empty string\n",
    "df['text'] = df['text'].apply(lambda x: str(x) if type(x) != str else x)\n",
    "\n",
    "# Remove stop words from the text column\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words_russian]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "NtCVVMqdlqHV",
    "outputId": "ca05e8d0-9d9f-4b6b-d81f-b5e2a2424396"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>работе полный пиддес :| закрытие месяца, свихн...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Коллеги сидят рубятся Urban terror, из-за долб...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@elina_4post говорят обещаного ждут...((</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Желаю хорошего полёта удачной посадки,я сильно...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Обновил каким-то лешим surf, работает простопл...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  label\n",
       "0   1  работе полный пиддес :| закрытие месяца, свихн...    0.0\n",
       "1   2  Коллеги сидят рубятся Urban terror, из-за долб...    1.0\n",
       "2   3           @elina_4post говорят обещаного ждут...((    0.0\n",
       "3   4  Желаю хорошего полёта удачной посадки,я сильно...    0.0\n",
       "4   5  Обновил каким-то лешим surf, работает простопл...    0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ZDbuLqrhmgTY"
   },
   "outputs": [],
   "source": [
    "# Define a function to convert text to lowercase\n",
    "def convert_to_lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "# Apply the function to the 'text' column of the DataFrame\n",
    "df['text'] = df['text'].apply(convert_to_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "ZZi5-nyOnUGJ",
    "outputId": "f163d6fd-b301-4947-86c0-bcedd8778be5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>работе полный пиддес :| закрытие месяца, свихн...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>коллеги сидят рубятся urban terror, из-за долб...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@elina_4post говорят обещаного ждут...((</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>желаю хорошего полёта удачной посадки,я сильно...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>обновил каким-то лешим surf, работает простопл...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>котёнка вчера носик разбила, плакала расстраив...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>@juliamayko @o_nika55 @and_possum зашли, затих...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>вообще болею - выздоравливаю :(</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>микрофраза :( учимся срать кирпичами режиме &amp;a...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>хочу помириться , сука гордая сделаю! (((</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>@dno_okeana_a3a3 @moe_mope_a3a3 ебет какие фот...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>блин начали сниться сны( снились ! ! нравиться...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>@realvold твоем месте, телек купил бы(</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>@faraonbgr111 плохо боишься значит(( где? мск ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>хотела... электромобиль =( http://t.co/vgs9jeuphz</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               text  label\n",
       "0    1  работе полный пиддес :| закрытие месяца, свихн...    0.0\n",
       "1    2  коллеги сидят рубятся urban terror, из-за долб...    1.0\n",
       "2    3           @elina_4post говорят обещаного ждут...((    0.0\n",
       "3    4  желаю хорошего полёта удачной посадки,я сильно...    0.0\n",
       "4    5  обновил каким-то лешим surf, работает простопл...    0.0\n",
       "5    6  котёнка вчера носик разбила, плакала расстраив...    0.0\n",
       "6    7  @juliamayko @o_nika55 @and_possum зашли, затих...    0.0\n",
       "7    8                    вообще болею - выздоравливаю :(    0.0\n",
       "8    9  микрофраза :( учимся срать кирпичами режиме &a...    1.0\n",
       "9   10          хочу помириться , сука гордая сделаю! (((    1.0\n",
       "10  11  @dno_okeana_a3a3 @moe_mope_a3a3 ебет какие фот...    1.0\n",
       "11  12  блин начали сниться сны( снились ! ! нравиться...    0.0\n",
       "12  13             @realvold твоем месте, телек купил бы(    0.0\n",
       "13  14  @faraonbgr111 плохо боишься значит(( где? мск ...    0.0\n",
       "14  15  хотела... электромобиль =( http://t.co/vgs9jeuphz    0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "DC3WwRAEnZf9"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "# Apply the function to the 'text' column of the DataFrame\n",
    "df['text'] = df['text'].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "k12lzCmhoR0p",
    "outputId": "e3fb299f-df45-4390-c668-39e02fc13730"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15855</th>\n",
       "      <td>15856</td>\n",
       "      <td>тасс, 21 марта. премьер-министр новой зеландии...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15856</th>\n",
       "      <td>15857</td>\n",
       "      <td>вой подсоса гомофорсера что, говно, неприятно ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15857</th>\n",
       "      <td>15858</td>\n",
       "      <td>шлюха. парад шлюх.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15858</th>\n",
       "      <td>15859</td>\n",
       "      <td>дебил-куколд значение знаешь?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15859</th>\n",
       "      <td>15860</td>\n",
       "      <td>хуею сосачеры, большиство прыщавые жиртресты р...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15860</th>\n",
       "      <td>15861</td>\n",
       "      <td>что-то появившееся небе пугает туристов расска...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15861</th>\n",
       "      <td>15862</td>\n",
       "      <td>моча анимаче решила окончательно убить реакшен...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15862</th>\n",
       "      <td>15863</td>\n",
       "      <td>65 мало? гражданина рейтинг 90 3 дня записи ви...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15863</th>\n",
       "      <td>15864</td>\n",
       "      <td>зря, вас, хохлов, свиньями кличут. грязные жив...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15864</th>\n",
       "      <td>15865</td>\n",
       "      <td>прямо сразу ватан бросился своему кредитному н...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15865</th>\n",
       "      <td>15866</td>\n",
       "      <td>эй михалыч, пожарка пищит хуй пущай пищит смор...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15866</th>\n",
       "      <td>15867</td>\n",
       "      <td>пусть евровидение стримит. долбоеб чтоли, посл...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15867</th>\n",
       "      <td>15868</td>\n",
       "      <td>женщина венец творения, помните ваньки! стоите...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15868</th>\n",
       "      <td>15869</td>\n",
       "      <td>авиакомпании вместе специалистами гугл карт см...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15869</th>\n",
       "      <td>15870</td>\n",
       "      <td>запад прошел хуйню пару сотен назад. большинст...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15870</th>\n",
       "      <td>15871</td>\n",
       "      <td>вонючий совковый скот прибежал ноет. сторонник...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15871</th>\n",
       "      <td>15872</td>\n",
       "      <td>любить? гоблина тупорылого что-ли? какую-нибуд...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15872</th>\n",
       "      <td>15873</td>\n",
       "      <td>посмотрел утомленных солнцем 2. оказалось, хор...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15873</th>\n",
       "      <td>15874</td>\n",
       "      <td>крымотред нарушает правила раздела т.к обсужде...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15874</th>\n",
       "      <td>15875</td>\n",
       "      <td>пересматриваю видео. орамбо кстати своем канал...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  label\n",
       "15855  15856  тасс, 21 марта. премьер-министр новой зеландии...    0.0\n",
       "15856  15857  вой подсоса гомофорсера что, говно, неприятно ...    1.0\n",
       "15857  15858                                 шлюха. парад шлюх.    1.0\n",
       "15858  15859                      дебил-куколд значение знаешь?    1.0\n",
       "15859  15860  хуею сосачеры, большиство прыщавые жиртресты р...    1.0\n",
       "15860  15861  что-то появившееся небе пугает туристов расска...    1.0\n",
       "15861  15862  моча анимаче решила окончательно убить реакшен...    1.0\n",
       "15862  15863  65 мало? гражданина рейтинг 90 3 дня записи ви...    0.0\n",
       "15863  15864  зря, вас, хохлов, свиньями кличут. грязные жив...    1.0\n",
       "15864  15865  прямо сразу ватан бросился своему кредитному н...    1.0\n",
       "15865  15866  эй михалыч, пожарка пищит хуй пущай пищит смор...    1.0\n",
       "15866  15867  пусть евровидение стримит. долбоеб чтоли, посл...    1.0\n",
       "15867  15868  женщина венец творения, помните ваньки! стоите...    1.0\n",
       "15868  15869  авиакомпании вместе специалистами гугл карт см...    1.0\n",
       "15869  15870  запад прошел хуйню пару сотен назад. большинст...    0.0\n",
       "15870  15871  вонючий совковый скот прибежал ноет. сторонник...    1.0\n",
       "15871  15872  любить? гоблина тупорылого что-ли? какую-нибуд...    1.0\n",
       "15872  15873  посмотрел утомленных солнцем 2. оказалось, хор...    0.0\n",
       "15873  15874  крымотред нарушает правила раздела т.к обсужде...    1.0\n",
       "15874  15875  пересматриваю видео. орамбо кстати своем канал...    0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "toSydxQHom5_"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define a function to remove punctuation and extra spaces from a text string\n",
    "def remove_punct_and_extra_space(text):\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove extra space\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Apply the function to the 'text' column of the DataFrame\n",
    "df['text'] = df['text'].apply(remove_punct_and_extra_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "JH_5I671pr1-",
    "outputId": "956c2fa3-8a34-46e0-fe36-8a3d451ff2af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15860</th>\n",
       "      <td>15861</td>\n",
       "      <td>чтото появившееся небе пугает туристов рассказ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15861</th>\n",
       "      <td>15862</td>\n",
       "      <td>моча анимаче решила окончательно убить реакшен...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15862</th>\n",
       "      <td>15863</td>\n",
       "      <td>65 мало гражданина рейтинг 90 3 дня записи видео</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15863</th>\n",
       "      <td>15864</td>\n",
       "      <td>зря вас хохлов свиньями кличут грязные животны...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15864</th>\n",
       "      <td>15865</td>\n",
       "      <td>прямо сразу ватан бросился своему кредитному н...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15865</th>\n",
       "      <td>15866</td>\n",
       "      <td>эй михалыч пожарка пищит хуй пущай пищит смори...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15866</th>\n",
       "      <td>15867</td>\n",
       "      <td>пусть евровидение стримит долбоеб чтоли послед...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15867</th>\n",
       "      <td>15868</td>\n",
       "      <td>женщина венец творения помните ваньки стоите ж...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15868</th>\n",
       "      <td>15869</td>\n",
       "      <td>авиакомпании вместе специалистами гугл карт см...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15869</th>\n",
       "      <td>15870</td>\n",
       "      <td>запад прошел хуйню пару сотен назад большинств...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15870</th>\n",
       "      <td>15871</td>\n",
       "      <td>вонючий совковый скот прибежал ноет сторонник ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15871</th>\n",
       "      <td>15872</td>\n",
       "      <td>любить гоблина тупорылого чтоли какуюнибудь пр...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15872</th>\n",
       "      <td>15873</td>\n",
       "      <td>посмотрел утомленных солнцем 2 оказалось хорош...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15873</th>\n",
       "      <td>15874</td>\n",
       "      <td>крымотред нарушает правила раздела тк обсужден...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15874</th>\n",
       "      <td>15875</td>\n",
       "      <td>пересматриваю видео орамбо кстати своем канале...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  label\n",
       "15860  15861  чтото появившееся небе пугает туристов рассказ...    1.0\n",
       "15861  15862  моча анимаче решила окончательно убить реакшен...    1.0\n",
       "15862  15863   65 мало гражданина рейтинг 90 3 дня записи видео    0.0\n",
       "15863  15864  зря вас хохлов свиньями кличут грязные животны...    1.0\n",
       "15864  15865  прямо сразу ватан бросился своему кредитному н...    1.0\n",
       "15865  15866  эй михалыч пожарка пищит хуй пущай пищит смори...    1.0\n",
       "15866  15867  пусть евровидение стримит долбоеб чтоли послед...    1.0\n",
       "15867  15868  женщина венец творения помните ваньки стоите ж...    1.0\n",
       "15868  15869  авиакомпании вместе специалистами гугл карт см...    1.0\n",
       "15869  15870  запад прошел хуйню пару сотен назад большинств...    0.0\n",
       "15870  15871  вонючий совковый скот прибежал ноет сторонник ...    1.0\n",
       "15871  15872  любить гоблина тупорылого чтоли какуюнибудь пр...    1.0\n",
       "15872  15873  посмотрел утомленных солнцем 2 оказалось хорош...    0.0\n",
       "15873  15874  крымотред нарушает правила раздела тк обсужден...    1.0\n",
       "15874  15875  пересматриваю видео орамбо кстати своем канале...    0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HtwTxCRpqQJN",
    "outputId": "7a9c5d07-207a-4044-e945-df79ba904f0c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "cL8BDio-sEUM"
   },
   "outputs": [],
   "source": [
    "# Tokenize the text in the 'text' column\n",
    "df['text_tokenized'] = df['text'].apply(lambda x: nltk.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "0wi9mtxrsKSm",
    "outputId": "1b0689cc-2bd2-4a68-9b28-08d58baacce8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15860</th>\n",
       "      <td>15861</td>\n",
       "      <td>чтото появившееся небе пугает туристов рассказ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[чтото, появившееся, небе, пугает, туристов, р...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15861</th>\n",
       "      <td>15862</td>\n",
       "      <td>моча анимаче решила окончательно убить реакшен...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[моча, анимаче, решила, окончательно, убить, р...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15862</th>\n",
       "      <td>15863</td>\n",
       "      <td>65 мало гражданина рейтинг 90 3 дня записи видео</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[65, мало, гражданина, рейтинг, 90, 3, дня, за...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15863</th>\n",
       "      <td>15864</td>\n",
       "      <td>зря вас хохлов свиньями кличут грязные животны...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[зря, вас, хохлов, свиньями, кличут, грязные, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15864</th>\n",
       "      <td>15865</td>\n",
       "      <td>прямо сразу ватан бросился своему кредитному н...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[прямо, сразу, ватан, бросился, своему, кредит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15865</th>\n",
       "      <td>15866</td>\n",
       "      <td>эй михалыч пожарка пищит хуй пущай пищит смори...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[эй, михалыч, пожарка, пищит, хуй, пущай, пищи...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15866</th>\n",
       "      <td>15867</td>\n",
       "      <td>пусть евровидение стримит долбоеб чтоли послед...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[пусть, евровидение, стримит, долбоеб, чтоли, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15867</th>\n",
       "      <td>15868</td>\n",
       "      <td>женщина венец творения помните ваньки стоите ж...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[женщина, венец, творения, помните, ваньки, ст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15868</th>\n",
       "      <td>15869</td>\n",
       "      <td>авиакомпании вместе специалистами гугл карт см...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[авиакомпании, вместе, специалистами, гугл, ка...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15869</th>\n",
       "      <td>15870</td>\n",
       "      <td>запад прошел хуйню пару сотен назад большинств...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[запад, прошел, хуйню, пару, сотен, назад, бол...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15870</th>\n",
       "      <td>15871</td>\n",
       "      <td>вонючий совковый скот прибежал ноет сторонник ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[вонючий, совковый, скот, прибежал, ноет, стор...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15871</th>\n",
       "      <td>15872</td>\n",
       "      <td>любить гоблина тупорылого чтоли какуюнибудь пр...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[любить, гоблина, тупорылого, чтоли, какуюнибу...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15872</th>\n",
       "      <td>15873</td>\n",
       "      <td>посмотрел утомленных солнцем 2 оказалось хорош...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[посмотрел, утомленных, солнцем, 2, оказалось,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15873</th>\n",
       "      <td>15874</td>\n",
       "      <td>крымотред нарушает правила раздела тк обсужден...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[крымотред, нарушает, правила, раздела, тк, об...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15874</th>\n",
       "      <td>15875</td>\n",
       "      <td>пересматриваю видео орамбо кстати своем канале...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[пересматриваю, видео, орамбо, кстати, своем, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  label  \\\n",
       "15860  15861  чтото появившееся небе пугает туристов рассказ...    1.0   \n",
       "15861  15862  моча анимаче решила окончательно убить реакшен...    1.0   \n",
       "15862  15863   65 мало гражданина рейтинг 90 3 дня записи видео    0.0   \n",
       "15863  15864  зря вас хохлов свиньями кличут грязные животны...    1.0   \n",
       "15864  15865  прямо сразу ватан бросился своему кредитному н...    1.0   \n",
       "15865  15866  эй михалыч пожарка пищит хуй пущай пищит смори...    1.0   \n",
       "15866  15867  пусть евровидение стримит долбоеб чтоли послед...    1.0   \n",
       "15867  15868  женщина венец творения помните ваньки стоите ж...    1.0   \n",
       "15868  15869  авиакомпании вместе специалистами гугл карт см...    1.0   \n",
       "15869  15870  запад прошел хуйню пару сотен назад большинств...    0.0   \n",
       "15870  15871  вонючий совковый скот прибежал ноет сторонник ...    1.0   \n",
       "15871  15872  любить гоблина тупорылого чтоли какуюнибудь пр...    1.0   \n",
       "15872  15873  посмотрел утомленных солнцем 2 оказалось хорош...    0.0   \n",
       "15873  15874  крымотред нарушает правила раздела тк обсужден...    1.0   \n",
       "15874  15875  пересматриваю видео орамбо кстати своем канале...    0.0   \n",
       "\n",
       "                                          text_tokenized  \n",
       "15860  [чтото, появившееся, небе, пугает, туристов, р...  \n",
       "15861  [моча, анимаче, решила, окончательно, убить, р...  \n",
       "15862  [65, мало, гражданина, рейтинг, 90, 3, дня, за...  \n",
       "15863  [зря, вас, хохлов, свиньями, кличут, грязные, ...  \n",
       "15864  [прямо, сразу, ватан, бросился, своему, кредит...  \n",
       "15865  [эй, михалыч, пожарка, пищит, хуй, пущай, пищи...  \n",
       "15866  [пусть, евровидение, стримит, долбоеб, чтоли, ...  \n",
       "15867  [женщина, венец, творения, помните, ваньки, ст...  \n",
       "15868  [авиакомпании, вместе, специалистами, гугл, ка...  \n",
       "15869  [запад, прошел, хуйню, пару, сотен, назад, бол...  \n",
       "15870  [вонючий, совковый, скот, прибежал, ноет, стор...  \n",
       "15871  [любить, гоблина, тупорылого, чтоли, какуюнибу...  \n",
       "15872  [посмотрел, утомленных, солнцем, 2, оказалось,...  \n",
       "15873  [крымотред, нарушает, правила, раздела, тк, об...  \n",
       "15874  [пересматриваю, видео, орамбо, кстати, своем, ...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in c:\\users\\admin\\anaconda3\\envs\\op11\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\admin\\anaconda3\\envs\\op11\\lib\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\admin\\anaconda3\\envs\\op11\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\admin\\anaconda3\\envs\\op11\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kt3GzSVsmN1O",
    "outputId": "b695a0e4-3780-4498-921e-0f67df9342e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [работа, полный, пиддес, закрытие, месяц, свих...\n",
       "1        [коллега, сидеть, рубиться, изз, долбать, винд...\n",
       "2                              [говорить, обещаной, ждать]\n",
       "3        [желать, хороший, полёт, удачный, посадкия, си...\n",
       "4        [обновить, какимтый, леший, работать, простопл...\n",
       "                               ...                        \n",
       "15870    [вонючий, совковый, скот, прибежать, ныть, сто...\n",
       "15871    [любить, гоблин, тупорылый, чтоль, какуюнибудь...\n",
       "15872    [посмотреть, утомлённый, солнце, оказаться, хо...\n",
       "15873    [крымотред, нарушать, правило, раздел, тк, обс...\n",
       "15874    [пересматривать, видео, орамбо, кстати, свой, ...\n",
       "Name: text, Length: 15875, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "patterns = \"[A-Za-z0-9!#$%&'()*+,./:;<=>?@[\\]^_`{|}~—\\\"\\-]+\"\n",
    "stopwords_ru = stopwords.words(\"russian\")\n",
    "morph = MorphAnalyzer()\n",
    "\n",
    "def lemmatize(doc):\n",
    "    doc = re.sub(patterns, ' ', doc)\n",
    "    tokens = []\n",
    "    for token in doc.split():\n",
    "        if token and token not in stopwords_ru:\n",
    "            token = token.strip()\n",
    "            token = morph.normal_forms(token)[0]\n",
    "            \n",
    "            tokens.append(token)\n",
    "    if len(tokens) >= 1:\n",
    "        return tokens\n",
    "    return None\n",
    "\n",
    "data = df.text.apply(lemmatize)\n",
    "#data = data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[работа, полный, пиддес, закрытие, месяц, свих...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[коллега, сидеть, рубиться, изз, долбать, винд...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[говорить, обещаной, ждать]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[желать, хороший, полёт, удачный, посадкия, си...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[обновить, какимтый, леший, работать, простопл...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15870</th>\n",
       "      <td>15871</td>\n",
       "      <td>[вонючий, совковый, скот, прибежать, ныть, сто...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15871</th>\n",
       "      <td>15872</td>\n",
       "      <td>[любить, гоблин, тупорылый, чтоль, какуюнибудь...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15872</th>\n",
       "      <td>15873</td>\n",
       "      <td>[посмотреть, утомлённый, солнце, оказаться, хо...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15873</th>\n",
       "      <td>15874</td>\n",
       "      <td>[крымотред, нарушать, правило, раздел, тк, обс...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15874</th>\n",
       "      <td>15875</td>\n",
       "      <td>[пересматривать, видео, орамбо, кстати, свой, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15858 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  label\n",
       "0          1  [работа, полный, пиддес, закрытие, месяц, свих...    0.0\n",
       "1          2  [коллега, сидеть, рубиться, изз, долбать, винд...    1.0\n",
       "2          3                        [говорить, обещаной, ждать]    0.0\n",
       "3          4  [желать, хороший, полёт, удачный, посадкия, си...    0.0\n",
       "4          5  [обновить, какимтый, леший, работать, простопл...    0.0\n",
       "...      ...                                                ...    ...\n",
       "15870  15871  [вонючий, совковый, скот, прибежать, ныть, сто...    1.0\n",
       "15871  15872  [любить, гоблин, тупорылый, чтоль, какуюнибудь...    1.0\n",
       "15872  15873  [посмотреть, утомлённый, солнце, оказаться, хо...    0.0\n",
       "15873  15874  [крымотред, нарушать, правило, раздел, тк, обс...    1.0\n",
       "15874  15875  [пересматривать, видео, орамбо, кстати, свой, ...    0.0\n",
       "\n",
       "[15858 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.DataFrame(columns=['id','text','label'])\n",
    "df3['text']=data\n",
    "df3['id']=df['id']\n",
    "df3['label']=df['label']\n",
    "df3=df3.dropna()\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('C:/Users/Admin/Documents/pythonNLP/word2vecmod/65/model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(word):\n",
    "    if word in model.key_to_index:\n",
    "        return model[word]\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# функция для получения среднего вектора всех слов в тексте\n",
    "def get_average_vector(text):\n",
    "    vectors = [get_vector(word) for word in text]\n",
    "    if len(vectors) > 0:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(word_vectors.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df3, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_train = [get_average_vector(text) for text in train_df['text']]\n",
    "vectors_test = [get_average_vector(text) for text in test_df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(vectors_train)\n",
    "x_test = torch.tensor(vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_list=list()\n",
    "for i in train_df['label']:\n",
    "    y_train_list.append(i)\n",
    "y_train=torch.tensor(y_train_list)\n",
    "y_train.unsqueeze_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_list=list()\n",
    "for i in test_df['label']:\n",
    "    y_test_list.append(i)\n",
    "y_test=torch.tensor(y_test_list)\n",
    "y_test.unsqueeze_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk1=MLP(100,300,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    dev = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev=torch.device('cuda:0')\n",
    "else: dev=torch.device('cpu:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.to(dev)\n",
    "x_test=x_test.to(dev)\n",
    "y_train=y_train.to(dev)\n",
    "y_test=y_test.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mk1=Mk1.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 , Loss:  0.8100041747093201   f1-score: 0.5077030062675476   accuracy: 0.42711710929870605\n",
      "Epoch:  2 , Loss:  0.8040925860404968   f1-score: 0.1392373889684677   accuracy: 0.6847747564315796\n",
      "Epoch:  3 , Loss:  0.7982625961303711   f1-score: 0.0005451076431199908   accuracy: 0.6696396470069885\n",
      "Epoch:  4 , Loss:  0.7924745082855225   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  5 , Loss:  0.7866997718811035   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  6 , Loss:  0.7809126973152161   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  7 , Loss:  0.7751019597053528   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  8 , Loss:  0.7692704796791077   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  9 , Loss:  0.7634300589561462   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  10 , Loss:  0.7576064467430115   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  11 , Loss:  0.7518355846405029   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  12 , Loss:  0.7461650371551514   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  13 , Loss:  0.740648090839386   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  14 , Loss:  0.7353396415710449   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  15 , Loss:  0.7302948832511902   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  16 , Loss:  0.725562572479248   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  17 , Loss:  0.7211843132972717   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  18 , Loss:  0.7171916961669922   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  19 , Loss:  0.7135995030403137   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  20 , Loss:  0.7104110717773438   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  21 , Loss:  0.7076172232627869   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  22 , Loss:  0.7051984071731567   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  23 , Loss:  0.7031266689300537   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  24 , Loss:  0.7013693451881409   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  25 , Loss:  0.6998910903930664   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  26 , Loss:  0.6986555457115173   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  27 , Loss:  0.697628378868103   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  28 , Loss:  0.6967776417732239   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  29 , Loss:  0.6960746049880981   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  30 , Loss:  0.6954941749572754   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  31 , Loss:  0.6950151324272156   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  32 , Loss:  0.6946190595626831   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  33 , Loss:  0.6942909359931946   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  34 , Loss:  0.6940180659294128   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  35 , Loss:  0.693790078163147   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  36 , Loss:  0.6935985088348389   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  37 , Loss:  0.6934364438056946   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  38 , Loss:  0.6932982206344604   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  39 , Loss:  0.6931793689727783   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  40 , Loss:  0.6930760741233826   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  41 , Loss:  0.6929854154586792   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  42 , Loss:  0.6929048299789429   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  43 , Loss:  0.6928322911262512   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  44 , Loss:  0.6927660703659058   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  45 , Loss:  0.6927045583724976   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  46 , Loss:  0.6926466226577759   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  47 , Loss:  0.6925911903381348   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  48 , Loss:  0.692537248134613   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  49 , Loss:  0.6924840211868286   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  50 , Loss:  0.6924304962158203   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  51 , Loss:  0.6923759579658508   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  52 , Loss:  0.6923196315765381   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  53 , Loss:  0.6922608017921448   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  54 , Loss:  0.6921985745429993   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  55 , Loss:  0.6921323537826538   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  56 , Loss:  0.692061185836792   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  57 , Loss:  0.6919841170310974   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  58 , Loss:  0.6919001340866089   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  59 , Loss:  0.6918080449104309   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  60 , Loss:  0.6917063593864441   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  61 , Loss:  0.6915934681892395   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  62 , Loss:  0.6914675235748291   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  63 , Loss:  0.6913259625434875   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  64 , Loss:  0.6911661028862   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  65 , Loss:  0.690984845161438   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  66 , Loss:  0.6907781958580017   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  67 , Loss:  0.6905414462089539   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  68 , Loss:  0.6902691125869751   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  69 , Loss:  0.6899545788764954   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  70 , Loss:  0.6895900964736938   f1-score: 0.0   accuracy: 0.6696396470069885\n",
      "Epoch:  71 , Loss:  0.6891669631004333   f1-score: 0.0016348774079233408   accuracy: 0.6699098944664001\n",
      "Epoch:  72 , Loss:  0.688674807548523   f1-score: 0.003267084015533328   accuracy: 0.6701802015304565\n",
      "Epoch:  73 , Loss:  0.6881023049354553   f1-score: 0.004353741649538279   accuracy: 0.6703603863716125\n",
      "Epoch:  74 , Loss:  0.6874371767044067   f1-score: 0.004896626807749271   accuracy: 0.6704504489898682\n",
      "Epoch:  75 , Loss:  0.6866668462753296   f1-score: 0.00814774539321661   accuracy: 0.6709910035133362\n",
      "Epoch:  76 , Loss:  0.6857793927192688   f1-score: 0.010845987126231194   accuracy: 0.6713513731956482\n",
      "Epoch:  77 , Loss:  0.684765100479126   f1-score: 0.019417475908994675   accuracy: 0.6724324226379395\n",
      "Epoch:  78 , Loss:  0.6836190819740295   f1-score: 0.031099196523427963   accuracy: 0.6744143962860107\n",
      "Epoch:  79 , Loss:  0.6823433041572571   f1-score: 0.04989384114742279   accuracy: 0.6774774789810181\n",
      "Epoch:  80 , Loss:  0.6809497475624084   f1-score: 0.07236497104167938   accuracy: 0.6812612414360046\n",
      "Epoch:  81 , Loss:  0.6794648766517639   f1-score: 0.10064516216516495   accuracy: 0.6860360503196716\n",
      "Epoch:  82 , Loss:  0.6779279708862305   f1-score: 0.14022698998451233   accuracy: 0.6928828954696655\n",
      "Epoch:  83 , Loss:  0.6763923764228821   f1-score: 0.18418467044830322   accuracy: 0.7007207274436951\n",
      "Epoch:  84 , Loss:  0.6749208569526672   f1-score: 0.23632904887199402   accuracy: 0.7106306552886963\n",
      "Epoch:  85 , Loss:  0.6735743284225464   f1-score: 0.2857142984867096   accuracy: 0.7202702760696411\n",
      "Epoch:  86 , Loss:  0.6723963618278503   f1-score: 0.341971218585968   accuracy: 0.7323423624038696\n",
      "Epoch:  87 , Loss:  0.6713964343070984   f1-score: 0.3943541347980499   accuracy: 0.7448648810386658\n",
      "Epoch:  88 , Loss:  0.6705377697944641   f1-score: 0.44091564416885376   accuracy: 0.7557657361030579\n",
      "Epoch:  89 , Loss:  0.669746458530426   f1-score: 0.4876788556575775   accuracy: 0.7677477598190308\n",
      "Epoch:  90 , Loss:  0.6689355373382568   f1-score: 0.5192791819572449   accuracy: 0.7764865159988403\n",
      "Epoch:  91 , Loss:  0.6680392622947693   f1-score: 0.5371711850166321   accuracy: 0.7812612652778625\n",
      "Epoch:  92 , Loss:  0.6670350432395935   f1-score: 0.5472730994224548   accuracy: 0.7838738560676575\n",
      "Epoch:  93 , Loss:  0.6659457683563232   f1-score: 0.5545966029167175   accuracy: 0.7861261367797852\n",
      "Epoch:  94 , Loss:  0.6648226380348206   f1-score: 0.5562839508056641   accuracy: 0.7865765690803528\n",
      "Epoch:  95 , Loss:  0.663722813129425   f1-score: 0.555513858795166   accuracy: 0.7864865064620972\n",
      "Epoch:  96 , Loss:  0.6626937985420227   f1-score: 0.5510357618331909   accuracy: 0.7852252125740051\n",
      "Epoch:  97 , Loss:  0.6617602109909058   f1-score: 0.5466237664222717   accuracy: 0.7840540409088135\n",
      "Epoch:  98 , Loss:  0.6609237790107727   f1-score: 0.5439362525939941   accuracy: 0.7835134863853455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  99 , Loss:  0.6601691842079163   f1-score: 0.5435897707939148   accuracy: 0.7835134863853455\n",
      "Epoch:  100 , Loss:  0.6594714522361755   f1-score: 0.5430690050125122   accuracy: 0.7835134863853455\n",
      "Epoch:  101 , Loss:  0.6588059663772583   f1-score: 0.5436229109764099   accuracy: 0.7836936712265015\n",
      "Epoch:  102 , Loss:  0.6581535935401917   f1-score: 0.5460751056671143   accuracy: 0.7843243479728699\n",
      "Epoch:  103 , Loss:  0.6575031280517578   f1-score: 0.5521010160446167   accuracy: 0.7858558297157288\n",
      "Epoch:  104 , Loss:  0.6568529605865479   f1-score: 0.5599401593208313   accuracy: 0.7880180478096008\n",
      "Epoch:  105 , Loss:  0.6562081575393677   f1-score: 0.5696834921836853   accuracy: 0.7905405163764954\n",
      "Epoch:  106 , Loss:  0.6555784940719604   f1-score: 0.5785033106803894   accuracy: 0.792972981929779\n",
      "Epoch:  107 , Loss:  0.654975175857544   f1-score: 0.5898784399032593   accuracy: 0.796306312084198\n",
      "Epoch:  108 , Loss:  0.6544075012207031   f1-score: 0.6005015969276428   accuracy: 0.7990990877151489\n",
      "Epoch:  109 , Loss:  0.6538806557655334   f1-score: 0.6112685799598694   accuracy: 0.8023423552513123\n",
      "Epoch:  110 , Loss:  0.6533945202827454   f1-score: 0.6205200552940369   accuracy: 0.8054053783416748\n",
      "Epoch:  111 , Loss:  0.6529435515403748   f1-score: 0.625980794429779   accuracy: 0.8067567348480225\n",
      "Epoch:  112 , Loss:  0.6525192856788635   f1-score: 0.6305589079856873   accuracy: 0.8076576590538025\n",
      "Epoch:  113 , Loss:  0.6521124839782715   f1-score: 0.634314239025116   accuracy: 0.8085585832595825\n",
      "Epoch:  114 , Loss:  0.6517155170440674   f1-score: 0.6390410661697388   accuracy: 0.8100900650024414\n",
      "Epoch:  115 , Loss:  0.6513246893882751   f1-score: 0.6423083543777466   accuracy: 0.8112612366676331\n",
      "Epoch:  116 , Loss:  0.6509398818016052   f1-score: 0.644853413105011   accuracy: 0.8122522234916687\n",
      "Epoch:  117 , Loss:  0.6505638957023621   f1-score: 0.6465781331062317   accuracy: 0.8129729628562927\n",
      "Epoch:  118 , Loss:  0.6502005457878113   f1-score: 0.6467983722686768   accuracy: 0.8131531476974487\n",
      "Epoch:  119 , Loss:  0.6498533487319946   f1-score: 0.6473693251609802   accuracy: 0.8134233951568604\n",
      "Epoch:  120 , Loss:  0.6495242118835449   f1-score: 0.6460961699485779   accuracy: 0.8129729628562927\n",
      "Epoch:  121 , Loss:  0.6492131352424622   f1-score: 0.6454033851623535   accuracy: 0.8127027153968811\n",
      "Epoch:  122 , Loss:  0.6489183306694031   f1-score: 0.6453924775123596   accuracy: 0.8127927780151367\n",
      "Epoch:  123 , Loss:  0.6486369371414185   f1-score: 0.6452823877334595   accuracy: 0.8127027153968811\n",
      "Epoch:  124 , Loss:  0.6483660936355591   f1-score: 0.6462063193321228   accuracy: 0.8130630850791931\n",
      "Epoch:  125 , Loss:  0.6481031775474548   f1-score: 0.6471489071846008   accuracy: 0.8132432699203491\n",
      "Epoch:  126 , Loss:  0.6478469967842102   f1-score: 0.6484189033508301   accuracy: 0.8136937022209167\n",
      "Epoch:  127 , Loss:  0.6475967168807983   f1-score: 0.6499150991439819   accuracy: 0.8142342567443848\n",
      "Epoch:  128 , Loss:  0.6473528146743774   f1-score: 0.653351366519928   accuracy: 0.815495491027832\n",
      "Epoch:  129 , Loss:  0.6471160650253296   f1-score: 0.656207799911499   accuracy: 0.8163964152336121\n",
      "Epoch:  130 , Loss:  0.6468872427940369   f1-score: 0.6598284840583801   accuracy: 0.8177477717399597\n",
      "Epoch:  131 , Loss:  0.646666944026947   f1-score: 0.6629815697669983   accuracy: 0.8187387585639954\n",
      "Epoch:  132 , Loss:  0.6464552879333496   f1-score: 0.6645495295524597   accuracy: 0.819189190864563\n",
      "Epoch:  133 , Loss:  0.6462517976760864   f1-score: 0.6659993529319763   accuracy: 0.8196396231651306\n",
      "Epoch:  134 , Loss:  0.6460555195808411   f1-score: 0.6689953207969666   accuracy: 0.8207207322120667\n",
      "Epoch:  135 , Loss:  0.645865261554718   f1-score: 0.6708692908287048   accuracy: 0.8212612867355347\n",
      "Epoch:  136 , Loss:  0.6456802487373352   f1-score: 0.6708651185035706   accuracy: 0.8210811018943787\n",
      "Epoch:  137 , Loss:  0.645499587059021   f1-score: 0.6732836961746216   accuracy: 0.8220720887184143\n",
      "Epoch:  138 , Loss:  0.6453230977058411   f1-score: 0.6741610169410706   accuracy: 0.8224324584007263\n",
      "Epoch:  139 , Loss:  0.6451506018638611   f1-score: 0.6749297380447388   accuracy: 0.8227927684783936\n",
      "Epoch:  140 , Loss:  0.6449823975563049   f1-score: 0.6753675937652588   accuracy: 0.8229729533195496\n",
      "Epoch:  141 , Loss:  0.6448186635971069   f1-score: 0.6763540506362915   accuracy: 0.823423445224762\n",
      "Epoch:  142 , Loss:  0.644659698009491   f1-score: 0.676460862159729   accuracy: 0.823423445224762\n",
      "Epoch:  143 , Loss:  0.6445052027702332   f1-score: 0.6769027709960938   accuracy: 0.8236936926841736\n",
      "Epoch:  144 , Loss:  0.6443551182746887   f1-score: 0.6772277355194092   accuracy: 0.8237837553024292\n",
      "Epoch:  145 , Loss:  0.6442090272903442   f1-score: 0.6777759194374084   accuracy: 0.8240540623664856\n",
      "Epoch:  146 , Loss:  0.6440666317939758   f1-score: 0.6784300804138184   accuracy: 0.8243243098258972\n",
      "Epoch:  147 , Loss:  0.6439275741577148   f1-score: 0.6798418760299683   accuracy: 0.8248648643493652\n",
      "Epoch:  148 , Loss:  0.6437914967536926   f1-score: 0.6799473166465759   accuracy: 0.8248648643493652\n",
      "Epoch:  149 , Loss:  0.6436583399772644   f1-score: 0.6803818345069885   accuracy: 0.8250450491905212\n",
      "Epoch:  150 , Loss:  0.6435279846191406   f1-score: 0.6811379790306091   accuracy: 0.8253152966499329\n",
      "Epoch:  151 , Loss:  0.6434003710746765   f1-score: 0.6825422644615173   accuracy: 0.8258558511734009\n",
      "Epoch:  152 , Loss:  0.6432755589485168   f1-score: 0.6830708384513855   accuracy: 0.8259459733963013\n",
      "Epoch:  153 , Loss:  0.6431535482406616   f1-score: 0.6844692230224609   accuracy: 0.8264864683151245\n",
      "Epoch:  154 , Loss:  0.6430343389511108   f1-score: 0.6855459213256836   accuracy: 0.8269369602203369\n",
      "Epoch:  155 , Loss:  0.6429176330566406   f1-score: 0.6873672008514404   accuracy: 0.8276576399803162\n",
      "Epoch:  156 , Loss:  0.642803430557251   f1-score: 0.6883159279823303   accuracy: 0.8279279470443726\n",
      "Epoch:  157 , Loss:  0.6426914930343628   f1-score: 0.6895989775657654   accuracy: 0.8284684419631958\n",
      "Epoch:  158 , Loss:  0.6425817608833313   f1-score: 0.6907669901847839   accuracy: 0.8289189338684082\n",
      "Epoch:  159 , Loss:  0.6424739360809326   f1-score: 0.692157506942749   accuracy: 0.8295495510101318\n",
      "Epoch:  160 , Loss:  0.6423680186271667   f1-score: 0.6924703121185303   accuracy: 0.8296396136283875\n",
      "Epoch:  161 , Loss:  0.6422641277313232   f1-score: 0.6928954720497131   accuracy: 0.8298197984695435\n",
      "Epoch:  162 , Loss:  0.642162024974823   f1-score: 0.6933203339576721   accuracy: 0.8299999833106995\n",
      "Epoch:  163 , Loss:  0.6420617699623108   f1-score: 0.6934199929237366   accuracy: 0.8299999833106995\n",
      "Epoch:  164 , Loss:  0.6419634222984314   f1-score: 0.6936190724372864   accuracy: 0.8299999833106995\n",
      "Epoch:  165 , Loss:  0.6418666839599609   f1-score: 0.6938311457633972   accuracy: 0.8300901055335999\n",
      "Epoch:  166 , Loss:  0.6417716145515442   f1-score: 0.6949042677879333   accuracy: 0.8306306600570679\n",
      "Epoch:  167 , Loss:  0.6416782140731812   f1-score: 0.69520103931427   accuracy: 0.8306306600570679\n",
      "Epoch:  168 , Loss:  0.6415863037109375   f1-score: 0.6962578892707825   accuracy: 0.8310810923576355\n",
      "Epoch:  169 , Loss:  0.6414958238601685   f1-score: 0.6962435245513916   accuracy: 0.8309909701347351\n",
      "Epoch:  170 , Loss:  0.641406774520874   f1-score: 0.6965528130531311   accuracy: 0.8310810923576355\n",
      "Epoch:  171 , Loss:  0.6413191556930542   f1-score: 0.6969745755195618   accuracy: 0.8312612771987915\n",
      "Epoch:  172 , Loss:  0.6412328481674194   f1-score: 0.697817325592041   accuracy: 0.8316216468811035\n",
      "Epoch:  173 , Loss:  0.641147792339325   f1-score: 0.6980125904083252   accuracy: 0.8316216468811035\n",
      "Epoch:  174 , Loss:  0.6410641074180603   f1-score: 0.6995804905891418   accuracy: 0.8322522640228271\n",
      "Epoch:  175 , Loss:  0.6409816741943359   f1-score: 0.6998870968818665   accuracy: 0.8323423266410828\n",
      "Epoch:  176 , Loss:  0.6409004330635071   f1-score: 0.7000805735588074   accuracy: 0.8323423266410828\n",
      "Epoch:  177 , Loss:  0.6408204436302185   f1-score: 0.700499415397644   accuracy: 0.8325225114822388\n",
      "Epoch:  178 , Loss:  0.6407415270805359   f1-score: 0.7013363242149353   accuracy: 0.8328828811645508\n",
      "Epoch:  179 , Loss:  0.6406638026237488   f1-score: 0.7017374634742737   accuracy: 0.8329729437828064\n",
      "Epoch:  180 , Loss:  0.6405871510505676   f1-score: 0.7027809023857117   accuracy: 0.8334234356880188\n",
      "Epoch:  181 , Loss:  0.6405115723609924   f1-score: 0.702989399433136   accuracy: 0.8335134983062744\n",
      "Epoch:  182 , Loss:  0.6404368877410889   f1-score: 0.7037096619606018   accuracy: 0.8337838053703308\n",
      "Epoch:  183 , Loss:  0.6403633952140808   f1-score: 0.7040308117866516   accuracy: 0.8339639902114868\n",
      "Epoch:  184 , Loss:  0.6402907371520996   f1-score: 0.704541802406311   accuracy: 0.834144115447998\n",
      "Epoch:  185 , Loss:  0.6402191519737244   f1-score: 0.7047497034072876   accuracy: 0.8342342376708984\n",
      "Epoch:  186 , Loss:  0.6401484608650208   f1-score: 0.7042027711868286   accuracy: 0.8338738679885864\n",
      "Epoch:  187 , Loss:  0.6400786638259888   f1-score: 0.704939067363739   accuracy: 0.8342342376708984\n",
      "Epoch:  188 , Loss:  0.6400097608566284   f1-score: 0.7053542733192444   accuracy: 0.8344144225120544\n",
      "Epoch:  189 , Loss:  0.6399416923522949   f1-score: 0.7059766054153442   accuracy: 0.8346846699714661\n",
      "Epoch:  190 , Loss:  0.6398744583129883   f1-score: 0.7059766054153442   accuracy: 0.8346846699714661\n",
      "Epoch:  191 , Loss:  0.6398081183433533   f1-score: 0.7063911557197571   accuracy: 0.8348648548126221\n",
      "Epoch:  192 , Loss:  0.6397424936294556   f1-score: 0.7064852118492126   accuracy: 0.8348648548126221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  193 , Loss:  0.6396776437759399   f1-score: 0.7066922783851624   accuracy: 0.8349549770355225\n",
      "Epoch:  194 , Loss:  0.6396136283874512   f1-score: 0.7074263691902161   accuracy: 0.8353152871131897\n",
      "Epoch:  195 , Loss:  0.6395502090454102   f1-score: 0.7076331973075867   accuracy: 0.8354054093360901\n",
      "Epoch:  196 , Loss:  0.639487624168396   f1-score: 0.7079334855079651   accuracy: 0.8354954719543457\n",
      "Epoch:  197 , Loss:  0.6394256353378296   f1-score: 0.7089659571647644   accuracy: 0.8359459638595581\n",
      "Epoch:  198 , Loss:  0.6393644213676453   f1-score: 0.7094713449478149   accuracy: 0.8361261487007141\n",
      "Epoch:  199 , Loss:  0.639303982257843   f1-score: 0.7100686430931091   accuracy: 0.8363063335418701\n",
      "Epoch:  200 , Loss:  0.6392441391944885   f1-score: 0.7101819515228271   accuracy: 0.8363963961601257\n",
      "Epoch:  201 , Loss:  0.6391850709915161   f1-score: 0.7104801535606384   accuracy: 0.8364864587783813\n",
      "Epoch:  202 , Loss:  0.6391265392303467   f1-score: 0.7115077972412109   accuracy: 0.8369369506835938\n",
      "Epoch:  203 , Loss:  0.6390687823295593   f1-score: 0.7117131352424622   accuracy: 0.8370270133018494\n",
      "Epoch:  204 , Loss:  0.639011561870575   f1-score: 0.711804986000061   accuracy: 0.8370270133018494\n",
      "Epoch:  205 , Loss:  0.6389549374580383   f1-score: 0.7126253843307495   accuracy: 0.8373873829841614\n",
      "Epoch:  206 , Loss:  0.6388989686965942   f1-score: 0.7128303050994873   accuracy: 0.8374775052070618\n",
      "Epoch:  207 , Loss:  0.6388435959815979   f1-score: 0.7128303050994873   accuracy: 0.8374775052070618\n",
      "Epoch:  208 , Loss:  0.6387888789176941   f1-score: 0.7133312225341797   accuracy: 0.837657630443573\n",
      "Epoch:  209 , Loss:  0.6387346386909485   f1-score: 0.7137404680252075   accuracy: 0.837837815284729\n",
      "Epoch:  210 , Loss:  0.6386810541152954   f1-score: 0.7139449715614319   accuracy: 0.8379279375076294\n",
      "Epoch:  211 , Loss:  0.6386280059814453   f1-score: 0.7151707410812378   accuracy: 0.8384684920310974\n",
      "Epoch:  212 , Loss:  0.6385753750801086   f1-score: 0.7154884934425354   accuracy: 0.8386486768722534\n",
      "Epoch:  213 , Loss:  0.6385232210159302   f1-score: 0.7156021595001221   accuracy: 0.838738739490509\n",
      "Epoch:  214 , Loss:  0.6384715437889099   f1-score: 0.7179892659187317   accuracy: 0.839279294013977\n",
      "Epoch:  215 , Loss:  0.6384204030036926   f1-score: 0.718799352645874   accuracy: 0.8396396636962891\n",
      "Epoch:  216 , Loss:  0.6383697986602783   f1-score: 0.719317615032196   accuracy: 0.8399099111557007\n",
      "Epoch:  217 , Loss:  0.6383196115493774   f1-score: 0.7203282713890076   accuracy: 0.8403603434562683\n",
      "Epoch:  218 , Loss:  0.6382699012756348   f1-score: 0.7208201885223389   accuracy: 0.8405405282974243\n",
      "Epoch:  219 , Loss:  0.6382207274436951   f1-score: 0.7218282222747803   accuracy: 0.8409910202026367\n",
      "Epoch:  220 , Loss:  0.6381719708442688   f1-score: 0.7222309708595276   accuracy: 0.841171145439148\n",
      "Epoch:  221 , Loss:  0.6381235122680664   f1-score: 0.7226599454879761   accuracy: 0.8414414525032043\n",
      "Epoch:  222 , Loss:  0.6380755305290222   f1-score: 0.7231495976448059   accuracy: 0.8416216373443604\n",
      "Epoch:  223 , Loss:  0.6380277872085571   f1-score: 0.7231495976448059   accuracy: 0.8416216373443604\n",
      "Epoch:  224 , Loss:  0.6379805207252502   f1-score: 0.7231495976448059   accuracy: 0.8416216373443604\n",
      "Epoch:  225 , Loss:  0.6379335522651672   f1-score: 0.7234377264976501   accuracy: 0.841711699962616\n",
      "Epoch:  226 , Loss:  0.637887179851532   f1-score: 0.7237525582313538   accuracy: 0.841891884803772\n",
      "Epoch:  227 , Loss:  0.6378411054611206   f1-score: 0.7244689464569092   accuracy: 0.842252254486084\n",
      "Epoch:  228 , Loss:  0.6377954483032227   f1-score: 0.7246695756912231   accuracy: 0.8423423171043396\n",
      "Epoch:  229 , Loss:  0.6377503275871277   f1-score: 0.7246695756912231   accuracy: 0.8423423171043396\n",
      "Epoch:  230 , Loss:  0.6377055048942566   f1-score: 0.7247836589813232   accuracy: 0.84243243932724\n",
      "Epoch:  231 , Loss:  0.6376612186431885   f1-score: 0.7249842882156372   accuracy: 0.8425225019454956\n",
      "Epoch:  232 , Loss:  0.6376173496246338   f1-score: 0.7251848578453064   accuracy: 0.842612624168396\n",
      "Epoch:  233 , Loss:  0.6375738978385925   f1-score: 0.7255857586860657   accuracy: 0.842792809009552\n",
      "Epoch:  234 , Loss:  0.6375307440757751   f1-score: 0.7255857586860657   accuracy: 0.842792809009552\n",
      "Epoch:  235 , Loss:  0.6374880075454712   f1-score: 0.7255857586860657   accuracy: 0.842792809009552\n",
      "Epoch:  236 , Loss:  0.6374455690383911   f1-score: 0.7258723378181458   accuracy: 0.8428828716278076\n",
      "Epoch:  237 , Loss:  0.6374034881591797   f1-score: 0.7262727618217468   accuracy: 0.8430630564689636\n",
      "Epoch:  238 , Loss:  0.6373617649078369   f1-score: 0.7261586785316467   accuracy: 0.842972993850708\n",
      "Epoch:  239 , Loss:  0.6373202800750732   f1-score: 0.7261586785316467   accuracy: 0.842972993850708\n",
      "Epoch:  240 , Loss:  0.637279212474823   f1-score: 0.7261306643486023   accuracy: 0.8428828716278076\n",
      "Epoch:  241 , Loss:  0.6372383832931519   f1-score: 0.7265306115150452   accuracy: 0.8430630564689636\n",
      "Epoch:  242 , Loss:  0.6371979117393494   f1-score: 0.7268162369728088   accuracy: 0.843153178691864\n",
      "Epoch:  243 , Loss:  0.6371577978134155   f1-score: 0.727016031742096   accuracy: 0.8432432413101196\n",
      "Epoch:  244 , Loss:  0.6371179819107056   f1-score: 0.727016031742096   accuracy: 0.8432432413101196\n",
      "Epoch:  245 , Loss:  0.6370784044265747   f1-score: 0.7273012399673462   accuracy: 0.8433333039283752\n",
      "Epoch:  246 , Loss:  0.6370391845703125   f1-score: 0.7282131910324097   accuracy: 0.8437837958335876\n",
      "Epoch:  247 , Loss:  0.6370001435279846   f1-score: 0.7282983660697937   accuracy: 0.8437837958335876\n",
      "Epoch:  248 , Loss:  0.6369614005088806   f1-score: 0.7282983660697937   accuracy: 0.8437837958335876\n",
      "Epoch:  249 , Loss:  0.6369228959083557   f1-score: 0.7286967635154724   accuracy: 0.8439639806747437\n",
      "Epoch:  250 , Loss:  0.6368846893310547   f1-score: 0.729094922542572   accuracy: 0.8441441655158997\n",
      "Epoch:  251 , Loss:  0.6368467211723328   f1-score: 0.7291797399520874   accuracy: 0.8441441655158997\n",
      "Epoch:  252 , Loss:  0.6368090510368347   f1-score: 0.7293786406517029   accuracy: 0.8442342281341553\n",
      "Epoch:  253 , Loss:  0.6367716193199158   f1-score: 0.7294632792472839   accuracy: 0.8442342281341553\n",
      "Epoch:  254 , Loss:  0.6367343664169312   f1-score: 0.729860782623291   accuracy: 0.8444144129753113\n",
      "Epoch:  255 , Loss:  0.6366973519325256   f1-score: 0.7305408120155334   accuracy: 0.8446846604347229\n",
      "Epoch:  256 , Loss:  0.636660635471344   f1-score: 0.730739176273346   accuracy: 0.8447747826576233\n",
      "Epoch:  257 , Loss:  0.6366240978240967   f1-score: 0.7311357855796814   accuracy: 0.8449549674987793\n",
      "Epoch:  258 , Loss:  0.6365878582000732   f1-score: 0.7313642501831055   accuracy: 0.8451351523399353\n",
      "Epoch:  259 , Loss:  0.6365517973899841   f1-score: 0.7314785718917847   accuracy: 0.8452252149581909\n",
      "Epoch:  260 , Loss:  0.6365159153938293   f1-score: 0.7315624952316284   accuracy: 0.8452252149581909\n",
      "Epoch:  261 , Loss:  0.6364802122116089   f1-score: 0.7316768169403076   accuracy: 0.8453153371810913\n",
      "Epoch:  262 , Loss:  0.6364448070526123   f1-score: 0.7316768169403076   accuracy: 0.8453153371810913\n",
      "Epoch:  263 , Loss:  0.6364095211029053   f1-score: 0.7320731282234192   accuracy: 0.8454955220222473\n",
      "Epoch:  264 , Loss:  0.6363745331764221   f1-score: 0.7322711944580078   accuracy: 0.8455855846405029\n",
      "Epoch:  265 , Loss:  0.6363397240638733   f1-score: 0.733062744140625   accuracy: 0.8459459543228149\n",
      "Epoch:  266 , Loss:  0.6363050937652588   f1-score: 0.733031690120697   accuracy: 0.8458558320999146\n",
      "Epoch:  267 , Loss:  0.6362708210945129   f1-score: 0.7333437204360962   accuracy: 0.8460360169410706\n",
      "Epoch:  268 , Loss:  0.6362366676330566   f1-score: 0.7335413694381714   accuracy: 0.846126139163971\n",
      "Epoch:  269 , Loss:  0.6362025737762451   f1-score: 0.7338533401489258   accuracy: 0.846306324005127\n",
      "Epoch:  270 , Loss:  0.6361688375473022   f1-score: 0.7340508699417114   accuracy: 0.8463963866233826\n",
      "Epoch:  271 , Loss:  0.6361351609230042   f1-score: 0.7340193390846252   accuracy: 0.846306324005127\n",
      "Epoch:  272 , Loss:  0.6361016631126404   f1-score: 0.7343311309814453   accuracy: 0.846486508846283\n",
      "Epoch:  273 , Loss:  0.6360684037208557   f1-score: 0.7345284223556519   accuracy: 0.8465765714645386\n",
      "Epoch:  274 , Loss:  0.6360352635383606   f1-score: 0.7344967126846313   accuracy: 0.846486508846283\n",
      "Epoch:  275 , Loss:  0.6360023617744446   f1-score: 0.7352024912834167   accuracy: 0.8468468189239502\n",
      "Epoch:  276 , Loss:  0.6359696388244629   f1-score: 0.7353994846343994   accuracy: 0.8469369411468506\n",
      "Epoch:  277 , Loss:  0.6359370946884155   f1-score: 0.7355963587760925   accuracy: 0.8470270037651062\n",
      "Epoch:  278 , Loss:  0.6359046697616577   f1-score: 0.7357932329177856   accuracy: 0.8471171259880066\n",
      "Epoch:  279 , Loss:  0.635872483253479   f1-score: 0.7357932329177856   accuracy: 0.8471171259880066\n",
      "Epoch:  280 , Loss:  0.6358405351638794   f1-score: 0.7363013625144958   accuracy: 0.8473873734474182\n",
      "Epoch:  281 , Loss:  0.6358087062835693   f1-score: 0.7369240522384644   accuracy: 0.8477477431297302\n",
      "Epoch:  282 , Loss:  0.6357770562171936   f1-score: 0.737005889415741   accuracy: 0.8477477431297302\n",
      "Epoch:  283 , Loss:  0.6357455253601074   f1-score: 0.736661970615387   accuracy: 0.8474774956703186\n",
      "Epoch:  284 , Loss:  0.6357141137123108   f1-score: 0.7374475598335266   accuracy: 0.8478378653526306\n",
      "Epoch:  285 , Loss:  0.635683000087738   f1-score: 0.7372512221336365   accuracy: 0.8477477431297302\n",
      "Epoch:  286 , Loss:  0.6356519460678101   f1-score: 0.7372512221336365   accuracy: 0.8477477431297302\n",
      "Epoch:  287 , Loss:  0.6356210708618164   f1-score: 0.7373659014701843   accuracy: 0.8478378653526306\n",
      "Epoch:  288 , Loss:  0.6355903744697571   f1-score: 0.7373659014701843   accuracy: 0.8478378653526306\n",
      "Epoch:  289 , Loss:  0.6355597972869873   f1-score: 0.7373659014701843   accuracy: 0.8478378653526306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  290 , Loss:  0.6355293989181519   f1-score: 0.737758457660675   accuracy: 0.8480179905891418\n",
      "Epoch:  291 , Loss:  0.6354990601539612   f1-score: 0.7379546165466309   accuracy: 0.8481081128120422\n",
      "Epoch:  292 , Loss:  0.6354689598083496   f1-score: 0.7381507158279419   accuracy: 0.8481981754302979\n",
      "Epoch:  293 , Loss:  0.635438859462738   f1-score: 0.7387387156486511   accuracy: 0.8484684824943542\n",
      "Epoch:  294 , Loss:  0.6354089975357056   f1-score: 0.7388198971748352   accuracy: 0.8484684824943542\n",
      "Epoch:  295 , Loss:  0.6353791952133179   f1-score: 0.7394071221351624   accuracy: 0.8487387299537659\n",
      "Epoch:  296 , Loss:  0.6353495717048645   f1-score: 0.7394071221351624   accuracy: 0.8487387299537659\n",
      "Epoch:  297 , Loss:  0.6353198885917664   f1-score: 0.7399131059646606   accuracy: 0.8490090370178223\n",
      "Epoch:  298 , Loss:  0.6352904438972473   f1-score: 0.7406143546104431   accuracy: 0.8493693470954895\n",
      "Epoch:  299 , Loss:  0.6352611184120178   f1-score: 0.7404994368553162   accuracy: 0.8492792844772339\n",
      "Epoch:  300 , Loss:  0.6352318525314331   f1-score: 0.7404994368553162   accuracy: 0.8492792844772339\n",
      "Epoch:  301 , Loss:  0.6352028846740723   f1-score: 0.7406143546104431   accuracy: 0.8493693470954895\n",
      "Epoch:  302 , Loss:  0.6351739764213562   f1-score: 0.7407292723655701   accuracy: 0.8494594693183899\n",
      "Epoch:  303 , Loss:  0.6351451873779297   f1-score: 0.7405338287353516   accuracy: 0.8493693470954895\n",
      "Epoch:  304 , Loss:  0.635116457939148   f1-score: 0.740924596786499   accuracy: 0.8495495319366455\n",
      "Epoch:  305 , Loss:  0.6350879073143005   f1-score: 0.7413151264190674   accuracy: 0.8497297167778015\n",
      "Epoch:  306 , Loss:  0.6350594162940979   f1-score: 0.7415103316307068   accuracy: 0.8498198390007019\n",
      "Epoch:  307 , Loss:  0.6350310444831848   f1-score: 0.7415103316307068   accuracy: 0.8498198390007019\n",
      "Epoch:  308 , Loss:  0.6350027322769165   f1-score: 0.7410852909088135   accuracy: 0.8495495319366455\n",
      "Epoch:  309 , Loss:  0.6349745392799377   f1-score: 0.741670548915863   accuracy: 0.8498198390007019\n",
      "Epoch:  310 , Loss:  0.6349464654922485   f1-score: 0.7415556311607361   accuracy: 0.8497297167778015\n",
      "Epoch:  311 , Loss:  0.6349183917045593   f1-score: 0.741830587387085   accuracy: 0.8498198390007019\n",
      "Epoch:  312 , Loss:  0.6348903775215149   f1-score: 0.7420253753662109   accuracy: 0.8499099016189575\n",
      "Epoch:  313 , Loss:  0.6348626017570496   f1-score: 0.7422201633453369   accuracy: 0.8500000238418579\n",
      "Epoch:  314 , Loss:  0.634834885597229   f1-score: 0.7428041100502014   accuracy: 0.8502702713012695\n",
      "Epoch:  315 , Loss:  0.6348072290420532   f1-score: 0.7433874607086182   accuracy: 0.8505405187606812\n",
      "Epoch:  316 , Loss:  0.634779691696167   f1-score: 0.7431930899620056   accuracy: 0.8504504561424255\n",
      "Epoch:  317 , Loss:  0.6347522735595703   f1-score: 0.7431930899620056   accuracy: 0.8504504561424255\n",
      "Epoch:  318 , Loss:  0.6347248554229736   f1-score: 0.7435024976730347   accuracy: 0.8506306409835815\n",
      "Epoch:  319 , Loss:  0.6346975564956665   f1-score: 0.7440062165260315   accuracy: 0.8509008884429932\n",
      "Epoch:  320 , Loss:  0.6346703767776489   f1-score: 0.7442795038223267   accuracy: 0.8509910106658936\n",
      "Epoch:  321 , Loss:  0.6346431970596313   f1-score: 0.7442795038223267   accuracy: 0.8509910106658936\n",
      "Epoch:  322 , Loss:  0.6346161365509033   f1-score: 0.7444736361503601   accuracy: 0.8510810732841492\n",
      "Epoch:  323 , Loss:  0.6345891356468201   f1-score: 0.7444736361503601   accuracy: 0.8510810732841492\n",
      "Epoch:  324 , Loss:  0.6345622539520264   f1-score: 0.7446677088737488   accuracy: 0.8511711955070496\n",
      "Epoch:  325 , Loss:  0.6345353722572327   f1-score: 0.7451344132423401   accuracy: 0.8513513803482056\n",
      "Epoch:  326 , Loss:  0.6345085501670837   f1-score: 0.7451344132423401   accuracy: 0.8513513803482056\n",
      "Epoch:  327 , Loss:  0.6344818472862244   f1-score: 0.7454432845115662   accuracy: 0.8515315055847168\n",
      "Epoch:  328 , Loss:  0.6344550251960754   f1-score: 0.745830774307251   accuracy: 0.8517116904258728\n",
      "Epoch:  329 , Loss:  0.6344283223152161   f1-score: 0.7464115023612976   accuracy: 0.8519819974899292\n",
      "Epoch:  330 , Loss:  0.6344017386436462   f1-score: 0.7462962865829468   accuracy: 0.8518918752670288\n",
      "Epoch:  331 , Loss:  0.6343751549720764   f1-score: 0.7466831207275391   accuracy: 0.8520720601081848\n",
      "Epoch:  332 , Loss:  0.6343485713005066   f1-score: 0.7466831207275391   accuracy: 0.8520720601081848\n",
      "Epoch:  333 , Loss:  0.6343219876289368   f1-score: 0.7466831207275391   accuracy: 0.8520720601081848\n",
      "Epoch:  334 , Loss:  0.6342954635620117   f1-score: 0.7469916939735413   accuracy: 0.8522522449493408\n",
      "Epoch:  335 , Loss:  0.634269118309021   f1-score: 0.7477644085884094   accuracy: 0.8526126146316528\n",
      "Epoch:  336 , Loss:  0.6342426538467407   f1-score: 0.7479574680328369   accuracy: 0.8527026772499084\n",
      "Epoch:  337 , Loss:  0.63421630859375   f1-score: 0.7479574680328369   accuracy: 0.8527026772499084\n",
      "Epoch:  338 , Loss:  0.634190022945404   f1-score: 0.7479574680328369   accuracy: 0.8527026772499084\n",
      "Epoch:  339 , Loss:  0.6341637969017029   f1-score: 0.7480727434158325   accuracy: 0.8527927994728088\n",
      "Epoch:  340 , Loss:  0.6341376304626465   f1-score: 0.7481881380081177   accuracy: 0.8528828620910645\n",
      "Epoch:  341 , Loss:  0.6341115236282349   f1-score: 0.7479950785636902   accuracy: 0.8527927994728088\n",
      "Epoch:  342 , Loss:  0.634085476398468   f1-score: 0.7478019595146179   accuracy: 0.8527026772499084\n",
      "Epoch:  343 , Loss:  0.6340593695640564   f1-score: 0.7478019595146179   accuracy: 0.8527026772499084\n",
      "Epoch:  344 , Loss:  0.6340333819389343   f1-score: 0.7485740780830383   accuracy: 0.8530630469322205\n",
      "Epoch:  345 , Loss:  0.634007453918457   f1-score: 0.7484586834907532   accuracy: 0.8529729843139648\n",
      "Epoch:  346 , Loss:  0.6339815258979797   f1-score: 0.7484586834907532   accuracy: 0.8529729843139648\n",
      "Epoch:  347 , Loss:  0.6339556574821472   f1-score: 0.7487289905548096   accuracy: 0.8530630469322205\n",
      "Epoch:  348 , Loss:  0.6339299082756042   f1-score: 0.7489597797393799   accuracy: 0.8532432317733765\n",
      "Epoch:  349 , Loss:  0.6339041590690613   f1-score: 0.7489597797393799   accuracy: 0.8532432317733765\n",
      "Epoch:  350 , Loss:  0.6338784694671631   f1-score: 0.7489597797393799   accuracy: 0.8532432317733765\n",
      "Epoch:  351 , Loss:  0.6338528394699097   f1-score: 0.7489597797393799   accuracy: 0.8532432317733765\n",
      "Epoch:  352 , Loss:  0.6338273286819458   f1-score: 0.7489597797393799   accuracy: 0.8532432317733765\n",
      "Epoch:  353 , Loss:  0.6338019371032715   f1-score: 0.7493452429771423   accuracy: 0.8534234166145325\n",
      "Epoch:  354 , Loss:  0.6337766051292419   f1-score: 0.7497304677963257   accuracy: 0.8536036014556885\n",
      "Epoch:  355 , Loss:  0.6337513327598572   f1-score: 0.7499229907989502   accuracy: 0.8536936640739441\n",
      "Epoch:  356 , Loss:  0.6337260603904724   f1-score: 0.7499229907989502   accuracy: 0.8536936640739441\n",
      "Epoch:  357 , Loss:  0.6337008476257324   f1-score: 0.7499229907989502   accuracy: 0.8536936640739441\n",
      "Epoch:  358 , Loss:  0.6336756944656372   f1-score: 0.7510002851486206   accuracy: 0.8542342185974121\n",
      "Epoch:  359 , Loss:  0.6336506605148315   f1-score: 0.7510002851486206   accuracy: 0.8542342185974121\n",
      "Epoch:  360 , Loss:  0.6336256265640259   f1-score: 0.7510002851486206   accuracy: 0.8542342185974121\n",
      "Epoch:  361 , Loss:  0.633600652217865   f1-score: 0.7511925101280212   accuracy: 0.8543243408203125\n",
      "Epoch:  362 , Loss:  0.6335757374763489   f1-score: 0.7511925101280212   accuracy: 0.8543243408203125\n",
      "Epoch:  363 , Loss:  0.6335509419441223   f1-score: 0.7515766620635986   accuracy: 0.8545045256614685\n",
      "Epoch:  364 , Loss:  0.633526086807251   f1-score: 0.7514610886573792   accuracy: 0.8544144034385681\n",
      "Epoch:  365 , Loss:  0.6335012912750244   f1-score: 0.7520368695259094   accuracy: 0.8546847105026245\n",
      "Epoch:  366 , Loss:  0.6334766149520874   f1-score: 0.7521525025367737   accuracy: 0.8547747731208801\n",
      "Epoch:  367 , Loss:  0.6334519386291504   f1-score: 0.7521525025367737   accuracy: 0.8547747731208801\n",
      "Epoch:  368 , Loss:  0.6334273219108582   f1-score: 0.7522681951522827   accuracy: 0.8548648357391357\n",
      "Epoch:  369 , Loss:  0.6334027051925659   f1-score: 0.7522681951522827   accuracy: 0.8548648357391357\n",
      "Epoch:  370 , Loss:  0.6333782076835632   f1-score: 0.752076268196106   accuracy: 0.8547747731208801\n",
      "Epoch:  371 , Loss:  0.6333536505699158   f1-score: 0.7524600028991699   accuracy: 0.8549549579620361\n",
      "Epoch:  372 , Loss:  0.6333292722702026   f1-score: 0.7526518106460571   accuracy: 0.8550450205802917\n",
      "Epoch:  373 , Loss:  0.6333049535751343   f1-score: 0.7529592514038086   accuracy: 0.8552252054214478\n",
      "Epoch:  374 , Loss:  0.6332805752754211   f1-score: 0.7530750036239624   accuracy: 0.8553153276443481\n",
      "Epoch:  375 , Loss:  0.6332563757896423   f1-score: 0.7530750036239624   accuracy: 0.8553153276443481\n",
      "Epoch:  376 , Loss:  0.633232057094574   f1-score: 0.7530750036239624   accuracy: 0.8553153276443481\n",
      "Epoch:  377 , Loss:  0.6332079172134399   f1-score: 0.7532666921615601   accuracy: 0.8554053902626038\n",
      "Epoch:  378 , Loss:  0.6331835985183716   f1-score: 0.7532666921615601   accuracy: 0.8554053902626038\n",
      "Epoch:  379 , Loss:  0.6331593990325928   f1-score: 0.7532666921615601   accuracy: 0.8554053902626038\n",
      "Epoch:  380 , Loss:  0.633135199546814   f1-score: 0.7530750036239624   accuracy: 0.8553153276443481\n",
      "Epoch:  381 , Loss:  0.6331110000610352   f1-score: 0.7532666921615601   accuracy: 0.8554053902626038\n",
      "Epoch:  382 , Loss:  0.6330868005752563   f1-score: 0.7532666921615601   accuracy: 0.8554053902626038\n",
      "Epoch:  383 , Loss:  0.6330626606941223   f1-score: 0.7534583210945129   accuracy: 0.8554955124855042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  384 , Loss:  0.6330385208129883   f1-score: 0.7534583210945129   accuracy: 0.8554955124855042\n",
      "Epoch:  385 , Loss:  0.6330143809318542   f1-score: 0.7534183263778687   accuracy: 0.8554053902626038\n",
      "Epoch:  386 , Loss:  0.6329902410507202   f1-score: 0.7531869411468506   accuracy: 0.8552252054214478\n",
      "Epoch:  387 , Loss:  0.6329661011695862   f1-score: 0.7533783912658691   accuracy: 0.8553153276443481\n",
      "Epoch:  388 , Loss:  0.6329419612884521   f1-score: 0.7533783912658691   accuracy: 0.8553153276443481\n",
      "Epoch:  389 , Loss:  0.6329177618026733   f1-score: 0.7532626986503601   accuracy: 0.8552252054214478\n",
      "Epoch:  390 , Loss:  0.6328935623168945   f1-score: 0.7534540891647339   accuracy: 0.8553153276443481\n",
      "Epoch:  391 , Loss:  0.6328692436218262   f1-score: 0.7533384561538696   accuracy: 0.8552252054214478\n",
      "Epoch:  392 , Loss:  0.6328450441360474   f1-score: 0.7532228231430054   accuracy: 0.8551351428031921\n",
      "Epoch:  393 , Loss:  0.6328206062316895   f1-score: 0.7534141540527344   accuracy: 0.8552252054214478\n",
      "Epoch:  394 , Loss:  0.6327961683273315   f1-score: 0.7535297870635986   accuracy: 0.8553153276443481\n",
      "Epoch:  395 , Loss:  0.6327716708183289   f1-score: 0.7537210583686829   accuracy: 0.8554053902626038\n",
      "Epoch:  396 , Loss:  0.6327471137046814   f1-score: 0.7537210583686829   accuracy: 0.8554053902626038\n",
      "Epoch:  397 , Loss:  0.6327224373817444   f1-score: 0.7538366913795471   accuracy: 0.8554955124855042\n",
      "Epoch:  398 , Loss:  0.6326976418495178   f1-score: 0.7540279030799866   accuracy: 0.8555855751037598\n",
      "Epoch:  399 , Loss:  0.6326727867126465   f1-score: 0.7543348073959351   accuracy: 0.8557657599449158\n",
      "Epoch:  400 , Loss:  0.6326477527618408   f1-score: 0.7543348073959351   accuracy: 0.8557657599449158\n",
      "Epoch:  401 , Loss:  0.6326226592063904   f1-score: 0.7547169923782349   accuracy: 0.8559459447860718\n",
      "Epoch:  402 , Loss:  0.6325975060462952   f1-score: 0.7549079656600952   accuracy: 0.8560360074043274\n",
      "Epoch:  403 , Loss:  0.6325721740722656   f1-score: 0.7550237774848938   accuracy: 0.8561261296272278\n",
      "Epoch:  404 , Loss:  0.6325469017028809   f1-score: 0.7552147507667542   accuracy: 0.8562161922454834\n",
      "Epoch:  405 , Loss:  0.632521390914917   f1-score: 0.7553305625915527   accuracy: 0.8563063144683838\n",
      "Epoch:  406 , Loss:  0.6324959397315979   f1-score: 0.7554464340209961   accuracy: 0.8563963770866394\n",
      "Epoch:  407 , Loss:  0.6324703097343445   f1-score: 0.7556373476982117   accuracy: 0.8564864993095398\n",
      "Epoch:  408 , Loss:  0.6324448585510254   f1-score: 0.7554464340209961   accuracy: 0.8563963770866394\n",
      "Epoch:  409 , Loss:  0.6324193477630615   f1-score: 0.7560601234436035   accuracy: 0.8567567467689514\n",
      "Epoch:  410 , Loss:  0.6323938965797424   f1-score: 0.7559441924095154   accuracy: 0.8566666841506958\n",
      "Epoch:  411 , Loss:  0.6323685646057129   f1-score: 0.7558282017707825   accuracy: 0.8565765619277954\n",
      "Epoch:  412 , Loss:  0.6323432326316833   f1-score: 0.7560189962387085   accuracy: 0.8566666841506958\n",
      "Epoch:  413 , Loss:  0.6323180794715881   f1-score: 0.7562509775161743   accuracy: 0.8568468689918518\n",
      "Epoch:  414 , Loss:  0.6322929263114929   f1-score: 0.7569391131401062   accuracy: 0.857207179069519\n",
      "Epoch:  415 , Loss:  0.632267951965332   f1-score: 0.7571297287940979   accuracy: 0.8572973012924194\n",
      "Epoch:  416 , Loss:  0.6322429776191711   f1-score: 0.7571297287940979   accuracy: 0.8572973012924194\n",
      "Epoch:  417 , Loss:  0.6322182416915894   f1-score: 0.7570136189460754   accuracy: 0.857207179069519\n",
      "Epoch:  418 , Loss:  0.632193386554718   f1-score: 0.7572041749954224   accuracy: 0.8572973012924194\n",
      "Epoch:  419 , Loss:  0.6321688890457153   f1-score: 0.7570136189460754   accuracy: 0.857207179069519\n",
      "Epoch:  420 , Loss:  0.6321443319320679   f1-score: 0.7574363946914673   accuracy: 0.8574774861335754\n",
      "Epoch:  421 , Loss:  0.6321198344230652   f1-score: 0.7576268315315247   accuracy: 0.857567548751831\n",
      "Epoch:  422 , Loss:  0.6320955753326416   f1-score: 0.7576268315315247   accuracy: 0.857567548751831\n",
      "Epoch:  423 , Loss:  0.6320711970329285   f1-score: 0.7574363946914673   accuracy: 0.8574774861335754\n",
      "Epoch:  424 , Loss:  0.6320469975471497   f1-score: 0.7577011585235596   accuracy: 0.857567548751831\n",
      "Epoch:  425 , Loss:  0.6320227980613708   f1-score: 0.7575850486755371   accuracy: 0.8574774861335754\n",
      "Epoch:  426 , Loss:  0.6319987177848816   f1-score: 0.7575850486755371   accuracy: 0.8574774861335754\n",
      "Epoch:  427 , Loss:  0.6319745779037476   f1-score: 0.7577753663063049   accuracy: 0.857567548751831\n",
      "Epoch:  428 , Loss:  0.6319506168365479   f1-score: 0.7579656839370728   accuracy: 0.8576576709747314\n",
      "Epoch:  429 , Loss:  0.6319265961647034   f1-score: 0.7579656839370728   accuracy: 0.8576576709747314\n",
      "Epoch:  430 , Loss:  0.6319026350975037   f1-score: 0.7579656839370728   accuracy: 0.8576576709747314\n",
      "Epoch:  431 , Loss:  0.6318786144256592   f1-score: 0.7579656839370728   accuracy: 0.8576576709747314\n",
      "Epoch:  432 , Loss:  0.6318547129631042   f1-score: 0.7580817937850952   accuracy: 0.8577477335929871\n",
      "Epoch:  433 , Loss:  0.6318307518959045   f1-score: 0.7582720518112183   accuracy: 0.8578378558158875\n",
      "Epoch:  434 , Loss:  0.6318068504333496   f1-score: 0.7581979632377625   accuracy: 0.8578378558158875\n",
      "Epoch:  435 , Loss:  0.6317828893661499   f1-score: 0.7583882212638855   accuracy: 0.8579279184341431\n",
      "Epoch:  436 , Loss:  0.631758987903595   f1-score: 0.7585784196853638   accuracy: 0.8580180406570435\n",
      "Epoch:  437 , Loss:  0.6317350268363953   f1-score: 0.7585784196853638   accuracy: 0.8580180406570435\n",
      "Epoch:  438 , Loss:  0.6317111849784851   f1-score: 0.7585784196853638   accuracy: 0.8580180406570435\n",
      "Epoch:  439 , Loss:  0.631687343120575   f1-score: 0.7585784196853638   accuracy: 0.8580180406570435\n",
      "Epoch:  440 , Loss:  0.6316635012626648   f1-score: 0.7586946487426758   accuracy: 0.8581081032752991\n",
      "Epoch:  441 , Loss:  0.6316395998001099   f1-score: 0.7590010762214661   accuracy: 0.8582882881164551\n",
      "Epoch:  442 , Loss:  0.6316156983375549   f1-score: 0.7592337131500244   accuracy: 0.8584684729576111\n",
      "Epoch:  443 , Loss:  0.631591796875   f1-score: 0.7589272260665894   accuracy: 0.8582882881164551\n",
      "Epoch:  444 , Loss:  0.6315678358078003   f1-score: 0.7589272260665894   accuracy: 0.8582882881164551\n",
      "Epoch:  445 , Loss:  0.6315439939498901   f1-score: 0.7594975233078003   accuracy: 0.8585585355758667\n",
      "Epoch:  446 , Loss:  0.6315202116966248   f1-score: 0.7594975233078003   accuracy: 0.8585585355758667\n",
      "Epoch:  447 , Loss:  0.6314963698387146   f1-score: 0.7596139311790466   accuracy: 0.8586486577987671\n",
      "Epoch:  448 , Loss:  0.6314725279808044   f1-score: 0.7596139311790466   accuracy: 0.8586486577987671\n",
      "Epoch:  449 , Loss:  0.6314486861228943   f1-score: 0.7594975233078003   accuracy: 0.8585585355758667\n",
      "Epoch:  450 , Loss:  0.6314248442649841   f1-score: 0.7594975233078003   accuracy: 0.8585585355758667\n",
      "Epoch:  451 , Loss:  0.631401002407074   f1-score: 0.7594975233078003   accuracy: 0.8585585355758667\n",
      "Epoch:  452 , Loss:  0.6313771605491638   f1-score: 0.7599203586578369   accuracy: 0.8588288426399231\n",
      "Epoch:  453 , Loss:  0.6313533782958984   f1-score: 0.7601103186607361   accuracy: 0.8589189052581787\n",
      "Epoch:  454 , Loss:  0.6313295364379883   f1-score: 0.7603002190589905   accuracy: 0.8590090274810791\n",
      "Epoch:  455 , Loss:  0.6313058137893677   f1-score: 0.7606798410415649   accuracy: 0.8591892123222351\n",
      "Epoch:  456 , Loss:  0.6312821507453918   f1-score: 0.760869562625885   accuracy: 0.8592792749404907\n",
      "Epoch:  457 , Loss:  0.6312583684921265   f1-score: 0.760869562625885   accuracy: 0.8592792749404907\n",
      "Epoch:  458 , Loss:  0.6312346458435059   f1-score: 0.7609860897064209   accuracy: 0.8593693971633911\n",
      "Epoch:  459 , Loss:  0.6312108635902405   f1-score: 0.7613653540611267   accuracy: 0.8595495223999023\n",
      "Epoch:  460 , Loss:  0.6311870813369751   f1-score: 0.7615549564361572   accuracy: 0.8596396446228027\n",
      "Epoch:  461 , Loss:  0.6311633586883545   f1-score: 0.7617881298065186   accuracy: 0.8598198294639587\n",
      "Epoch:  462 , Loss:  0.6311395168304443   f1-score: 0.7619776725769043   accuracy: 0.8599098920822144\n",
      "Epoch:  463 , Loss:  0.6311158537864685   f1-score: 0.7619776725769043   accuracy: 0.8599098920822144\n",
      "Epoch:  464 , Loss:  0.6310920715332031   f1-score: 0.7619339227676392   accuracy: 0.8598198294639587\n",
      "Epoch:  465 , Loss:  0.6310683488845825   f1-score: 0.7619339227676392   accuracy: 0.8598198294639587\n",
      "Epoch:  466 , Loss:  0.6310445666313171   f1-score: 0.7619339227676392   accuracy: 0.8598198294639587\n",
      "Epoch:  467 , Loss:  0.6310210227966309   f1-score: 0.7617008090019226   accuracy: 0.8596396446228027\n",
      "Epoch:  468 , Loss:  0.6309974789619446   f1-score: 0.761890172958374   accuracy: 0.8597297072410583\n",
      "Epoch:  469 , Loss:  0.6309739351272583   f1-score: 0.761890172958374   accuracy: 0.8597297072410583\n",
      "Epoch:  470 , Loss:  0.6309504508972168   f1-score: 0.761890172958374   accuracy: 0.8597297072410583\n",
      "Epoch:  471 , Loss:  0.6309269666671753   f1-score: 0.7615113854408264   accuracy: 0.8595495223999023\n",
      "Epoch:  472 , Loss:  0.6309036612510681   f1-score: 0.7620067596435547   accuracy: 0.8598198294639587\n",
      "Epoch:  473 , Loss:  0.6308802366256714   f1-score: 0.7618173360824585   accuracy: 0.8597297072410583\n",
      "Epoch:  474 , Loss:  0.630856990814209   f1-score: 0.7620067596435547   accuracy: 0.8598198294639587\n",
      "Epoch:  475 , Loss:  0.6308336853981018   f1-score: 0.7620067596435547   accuracy: 0.8598198294639587\n",
      "Epoch:  476 , Loss:  0.6308104991912842   f1-score: 0.7623853087425232   accuracy: 0.8600000143051147\n",
      "Epoch:  477 , Loss:  0.6307873129844666   f1-score: 0.7622687816619873   accuracy: 0.8599098920822144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  478 , Loss:  0.6307643055915833   f1-score: 0.7622687816619873   accuracy: 0.8599098920822144\n",
      "Epoch:  479 , Loss:  0.6307411789894104   f1-score: 0.7622687816619873   accuracy: 0.8599098920822144\n",
      "Epoch:  480 , Loss:  0.6307181715965271   f1-score: 0.7621960639953613   accuracy: 0.8599098920822144\n",
      "Epoch:  481 , Loss:  0.6306952834129333   f1-score: 0.7623853087425232   accuracy: 0.8600000143051147\n",
      "Epoch:  482 , Loss:  0.63067227602005   f1-score: 0.7627636790275574   accuracy: 0.8601801991462708\n",
      "Epoch:  483 , Loss:  0.6306493878364563   f1-score: 0.7629527449607849   accuracy: 0.8602702617645264\n",
      "Epoch:  484 , Loss:  0.6306265592575073   f1-score: 0.7634474039077759   accuracy: 0.8605405688285828\n",
      "Epoch:  485 , Loss:  0.6306037306785583   f1-score: 0.7636363506317139   accuracy: 0.8606306314468384\n",
      "Epoch:  486 , Loss:  0.6305809617042542   f1-score: 0.7636363506317139   accuracy: 0.8606306314468384\n",
      "Epoch:  487 , Loss:  0.6305583119392395   f1-score: 0.7636363506317139   accuracy: 0.8606306314468384\n",
      "Epoch:  488 , Loss:  0.6305357813835144   f1-score: 0.7638252377510071   accuracy: 0.860720694065094\n",
      "Epoch:  489 , Loss:  0.6305131316184998   f1-score: 0.7638252377510071   accuracy: 0.860720694065094\n",
      "Epoch:  490 , Loss:  0.6304906010627747   f1-score: 0.7639419436454773   accuracy: 0.8608108162879944\n",
      "Epoch:  491 , Loss:  0.6304681301116943   f1-score: 0.7639419436454773   accuracy: 0.8608108162879944\n",
      "Epoch:  492 , Loss:  0.6304455995559692   f1-score: 0.7639419436454773   accuracy: 0.8608108162879944\n",
      "Epoch:  493 , Loss:  0.6304231882095337   f1-score: 0.7638252377510071   accuracy: 0.860720694065094\n",
      "Epoch:  494 , Loss:  0.6304008364677429   f1-score: 0.7640140652656555   accuracy: 0.8608108162879944\n",
      "Epoch:  495 , Loss:  0.6303786039352417   f1-score: 0.7638252377510071   accuracy: 0.860720694065094\n",
      "Epoch:  496 , Loss:  0.6303564310073853   f1-score: 0.7638252377510071   accuracy: 0.860720694065094\n",
      "Epoch:  497 , Loss:  0.6303342580795288   f1-score: 0.7637085914611816   accuracy: 0.8606306314468384\n",
      "Epoch:  498 , Loss:  0.6303122639656067   f1-score: 0.764086127281189   accuracy: 0.8608108162879944\n",
      "Epoch:  499 , Loss:  0.630290150642395   f1-score: 0.7638973593711853   accuracy: 0.860720694065094\n",
      "Epoch:  500 , Loss:  0.6302679777145386   f1-score: 0.7638973593711853   accuracy: 0.860720694065094\n",
      "Epoch:  501 , Loss:  0.6302459239959717   f1-score: 0.764086127281189   accuracy: 0.8608108162879944\n",
      "Epoch:  502 , Loss:  0.6302235722541809   f1-score: 0.7643914818763733   accuracy: 0.8609910011291504\n",
      "Epoch:  503 , Loss:  0.6302016973495483   f1-score: 0.7646968960762024   accuracy: 0.8611711859703064\n",
      "Epoch:  504 , Loss:  0.6301793456077576   f1-score: 0.7648136615753174   accuracy: 0.861261248588562\n",
      "Epoch:  505 , Loss:  0.6301576495170593   f1-score: 0.7650023102760315   accuracy: 0.8613513708114624\n",
      "Epoch:  506 , Loss:  0.6301354765892029   f1-score: 0.7651191353797913   accuracy: 0.861441433429718\n",
      "Epoch:  507 , Loss:  0.6301132440567017   f1-score: 0.7651191353797913   accuracy: 0.861441433429718\n",
      "Epoch:  508 , Loss:  0.6300911903381348   f1-score: 0.7654961943626404   accuracy: 0.861621618270874\n",
      "Epoch:  509 , Loss:  0.6300687193870544   f1-score: 0.7656846046447754   accuracy: 0.8617117404937744\n",
      "Epoch:  510 , Loss:  0.6300466656684875   f1-score: 0.7657561302185059   accuracy: 0.8617117404937744\n",
      "Epoch:  511 , Loss:  0.6300244927406311   f1-score: 0.7661327123641968   accuracy: 0.8618918657302856\n",
      "Epoch:  512 , Loss:  0.630002498626709   f1-score: 0.7661327123641968   accuracy: 0.8618918657302856\n",
      "Epoch:  513 , Loss:  0.6299802660942078   f1-score: 0.7666971683502197   accuracy: 0.862162172794342\n",
      "Epoch:  514 , Loss:  0.6299580335617065   f1-score: 0.7666971683502197   accuracy: 0.862162172794342\n",
      "Epoch:  515 , Loss:  0.6299358606338501   f1-score: 0.7665802836418152   accuracy: 0.8620720505714417\n",
      "Epoch:  516 , Loss:  0.6299136877059937   f1-score: 0.7668852210044861   accuracy: 0.8622522354125977\n",
      "Epoch:  517 , Loss:  0.6298914551734924   f1-score: 0.7670021057128906   accuracy: 0.862342357635498\n",
      "Epoch:  518 , Loss:  0.6298691630363464   f1-score: 0.7670021057128906   accuracy: 0.862342357635498\n",
      "Epoch:  519 , Loss:  0.6298467516899109   f1-score: 0.7670021057128906   accuracy: 0.862342357635498\n",
      "Epoch:  520 , Loss:  0.6298243403434753   f1-score: 0.7671900987625122   accuracy: 0.8624324202537537\n",
      "Epoch:  521 , Loss:  0.629801869392395   f1-score: 0.7671900987625122   accuracy: 0.8624324202537537\n",
      "Epoch:  522 , Loss:  0.6297793984413147   f1-score: 0.7673071026802063   accuracy: 0.862522542476654\n",
      "Epoch:  523 , Loss:  0.6297570466995239   f1-score: 0.7673071026802063   accuracy: 0.862522542476654\n",
      "Epoch:  524 , Loss:  0.6297345757484436   f1-score: 0.7673071026802063   accuracy: 0.862522542476654\n",
      "Epoch:  525 , Loss:  0.6297120451927185   f1-score: 0.7673071026802063   accuracy: 0.862522542476654\n",
      "Epoch:  526 , Loss:  0.6296896934509277   f1-score: 0.7671191096305847   accuracy: 0.8624324202537537\n",
      "Epoch:  527 , Loss:  0.6296671628952026   f1-score: 0.7674241065979004   accuracy: 0.8626126050949097\n",
      "Epoch:  528 , Loss:  0.6296445727348328   f1-score: 0.767799973487854   accuracy: 0.8627927899360657\n",
      "Epoch:  529 , Loss:  0.6296220421791077   f1-score: 0.767799973487854   accuracy: 0.8627927899360657\n",
      "Epoch:  530 , Loss:  0.6295995116233826   f1-score: 0.767799973487854   accuracy: 0.8627927899360657\n",
      "Epoch:  531 , Loss:  0.6295767426490784   f1-score: 0.767799973487854   accuracy: 0.8627927899360657\n",
      "Epoch:  532 , Loss:  0.629554033279419   f1-score: 0.7679170370101929   accuracy: 0.8628829121589661\n",
      "Epoch:  533 , Loss:  0.6295312643051147   f1-score: 0.7679170370101929   accuracy: 0.8628829121589661\n",
      "Epoch:  534 , Loss:  0.6295085549354553   f1-score: 0.7679170370101929   accuracy: 0.8628829121589661\n",
      "Epoch:  535 , Loss:  0.6294857859611511   f1-score: 0.7679170370101929   accuracy: 0.8628829121589661\n",
      "Epoch:  536 , Loss:  0.6294628977775574   f1-score: 0.7679170370101929   accuracy: 0.8628829121589661\n",
      "Epoch:  537 , Loss:  0.6294401288032532   f1-score: 0.7680341601371765   accuracy: 0.8629729747772217\n",
      "Epoch:  538 , Loss:  0.6294170022010803   f1-score: 0.7682220339775085   accuracy: 0.8630630373954773\n",
      "Epoch:  539 , Loss:  0.6293941736221313   f1-score: 0.7682220339775085   accuracy: 0.8630630373954773\n",
      "Epoch:  540 , Loss:  0.629371166229248   f1-score: 0.7684098482131958   accuracy: 0.8631531596183777\n",
      "Epoch:  541 , Loss:  0.6293479800224304   f1-score: 0.7684098482131958   accuracy: 0.8631531596183777\n",
      "Epoch:  542 , Loss:  0.6293248534202576   f1-score: 0.7684098482131958   accuracy: 0.8631531596183777\n",
      "Epoch:  543 , Loss:  0.6293017268180847   f1-score: 0.7684098482131958   accuracy: 0.8631531596183777\n",
      "Epoch:  544 , Loss:  0.6292786002159119   f1-score: 0.7685269713401794   accuracy: 0.8632432222366333\n",
      "Epoch:  545 , Loss:  0.6292552947998047   f1-score: 0.7686442136764526   accuracy: 0.8633333444595337\n",
      "Epoch:  546 , Loss:  0.6292321085929871   f1-score: 0.7692072987556458   accuracy: 0.8636035919189453\n",
      "Epoch:  547 , Loss:  0.6292087435722351   f1-score: 0.7693949341773987   accuracy: 0.8636937141418457\n",
      "Epoch:  548 , Loss:  0.6291854381561279   f1-score: 0.7693949341773987   accuracy: 0.8636937141418457\n",
      "Epoch:  549 , Loss:  0.6291621327400208   f1-score: 0.7695824503898621   accuracy: 0.8637837767601013\n",
      "Epoch:  550 , Loss:  0.6291387677192688   f1-score: 0.7698872089385986   accuracy: 0.8639639616012573\n",
      "Epoch:  551 , Loss:  0.6291153430938721   f1-score: 0.77019202709198   accuracy: 0.8641441464424133\n",
      "Epoch:  552 , Loss:  0.6290918588638306   f1-score: 0.7705667018890381   accuracy: 0.8643243312835693\n",
      "Epoch:  553 , Loss:  0.6290683150291443   f1-score: 0.7705667018890381   accuracy: 0.8643243312835693\n",
      "Epoch:  554 , Loss:  0.6290446519851685   f1-score: 0.7707539796829224   accuracy: 0.864414393901825\n",
      "Epoch:  555 , Loss:  0.6290212273597717   f1-score: 0.7707539796829224   accuracy: 0.864414393901825\n",
      "Epoch:  556 , Loss:  0.6289973855018616   f1-score: 0.7709411978721619   accuracy: 0.8645045161247253\n",
      "Epoch:  557 , Loss:  0.6289740800857544   f1-score: 0.7709411978721619   accuracy: 0.8645045161247253\n",
      "Epoch:  558 , Loss:  0.6289500594139099   f1-score: 0.7709411978721619   accuracy: 0.8645045161247253\n",
      "Epoch:  559 , Loss:  0.6289265155792236   f1-score: 0.7711283564567566   accuracy: 0.864594578742981\n",
      "Epoch:  560 , Loss:  0.6289026141166687   f1-score: 0.7713154554367065   accuracy: 0.8646847009658813\n",
      "Epoch:  561 , Loss:  0.6288788318634033   f1-score: 0.7713154554367065   accuracy: 0.8646847009658813\n",
      "Epoch:  562 , Loss:  0.6288550496101379   f1-score: 0.7713154554367065   accuracy: 0.8646847009658813\n",
      "Epoch:  563 , Loss:  0.628831148147583   f1-score: 0.7713154554367065   accuracy: 0.8646847009658813\n",
      "Epoch:  564 , Loss:  0.6288073658943176   f1-score: 0.7713154554367065   accuracy: 0.8646847009658813\n",
      "Epoch:  565 , Loss:  0.6287832856178284   f1-score: 0.7714329361915588   accuracy: 0.864774763584137\n",
      "Epoch:  566 , Loss:  0.6287593245506287   f1-score: 0.771619975566864   accuracy: 0.8648648858070374\n",
      "Epoch:  567 , Loss:  0.6287351846694946   f1-score: 0.7719244956970215   accuracy: 0.8650450706481934\n",
      "Epoch:  568 , Loss:  0.6287111043930054   f1-score: 0.772229015827179   accuracy: 0.8652251958847046\n",
      "Epoch:  569 , Loss:  0.6286869049072266   f1-score: 0.772229015827179   accuracy: 0.8652251958847046\n",
      "Epoch:  570 , Loss:  0.6286627054214478   f1-score: 0.772229015827179   accuracy: 0.8652251958847046\n",
      "Epoch:  571 , Loss:  0.6286385655403137   f1-score: 0.772229015827179   accuracy: 0.8652251958847046\n",
      "Epoch:  572 , Loss:  0.6286142468452454   f1-score: 0.772229015827179   accuracy: 0.8652251958847046\n",
      "Epoch:  573 , Loss:  0.6285898685455322   f1-score: 0.772229015827179   accuracy: 0.8652251958847046\n",
      "Epoch:  574 , Loss:  0.6285655498504639   f1-score: 0.7724158763885498   accuracy: 0.865315318107605\n",
      "Epoch:  575 , Loss:  0.6285410523414612   f1-score: 0.7727203369140625   accuracy: 0.865495502948761\n",
      "Epoch:  576 , Loss:  0.6285166144371033   f1-score: 0.7727203369140625   accuracy: 0.865495502948761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  577 , Loss:  0.628491997718811   f1-score: 0.7727895379066467   accuracy: 0.865495502948761\n",
      "Epoch:  578 , Loss:  0.6284673810005188   f1-score: 0.7728586792945862   accuracy: 0.865495502948761\n",
      "Epoch:  579 , Loss:  0.6284427642822266   f1-score: 0.7728586792945862   accuracy: 0.865495502948761\n",
      "Epoch:  580 , Loss:  0.6284180879592896   f1-score: 0.7730453014373779   accuracy: 0.8655855655670166\n",
      "Epoch:  581 , Loss:  0.6283932328224182   f1-score: 0.7730453014373779   accuracy: 0.8655855655670166\n",
      "Epoch:  582 , Loss:  0.6283684372901917   f1-score: 0.7730453014373779   accuracy: 0.8655855655670166\n",
      "Epoch:  583 , Loss:  0.6283435821533203   f1-score: 0.7736049890518188   accuracy: 0.865855872631073\n",
      "Epoch:  584 , Loss:  0.6283188462257385   f1-score: 0.7736049890518188   accuracy: 0.865855872631073\n",
      "Epoch:  585 , Loss:  0.6282936930656433   f1-score: 0.7737914323806763   accuracy: 0.8659459352493286\n",
      "Epoch:  586 , Loss:  0.628268837928772   f1-score: 0.7737914323806763   accuracy: 0.8659459352493286\n",
      "Epoch:  587 , Loss:  0.6282438039779663   f1-score: 0.7739090919494629   accuracy: 0.866036057472229\n",
      "Epoch:  588 , Loss:  0.6282188296318054   f1-score: 0.7740954756736755   accuracy: 0.8661261200904846\n",
      "Epoch:  589 , Loss:  0.6281937956809998   f1-score: 0.7740954756736755   accuracy: 0.8661261200904846\n",
      "Epoch:  590 , Loss:  0.6281687617301941   f1-score: 0.7746543288230896   accuracy: 0.8663963675498962\n",
      "Epoch:  591 , Loss:  0.6281437277793884   f1-score: 0.774772047996521   accuracy: 0.8664864897727966\n",
      "Epoch:  592 , Loss:  0.6281187534332275   f1-score: 0.7745857834815979   accuracy: 0.8663963675498962\n",
      "Epoch:  593 , Loss:  0.6280938982963562   f1-score: 0.7745857834815979   accuracy: 0.8663963675498962\n",
      "Epoch:  594 , Loss:  0.6280689835548401   f1-score: 0.7745857834815979   accuracy: 0.8663963675498962\n",
      "Epoch:  595 , Loss:  0.6280442476272583   f1-score: 0.7745857834815979   accuracy: 0.8663963675498962\n",
      "Epoch:  596 , Loss:  0.6280194520950317   f1-score: 0.7749581933021545   accuracy: 0.8665765523910522\n",
      "Epoch:  597 , Loss:  0.6279946565628052   f1-score: 0.7751443386077881   accuracy: 0.8666666746139526\n",
      "Epoch:  598 , Loss:  0.6279698610305786   f1-score: 0.7753304243087769   accuracy: 0.8667567372322083\n",
      "Epoch:  599 , Loss:  0.627945065498352   f1-score: 0.7755163908004761   accuracy: 0.8668468594551086\n",
      "Epoch:  600 , Loss:  0.627920389175415   f1-score: 0.7753986120223999   accuracy: 0.8667567372322083\n",
      "Epoch:  601 , Loss:  0.6278955936431885   f1-score: 0.775448203086853   accuracy: 0.8668468594551086\n",
      "Epoch:  602 , Loss:  0.6278710961341858   f1-score: 0.775448203086853   accuracy: 0.8668468594551086\n",
      "Epoch:  603 , Loss:  0.6278462409973145   f1-score: 0.775634229183197   accuracy: 0.8669369220733643\n",
      "Epoch:  604 , Loss:  0.6278218030929565   f1-score: 0.7760061025619507   accuracy: 0.8671171069145203\n",
      "Epoch:  605 , Loss:  0.6277971267700195   f1-score: 0.7761919498443604   accuracy: 0.8672072291374207\n",
      "Epoch:  606 , Loss:  0.6277723908424377   f1-score: 0.7766135334968567   accuracy: 0.8674774765968323\n",
      "Epoch:  607 , Loss:  0.6277478337287903   f1-score: 0.7766135334968567   accuracy: 0.8674774765968323\n",
      "Epoch:  608 , Loss:  0.6277232766151428   f1-score: 0.7766813635826111   accuracy: 0.8674774765968323\n",
      "Epoch:  609 , Loss:  0.6276987791061401   f1-score: 0.7766813635826111   accuracy: 0.8674774765968323\n",
      "Epoch:  610 , Loss:  0.6276743412017822   f1-score: 0.7766813635826111   accuracy: 0.8674774765968323\n",
      "Epoch:  611 , Loss:  0.6276500225067139   f1-score: 0.777052640914917   accuracy: 0.8676576614379883\n",
      "Epoch:  612 , Loss:  0.6276256442070007   f1-score: 0.7771202921867371   accuracy: 0.8676576614379883\n",
      "Epoch:  613 , Loss:  0.6276012659072876   f1-score: 0.7773058414459229   accuracy: 0.8677477240562439\n",
      "Epoch:  614 , Loss:  0.6275769472122192   f1-score: 0.7774237394332886   accuracy: 0.8678378462791443\n",
      "Epoch:  615 , Loss:  0.6275526881217957   f1-score: 0.7777946591377258   accuracy: 0.8680180311203003\n",
      "Epoch:  616 , Loss:  0.6275284886360168   f1-score: 0.7777271866798401   accuracy: 0.8680180311203003\n",
      "Epoch:  617 , Loss:  0.6275042295455933   f1-score: 0.7777271866798401   accuracy: 0.8680180311203003\n",
      "Epoch:  618 , Loss:  0.6274800896644592   f1-score: 0.7777271866798401   accuracy: 0.8680180311203003\n",
      "Epoch:  619 , Loss:  0.6274558305740356   f1-score: 0.7777946591377258   accuracy: 0.8680180311203003\n",
      "Epoch:  620 , Loss:  0.6274316906929016   f1-score: 0.7779799699783325   accuracy: 0.8681080937385559\n",
      "Epoch:  621 , Loss:  0.6274073719978333   f1-score: 0.7779799699783325   accuracy: 0.8681080937385559\n",
      "Epoch:  622 , Loss:  0.6273831129074097   f1-score: 0.7779799699783325   accuracy: 0.8681080937385559\n",
      "Epoch:  623 , Loss:  0.6273588538169861   f1-score: 0.7786537408828735   accuracy: 0.8684684634208679\n",
      "Epoch:  624 , Loss:  0.6273345351219177   f1-score: 0.7792758941650391   accuracy: 0.8687387108802795\n",
      "Epoch:  625 , Loss:  0.6273103952407837   f1-score: 0.7796456217765808   accuracy: 0.8689188957214355\n",
      "Epoch:  626 , Loss:  0.6272863149642944   f1-score: 0.7800151109695435   accuracy: 0.8690990805625916\n",
      "Epoch:  627 , Loss:  0.6272622346878052   f1-score: 0.7800151109695435   accuracy: 0.8690990805625916\n",
      "Epoch:  628 , Loss:  0.6272381544113159   f1-score: 0.7801998257637024   accuracy: 0.8691892027854919\n",
      "Epoch:  629 , Loss:  0.6272140741348267   f1-score: 0.7803844213485718   accuracy: 0.8692792654037476\n",
      "Epoch:  630 , Loss:  0.627190113067627   f1-score: 0.7803844213485718   accuracy: 0.8692792654037476\n",
      "Epoch:  631 , Loss:  0.6271661520004272   f1-score: 0.7802663445472717   accuracy: 0.8691892027854919\n",
      "Epoch:  632 , Loss:  0.6271421909332275   f1-score: 0.780687153339386   accuracy: 0.8694594502449036\n",
      "Epoch:  633 , Loss:  0.6271181702613831   f1-score: 0.7808053493499756   accuracy: 0.869549572467804\n",
      "Epoch:  634 , Loss:  0.6270942687988281   f1-score: 0.780687153339386   accuracy: 0.8694594502449036\n",
      "Epoch:  635 , Loss:  0.627070426940918   f1-score: 0.7812405228614807   accuracy: 0.86972975730896\n",
      "Epoch:  636 , Loss:  0.6270464062690735   f1-score: 0.7812405228614807   accuracy: 0.86972975730896\n",
      "Epoch:  637 , Loss:  0.6270227432250977   f1-score: 0.781424880027771   accuracy: 0.8698198199272156\n",
      "Epoch:  638 , Loss:  0.626998782157898   f1-score: 0.7816091775894165   accuracy: 0.8699098825454712\n",
      "Epoch:  639 , Loss:  0.6269752383232117   f1-score: 0.7819775938987732   accuracy: 0.8700900673866272\n",
      "Epoch:  640 , Loss:  0.6269513964653015   f1-score: 0.7819775938987732   accuracy: 0.8700900673866272\n",
      "Epoch:  641 , Loss:  0.6269278526306152   f1-score: 0.7820435166358948   accuracy: 0.8700900673866272\n",
      "Epoch:  642 , Loss:  0.6269042491912842   f1-score: 0.7820435166358948   accuracy: 0.8700900673866272\n",
      "Epoch:  643 , Loss:  0.6268806457519531   f1-score: 0.7822275757789612   accuracy: 0.8701801896095276\n",
      "Epoch:  644 , Loss:  0.6268570423126221   f1-score: 0.7828320860862732   accuracy: 0.8705405592918396\n",
      "Epoch:  645 , Loss:  0.6268333792686462   f1-score: 0.7828320860862732   accuracy: 0.8705405592918396\n",
      "Epoch:  646 , Loss:  0.6268097162246704   f1-score: 0.7828320860862732   accuracy: 0.8705405592918396\n",
      "Epoch:  647 , Loss:  0.6267861723899841   f1-score: 0.7828977108001709   accuracy: 0.8705405592918396\n",
      "Epoch:  648 , Loss:  0.626762866973877   f1-score: 0.783081591129303   accuracy: 0.8706306219100952\n",
      "Epoch:  649 , Loss:  0.6267392039299011   f1-score: 0.7832653522491455   accuracy: 0.8707207441329956\n",
      "Epoch:  650 , Loss:  0.626716136932373   f1-score: 0.7832125425338745   accuracy: 0.8706306219100952\n",
      "Epoch:  651 , Loss:  0.626692533493042   f1-score: 0.7833962440490723   accuracy: 0.8707207441329956\n",
      "Epoch:  652 , Loss:  0.6266694068908691   f1-score: 0.7833962440490723   accuracy: 0.8707207441329956\n",
      "Epoch:  653 , Loss:  0.6266458034515381   f1-score: 0.7833962440490723   accuracy: 0.8707207441329956\n",
      "Epoch:  654 , Loss:  0.6266223192214966   f1-score: 0.7835144996643066   accuracy: 0.8708108067512512\n",
      "Epoch:  655 , Loss:  0.6265989542007446   f1-score: 0.7835798263549805   accuracy: 0.8708108067512512\n",
      "Epoch:  656 , Loss:  0.626575231552124   f1-score: 0.7836981415748596   accuracy: 0.8709009289741516\n",
      "Epoch:  657 , Loss:  0.6265519857406616   f1-score: 0.783881664276123   accuracy: 0.8709909915924072\n",
      "Epoch:  658 , Loss:  0.6265287399291992   f1-score: 0.7836981415748596   accuracy: 0.8709009289741516\n",
      "Epoch:  659 , Loss:  0.6265050172805786   f1-score: 0.783881664276123   accuracy: 0.8709909915924072\n",
      "Epoch:  660 , Loss:  0.6264817118644714   f1-score: 0.783881664276123   accuracy: 0.8709909915924072\n",
      "Epoch:  661 , Loss:  0.6264584064483643   f1-score: 0.7839999794960022   accuracy: 0.8710810542106628\n",
      "Epoch:  662 , Loss:  0.6264348030090332   f1-score: 0.7845503687858582   accuracy: 0.8713513612747192\n",
      "Epoch:  663 , Loss:  0.6264115571975708   f1-score: 0.7849170565605164   accuracy: 0.8715315461158752\n",
      "Epoch:  664 , Loss:  0.6263882517814636   f1-score: 0.785153865814209   accuracy: 0.8717117309570312\n",
      "Epoch:  665 , Loss:  0.6263647675514221   f1-score: 0.7853371500968933   accuracy: 0.8718017935752869\n",
      "Epoch:  666 , Loss:  0.6263414621353149   f1-score: 0.7856388688087463   accuracy: 0.8719819784164429\n",
      "Epoch:  667 , Loss:  0.626318097114563   f1-score: 0.7856388688087463   accuracy: 0.8719819784164429\n",
      "Epoch:  668 , Loss:  0.6262946724891663   f1-score: 0.7858220338821411   accuracy: 0.8720721006393433\n",
      "Epoch:  669 , Loss:  0.6262713074684143   f1-score: 0.7859405875205994   accuracy: 0.8721621632575989\n",
      "Epoch:  670 , Loss:  0.6262481808662415   f1-score: 0.7863067388534546   accuracy: 0.8723423480987549\n",
      "Epoch:  671 , Loss:  0.6262246370315552   f1-score: 0.7861236929893494   accuracy: 0.8722522258758545\n",
      "Epoch:  672 , Loss:  0.6262013912200928   f1-score: 0.7861236929893494   accuracy: 0.8722522258758545\n",
      "Epoch:  673 , Loss:  0.6261781454086304   f1-score: 0.7863711714744568   accuracy: 0.8723423480987549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  674 , Loss:  0.6261546611785889   f1-score: 0.786489725112915   accuracy: 0.8724324107170105\n",
      "Epoch:  675 , Loss:  0.6261314153671265   f1-score: 0.7866727113723755   accuracy: 0.8725225329399109\n",
      "Epoch:  676 , Loss:  0.6261081099510193   f1-score: 0.7866727113723755   accuracy: 0.8725225329399109\n",
      "Epoch:  677 , Loss:  0.6260848641395569   f1-score: 0.7868555784225464   accuracy: 0.8726125955581665\n",
      "Epoch:  678 , Loss:  0.6260616779327393   f1-score: 0.7870384454727173   accuracy: 0.8727027177810669\n",
      "Epoch:  679 , Loss:  0.6260383725166321   f1-score: 0.7872211933135986   accuracy: 0.8727927803993225\n",
      "Epoch:  680 , Loss:  0.6260151267051697   f1-score: 0.7873398661613464   accuracy: 0.8728829026222229\n",
      "Epoch:  681 , Loss:  0.6259920597076416   f1-score: 0.7878239750862122   accuracy: 0.8731531500816345\n",
      "Epoch:  682 , Loss:  0.6259686350822449   f1-score: 0.7878239750862122   accuracy: 0.8731531500816345\n",
      "Epoch:  683 , Loss:  0.6259454488754272   f1-score: 0.7878239750862122   accuracy: 0.8731531500816345\n",
      "Epoch:  684 , Loss:  0.6259223222732544   f1-score: 0.7878239750862122   accuracy: 0.8731531500816345\n",
      "Epoch:  685 , Loss:  0.6258987784385681   f1-score: 0.7878239750862122   accuracy: 0.8731531500816345\n",
      "Epoch:  686 , Loss:  0.6258754730224609   f1-score: 0.7878239750862122   accuracy: 0.8731531500816345\n",
      "Epoch:  687 , Loss:  0.6258521676063538   f1-score: 0.7881892323493958   accuracy: 0.8733333349227905\n",
      "Epoch:  688 , Loss:  0.6258286833763123   f1-score: 0.7881892323493958   accuracy: 0.8733333349227905\n",
      "Epoch:  689 , Loss:  0.6258054375648499   f1-score: 0.788371741771698   accuracy: 0.8734233975410461\n",
      "Epoch:  690 , Loss:  0.6257820725440979   f1-score: 0.7885541915893555   accuracy: 0.8735135197639465\n",
      "Epoch:  691 , Loss:  0.6257588863372803   f1-score: 0.7886179089546204   accuracy: 0.8735135197639465\n",
      "Epoch:  692 , Loss:  0.6257355213165283   f1-score: 0.7886179089546204   accuracy: 0.8735135197639465\n",
      "Epoch:  693 , Loss:  0.6257122755050659   f1-score: 0.7884354591369629   accuracy: 0.8734233975410461\n",
      "Epoch:  694 , Loss:  0.6256887316703796   f1-score: 0.7886179089546204   accuracy: 0.8735135197639465\n",
      "Epoch:  695 , Loss:  0.6256654262542725   f1-score: 0.7888002395629883   accuracy: 0.8736035823822021\n",
      "Epoch:  696 , Loss:  0.6256420612335205   f1-score: 0.789046049118042   accuracy: 0.8736937046051025\n",
      "Epoch:  697 , Loss:  0.625618577003479   f1-score: 0.7889273166656494   accuracy: 0.8736035823822021\n",
      "Epoch:  698 , Loss:  0.6255952715873718   f1-score: 0.7889273166656494   accuracy: 0.8736035823822021\n",
      "Epoch:  699 , Loss:  0.6255719065666199   f1-score: 0.7889273166656494   accuracy: 0.8736035823822021\n",
      "Epoch:  700 , Loss:  0.6255486011505127   f1-score: 0.7889273166656494   accuracy: 0.8736035823822021\n",
      "Epoch:  701 , Loss:  0.6255252361297607   f1-score: 0.7892916202545166   accuracy: 0.8737837672233582\n",
      "Epoch:  702 , Loss:  0.6255018711090088   f1-score: 0.7894103527069092   accuracy: 0.8738738894462585\n",
      "Epoch:  703 , Loss:  0.6254786252975464   f1-score: 0.789592444896698   accuracy: 0.8739639520645142\n",
      "Epoch:  704 , Loss:  0.6254552006721497   f1-score: 0.7899563908576965   accuracy: 0.8741441369056702\n",
      "Epoch:  705 , Loss:  0.6254318952560425   f1-score: 0.7899563908576965   accuracy: 0.8741441369056702\n",
      "Epoch:  706 , Loss:  0.6254083514213562   f1-score: 0.7899563908576965   accuracy: 0.8741441369056702\n",
      "Epoch:  707 , Loss:  0.6253851056098938   f1-score: 0.7899563908576965   accuracy: 0.8741441369056702\n",
      "Epoch:  708 , Loss:  0.6253616809844971   f1-score: 0.7899563908576965   accuracy: 0.8741441369056702\n",
      "Epoch:  709 , Loss:  0.6253381967544556   f1-score: 0.790138304233551   accuracy: 0.8742342591285706\n",
      "Epoch:  710 , Loss:  0.6253150105476379   f1-score: 0.7903201580047607   accuracy: 0.8743243217468262\n",
      "Epoch:  711 , Loss:  0.6252913475036621   f1-score: 0.7904389500617981   accuracy: 0.8744144439697266\n",
      "Epoch:  712 , Loss:  0.6252680420875549   f1-score: 0.790802538394928   accuracy: 0.8745945692062378\n",
      "Epoch:  713 , Loss:  0.6252444386482239   f1-score: 0.790802538394928   accuracy: 0.8745945692062378\n",
      "Epoch:  714 , Loss:  0.6252209544181824   f1-score: 0.790802538394928   accuracy: 0.8745945692062378\n",
      "Epoch:  715 , Loss:  0.6251974105834961   f1-score: 0.7915289998054504   accuracy: 0.8749549388885498\n",
      "Epoch:  716 , Loss:  0.6251741051673889   f1-score: 0.7919483184814453   accuracy: 0.8752252459526062\n",
      "Epoch:  717 , Loss:  0.6251502633094788   f1-score: 0.7923111319541931   accuracy: 0.8754054307937622\n",
      "Epoch:  718 , Loss:  0.6251271367073059   f1-score: 0.7923111319541931   accuracy: 0.8754054307937622\n",
      "Epoch:  719 , Loss:  0.6251034736633301   f1-score: 0.7923111319541931   accuracy: 0.8754054307937622\n",
      "Epoch:  720 , Loss:  0.6250801682472229   f1-score: 0.7924925088882446   accuracy: 0.8754954934120178\n",
      "Epoch:  721 , Loss:  0.6250565648078918   f1-score: 0.7928550243377686   accuracy: 0.8756756782531738\n",
      "Epoch:  722 , Loss:  0.6250331997871399   f1-score: 0.7928550243377686   accuracy: 0.8756756782531738\n",
      "Epoch:  723 , Loss:  0.6250097155570984   f1-score: 0.793036162853241   accuracy: 0.8757657408714294\n",
      "Epoch:  724 , Loss:  0.6249861121177673   f1-score: 0.792792797088623   accuracy: 0.8756756782531738\n",
      "Epoch:  725 , Loss:  0.6249625086784363   f1-score: 0.7929118275642395   accuracy: 0.8757657408714294\n",
      "Epoch:  726 , Loss:  0.6249390244483948   f1-score: 0.7929118275642395   accuracy: 0.8757657408714294\n",
      "Epoch:  727 , Loss:  0.6249154806137085   f1-score: 0.792974054813385   accuracy: 0.8757657408714294\n",
      "Epoch:  728 , Loss:  0.6248916983604431   f1-score: 0.7928550243377686   accuracy: 0.8756756782531738\n",
      "Epoch:  729 , Loss:  0.6248683929443359   f1-score: 0.792974054813385   accuracy: 0.8757657408714294\n",
      "Epoch:  730 , Loss:  0.6248446106910706   f1-score: 0.7931551933288574   accuracy: 0.8758558630943298\n",
      "Epoch:  731 , Loss:  0.624821126461029   f1-score: 0.7931551933288574   accuracy: 0.8758558630943298\n",
      "Epoch:  732 , Loss:  0.6247975826263428   f1-score: 0.7933363318443298   accuracy: 0.8759459257125854\n",
      "Epoch:  733 , Loss:  0.6247740387916565   f1-score: 0.7934554219245911   accuracy: 0.8760360479354858\n",
      "Epoch:  734 , Loss:  0.6247503161430359   f1-score: 0.7936365008354187   accuracy: 0.8761261105537415\n",
      "Epoch:  735 , Loss:  0.6247268319129944   f1-score: 0.7938175201416016   accuracy: 0.8762162327766418\n",
      "Epoch:  736 , Loss:  0.6247029304504395   f1-score: 0.7939984798431396   accuracy: 0.8763062953948975\n",
      "Epoch:  737 , Loss:  0.624679446220398   f1-score: 0.7938793897628784   accuracy: 0.8762162327766418\n",
      "Epoch:  738 , Loss:  0.6246556639671326   f1-score: 0.7942411303520203   accuracy: 0.8763964176177979\n",
      "Epoch:  739 , Loss:  0.6246320605278015   f1-score: 0.7942411303520203   accuracy: 0.8763964176177979\n",
      "Epoch:  740 , Loss:  0.6246082186698914   f1-score: 0.7942411303520203   accuracy: 0.8763964176177979\n",
      "Epoch:  741 , Loss:  0.624584436416626   f1-score: 0.7948410511016846   accuracy: 0.8767567276954651\n",
      "Epoch:  742 , Loss:  0.6245606541633606   f1-score: 0.795202374458313   accuracy: 0.8769369125366211\n",
      "Epoch:  743 , Loss:  0.6245368719100952   f1-score: 0.7955635786056519   accuracy: 0.8771170973777771\n",
      "Epoch:  744 , Loss:  0.6245131492614746   f1-score: 0.7957440614700317   accuracy: 0.8772072196006775\n",
      "Epoch:  745 , Loss:  0.6244894862174988   f1-score: 0.7957440614700317   accuracy: 0.8772072196006775\n",
      "Epoch:  746 , Loss:  0.6244655251502991   f1-score: 0.7959244847297668   accuracy: 0.8772972822189331\n",
      "Epoch:  747 , Loss:  0.6244419813156128   f1-score: 0.7964654564857483   accuracy: 0.8775675892829895\n",
      "Epoch:  748 , Loss:  0.6244180202484131   f1-score: 0.7964654564857483   accuracy: 0.8775675892829895\n",
      "Epoch:  749 , Loss:  0.6243942379951477   f1-score: 0.7963461875915527   accuracy: 0.8774774670600891\n",
      "Epoch:  750 , Loss:  0.6243704557418823   f1-score: 0.7970667481422424   accuracy: 0.8778378367424011\n",
      "Epoch:  751 , Loss:  0.6243465542793274   f1-score: 0.7970667481422424   accuracy: 0.8778378367424011\n",
      "Epoch:  752 , Loss:  0.6243226528167725   f1-score: 0.797426700592041   accuracy: 0.8780180215835571\n",
      "Epoch:  753 , Loss:  0.6242989301681519   f1-score: 0.797426700592041   accuracy: 0.8780180215835571\n",
      "Epoch:  754 , Loss:  0.624274730682373   f1-score: 0.797426700592041   accuracy: 0.8780180215835571\n",
      "Epoch:  755 , Loss:  0.6242509484291077   f1-score: 0.7976065874099731   accuracy: 0.8781080842018127\n",
      "Epoch:  756 , Loss:  0.6242267489433289   f1-score: 0.7976065874099731   accuracy: 0.8781080842018127\n",
      "Epoch:  757 , Loss:  0.6242029070854187   f1-score: 0.7977259159088135   accuracy: 0.8781982064247131\n",
      "Epoch:  758 , Loss:  0.6241787672042847   f1-score: 0.7977259159088135   accuracy: 0.8781982064247131\n",
      "Epoch:  759 , Loss:  0.6241546273231506   f1-score: 0.7979057431221008   accuracy: 0.8782882690429688\n",
      "Epoch:  760 , Loss:  0.6241305470466614   f1-score: 0.7979057431221008   accuracy: 0.8782882690429688\n",
      "Epoch:  761 , Loss:  0.6241064071655273   f1-score: 0.7974854111671448   accuracy: 0.8781080842018127\n",
      "Epoch:  762 , Loss:  0.6240823864936829   f1-score: 0.7979646921157837   accuracy: 0.8783783912658691\n",
      "Epoch:  763 , Loss:  0.6240584850311279   f1-score: 0.7979646921157837   accuracy: 0.8783783912658691\n",
      "Epoch:  764 , Loss:  0.6240344643592834   f1-score: 0.7983243465423584   accuracy: 0.8785585761070251\n",
      "Epoch:  765 , Loss:  0.6240100860595703   f1-score: 0.7986235618591309   accuracy: 0.8787387609481812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  766 , Loss:  0.6239861249923706   f1-score: 0.7989227771759033   accuracy: 0.8789189457893372\n",
      "Epoch:  767 , Loss:  0.6239618062973022   f1-score: 0.7991024851799011   accuracy: 0.8790090084075928\n",
      "Epoch:  768 , Loss:  0.6239380240440369   f1-score: 0.7991024851799011   accuracy: 0.8790090084075928\n",
      "Epoch:  769 , Loss:  0.6239137649536133   f1-score: 0.7991024851799011   accuracy: 0.8790090084075928\n",
      "Epoch:  770 , Loss:  0.6238898038864136   f1-score: 0.7991024851799011   accuracy: 0.8790090084075928\n",
      "Epoch:  771 , Loss:  0.6238656044006348   f1-score: 0.7994016408920288   accuracy: 0.8791891932487488\n",
      "Epoch:  772 , Loss:  0.6238415241241455   f1-score: 0.79934161901474   accuracy: 0.8791891932487488\n",
      "Epoch:  773 , Loss:  0.6238175630569458   f1-score: 0.79934161901474   accuracy: 0.8791891932487488\n",
      "Epoch:  774 , Loss:  0.6237933039665222   f1-score: 0.7991619110107422   accuracy: 0.8790990710258484\n",
      "Epoch:  775 , Loss:  0.6237693428993225   f1-score: 0.7998204827308655   accuracy: 0.8794594407081604\n",
      "Epoch:  776 , Loss:  0.6237451434135437   f1-score: 0.8001794815063477   accuracy: 0.8796396255493164\n",
      "Epoch:  777 , Loss:  0.6237208843231201   f1-score: 0.8001794815063477   accuracy: 0.8796396255493164\n",
      "Epoch:  778 , Loss:  0.6236968040466309   f1-score: 0.8002991676330566   accuracy: 0.8797297477722168\n",
      "Epoch:  779 , Loss:  0.6236724853515625   f1-score: 0.8002991676330566   accuracy: 0.8797297477722168\n",
      "Epoch:  780 , Loss:  0.623648464679718   f1-score: 0.8004786372184753   accuracy: 0.8798198103904724\n",
      "Epoch:  781 , Loss:  0.6236241459846497   f1-score: 0.8004786372184753   accuracy: 0.8798198103904724\n",
      "Epoch:  782 , Loss:  0.6236000061035156   f1-score: 0.8006579875946045   accuracy: 0.8799099326133728\n",
      "Epoch:  783 , Loss:  0.623575747013092   f1-score: 0.8006579875946045   accuracy: 0.8799099326133728\n",
      "Epoch:  784 , Loss:  0.6235517263412476   f1-score: 0.8005383014678955   accuracy: 0.8798198103904724\n",
      "Epoch:  785 , Loss:  0.623527467250824   f1-score: 0.8006579875946045   accuracy: 0.8799099326133728\n",
      "Epoch:  786 , Loss:  0.6235033273696899   f1-score: 0.8007777333259583   accuracy: 0.8799999952316284\n",
      "Epoch:  787 , Loss:  0.6234791278839111   f1-score: 0.8012561798095703   accuracy: 0.88027024269104\n",
      "Epoch:  788 , Loss:  0.6234549283981323   f1-score: 0.8014354109764099   accuracy: 0.8803603649139404\n",
      "Epoch:  789 , Loss:  0.6234306693077087   f1-score: 0.8017936944961548   accuracy: 0.8805405497550964\n",
      "Epoch:  790 , Loss:  0.6234064698219299   f1-score: 0.8017936944961548   accuracy: 0.8805405497550964\n",
      "Epoch:  791 , Loss:  0.6233823895454407   f1-score: 0.8017936944961548   accuracy: 0.8805405497550964\n",
      "Epoch:  792 , Loss:  0.6233581304550171   f1-score: 0.8019136190414429   accuracy: 0.880630612373352\n",
      "Epoch:  793 , Loss:  0.6233338713645935   f1-score: 0.8022717237472534   accuracy: 0.8808107972145081\n",
      "Epoch:  794 , Loss:  0.6233094930648804   f1-score: 0.8026295900344849   accuracy: 0.8809909820556641\n",
      "Epoch:  795 , Loss:  0.6232852935791016   f1-score: 0.8026295900344849   accuracy: 0.8809909820556641\n",
      "Epoch:  796 , Loss:  0.6232608556747437   f1-score: 0.8026295900344849   accuracy: 0.8809909820556641\n",
      "Epoch:  797 , Loss:  0.6232365965843201   f1-score: 0.8026295900344849   accuracy: 0.8809909820556641\n",
      "Epoch:  798 , Loss:  0.6232122182846069   f1-score: 0.8028084635734558   accuracy: 0.8810811042785645\n",
      "Epoch:  799 , Loss:  0.623187780380249   f1-score: 0.8028084635734558   accuracy: 0.8810811042785645\n",
      "Epoch:  800 , Loss:  0.6231632232666016   f1-score: 0.8028084635734558   accuracy: 0.8810811042785645\n",
      "Epoch:  801 , Loss:  0.6231386661529541   f1-score: 0.8032272458076477   accuracy: 0.8813513517379761\n",
      "Epoch:  802 , Loss:  0.6231141686439514   f1-score: 0.8034060597419739   accuracy: 0.8814414143562317\n",
      "Epoch:  803 , Loss:  0.6230896711349487   f1-score: 0.8035847544670105   accuracy: 0.8815315365791321\n",
      "Epoch:  804 , Loss:  0.6230651140213013   f1-score: 0.8035847544670105   accuracy: 0.8815315365791321\n",
      "Epoch:  805 , Loss:  0.6230407357215881   f1-score: 0.8034647703170776   accuracy: 0.8814414143562317\n",
      "Epoch:  806 , Loss:  0.6230161190032959   f1-score: 0.8037634491920471   accuracy: 0.8816215991973877\n",
      "Epoch:  807 , Loss:  0.6229919195175171   f1-score: 0.803942084312439   accuracy: 0.8817117214202881\n",
      "Epoch:  808 , Loss:  0.6229673624038696   f1-score: 0.803942084312439   accuracy: 0.8817117214202881\n",
      "Epoch:  809 , Loss:  0.622943103313446   f1-score: 0.804120659828186   accuracy: 0.8818017840385437\n",
      "Epoch:  810 , Loss:  0.6229186058044434   f1-score: 0.8042991757392883   accuracy: 0.8818919062614441\n",
      "Epoch:  811 , Loss:  0.6228943467140198   f1-score: 0.8046560287475586   accuracy: 0.8820720911026001\n",
      "Epoch:  812 , Loss:  0.6228700280189514   f1-score: 0.8048343658447266   accuracy: 0.8821621537208557\n",
      "Epoch:  813 , Loss:  0.6228458881378174   f1-score: 0.804954469203949   accuracy: 0.8822522759437561\n",
      "Epoch:  814 , Loss:  0.6228216886520386   f1-score: 0.804954469203949   accuracy: 0.8822522759437561\n",
      "Epoch:  815 , Loss:  0.6227973699569702   f1-score: 0.8050746321678162   accuracy: 0.8823423385620117\n",
      "Epoch:  816 , Loss:  0.6227731704711914   f1-score: 0.8052529692649841   accuracy: 0.8824324607849121\n",
      "Epoch:  817 , Loss:  0.6227489113807678   f1-score: 0.8053731322288513   accuracy: 0.8825225234031677\n",
      "Epoch:  818 , Loss:  0.6227247714996338   f1-score: 0.8056716322898865   accuracy: 0.8827027082443237\n",
      "Epoch:  819 , Loss:  0.622700572013855   f1-score: 0.8057919144630432   accuracy: 0.8827927708625793\n",
      "Epoch:  820 , Loss:  0.6226766705513   f1-score: 0.8057919144630432   accuracy: 0.8827927708625793\n",
      "Epoch:  821 , Loss:  0.6226524114608765   f1-score: 0.8057919144630432   accuracy: 0.8827927708625793\n",
      "Epoch:  822 , Loss:  0.6226285696029663   f1-score: 0.8056716322898865   accuracy: 0.8827027082443237\n",
      "Epoch:  823 , Loss:  0.6226044297218323   f1-score: 0.8056716322898865   accuracy: 0.8827027082443237\n",
      "Epoch:  824 , Loss:  0.6225804090499878   f1-score: 0.8058498501777649   accuracy: 0.8827927708625793\n",
      "Epoch:  825 , Loss:  0.6225566864013672   f1-score: 0.8060280680656433   accuracy: 0.8828828930854797\n",
      "Epoch:  826 , Loss:  0.6225325465202332   f1-score: 0.8063264489173889   accuracy: 0.8830630779266357\n",
      "Epoch:  827 , Loss:  0.6225087642669678   f1-score: 0.8065045475959778   accuracy: 0.8831531405448914\n",
      "Epoch:  828 , Loss:  0.6224849224090576   f1-score: 0.8066825866699219   accuracy: 0.8832432627677917\n",
      "Epoch:  829 , Loss:  0.622461199760437   f1-score: 0.8066825866699219   accuracy: 0.8832432627677917\n",
      "Epoch:  830 , Loss:  0.6224372982978821   f1-score: 0.8066825866699219   accuracy: 0.8832432627677917\n",
      "Epoch:  831 , Loss:  0.6224136352539062   f1-score: 0.8066825866699219   accuracy: 0.8832432627677917\n",
      "Epoch:  832 , Loss:  0.6223897933959961   f1-score: 0.8068029284477234   accuracy: 0.8833333253860474\n",
      "Epoch:  833 , Loss:  0.6223659515380859   f1-score: 0.8068605661392212   accuracy: 0.8833333253860474\n",
      "Epoch:  834 , Loss:  0.6223424077033997   f1-score: 0.8068605661392212   accuracy: 0.8833333253860474\n",
      "Epoch:  835 , Loss:  0.6223184466362   f1-score: 0.8069809079170227   accuracy: 0.8834234476089478\n",
      "Epoch:  836 , Loss:  0.6222947835922241   f1-score: 0.807336688041687   accuracy: 0.8836036324501038\n",
      "Epoch:  837 , Loss:  0.6222708821296692   f1-score: 0.8075145483016968   accuracy: 0.8836936950683594\n",
      "Epoch:  838 , Loss:  0.6222470998764038   f1-score: 0.807692289352417   accuracy: 0.883783757686615\n",
      "Epoch:  839 , Loss:  0.6222232580184937   f1-score: 0.8080477118492126   accuracy: 0.883963942527771\n",
      "Epoch:  840 , Loss:  0.6221994161605835   f1-score: 0.8078700304031372   accuracy: 0.8838738799095154\n",
      "Epoch:  841 , Loss:  0.6221757531166077   f1-score: 0.8081048727035522   accuracy: 0.883963942527771\n",
      "Epoch:  842 , Loss:  0.6221519112586975   f1-score: 0.8081048727035522   accuracy: 0.883963942527771\n",
      "Epoch:  843 , Loss:  0.6221280694007874   f1-score: 0.8081048727035522   accuracy: 0.883963942527771\n",
      "Epoch:  844 , Loss:  0.6221043467521667   f1-score: 0.8081048727035522   accuracy: 0.883963942527771\n",
      "Epoch:  845 , Loss:  0.6220806837081909   f1-score: 0.8082824349403381   accuracy: 0.8840540647506714\n",
      "Epoch:  846 , Loss:  0.6220570206642151   f1-score: 0.8082824349403381   accuracy: 0.8840540647506714\n",
      "Epoch:  847 , Loss:  0.6220333576202393   f1-score: 0.8082824349403381   accuracy: 0.8840540647506714\n",
      "Epoch:  848 , Loss:  0.6220098733901978   f1-score: 0.8084599375724792   accuracy: 0.884144127368927\n",
      "Epoch:  849 , Loss:  0.6219863295555115   f1-score: 0.8085169792175293   accuracy: 0.884144127368927\n",
      "Epoch:  850 , Loss:  0.6219626069068909   f1-score: 0.8086943626403809   accuracy: 0.8842342495918274\n",
      "Epoch:  851 , Loss:  0.6219391226768494   f1-score: 0.8088147640228271   accuracy: 0.884324312210083\n",
      "Epoch:  852 , Loss:  0.6219154000282288   f1-score: 0.8086373805999756   accuracy: 0.8842342495918274\n",
      "Epoch:  853 , Loss:  0.6218920946121216   f1-score: 0.8086373805999756   accuracy: 0.8842342495918274\n",
      "Epoch:  854 , Loss:  0.6218684315681458   f1-score: 0.8088147640228271   accuracy: 0.884324312210083\n",
      "Epoch:  855 , Loss:  0.6218449473381042   f1-score: 0.809346616268158   accuracy: 0.8845946192741394\n",
      "Epoch:  856 , Loss:  0.6218214631080627   f1-score: 0.8095238208770752   accuracy: 0.884684681892395\n",
      "Epoch:  857 , Loss:  0.6217979192733765   f1-score: 0.8095238208770752   accuracy: 0.884684681892395\n",
      "Epoch:  858 , Loss:  0.621774435043335   f1-score: 0.8095238208770752   accuracy: 0.884684681892395\n",
      "Epoch:  859 , Loss:  0.6217509508132935   f1-score: 0.8095238208770752   accuracy: 0.884684681892395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  860 , Loss:  0.621727466583252   f1-score: 0.8098779916763306   accuracy: 0.884864866733551\n",
      "Epoch:  861 , Loss:  0.6217041611671448   f1-score: 0.8098779916763306   accuracy: 0.884864866733551\n",
      "Epoch:  862 , Loss:  0.6216805577278137   f1-score: 0.8098214268684387   accuracy: 0.884864866733551\n",
      "Epoch:  863 , Loss:  0.6216574311256409   f1-score: 0.8102960586547852   accuracy: 0.8851351141929626\n",
      "Epoch:  864 , Loss:  0.6216338872909546   f1-score: 0.8106499910354614   accuracy: 0.8853152990341187\n",
      "Epoch:  865 , Loss:  0.6216105222702026   f1-score: 0.8111804723739624   accuracy: 0.885585606098175\n",
      "Epoch:  866 , Loss:  0.6215871572494507   f1-score: 0.8113572001457214   accuracy: 0.8856756687164307\n",
      "Epoch:  867 , Loss:  0.621563732624054   f1-score: 0.8115338683128357   accuracy: 0.885765790939331\n",
      "Epoch:  868 , Loss:  0.621540367603302   f1-score: 0.81171053647995   accuracy: 0.8858558535575867\n",
      "Epoch:  869 , Loss:  0.6215167045593262   f1-score: 0.81171053647995   accuracy: 0.8858558535575867\n",
      "Epoch:  870 , Loss:  0.6214934587478638   f1-score: 0.8115338683128357   accuracy: 0.885765790939331\n",
      "Epoch:  871 , Loss:  0.6214699745178223   f1-score: 0.8118311762809753   accuracy: 0.8859459161758423\n",
      "Epoch:  872 , Loss:  0.6214466094970703   f1-score: 0.8120635747909546   accuracy: 0.8860360383987427\n",
      "Epoch:  873 , Loss:  0.6214228868484497   f1-score: 0.8120635747909546   accuracy: 0.8860360383987427\n",
      "Epoch:  874 , Loss:  0.621399462223053   f1-score: 0.8123607039451599   accuracy: 0.8862162232398987\n",
      "Epoch:  875 , Loss:  0.6213756203651428   f1-score: 0.8125371336936951   accuracy: 0.8863062858581543\n",
      "Epoch:  876 , Loss:  0.6213520765304565   f1-score: 0.8127785921096802   accuracy: 0.8864864706993103\n",
      "Epoch:  877 , Loss:  0.6213282346725464   f1-score: 0.8127785921096802   accuracy: 0.8864864706993103\n",
      "Epoch:  878 , Loss:  0.6213045716285706   f1-score: 0.8129549622535706   accuracy: 0.8865765929222107\n",
      "Epoch:  879 , Loss:  0.6212807297706604   f1-score: 0.8133075833320618   accuracy: 0.8867567777633667\n",
      "Epoch:  880 , Loss:  0.6212567687034607   f1-score: 0.8133075833320618   accuracy: 0.8867567777633667\n",
      "Epoch:  881 , Loss:  0.6212329268455505   f1-score: 0.8133075833320618   accuracy: 0.8867567777633667\n",
      "Epoch:  882 , Loss:  0.621208906173706   f1-score: 0.8136046528816223   accuracy: 0.8869369626045227\n",
      "Epoch:  883 , Loss:  0.6211848855018616   f1-score: 0.8137807846069336   accuracy: 0.8870270252227783\n",
      "Epoch:  884 , Loss:  0.6211609244346619   f1-score: 0.8137807846069336   accuracy: 0.8870270252227783\n",
      "Epoch:  885 , Loss:  0.6211369037628174   f1-score: 0.8141329884529114   accuracy: 0.8872072100639343\n",
      "Epoch:  886 , Loss:  0.6211128234863281   f1-score: 0.8144850134849548   accuracy: 0.8873873949050903\n",
      "Epoch:  887 , Loss:  0.6210888624191284   f1-score: 0.8144850134849548   accuracy: 0.8873873949050903\n",
      "Epoch:  888 , Loss:  0.6210647225379944   f1-score: 0.8150126338005066   accuracy: 0.887657642364502\n",
      "Epoch:  889 , Loss:  0.6210407018661499   f1-score: 0.8151883482933044   accuracy: 0.8877477645874023\n",
      "Epoch:  890 , Loss:  0.621016800403595   f1-score: 0.8153092861175537   accuracy: 0.887837827205658\n",
      "Epoch:  891 , Loss:  0.6209927797317505   f1-score: 0.8156606554985046   accuracy: 0.888018012046814\n",
      "Epoch:  892 , Loss:  0.6209691166877747   f1-score: 0.8157816529273987   accuracy: 0.8881081342697144\n",
      "Epoch:  893 , Loss:  0.620945155620575   f1-score: 0.8159027099609375   accuracy: 0.88819819688797\n",
      "Epoch:  894 , Loss:  0.6209213137626648   f1-score: 0.8161993622779846   accuracy: 0.888378381729126\n",
      "Epoch:  895 , Loss:  0.6208975911140442   f1-score: 0.8163749575614929   accuracy: 0.8884684443473816\n",
      "Epoch:  896 , Loss:  0.6208738088607788   f1-score: 0.8163749575614929   accuracy: 0.8884684443473816\n",
      "Epoch:  897 , Loss:  0.6208502650260925   f1-score: 0.8167259693145752   accuracy: 0.8886486291885376\n",
      "Epoch:  898 , Loss:  0.6208266615867615   f1-score: 0.8167259693145752   accuracy: 0.8886486291885376\n",
      "Epoch:  899 , Loss:  0.6208028197288513   f1-score: 0.8167259693145752   accuracy: 0.8886486291885376\n",
      "Epoch:  900 , Loss:  0.6207795143127441   f1-score: 0.8167259693145752   accuracy: 0.8886486291885376\n",
      "Epoch:  901 , Loss:  0.6207559108734131   f1-score: 0.8167259693145752   accuracy: 0.8886486291885376\n",
      "Epoch:  902 , Loss:  0.6207326650619507   f1-score: 0.8167259693145752   accuracy: 0.8886486291885376\n",
      "Epoch:  903 , Loss:  0.6207093000411987   f1-score: 0.8167259693145752   accuracy: 0.8886486291885376\n",
      "Epoch:  904 , Loss:  0.6206860542297363   f1-score: 0.8167259693145752   accuracy: 0.8886486291885376\n",
      "Epoch:  905 , Loss:  0.6206628084182739   f1-score: 0.8167259693145752   accuracy: 0.8886486291885376\n",
      "Epoch:  906 , Loss:  0.6206393837928772   f1-score: 0.8167259693145752   accuracy: 0.8886486291885376\n",
      "Epoch:  907 , Loss:  0.6206161975860596   f1-score: 0.8172520995140076   accuracy: 0.888918936252594\n",
      "Epoch:  908 , Loss:  0.6205928325653076   f1-score: 0.8173732757568359   accuracy: 0.8890089988708496\n",
      "Epoch:  909 , Loss:  0.6205695867538452   f1-score: 0.8174944519996643   accuracy: 0.88909912109375\n",
      "Epoch:  910 , Loss:  0.620546281337738   f1-score: 0.8176697492599487   accuracy: 0.8891891837120056\n",
      "Epoch:  911 , Loss:  0.6205230355262756   f1-score: 0.8176697492599487   accuracy: 0.8891891837120056\n",
      "Epoch:  912 , Loss:  0.6204997897148132   f1-score: 0.8176697492599487   accuracy: 0.8891891837120056\n",
      "Epoch:  913 , Loss:  0.6204766631126404   f1-score: 0.8177909851074219   accuracy: 0.889279305934906\n",
      "Epoch:  914 , Loss:  0.6204534769058228   f1-score: 0.8177909851074219   accuracy: 0.889279305934906\n",
      "Epoch:  915 , Loss:  0.6204302906990051   f1-score: 0.8177909851074219   accuracy: 0.889279305934906\n",
      "Epoch:  916 , Loss:  0.6204071640968323   f1-score: 0.8179662227630615   accuracy: 0.8893693685531616\n",
      "Epoch:  917 , Loss:  0.6203839778900146   f1-score: 0.8181414008140564   accuracy: 0.8894594311714172\n",
      "Epoch:  918 , Loss:  0.6203608512878418   f1-score: 0.8181414008140564   accuracy: 0.8894594311714172\n",
      "Epoch:  919 , Loss:  0.6203376054763794   f1-score: 0.8181414008140564   accuracy: 0.8894594311714172\n",
      "Epoch:  920 , Loss:  0.6203144788742065   f1-score: 0.8183165192604065   accuracy: 0.8895495533943176\n",
      "Epoch:  921 , Loss:  0.6202908754348755   f1-score: 0.8183165192604065   accuracy: 0.8895495533943176\n",
      "Epoch:  922 , Loss:  0.6202677488327026   f1-score: 0.8183165192604065   accuracy: 0.8895495533943176\n",
      "Epoch:  923 , Loss:  0.6202443242073059   f1-score: 0.8184916377067566   accuracy: 0.8896396160125732\n",
      "Epoch:  924 , Loss:  0.6202210187911987   f1-score: 0.8186666369438171   accuracy: 0.8897297382354736\n",
      "Epoch:  925 , Loss:  0.620197594165802   f1-score: 0.8190165758132935   accuracy: 0.8899099230766296\n",
      "Epoch:  926 , Loss:  0.62017422914505   f1-score: 0.8190165758132935   accuracy: 0.8899099230766296\n",
      "Epoch:  927 , Loss:  0.6201509237289429   f1-score: 0.8193662762641907   accuracy: 0.8900901079177856\n",
      "Epoch:  928 , Loss:  0.6201275587081909   f1-score: 0.8193662762641907   accuracy: 0.8900901079177856\n",
      "Epoch:  929 , Loss:  0.6201042532920837   f1-score: 0.8190701603889465   accuracy: 0.8899099230766296\n",
      "Epoch:  930 , Loss:  0.6200807094573975   f1-score: 0.8188952803611755   accuracy: 0.8898198008537292\n",
      "Epoch:  931 , Loss:  0.6200577020645142   f1-score: 0.8190701603889465   accuracy: 0.8899099230766296\n",
      "Epoch:  932 , Loss:  0.6200340986251831   f1-score: 0.8193128108978271   accuracy: 0.8900901079177856\n",
      "Epoch:  933 , Loss:  0.6200108528137207   f1-score: 0.8193128108978271   accuracy: 0.8900901079177856\n",
      "Epoch:  934 , Loss:  0.6199873685836792   f1-score: 0.8196624517440796   accuracy: 0.8902702927589417\n",
      "Epoch:  935 , Loss:  0.6199638843536377   f1-score: 0.8196624517440796   accuracy: 0.8902702927589417\n",
      "Epoch:  936 , Loss:  0.6199405789375305   f1-score: 0.8196624517440796   accuracy: 0.8902702927589417\n",
      "Epoch:  937 , Loss:  0.6199169754981995   f1-score: 0.8198371529579163   accuracy: 0.8903603553771973\n",
      "Epoch:  938 , Loss:  0.6198934316635132   f1-score: 0.8199585676193237   accuracy: 0.8904504776000977\n",
      "Epoch:  939 , Loss:  0.6198700070381165   f1-score: 0.8199585676193237   accuracy: 0.8904504776000977\n",
      "Epoch:  940 , Loss:  0.6198465824127197   f1-score: 0.8201332092285156   accuracy: 0.8905405402183533\n",
      "Epoch:  941 , Loss:  0.6198228597640991   f1-score: 0.8201332092285156   accuracy: 0.8905405402183533\n",
      "Epoch:  942 , Loss:  0.6197996139526367   f1-score: 0.8204293251037598   accuracy: 0.8907207250595093\n",
      "Epoch:  943 , Loss:  0.6197759509086609   f1-score: 0.8206039071083069   accuracy: 0.8908107876777649\n",
      "Epoch:  944 , Loss:  0.6197527050971985   f1-score: 0.8206039071083069   accuracy: 0.8908107876777649\n",
      "Epoch:  945 , Loss:  0.619729220867157   f1-score: 0.8206039071083069   accuracy: 0.8908107876777649\n",
      "Epoch:  946 , Loss:  0.6197057366371155   f1-score: 0.8207784295082092   accuracy: 0.8909009099006653\n",
      "Epoch:  947 , Loss:  0.6196824312210083   f1-score: 0.8207784295082092   accuracy: 0.8909009099006653\n",
      "Epoch:  948 , Loss:  0.6196591258049011   f1-score: 0.8209529519081116   accuracy: 0.8909909725189209\n",
      "Epoch:  949 , Loss:  0.6196359395980835   f1-score: 0.8207784295082092   accuracy: 0.8909009099006653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  950 , Loss:  0.6196125745773315   f1-score: 0.8207784295082092   accuracy: 0.8909009099006653\n",
      "Epoch:  951 , Loss:  0.6195895075798035   f1-score: 0.8209529519081116   accuracy: 0.8909909725189209\n",
      "Epoch:  952 , Loss:  0.6195663809776306   f1-score: 0.8211274147033691   accuracy: 0.8910810947418213\n",
      "Epoch:  953 , Loss:  0.6195431351661682   f1-score: 0.8211274147033691   accuracy: 0.8910810947418213\n",
      "Epoch:  954 , Loss:  0.6195201277732849   f1-score: 0.8211274147033691   accuracy: 0.8910810947418213\n",
      "Epoch:  955 , Loss:  0.6194969415664673   f1-score: 0.8214761018753052   accuracy: 0.8912612795829773\n",
      "Epoch:  956 , Loss:  0.6194738745689392   f1-score: 0.8214761018753052   accuracy: 0.8912612795829773\n",
      "Epoch:  957 , Loss:  0.6194508671760559   f1-score: 0.8217719197273254   accuracy: 0.8914414644241333\n",
      "Epoch:  958 , Loss:  0.6194279193878174   f1-score: 0.8219461441040039   accuracy: 0.8915315270423889\n",
      "Epoch:  959 , Loss:  0.6194049715995789   f1-score: 0.8219461441040039   accuracy: 0.8915315270423889\n",
      "Epoch:  960 , Loss:  0.6193819046020508   f1-score: 0.8219461441040039   accuracy: 0.8915315270423889\n",
      "Epoch:  961 , Loss:  0.6193591952323914   f1-score: 0.8222419619560242   accuracy: 0.8917117118835449\n",
      "Epoch:  962 , Loss:  0.6193363666534424   f1-score: 0.8224160671234131   accuracy: 0.8918017745018005\n",
      "Epoch:  963 , Loss:  0.6193133592605591   f1-score: 0.8224160671234131   accuracy: 0.8918017745018005\n",
      "Epoch:  964 , Loss:  0.6192904710769653   f1-score: 0.822590172290802   accuracy: 0.8918918967247009\n",
      "Epoch:  965 , Loss:  0.6192676424980164   f1-score: 0.822590172290802   accuracy: 0.8918918967247009\n",
      "Epoch:  966 , Loss:  0.6192446947097778   f1-score: 0.8229382038116455   accuracy: 0.8920720815658569\n",
      "Epoch:  967 , Loss:  0.6192220449447632   f1-score: 0.8230598568916321   accuracy: 0.8921621441841125\n",
      "Epoch:  968 , Loss:  0.6191990375518799   f1-score: 0.8230598568916321   accuracy: 0.8921621441841125\n",
      "Epoch:  969 , Loss:  0.6191765069961548   f1-score: 0.8230598568916321   accuracy: 0.8921621441841125\n",
      "Epoch:  970 , Loss:  0.6191536784172058   f1-score: 0.8232338428497314   accuracy: 0.8922522664070129\n",
      "Epoch:  971 , Loss:  0.6191307902336121   f1-score: 0.8234077095985413   accuracy: 0.8923423290252686\n",
      "Epoch:  972 , Loss:  0.6191082000732422   f1-score: 0.8234077095985413   accuracy: 0.8923423290252686\n",
      "Epoch:  973 , Loss:  0.6190853714942932   f1-score: 0.8234077095985413   accuracy: 0.8923423290252686\n",
      "Epoch:  974 , Loss:  0.6190627217292786   f1-score: 0.8235815763473511   accuracy: 0.892432451248169\n",
      "Epoch:  975 , Loss:  0.6190400719642639   f1-score: 0.8235815763473511   accuracy: 0.892432451248169\n",
      "Epoch:  976 , Loss:  0.6190173625946045   f1-score: 0.8239290714263916   accuracy: 0.892612636089325\n",
      "Epoch:  977 , Loss:  0.6189947128295898   f1-score: 0.8241028189659119   accuracy: 0.8927026987075806\n",
      "Epoch:  978 , Loss:  0.6189720630645752   f1-score: 0.8242764472961426   accuracy: 0.892792820930481\n",
      "Epoch:  979 , Loss:  0.6189494729042053   f1-score: 0.8245717883110046   accuracy: 0.8929729461669922\n",
      "Epoch:  980 , Loss:  0.6189267635345459   f1-score: 0.824918806552887   accuracy: 0.8931531310081482\n",
      "Epoch:  981 , Loss:  0.6189044117927551   f1-score: 0.824918806552887   accuracy: 0.8931531310081482\n",
      "Epoch:  982 , Loss:  0.6188817024230957   f1-score: 0.824918806552887   accuracy: 0.8931531310081482\n",
      "Epoch:  983 , Loss:  0.6188591718673706   f1-score: 0.8252140283584595   accuracy: 0.8933333158493042\n",
      "Epoch:  984 , Loss:  0.6188367009162903   f1-score: 0.8252140283584595   accuracy: 0.8933333158493042\n",
      "Epoch:  985 , Loss:  0.6188140511512756   f1-score: 0.8252140283584595   accuracy: 0.8933333158493042\n",
      "Epoch:  986 , Loss:  0.6187916994094849   f1-score: 0.8252140283584595   accuracy: 0.8933333158493042\n",
      "Epoch:  987 , Loss:  0.6187692284584045   f1-score: 0.8252140283584595   accuracy: 0.8933333158493042\n",
      "Epoch:  988 , Loss:  0.6187467575073242   f1-score: 0.8253874778747559   accuracy: 0.8934234380722046\n",
      "Epoch:  989 , Loss:  0.6187244057655334   f1-score: 0.8255608081817627   accuracy: 0.8935135006904602\n",
      "Epoch:  990 , Loss:  0.6187018156051636   f1-score: 0.8255608081817627   accuracy: 0.8935135006904602\n",
      "Epoch:  991 , Loss:  0.6186797618865967   f1-score: 0.8255608081817627   accuracy: 0.8935135006904602\n",
      "Epoch:  992 , Loss:  0.6186572909355164   f1-score: 0.8255608081817627   accuracy: 0.8935135006904602\n",
      "Epoch:  993 , Loss:  0.6186347603797913   f1-score: 0.8256826400756836   accuracy: 0.8936036229133606\n",
      "Epoch:  994 , Loss:  0.6186125874519348   f1-score: 0.8256826400756836   accuracy: 0.8936036229133606\n",
      "Epoch:  995 , Loss:  0.6185899972915649   f1-score: 0.8260292410850525   accuracy: 0.8937838077545166\n",
      "Epoch:  996 , Loss:  0.618567705154419   f1-score: 0.826202392578125   accuracy: 0.8938738703727722\n",
      "Epoch:  997 , Loss:  0.6185452938079834   f1-score: 0.8263755440711975   accuracy: 0.8939639925956726\n",
      "Epoch:  998 , Loss:  0.6185231804847717   f1-score: 0.8263755440711975   accuracy: 0.8939639925956726\n",
      "Epoch:  999 , Loss:  0.6185007691383362   f1-score: 0.8266705870628357   accuracy: 0.8941441178321838\n",
      "Epoch:  1000 , Loss:  0.6184784173965454   f1-score: 0.82654869556427   accuracy: 0.8940540552139282\n",
      "Epoch:  1001 , Loss:  0.6184563040733337   f1-score: 0.826721727848053   accuracy: 0.8941441178321838\n",
      "Epoch:  1002 , Loss:  0.6184338927268982   f1-score: 0.8266705870628357   accuracy: 0.8941441178321838\n",
      "Epoch:  1003 , Loss:  0.6184118986129761   f1-score: 0.8266705870628357   accuracy: 0.8941441178321838\n",
      "Epoch:  1004 , Loss:  0.6183894276618958   f1-score: 0.8269656300544739   accuracy: 0.8943243026733398\n",
      "Epoch:  1005 , Loss:  0.618367612361908   f1-score: 0.8272606730461121   accuracy: 0.8945044875144958\n",
      "Epoch:  1006 , Loss:  0.6183452010154724   f1-score: 0.8270876407623291   accuracy: 0.8944144248962402\n",
      "Epoch:  1007 , Loss:  0.6183233261108398   f1-score: 0.8272096514701843   accuracy: 0.8945044875144958\n",
      "Epoch:  1008 , Loss:  0.6183010935783386   f1-score: 0.8272096514701843   accuracy: 0.8945044875144958\n",
      "Epoch:  1009 , Loss:  0.6182790994644165   f1-score: 0.8272096514701843   accuracy: 0.8945044875144958\n",
      "Epoch:  1010 , Loss:  0.6182571649551392   f1-score: 0.8272096514701843   accuracy: 0.8945044875144958\n",
      "Epoch:  1011 , Loss:  0.6182352900505066   f1-score: 0.8272096514701843   accuracy: 0.8945044875144958\n",
      "Epoch:  1012 , Loss:  0.6182133555412292   f1-score: 0.8275048136711121   accuracy: 0.8946846723556519\n",
      "Epoch:  1013 , Loss:  0.6181914210319519   f1-score: 0.8275048136711121   accuracy: 0.8946846723556519\n",
      "Epoch:  1014 , Loss:  0.6181694269180298   f1-score: 0.8274538516998291   accuracy: 0.8946846723556519\n",
      "Epoch:  1015 , Loss:  0.6181474328041077   f1-score: 0.827799916267395   accuracy: 0.8948648571968079\n",
      "Epoch:  1016 , Loss:  0.6181256771087646   f1-score: 0.827799916267395   accuracy: 0.8948648571968079\n",
      "Epoch:  1017 , Loss:  0.6181036233901978   f1-score: 0.827799916267395   accuracy: 0.8948648571968079\n",
      "Epoch:  1018 , Loss:  0.61808180809021   f1-score: 0.8279221057891846   accuracy: 0.8949549794197083\n",
      "Epoch:  1019 , Loss:  0.6180599331855774   f1-score: 0.8277490735054016   accuracy: 0.8948648571968079\n",
      "Epoch:  1020 , Loss:  0.6180379986763   f1-score: 0.8282679319381714   accuracy: 0.8951351642608643\n",
      "Epoch:  1021 , Loss:  0.618016242980957   f1-score: 0.8286135792732239   accuracy: 0.8953152894973755\n",
      "Epoch:  1022 , Loss:  0.6179943084716797   f1-score: 0.828095018863678   accuracy: 0.8950450420379639\n",
      "Epoch:  1023 , Loss:  0.6179723739624023   f1-score: 0.828095018863678   accuracy: 0.8950450420379639\n",
      "Epoch:  1024 , Loss:  0.6179505586624146   f1-score: 0.82844078540802   accuracy: 0.8952252268791199\n",
      "Epoch:  1025 , Loss:  0.6179286241531372   f1-score: 0.82844078540802   accuracy: 0.8952252268791199\n",
      "Epoch:  1026 , Loss:  0.6179066300392151   f1-score: 0.82844078540802   accuracy: 0.8952252268791199\n",
      "Epoch:  1027 , Loss:  0.6178848147392273   f1-score: 0.82844078540802   accuracy: 0.8952252268791199\n",
      "Epoch:  1028 , Loss:  0.6178628206253052   f1-score: 0.82844078540802   accuracy: 0.8952252268791199\n",
      "Epoch:  1029 , Loss:  0.6178407073020935   f1-score: 0.8286135792732239   accuracy: 0.8953152894973755\n",
      "Epoch:  1030 , Loss:  0.6178187131881714   f1-score: 0.828786313533783   accuracy: 0.8954054117202759\n",
      "Epoch:  1031 , Loss:  0.617796778678894   f1-score: 0.8289589881896973   accuracy: 0.8954954743385315\n",
      "Epoch:  1032 , Loss:  0.6177746057510376   f1-score: 0.8289589881896973   accuracy: 0.8954954743385315\n",
      "Epoch:  1033 , Loss:  0.6177526116371155   f1-score: 0.8289589881896973   accuracy: 0.8954954743385315\n",
      "Epoch:  1034 , Loss:  0.6177303194999695   f1-score: 0.8294265270233154   accuracy: 0.8957657814025879\n",
      "Epoch:  1035 , Loss:  0.617708146572113   f1-score: 0.8294265270233154   accuracy: 0.8957657814025879\n",
      "Epoch:  1036 , Loss:  0.6176859140396118   f1-score: 0.8294265270233154   accuracy: 0.8957657814025879\n",
      "Epoch:  1037 , Loss:  0.6176636815071106   f1-score: 0.8295990824699402   accuracy: 0.8958558440208435\n",
      "Epoch:  1038 , Loss:  0.6176415681838989   f1-score: 0.8295990824699402   accuracy: 0.8958558440208435\n",
      "Epoch:  1039 , Loss:  0.6176193356513977   f1-score: 0.8297715783119202   accuracy: 0.8959459662437439\n",
      "Epoch:  1040 , Loss:  0.6175971627235413   f1-score: 0.8298938870429993   accuracy: 0.8960360288619995\n",
      "Epoch:  1041 , Loss:  0.6175748705863953   f1-score: 0.8300663232803345   accuracy: 0.8961261510848999\n",
      "Epoch:  1042 , Loss:  0.6175527572631836   f1-score: 0.8301886916160583   accuracy: 0.8962162137031555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1043 , Loss:  0.6175304651260376   f1-score: 0.8300161957740784   accuracy: 0.8961261510848999\n",
      "Epoch:  1044 , Loss:  0.6175081729888916   f1-score: 0.8301886916160583   accuracy: 0.8962162137031555\n",
      "Epoch:  1045 , Loss:  0.6174861192703247   f1-score: 0.8303610682487488   accuracy: 0.8963063359260559\n",
      "Epoch:  1046 , Loss:  0.6174639463424683   f1-score: 0.8308780193328857   accuracy: 0.8965765833854675\n",
      "Epoch:  1047 , Loss:  0.617441713809967   f1-score: 0.8305334448814392   accuracy: 0.8963963985443115\n",
      "Epoch:  1048 , Loss:  0.6174197196960449   f1-score: 0.8308780193328857   accuracy: 0.8965765833854675\n",
      "Epoch:  1049 , Loss:  0.6173975467681885   f1-score: 0.8310502171516418   accuracy: 0.8966666460037231\n",
      "Epoch:  1050 , Loss:  0.6173752546310425   f1-score: 0.8313448429107666   accuracy: 0.8968468308448792\n",
      "Epoch:  1051 , Loss:  0.6173532009124756   f1-score: 0.831222414970398   accuracy: 0.8967567682266235\n",
      "Epoch:  1052 , Loss:  0.6173309087753296   f1-score: 0.831222414970398   accuracy: 0.8967567682266235\n",
      "Epoch:  1053 , Loss:  0.6173087358474731   f1-score: 0.8313944935798645   accuracy: 0.8968468308448792\n",
      "Epoch:  1054 , Loss:  0.6172864437103271   f1-score: 0.8313944935798645   accuracy: 0.8968468308448792\n",
      "Epoch:  1055 , Loss:  0.6172642111778259   f1-score: 0.8316394090652466   accuracy: 0.8970270156860352\n",
      "Epoch:  1056 , Loss:  0.6172418594360352   f1-score: 0.8317619562149048   accuracy: 0.8971171379089355\n",
      "Epoch:  1057 , Loss:  0.6172193884849548   f1-score: 0.8315169215202332   accuracy: 0.8969369530677795\n",
      "Epoch:  1058 , Loss:  0.6171969175338745   f1-score: 0.8316890001296997   accuracy: 0.8970270156860352\n",
      "Epoch:  1059 , Loss:  0.6171744465827942   f1-score: 0.8319340348243713   accuracy: 0.8972072005271912\n",
      "Epoch:  1060 , Loss:  0.6171518564224243   f1-score: 0.8321060538291931   accuracy: 0.8972973227500916\n",
      "Epoch:  1061 , Loss:  0.6171292662620544   f1-score: 0.8318610191345215   accuracy: 0.8971171379089355\n",
      "Epoch:  1062 , Loss:  0.617106556892395   f1-score: 0.8321554660797119   accuracy: 0.8972973227500916\n",
      "Epoch:  1063 , Loss:  0.6170840263366699   f1-score: 0.8324499130249023   accuracy: 0.8974774479866028\n",
      "Epoch:  1064 , Loss:  0.6170612573623657   f1-score: 0.8324499130249023   accuracy: 0.8974774479866028\n",
      "Epoch:  1065 , Loss:  0.6170385479927063   f1-score: 0.8326218128204346   accuracy: 0.8975675702095032\n",
      "Epoch:  1066 , Loss:  0.6170157790184021   f1-score: 0.832916259765625   accuracy: 0.8977477550506592\n",
      "Epoch:  1067 , Loss:  0.6169928908348083   f1-score: 0.8332106471061707   accuracy: 0.8979279398918152\n",
      "Epoch:  1068 , Loss:  0.6169701814651489   f1-score: 0.8333823680877686   accuracy: 0.8980180025100708\n",
      "Epoch:  1069 , Loss:  0.6169469952583313   f1-score: 0.8335540890693665   accuracy: 0.8981081247329712\n",
      "Epoch:  1070 , Loss:  0.6169239282608032   f1-score: 0.8335540890693665   accuracy: 0.8981081247329712\n",
      "Epoch:  1071 , Loss:  0.6169008612632751   f1-score: 0.8335540890693665   accuracy: 0.8981081247329712\n",
      "Epoch:  1072 , Loss:  0.616877555847168   f1-score: 0.8335540890693665   accuracy: 0.8981081247329712\n",
      "Epoch:  1073 , Loss:  0.6168544292449951   f1-score: 0.8338972926139832   accuracy: 0.8982883095741272\n",
      "Epoch:  1074 , Loss:  0.6168311238288879   f1-score: 0.8340200185775757   accuracy: 0.8983783721923828\n",
      "Epoch:  1075 , Loss:  0.6168079972267151   f1-score: 0.8340200185775757   accuracy: 0.8983783721923828\n",
      "Epoch:  1076 , Loss:  0.6167846322059631   f1-score: 0.8338484168052673   accuracy: 0.8982883095741272\n",
      "Epoch:  1077 , Loss:  0.6167615056037903   f1-score: 0.8338484168052673   accuracy: 0.8982883095741272\n",
      "Epoch:  1078 , Loss:  0.6167381405830383   f1-score: 0.8340939283370972   accuracy: 0.8984684944152832\n",
      "Epoch:  1079 , Loss:  0.6167149543762207   f1-score: 0.8340939283370972   accuracy: 0.8984684944152832\n",
      "Epoch:  1080 , Loss:  0.6166917681694031   f1-score: 0.8342655301094055   accuracy: 0.8985585570335388\n",
      "Epoch:  1081 , Loss:  0.6166685819625854   f1-score: 0.8342655301094055   accuracy: 0.8985585570335388\n",
      "Epoch:  1082 , Loss:  0.6166454553604126   f1-score: 0.8342655301094055   accuracy: 0.8985585570335388\n",
      "Epoch:  1083 , Loss:  0.6166225075721741   f1-score: 0.8342655301094055   accuracy: 0.8985585570335388\n",
      "Epoch:  1084 , Loss:  0.6165995597839355   f1-score: 0.8345599174499512   accuracy: 0.8987387418746948\n",
      "Epoch:  1085 , Loss:  0.6165764927864075   f1-score: 0.83473140001297   accuracy: 0.8988288044929504\n",
      "Epoch:  1086 , Loss:  0.616553544998169   f1-score: 0.83473140001297   accuracy: 0.8988288044929504\n",
      "Epoch:  1087 , Loss:  0.6165305972099304   f1-score: 0.83473140001297   accuracy: 0.8988288044929504\n",
      "Epoch:  1088 , Loss:  0.6165075302124023   f1-score: 0.83473140001297   accuracy: 0.8988288044929504\n",
      "Epoch:  1089 , Loss:  0.6164847612380981   f1-score: 0.8349028825759888   accuracy: 0.8989189267158508\n",
      "Epoch:  1090 , Loss:  0.6164618730545044   f1-score: 0.8349514603614807   accuracy: 0.8989189267158508\n",
      "Epoch:  1091 , Loss:  0.6164389252662659   f1-score: 0.83512282371521   accuracy: 0.8990089893341064\n",
      "Epoch:  1092 , Loss:  0.6164160966873169   f1-score: 0.835245668888092   accuracy: 0.8990991115570068\n",
      "Epoch:  1093 , Loss:  0.6163930892944336   f1-score: 0.8354169726371765   accuracy: 0.8991891741752625\n",
      "Epoch:  1094 , Loss:  0.6163700222969055   f1-score: 0.8355882167816162   accuracy: 0.8992792963981628\n",
      "Epoch:  1095 , Loss:  0.6163471341133118   f1-score: 0.8355882167816162   accuracy: 0.8992792963981628\n",
      "Epoch:  1096 , Loss:  0.6163241267204285   f1-score: 0.8355882167816162   accuracy: 0.8992792963981628\n",
      "Epoch:  1097 , Loss:  0.6163010597229004   f1-score: 0.8355882167816162   accuracy: 0.8992792963981628\n",
      "Epoch:  1098 , Loss:  0.6162777543067932   f1-score: 0.8354169726371765   accuracy: 0.8991891741752625\n",
      "Epoch:  1099 , Loss:  0.6162545680999756   f1-score: 0.8355882167816162   accuracy: 0.8992792963981628\n",
      "Epoch:  1100 , Loss:  0.6162313222885132   f1-score: 0.8355882167816162   accuracy: 0.8992792963981628\n",
      "Epoch:  1101 , Loss:  0.6162080764770508   f1-score: 0.8357111215591431   accuracy: 0.8993693590164185\n",
      "Epoch:  1102 , Loss:  0.6161847114562988   f1-score: 0.8357111215591431   accuracy: 0.8993693590164185\n",
      "Epoch:  1103 , Loss:  0.6161611676216125   f1-score: 0.8362246155738831   accuracy: 0.8996396660804749\n",
      "Epoch:  1104 , Loss:  0.6161375641822815   f1-score: 0.8362246155738831   accuracy: 0.8996396660804749\n",
      "Epoch:  1105 , Loss:  0.6161140203475952   f1-score: 0.8362246155738831   accuracy: 0.8996396660804749\n",
      "Epoch:  1106 , Loss:  0.6160904169082642   f1-score: 0.8363956809043884   accuracy: 0.8997297286987305\n",
      "Epoch:  1107 , Loss:  0.6160666942596436   f1-score: 0.8365667462348938   accuracy: 0.8998197913169861\n",
      "Epoch:  1108 , Loss:  0.6160430908203125   f1-score: 0.8365667462348938   accuracy: 0.8998197913169861\n",
      "Epoch:  1109 , Loss:  0.6160193085670471   f1-score: 0.8365186452865601   accuracy: 0.8998197913169861\n",
      "Epoch:  1110 , Loss:  0.6159956455230713   f1-score: 0.8366897106170654   accuracy: 0.8999099135398865\n",
      "Epoch:  1111 , Loss:  0.6159719228744507   f1-score: 0.8366897106170654   accuracy: 0.8999099135398865\n",
      "Epoch:  1112 , Loss:  0.6159477829933167   f1-score: 0.8371546268463135   accuracy: 0.9001801609992981\n",
      "Epoch:  1113 , Loss:  0.6159242391586304   f1-score: 0.8372776508331299   accuracy: 0.9002702832221985\n",
      "Epoch:  1114 , Loss:  0.6159002780914307   f1-score: 0.8374485373497009   accuracy: 0.9003603458404541\n",
      "Epoch:  1115 , Loss:  0.6158765554428101   f1-score: 0.8374485373497009   accuracy: 0.9003603458404541\n",
      "Epoch:  1116 , Loss:  0.6158530116081238   f1-score: 0.837619423866272   accuracy: 0.9004504680633545\n",
      "Epoch:  1117 , Loss:  0.6158292889595032   f1-score: 0.837619423866272   accuracy: 0.9004504680633545\n",
      "Epoch:  1118 , Loss:  0.6158056259155273   f1-score: 0.837619423866272   accuracy: 0.9004504680633545\n",
      "Epoch:  1119 , Loss:  0.6157822608947754   f1-score: 0.837619423866272   accuracy: 0.9004504680633545\n",
      "Epoch:  1120 , Loss:  0.6157587170600891   f1-score: 0.837619423866272   accuracy: 0.9004504680633545\n",
      "Epoch:  1121 , Loss:  0.6157354116439819   f1-score: 0.8377425074577332   accuracy: 0.9005405306816101\n",
      "Epoch:  1122 , Loss:  0.6157122254371643   f1-score: 0.8377425074577332   accuracy: 0.9005405306816101\n",
      "Epoch:  1123 , Loss:  0.6156888604164124   f1-score: 0.8377425074577332   accuracy: 0.9005405306816101\n",
      "Epoch:  1124 , Loss:  0.6156657338142395   f1-score: 0.8379132747650146   accuracy: 0.9006306529045105\n",
      "Epoch:  1125 , Loss:  0.6156426072120667   f1-score: 0.8379132747650146   accuracy: 0.9006306529045105\n",
      "Epoch:  1126 , Loss:  0.6156195402145386   f1-score: 0.8380364775657654   accuracy: 0.9007207155227661\n",
      "Epoch:  1127 , Loss:  0.6155966520309448   f1-score: 0.8381596207618713   accuracy: 0.9008108377456665\n",
      "Epoch:  1128 , Loss:  0.615573525428772   f1-score: 0.8381596207618713   accuracy: 0.9008108377456665\n",
      "Epoch:  1129 , Loss:  0.615550696849823   f1-score: 0.8383303880691528   accuracy: 0.9009009003639221\n",
      "Epoch:  1130 , Loss:  0.615527868270874   f1-score: 0.8384536504745483   accuracy: 0.9009909629821777\n",
      "Epoch:  1131 , Loss:  0.6155050992965698   f1-score: 0.8384536504745483   accuracy: 0.9009909629821777\n",
      "Epoch:  1132 , Loss:  0.6154823303222656   f1-score: 0.8384536504745483   accuracy: 0.9009909629821777\n",
      "Epoch:  1133 , Loss:  0.6154595017433167   f1-score: 0.8384536504745483   accuracy: 0.9009909629821777\n",
      "Epoch:  1134 , Loss:  0.615436851978302   f1-score: 0.8385769128799438   accuracy: 0.9010810852050781\n",
      "Epoch:  1135 , Loss:  0.6154140830039978   f1-score: 0.8385769128799438   accuracy: 0.9010810852050781\n",
      "Epoch:  1136 , Loss:  0.6153914928436279   f1-score: 0.8387476205825806   accuracy: 0.9011711478233337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1137 , Loss:  0.6153690218925476   f1-score: 0.8387476205825806   accuracy: 0.9011711478233337\n",
      "Epoch:  1138 , Loss:  0.6153464913368225   f1-score: 0.8387476205825806   accuracy: 0.9011711478233337\n",
      "Epoch:  1139 , Loss:  0.6153238415718079   f1-score: 0.8392595052719116   accuracy: 0.9014414548873901\n",
      "Epoch:  1140 , Loss:  0.6153014898300171   f1-score: 0.8392595052719116   accuracy: 0.9014414548873901\n",
      "Epoch:  1141 , Loss:  0.615278959274292   f1-score: 0.8393067121505737   accuracy: 0.9014414548873901\n",
      "Epoch:  1142 , Loss:  0.6152567267417908   f1-score: 0.8393067121505737   accuracy: 0.9014414548873901\n",
      "Epoch:  1143 , Loss:  0.6152341961860657   f1-score: 0.8394771814346313   accuracy: 0.9015315175056458\n",
      "Epoch:  1144 , Loss:  0.6152118444442749   f1-score: 0.8394771814346313   accuracy: 0.9015315175056458\n",
      "Epoch:  1145 , Loss:  0.6151894927024841   f1-score: 0.8397709131240845   accuracy: 0.9017117023468018\n",
      "Epoch:  1146 , Loss:  0.6151670217514038   f1-score: 0.8397709131240845   accuracy: 0.9017117023468018\n",
      "Epoch:  1147 , Loss:  0.615144670009613   f1-score: 0.8397709131240845   accuracy: 0.9017117023468018\n",
      "Epoch:  1148 , Loss:  0.6151223182678223   f1-score: 0.8397709131240845   accuracy: 0.9017117023468018\n",
      "Epoch:  1149 , Loss:  0.6150999665260315   f1-score: 0.8398942351341248   accuracy: 0.9018018245697021\n",
      "Epoch:  1150 , Loss:  0.615077555179596   f1-score: 0.8398942351341248   accuracy: 0.9018018245697021\n",
      "Epoch:  1151 , Loss:  0.61505526304245   f1-score: 0.8398942351341248   accuracy: 0.9018018245697021\n",
      "Epoch:  1152 , Loss:  0.6150329113006592   f1-score: 0.8398942351341248   accuracy: 0.9018018245697021\n",
      "Epoch:  1153 , Loss:  0.6150107383728027   f1-score: 0.8400176167488098   accuracy: 0.9018918871879578\n",
      "Epoch:  1154 , Loss:  0.6149883270263672   f1-score: 0.8401880264282227   accuracy: 0.9019820094108582\n",
      "Epoch:  1155 , Loss:  0.6149662733078003   f1-score: 0.8403583765029907   accuracy: 0.9020720720291138\n",
      "Epoch:  1156 , Loss:  0.6149442195892334   f1-score: 0.8405286073684692   accuracy: 0.9021621346473694\n",
      "Epoch:  1157 , Loss:  0.614922285079956   f1-score: 0.8405286073684692   accuracy: 0.9021621346473694\n",
      "Epoch:  1158 , Loss:  0.6149001717567444   f1-score: 0.8405286073684692   accuracy: 0.9021621346473694\n",
      "Epoch:  1159 , Loss:  0.6148783564567566   f1-score: 0.8405286073684692   accuracy: 0.9021621346473694\n",
      "Epoch:  1160 , Loss:  0.6148562431335449   f1-score: 0.8406520485877991   accuracy: 0.9022522568702698\n",
      "Epoch:  1161 , Loss:  0.6148346066474915   f1-score: 0.8408223390579224   accuracy: 0.9023423194885254\n",
      "Epoch:  1162 , Loss:  0.6148127913475037   f1-score: 0.8408223390579224   accuracy: 0.9023423194885254\n",
      "Epoch:  1163 , Loss:  0.6147909164428711   f1-score: 0.8408223390579224   accuracy: 0.9023423194885254\n",
      "Epoch:  1164 , Loss:  0.6147693991661072   f1-score: 0.8408223390579224   accuracy: 0.9023423194885254\n",
      "Epoch:  1165 , Loss:  0.6147477030754089   f1-score: 0.8408223390579224   accuracy: 0.9023423194885254\n",
      "Epoch:  1166 , Loss:  0.6147261261940002   f1-score: 0.8408223390579224   accuracy: 0.9023423194885254\n",
      "Epoch:  1167 , Loss:  0.6147046685218811   f1-score: 0.8409925103187561   accuracy: 0.9024324417114258\n",
      "Epoch:  1168 , Loss:  0.614683210849762   f1-score: 0.8411626815795898   accuracy: 0.9025225043296814\n",
      "Epoch:  1169 , Loss:  0.6146621108055115   f1-score: 0.8411626815795898   accuracy: 0.9025225043296814\n",
      "Epoch:  1170 , Loss:  0.6146407723426819   f1-score: 0.8411626815795898   accuracy: 0.9025225043296814\n",
      "Epoch:  1171 , Loss:  0.6146197319030762   f1-score: 0.8412861824035645   accuracy: 0.9026126265525818\n",
      "Epoch:  1172 , Loss:  0.6145985722541809   f1-score: 0.8412861824035645   accuracy: 0.9026126265525818\n",
      "Epoch:  1173 , Loss:  0.6145774722099304   f1-score: 0.8412861824035645   accuracy: 0.9026126265525818\n",
      "Epoch:  1174 , Loss:  0.6145564317703247   f1-score: 0.8414562344551086   accuracy: 0.9027026891708374\n",
      "Epoch:  1175 , Loss:  0.6145354509353638   f1-score: 0.8414562344551086   accuracy: 0.9027026891708374\n",
      "Epoch:  1176 , Loss:  0.6145143508911133   f1-score: 0.8414562344551086   accuracy: 0.9027026891708374\n",
      "Epoch:  1177 , Loss:  0.6144934296607971   f1-score: 0.8414562344551086   accuracy: 0.9027026891708374\n",
      "Epoch:  1178 , Loss:  0.614472508430481   f1-score: 0.8416262865066528   accuracy: 0.9027928113937378\n",
      "Epoch:  1179 , Loss:  0.6144517064094543   f1-score: 0.8416262865066528   accuracy: 0.9027928113937378\n",
      "Epoch:  1180 , Loss:  0.614430844783783   f1-score: 0.8416262865066528   accuracy: 0.9027928113937378\n",
      "Epoch:  1181 , Loss:  0.6144099831581116   f1-score: 0.8419198393821716   accuracy: 0.9029729962348938\n",
      "Epoch:  1182 , Loss:  0.614389181137085   f1-score: 0.8419198393821716   accuracy: 0.9029729962348938\n",
      "Epoch:  1183 , Loss:  0.6143684387207031   f1-score: 0.8419198393821716   accuracy: 0.9029729962348938\n",
      "Epoch:  1184 , Loss:  0.6143475770950317   f1-score: 0.8419198393821716   accuracy: 0.9029729962348938\n",
      "Epoch:  1185 , Loss:  0.6143270134925842   f1-score: 0.8419198393821716   accuracy: 0.9029729962348938\n",
      "Epoch:  1186 , Loss:  0.6143063306808472   f1-score: 0.842089831829071   accuracy: 0.9030630588531494\n",
      "Epoch:  1187 , Loss:  0.6142857670783997   f1-score: 0.842089831829071   accuracy: 0.9030630588531494\n",
      "Epoch:  1188 , Loss:  0.614264965057373   f1-score: 0.8424295783042908   accuracy: 0.9032432436943054\n",
      "Epoch:  1189 , Loss:  0.6142446398735046   f1-score: 0.8424295783042908   accuracy: 0.9032432436943054\n",
      "Epoch:  1190 , Loss:  0.6142239570617676   f1-score: 0.8424295783042908   accuracy: 0.9032432436943054\n",
      "Epoch:  1191 , Loss:  0.6142035126686096   f1-score: 0.8425993919372559   accuracy: 0.903333306312561\n",
      "Epoch:  1192 , Loss:  0.6141830682754517   f1-score: 0.8425993919372559   accuracy: 0.903333306312561\n",
      "Epoch:  1193 , Loss:  0.6141625642776489   f1-score: 0.8424295783042908   accuracy: 0.9032432436943054\n",
      "Epoch:  1194 , Loss:  0.614142119884491   f1-score: 0.8427691459655762   accuracy: 0.9034234285354614\n",
      "Epoch:  1195 , Loss:  0.6141217350959778   f1-score: 0.8427691459655762   accuracy: 0.9034234285354614\n",
      "Epoch:  1196 , Loss:  0.6141014099121094   f1-score: 0.8425993919372559   accuracy: 0.903333306312561\n",
      "Epoch:  1197 , Loss:  0.6140809655189514   f1-score: 0.84272301197052   accuracy: 0.9034234285354614\n",
      "Epoch:  1198 , Loss:  0.614060640335083   f1-score: 0.8428927659988403   accuracy: 0.903513491153717\n",
      "Epoch:  1199 , Loss:  0.6140404343605042   f1-score: 0.84272301197052   accuracy: 0.9034234285354614\n",
      "Epoch:  1200 , Loss:  0.6140197515487671   f1-score: 0.84272301197052   accuracy: 0.9034234285354614\n",
      "Epoch:  1201 , Loss:  0.6139997839927673   f1-score: 0.84272301197052   accuracy: 0.9034234285354614\n",
      "Epoch:  1202 , Loss:  0.6139792799949646   f1-score: 0.84272301197052   accuracy: 0.9034234285354614\n",
      "Epoch:  1203 , Loss:  0.613959014415741   f1-score: 0.8428927659988403   accuracy: 0.903513491153717\n",
      "Epoch:  1204 , Loss:  0.6139387488365173   f1-score: 0.8428927659988403   accuracy: 0.903513491153717\n",
      "Epoch:  1205 , Loss:  0.6139184236526489   f1-score: 0.8430624604225159   accuracy: 0.9036036133766174\n",
      "Epoch:  1206 , Loss:  0.613897979259491   f1-score: 0.8430624604225159   accuracy: 0.9036036133766174\n",
      "Epoch:  1207 , Loss:  0.6138778328895569   f1-score: 0.8430624604225159   accuracy: 0.9036036133766174\n",
      "Epoch:  1208 , Loss:  0.6138575077056885   f1-score: 0.8430624604225159   accuracy: 0.9036036133766174\n",
      "Epoch:  1209 , Loss:  0.6138374209403992   f1-score: 0.8430624604225159   accuracy: 0.9036036133766174\n",
      "Epoch:  1210 , Loss:  0.613817036151886   f1-score: 0.8432321548461914   accuracy: 0.903693675994873\n",
      "Epoch:  1211 , Loss:  0.6137970089912415   f1-score: 0.8434017300605774   accuracy: 0.9037837982177734\n",
      "Epoch:  1212 , Loss:  0.6137768626213074   f1-score: 0.8434017300605774   accuracy: 0.9037837982177734\n",
      "Epoch:  1213 , Loss:  0.6137568354606628   f1-score: 0.8437408208847046   accuracy: 0.9039639830589294\n",
      "Epoch:  1214 , Loss:  0.6137362718582153   f1-score: 0.8437408208847046   accuracy: 0.9039639830589294\n",
      "Epoch:  1215 , Loss:  0.6137166023254395   f1-score: 0.8435713052749634   accuracy: 0.903873860836029\n",
      "Epoch:  1216 , Loss:  0.6136962175369263   f1-score: 0.8435713052749634   accuracy: 0.903873860836029\n",
      "Epoch:  1217 , Loss:  0.6136761903762817   f1-score: 0.8435713052749634   accuracy: 0.903873860836029\n",
      "Epoch:  1218 , Loss:  0.6136561632156372   f1-score: 0.8436949849128723   accuracy: 0.9039639830589294\n",
      "Epoch:  1219 , Loss:  0.613635778427124   f1-score: 0.8436949849128723   accuracy: 0.9039639830589294\n",
      "Epoch:  1220 , Loss:  0.6136157512664795   f1-score: 0.8436949849128723   accuracy: 0.9039639830589294\n",
      "Epoch:  1221 , Loss:  0.6135955452919006   f1-score: 0.8438645601272583   accuracy: 0.9040540456771851\n",
      "Epoch:  1222 , Loss:  0.6135755777359009   f1-score: 0.8441577553749084   accuracy: 0.9042342305183411\n",
      "Epoch:  1223 , Loss:  0.6135556697845459   f1-score: 0.8443271517753601   accuracy: 0.9043243527412415\n",
      "Epoch:  1224 , Loss:  0.613535463809967   f1-score: 0.8443271517753601   accuracy: 0.9043243527412415\n",
      "Epoch:  1225 , Loss:  0.6135152578353882   f1-score: 0.8442815542221069   accuracy: 0.9043243527412415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1226 , Loss:  0.6134952306747437   f1-score: 0.8444509506225586   accuracy: 0.9044144153594971\n",
      "Epoch:  1227 , Loss:  0.6134750843048096   f1-score: 0.8446986079216003   accuracy: 0.9045946002006531\n",
      "Epoch:  1228 , Loss:  0.6134548783302307   f1-score: 0.8445292115211487   accuracy: 0.9045044779777527\n",
      "Epoch:  1229 , Loss:  0.6134347915649414   f1-score: 0.8445292115211487   accuracy: 0.9045044779777527\n",
      "Epoch:  1230 , Loss:  0.6134148240089417   f1-score: 0.8445292115211487   accuracy: 0.9045044779777527\n",
      "Epoch:  1231 , Loss:  0.6133943796157837   f1-score: 0.8445292115211487   accuracy: 0.9045044779777527\n",
      "Epoch:  1232 , Loss:  0.6133740544319153   f1-score: 0.8445292115211487   accuracy: 0.9045044779777527\n",
      "Epoch:  1233 , Loss:  0.6133540868759155   f1-score: 0.8444053530693054   accuracy: 0.9044144153594971\n",
      "Epoch:  1234 , Loss:  0.6133337616920471   f1-score: 0.8446986079216003   accuracy: 0.9045946002006531\n",
      "Epoch:  1235 , Loss:  0.613313615322113   f1-score: 0.8445748090744019   accuracy: 0.9045044779777527\n",
      "Epoch:  1236 , Loss:  0.6132932305335999   f1-score: 0.8447441458702087   accuracy: 0.9045946002006531\n",
      "Epoch:  1237 , Loss:  0.613273024559021   f1-score: 0.8447441458702087   accuracy: 0.9045946002006531\n",
      "Epoch:  1238 , Loss:  0.6132523417472839   f1-score: 0.8450374007225037   accuracy: 0.9047747850418091\n",
      "Epoch:  1239 , Loss:  0.6132322549819946   f1-score: 0.8450374007225037   accuracy: 0.9047747850418091\n",
      "Epoch:  1240 , Loss:  0.6132115125656128   f1-score: 0.8450374007225037   accuracy: 0.9047747850418091\n",
      "Epoch:  1241 , Loss:  0.6131913661956787   f1-score: 0.8450374007225037   accuracy: 0.9047747850418091\n",
      "Epoch:  1242 , Loss:  0.6131707429885864   f1-score: 0.8450374007225037   accuracy: 0.9047747850418091\n",
      "Epoch:  1243 , Loss:  0.6131503582000732   f1-score: 0.8452066779136658   accuracy: 0.9048648476600647\n",
      "Epoch:  1244 , Loss:  0.6131299138069153   f1-score: 0.8453759551048279   accuracy: 0.9049549698829651\n",
      "Epoch:  1245 , Loss:  0.6131093502044678   f1-score: 0.8454998731613159   accuracy: 0.9050450325012207\n",
      "Epoch:  1246 , Loss:  0.6130889058113098   f1-score: 0.8457930088043213   accuracy: 0.9052252173423767\n",
      "Epoch:  1247 , Loss:  0.6130684614181519   f1-score: 0.8459170460700989   accuracy: 0.9053153395652771\n",
      "Epoch:  1248 , Loss:  0.6130478382110596   f1-score: 0.8460410833358765   accuracy: 0.9054054021835327\n",
      "Epoch:  1249 , Loss:  0.6130271553993225   f1-score: 0.8460410833358765   accuracy: 0.9054054021835327\n",
      "Epoch:  1250 , Loss:  0.6130065321922302   f1-score: 0.846210241317749   accuracy: 0.9054955244064331\n",
      "Epoch:  1251 , Loss:  0.6129859089851379   f1-score: 0.846210241317749   accuracy: 0.9054955244064331\n",
      "Epoch:  1252 , Loss:  0.6129650473594666   f1-score: 0.846210241317749   accuracy: 0.9054955244064331\n",
      "Epoch:  1253 , Loss:  0.6129445433616638   f1-score: 0.8463343381881714   accuracy: 0.9055855870246887\n",
      "Epoch:  1254 , Loss:  0.6129233837127686   f1-score: 0.846672534942627   accuracy: 0.9057657718658447\n",
      "Epoch:  1255 , Loss:  0.6129028797149658   f1-score: 0.8470105528831482   accuracy: 0.9059459567070007\n",
      "Epoch:  1256 , Loss:  0.6128817796707153   f1-score: 0.84684157371521   accuracy: 0.9058558344841003\n",
      "Epoch:  1257 , Loss:  0.6128610372543335   f1-score: 0.84684157371521   accuracy: 0.9058558344841003\n",
      "Epoch:  1258 , Loss:  0.612839937210083   f1-score: 0.8470105528831482   accuracy: 0.9059459567070007\n",
      "Epoch:  1259 , Loss:  0.6128188967704773   f1-score: 0.8471794724464417   accuracy: 0.9060360193252563\n",
      "Epoch:  1260 , Loss:  0.6127979159355164   f1-score: 0.8471794724464417   accuracy: 0.9060360193252563\n",
      "Epoch:  1261 , Loss:  0.6127766966819763   f1-score: 0.8471794724464417   accuracy: 0.9060360193252563\n",
      "Epoch:  1262 , Loss:  0.6127558350563049   f1-score: 0.8471794724464417   accuracy: 0.9060360193252563\n",
      "Epoch:  1263 , Loss:  0.6127344369888306   f1-score: 0.8471794724464417   accuracy: 0.9060360193252563\n",
      "Epoch:  1264 , Loss:  0.6127133965492249   f1-score: 0.8473483920097351   accuracy: 0.9061261415481567\n",
      "Epoch:  1265 , Loss:  0.6126921772956848   f1-score: 0.8473483920097351   accuracy: 0.9061261415481567\n",
      "Epoch:  1266 , Loss:  0.6126706600189209   f1-score: 0.847517192363739   accuracy: 0.9062162041664124\n",
      "Epoch:  1267 , Loss:  0.6126492619514465   f1-score: 0.8476859927177429   accuracy: 0.9063063263893127\n",
      "Epoch:  1268 , Loss:  0.6126279234886169   f1-score: 0.8480234146118164   accuracy: 0.9064865112304688\n",
      "Epoch:  1269 , Loss:  0.6126063466072083   f1-score: 0.8483606576919556   accuracy: 0.9066666960716248\n",
      "Epoch:  1270 , Loss:  0.6125850081443787   f1-score: 0.8485292196273804   accuracy: 0.9067567586898804\n",
      "Epoch:  1271 , Loss:  0.6125633716583252   f1-score: 0.8489019274711609   accuracy: 0.907027006149292\n",
      "Epoch:  1272 , Loss:  0.6125417351722717   f1-score: 0.8490704298019409   accuracy: 0.9071171283721924\n",
      "Epoch:  1273 , Loss:  0.612520158290863   f1-score: 0.8491947054862976   accuracy: 0.907207190990448\n",
      "Epoch:  1274 , Loss:  0.6124985814094543   f1-score: 0.8493191003799438   accuracy: 0.9072973132133484\n",
      "Epoch:  1275 , Loss:  0.6124764680862427   f1-score: 0.8496119379997253   accuracy: 0.9074774980545044\n",
      "Epoch:  1276 , Loss:  0.6124551296234131   f1-score: 0.8496119379997253   accuracy: 0.9074774980545044\n",
      "Epoch:  1277 , Loss:  0.6124333143234253   f1-score: 0.8497803807258606   accuracy: 0.90756756067276\n",
      "Epoch:  1278 , Loss:  0.6124113202095032   f1-score: 0.8497803807258606   accuracy: 0.90756756067276\n",
      "Epoch:  1279 , Loss:  0.6123897433280945   f1-score: 0.8501170873641968   accuracy: 0.907747745513916\n",
      "Epoch:  1280 , Loss:  0.6123679876327515   f1-score: 0.8502853512763977   accuracy: 0.9078378081321716\n",
      "Epoch:  1281 , Loss:  0.6123459935188293   f1-score: 0.8502853512763977   accuracy: 0.9078378081321716\n",
      "Epoch:  1282 , Loss:  0.6123242974281311   f1-score: 0.8502853512763977   accuracy: 0.9078378081321716\n",
      "Epoch:  1283 , Loss:  0.6123027801513672   f1-score: 0.8502853512763977   accuracy: 0.9078378081321716\n",
      "Epoch:  1284 , Loss:  0.6122808456420898   f1-score: 0.8502853512763977   accuracy: 0.9078378081321716\n",
      "Epoch:  1285 , Loss:  0.6122593283653259   f1-score: 0.8504536151885986   accuracy: 0.907927930355072\n",
      "Epoch:  1286 , Loss:  0.6122375130653381   f1-score: 0.8506218194961548   accuracy: 0.9080179929733276\n",
      "Epoch:  1287 , Loss:  0.6122156977653503   f1-score: 0.8506218194961548   accuracy: 0.9080179929733276\n",
      "Epoch:  1288 , Loss:  0.6121940016746521   f1-score: 0.8507899641990662   accuracy: 0.908108115196228\n",
      "Epoch:  1289 , Loss:  0.6121723055839539   f1-score: 0.8506218194961548   accuracy: 0.9080179929733276\n",
      "Epoch:  1290 , Loss:  0.6121503114700317   f1-score: 0.8507899641990662   accuracy: 0.908108115196228\n",
      "Epoch:  1291 , Loss:  0.612128496170044   f1-score: 0.8507899641990662   accuracy: 0.908108115196228\n",
      "Epoch:  1292 , Loss:  0.6121065020561218   f1-score: 0.8511260747909546   accuracy: 0.908288300037384\n",
      "Epoch:  1293 , Loss:  0.6120847463607788   f1-score: 0.8507899641990662   accuracy: 0.908108115196228\n",
      "Epoch:  1294 , Loss:  0.6120627522468567   f1-score: 0.8507899641990662   accuracy: 0.908108115196228\n",
      "Epoch:  1295 , Loss:  0.6120406985282898   f1-score: 0.8511260747909546   accuracy: 0.908288300037384\n",
      "Epoch:  1296 , Loss:  0.6120190620422363   f1-score: 0.8509580492973328   accuracy: 0.9081981778144836\n",
      "Epoch:  1297 , Loss:  0.6119970083236694   f1-score: 0.8512940406799316   accuracy: 0.9083783626556396\n",
      "Epoch:  1298 , Loss:  0.6119751930236816   f1-score: 0.8512940406799316   accuracy: 0.9083783626556396\n",
      "Epoch:  1299 , Loss:  0.6119534969329834   f1-score: 0.8514620065689087   accuracy: 0.90846848487854\n",
      "Epoch:  1300 , Loss:  0.611931562423706   f1-score: 0.8514620065689087   accuracy: 0.90846848487854\n",
      "Epoch:  1301 , Loss:  0.6119100451469421   f1-score: 0.8516298532485962   accuracy: 0.9085585474967957\n",
      "Epoch:  1302 , Loss:  0.61188805103302   f1-score: 0.851754367351532   accuracy: 0.908648669719696\n",
      "Epoch:  1303 , Loss:  0.611866295337677   f1-score: 0.851754367351532   accuracy: 0.908648669719696\n",
      "Epoch:  1304 , Loss:  0.6118447780609131   f1-score: 0.851754367351532   accuracy: 0.908648669719696\n",
      "Epoch:  1305 , Loss:  0.6118230223655701   f1-score: 0.851754367351532   accuracy: 0.908648669719696\n",
      "Epoch:  1306 , Loss:  0.6118011474609375   f1-score: 0.851754367351532   accuracy: 0.908648669719696\n",
      "Epoch:  1307 , Loss:  0.6117795705795288   f1-score: 0.851754367351532   accuracy: 0.908648669719696\n",
      "Epoch:  1308 , Loss:  0.611757755279541   f1-score: 0.8519222140312195   accuracy: 0.9087387323379517\n",
      "Epoch:  1309 , Loss:  0.6117360591888428   f1-score: 0.8520467877388   accuracy: 0.908828854560852\n",
      "Epoch:  1310 , Loss:  0.6117143034934998   f1-score: 0.8523823618888855   accuracy: 0.9090089797973633\n",
      "Epoch:  1311 , Loss:  0.6116926074028015   f1-score: 0.8523823618888855   accuracy: 0.9090089797973633\n",
      "Epoch:  1312 , Loss:  0.6116710901260376   f1-score: 0.8527176976203918   accuracy: 0.9091891646385193\n",
      "Epoch:  1313 , Loss:  0.6116494536399841   f1-score: 0.8527176976203918   accuracy: 0.9091891646385193\n",
      "Epoch:  1314 , Loss:  0.611627995967865   f1-score: 0.8530528545379639   accuracy: 0.9093693494796753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1315 , Loss:  0.611606240272522   f1-score: 0.8532204031944275   accuracy: 0.9094594717025757\n",
      "Epoch:  1316 , Loss:  0.6115847229957581   f1-score: 0.8532204031944275   accuracy: 0.9094594717025757\n",
      "Epoch:  1317 , Loss:  0.6115633249282837   f1-score: 0.8530528545379639   accuracy: 0.9093693494796753\n",
      "Epoch:  1318 , Loss:  0.6115418076515198   f1-score: 0.8532204031944275   accuracy: 0.9094594717025757\n",
      "Epoch:  1319 , Loss:  0.6115202307701111   f1-score: 0.8532204031944275   accuracy: 0.9094594717025757\n",
      "Epoch:  1320 , Loss:  0.6114985346794128   f1-score: 0.8532204031944275   accuracy: 0.9094594717025757\n",
      "Epoch:  1321 , Loss:  0.6114768981933594   f1-score: 0.8532204031944275   accuracy: 0.9094594717025757\n",
      "Epoch:  1322 , Loss:  0.6114556193351746   f1-score: 0.8532204031944275   accuracy: 0.9094594717025757\n",
      "Epoch:  1323 , Loss:  0.6114338040351868   f1-score: 0.8533450365066528   accuracy: 0.9095495343208313\n",
      "Epoch:  1324 , Loss:  0.6114122867584229   f1-score: 0.8534696698188782   accuracy: 0.9096396565437317\n",
      "Epoch:  1325 , Loss:  0.6113905310630798   f1-score: 0.8534696698188782   accuracy: 0.9096396565437317\n",
      "Epoch:  1326 , Loss:  0.6113690137863159   f1-score: 0.8526176810264587   accuracy: 0.9094594717025757\n",
      "Epoch:  1327 , Loss:  0.6113473176956177   f1-score: 0.8526176810264587   accuracy: 0.9094594717025757\n",
      "Epoch:  1328 , Loss:  0.6113256812095642   f1-score: 0.8527859449386597   accuracy: 0.9095495343208313\n",
      "Epoch:  1329 , Loss:  0.6113042831420898   f1-score: 0.8527859449386597   accuracy: 0.9095495343208313\n",
      "Epoch:  1330 , Loss:  0.611282467842102   f1-score: 0.8527859449386597   accuracy: 0.9095495343208313\n",
      "Epoch:  1331 , Loss:  0.6112611293792725   f1-score: 0.853036105632782   accuracy: 0.9097297191619873\n",
      "Epoch:  1332 , Loss:  0.611239492893219   f1-score: 0.8531612157821655   accuracy: 0.9098198413848877\n",
      "Epoch:  1333 , Loss:  0.6112180948257446   f1-score: 0.8531612157821655   accuracy: 0.9098198413848877\n",
      "Epoch:  1334 , Loss:  0.6111968755722046   f1-score: 0.8533294200897217   accuracy: 0.9099099040031433\n",
      "Epoch:  1335 , Loss:  0.6111754775047302   f1-score: 0.8536657094955444   accuracy: 0.9100900888442993\n",
      "Epoch:  1336 , Loss:  0.6111540198326111   f1-score: 0.8536657094955444   accuracy: 0.9100900888442993\n",
      "Epoch:  1337 , Loss:  0.611132800579071   f1-score: 0.8536657094955444   accuracy: 0.9100900888442993\n",
      "Epoch:  1338 , Loss:  0.6111114621162415   f1-score: 0.8538337349891663   accuracy: 0.9101801514625549\n",
      "Epoch:  1339 , Loss:  0.611090362071991   f1-score: 0.8543376326560974   accuracy: 0.9104504585266113\n",
      "Epoch:  1340 , Loss:  0.6110692620277405   f1-score: 0.8544628620147705   accuracy: 0.9105405211448669\n",
      "Epoch:  1341 , Loss:  0.6110480427742004   f1-score: 0.854630708694458   accuracy: 0.9106306433677673\n",
      "Epoch:  1342 , Loss:  0.611027181148529   f1-score: 0.8547985553741455   accuracy: 0.910720705986023\n",
      "Epoch:  1343 , Loss:  0.6110061407089233   f1-score: 0.8547985553741455   accuracy: 0.910720705986023\n",
      "Epoch:  1344 , Loss:  0.6109854578971863   f1-score: 0.8549662828445435   accuracy: 0.9108108282089233\n",
      "Epoch:  1345 , Loss:  0.610964298248291   f1-score: 0.8549662828445435   accuracy: 0.9108108282089233\n",
      "Epoch:  1346 , Loss:  0.6109435558319092   f1-score: 0.8549662828445435   accuracy: 0.9108108282089233\n",
      "Epoch:  1347 , Loss:  0.6109226942062378   f1-score: 0.8549662828445435   accuracy: 0.9108108282089233\n",
      "Epoch:  1348 , Loss:  0.6109018921852112   f1-score: 0.8549662828445435   accuracy: 0.9108108282089233\n",
      "Epoch:  1349 , Loss:  0.6108812093734741   f1-score: 0.8549662828445435   accuracy: 0.9108108282089233\n",
      "Epoch:  1350 , Loss:  0.6108603477478027   f1-score: 0.8549662828445435   accuracy: 0.9108108282089233\n",
      "Epoch:  1351 , Loss:  0.6108396649360657   f1-score: 0.8549662828445435   accuracy: 0.9108108282089233\n",
      "Epoch:  1352 , Loss:  0.6108190417289734   f1-score: 0.8549662828445435   accuracy: 0.9108108282089233\n",
      "Epoch:  1353 , Loss:  0.6107982397079468   f1-score: 0.8550915718078613   accuracy: 0.910900890827179\n",
      "Epoch:  1354 , Loss:  0.610777735710144   f1-score: 0.8550915718078613   accuracy: 0.910900890827179\n",
      "Epoch:  1355 , Loss:  0.6107571721076965   f1-score: 0.8550915718078613   accuracy: 0.910900890827179\n",
      "Epoch:  1356 , Loss:  0.6107366681098938   f1-score: 0.8550915718078613   accuracy: 0.910900890827179\n",
      "Epoch:  1357 , Loss:  0.6107163429260254   f1-score: 0.8553845882415771   accuracy: 0.911081075668335\n",
      "Epoch:  1358 , Loss:  0.6106956601142883   f1-score: 0.8557199239730835   accuracy: 0.911261260509491\n",
      "Epoch:  1359 , Loss:  0.6106754541397095   f1-score: 0.8560128808021545   accuracy: 0.911441445350647\n",
      "Epoch:  1360 , Loss:  0.6106549501419067   f1-score: 0.8558452725410461   accuracy: 0.9113513231277466\n",
      "Epoch:  1361 , Loss:  0.6106346845626831   f1-score: 0.8559706807136536   accuracy: 0.911441445350647\n",
      "Epoch:  1362 , Loss:  0.6106142997741699   f1-score: 0.856138288974762   accuracy: 0.9115315079689026\n",
      "Epoch:  1363 , Loss:  0.6105939745903015   f1-score: 0.8563058376312256   accuracy: 0.911621630191803\n",
      "Epoch:  1364 , Loss:  0.6105738878250122   f1-score: 0.8564313054084778   accuracy: 0.9117116928100586\n",
      "Epoch:  1365 , Loss:  0.6105532050132751   f1-score: 0.8564313054084778   accuracy: 0.9117116928100586\n",
      "Epoch:  1366 , Loss:  0.6105332374572754   f1-score: 0.8563058376312256   accuracy: 0.911621630191803\n",
      "Epoch:  1367 , Loss:  0.6105127334594727   f1-score: 0.8564733266830444   accuracy: 0.9117116928100586\n",
      "Epoch:  1368 , Loss:  0.6104927062988281   f1-score: 0.8564733266830444   accuracy: 0.9117116928100586\n",
      "Epoch:  1369 , Loss:  0.6104723811149597   f1-score: 0.8566408157348633   accuracy: 0.911801815032959\n",
      "Epoch:  1370 , Loss:  0.6104524731636047   f1-score: 0.8566408157348633   accuracy: 0.911801815032959\n",
      "Epoch:  1371 , Loss:  0.6104323267936707   f1-score: 0.8566408157348633   accuracy: 0.911801815032959\n",
      "Epoch:  1372 , Loss:  0.6104122996330261   f1-score: 0.8566408157348633   accuracy: 0.911801815032959\n",
      "Epoch:  1373 , Loss:  0.6103922128677368   f1-score: 0.8566408157348633   accuracy: 0.911801815032959\n",
      "Epoch:  1374 , Loss:  0.6103724241256714   f1-score: 0.8566408157348633   accuracy: 0.911801815032959\n",
      "Epoch:  1375 , Loss:  0.6103524565696716   f1-score: 0.8568081855773926   accuracy: 0.9118918776512146\n",
      "Epoch:  1376 , Loss:  0.6103323698043823   f1-score: 0.8568081855773926   accuracy: 0.9118918776512146\n",
      "Epoch:  1377 , Loss:  0.6103125810623169   f1-score: 0.8568081855773926   accuracy: 0.9118918776512146\n",
      "Epoch:  1378 , Loss:  0.6102925539016724   f1-score: 0.8569755554199219   accuracy: 0.911981999874115\n",
      "Epoch:  1379 , Loss:  0.6102727651596069   f1-score: 0.8569755554199219   accuracy: 0.911981999874115\n",
      "Epoch:  1380 , Loss:  0.6102527976036072   f1-score: 0.8569755554199219   accuracy: 0.911981999874115\n",
      "Epoch:  1381 , Loss:  0.6102330088615417   f1-score: 0.8574773073196411   accuracy: 0.9122522473335266\n",
      "Epoch:  1382 , Loss:  0.6102133393287659   f1-score: 0.8571428656578064   accuracy: 0.9120720624923706\n",
      "Epoch:  1383 , Loss:  0.6101933121681213   f1-score: 0.8574773073196411   accuracy: 0.9122522473335266\n",
      "Epoch:  1384 , Loss:  0.6101738810539246   f1-score: 0.8574773073196411   accuracy: 0.9122522473335266\n",
      "Epoch:  1385 , Loss:  0.6101540327072144   f1-score: 0.8574773073196411   accuracy: 0.9122522473335266\n",
      "Epoch:  1386 , Loss:  0.6101340055465698   f1-score: 0.8576444983482361   accuracy: 0.912342369556427\n",
      "Epoch:  1387 , Loss:  0.6101144552230835   f1-score: 0.8578115701675415   accuracy: 0.9124324321746826\n",
      "Epoch:  1388 , Loss:  0.6100946068763733   f1-score: 0.8579786419868469   accuracy: 0.9125224947929382\n",
      "Epoch:  1389 , Loss:  0.6100748777389526   f1-score: 0.8581456542015076   accuracy: 0.9126126170158386\n",
      "Epoch:  1390 , Loss:  0.610055148601532   f1-score: 0.8581456542015076   accuracy: 0.9126126170158386\n",
      "Epoch:  1391 , Loss:  0.6100353598594666   f1-score: 0.8584795594215393   accuracy: 0.9127928018569946\n",
      "Epoch:  1392 , Loss:  0.610015869140625   f1-score: 0.8583126068115234   accuracy: 0.9127026796340942\n",
      "Epoch:  1393 , Loss:  0.6099960803985596   f1-score: 0.8584795594215393   accuracy: 0.9127928018569946\n",
      "Epoch:  1394 , Loss:  0.6099762320518494   f1-score: 0.8584795594215393   accuracy: 0.9127928018569946\n",
      "Epoch:  1395 , Loss:  0.6099569797515869   f1-score: 0.8584795594215393   accuracy: 0.9127928018569946\n",
      "Epoch:  1396 , Loss:  0.6099371314048767   f1-score: 0.8586463928222656   accuracy: 0.9128828644752502\n",
      "Epoch:  1397 , Loss:  0.6099174618721008   f1-score: 0.8586463928222656   accuracy: 0.9128828644752502\n",
      "Epoch:  1398 , Loss:  0.6098981499671936   f1-score: 0.8586463928222656   accuracy: 0.9128828644752502\n",
      "Epoch:  1399 , Loss:  0.609878420829773   f1-score: 0.8586463928222656   accuracy: 0.9128828644752502\n",
      "Epoch:  1400 , Loss:  0.6098587512969971   f1-score: 0.8586463928222656   accuracy: 0.9128828644752502\n",
      "Epoch:  1401 , Loss:  0.6098394393920898   f1-score: 0.8586463928222656   accuracy: 0.9128828644752502\n",
      "Epoch:  1402 , Loss:  0.6098196506500244   f1-score: 0.8586463928222656   accuracy: 0.9128828644752502\n",
      "Epoch:  1403 , Loss:  0.6098001003265381   f1-score: 0.8587719202041626   accuracy: 0.9129729866981506\n",
      "Epoch:  1404 , Loss:  0.6097805500030518   f1-score: 0.8587719202041626   accuracy: 0.9129729866981506\n",
      "Epoch:  1405 , Loss:  0.6097610592842102   f1-score: 0.8587719202041626   accuracy: 0.9129729866981506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1406 , Loss:  0.6097416281700134   f1-score: 0.8588975071907043   accuracy: 0.9130630493164062\n",
      "Epoch:  1407 , Loss:  0.6097221374511719   f1-score: 0.8588975071907043   accuracy: 0.9130630493164062\n",
      "Epoch:  1408 , Loss:  0.6097027063369751   f1-score: 0.8588975071907043   accuracy: 0.9130630493164062\n",
      "Epoch:  1409 , Loss:  0.6096832752227783   f1-score: 0.8588975071907043   accuracy: 0.9130630493164062\n",
      "Epoch:  1410 , Loss:  0.6096639633178711   f1-score: 0.8590643405914307   accuracy: 0.9131531715393066\n",
      "Epoch:  1411 , Loss:  0.6096444129943848   f1-score: 0.8590643405914307   accuracy: 0.9131531715393066\n",
      "Epoch:  1412 , Loss:  0.6096253395080566   f1-score: 0.8593155741691589   accuracy: 0.9133333563804626\n",
      "Epoch:  1413 , Loss:  0.6096059679985046   f1-score: 0.8594824075698853   accuracy: 0.9134234189987183\n",
      "Epoch:  1414 , Loss:  0.6095869541168213   f1-score: 0.8594824075698853   accuracy: 0.9134234189987183\n",
      "Epoch:  1415 , Loss:  0.6095675826072693   f1-score: 0.8594824075698853   accuracy: 0.9134234189987183\n",
      "Epoch:  1416 , Loss:  0.6095486879348755   f1-score: 0.8594824075698853   accuracy: 0.9134234189987183\n",
      "Epoch:  1417 , Loss:  0.6095294952392578   f1-score: 0.8596080541610718   accuracy: 0.9135135412216187\n",
      "Epoch:  1418 , Loss:  0.6095107793807983   f1-score: 0.859649121761322   accuracy: 0.9135135412216187\n",
      "Epoch:  1419 , Loss:  0.6094917058944702   f1-score: 0.8598158359527588   accuracy: 0.9136036038398743\n",
      "Epoch:  1420 , Loss:  0.6094728708267212   f1-score: 0.8599415421485901   accuracy: 0.9136936664581299\n",
      "Epoch:  1421 , Loss:  0.6094540953636169   f1-score: 0.8598158359527588   accuracy: 0.9136036038398743\n",
      "Epoch:  1422 , Loss:  0.6094350218772888   f1-score: 0.8598158359527588   accuracy: 0.9136036038398743\n",
      "Epoch:  1423 , Loss:  0.6094165444374084   f1-score: 0.8598158359527588   accuracy: 0.9136036038398743\n",
      "Epoch:  1424 , Loss:  0.6093974709510803   f1-score: 0.8598158359527588   accuracy: 0.9136036038398743\n",
      "Epoch:  1425 , Loss:  0.6093788146972656   f1-score: 0.8598158359527588   accuracy: 0.9136036038398743\n",
      "Epoch:  1426 , Loss:  0.6093600392341614   f1-score: 0.8599824905395508   accuracy: 0.9136936664581299\n",
      "Epoch:  1427 , Loss:  0.609341561794281   f1-score: 0.8599824905395508   accuracy: 0.9136936664581299\n",
      "Epoch:  1428 , Loss:  0.6093229651451111   f1-score: 0.8599824905395508   accuracy: 0.9136936664581299\n",
      "Epoch:  1429 , Loss:  0.6093044281005859   f1-score: 0.8599824905395508   accuracy: 0.9136936664581299\n",
      "Epoch:  1430 , Loss:  0.609285831451416   f1-score: 0.8599824905395508   accuracy: 0.9136936664581299\n",
      "Epoch:  1431 , Loss:  0.6092673540115356   f1-score: 0.8601081967353821   accuracy: 0.9137837886810303\n",
      "Epoch:  1432 , Loss:  0.6092489361763   f1-score: 0.8601081967353821   accuracy: 0.9137837886810303\n",
      "Epoch:  1433 , Loss:  0.6092303395271301   f1-score: 0.8601081967353821   accuracy: 0.9137837886810303\n",
      "Epoch:  1434 , Loss:  0.6092121005058289   f1-score: 0.8601081967353821   accuracy: 0.9137837886810303\n",
      "Epoch:  1435 , Loss:  0.6091938614845276   f1-score: 0.8601081967353821   accuracy: 0.9137837886810303\n",
      "Epoch:  1436 , Loss:  0.6091753244400024   f1-score: 0.8601081967353821   accuracy: 0.9137837886810303\n",
      "Epoch:  1437 , Loss:  0.6091572642326355   f1-score: 0.8601081967353821   accuracy: 0.9137837886810303\n",
      "Epoch:  1438 , Loss:  0.6091388463973999   f1-score: 0.8601081967353821   accuracy: 0.9137837886810303\n",
      "Epoch:  1439 , Loss:  0.6091204285621643   f1-score: 0.8602339029312134   accuracy: 0.9138738512992859\n",
      "Epoch:  1440 , Loss:  0.6091024875640869   f1-score: 0.8602339029312134   accuracy: 0.9138738512992859\n",
      "Epoch:  1441 , Loss:  0.6090838313102722   f1-score: 0.8603597283363342   accuracy: 0.9139639735221863\n",
      "Epoch:  1442 , Loss:  0.60906583070755   f1-score: 0.8603597283363342   accuracy: 0.9139639735221863\n",
      "Epoch:  1443 , Loss:  0.6090472936630249   f1-score: 0.8606928586959839   accuracy: 0.9141441583633423\n",
      "Epoch:  1444 , Loss:  0.6090294122695923   f1-score: 0.8606521487236023   accuracy: 0.9141441583633423\n",
      "Epoch:  1445 , Loss:  0.6090110540390015   f1-score: 0.8608186841011047   accuracy: 0.9142342209815979\n",
      "Epoch:  1446 , Loss:  0.6089928150177002   f1-score: 0.8609852194786072   accuracy: 0.9143243432044983\n",
      "Epoch:  1447 , Loss:  0.6089745163917542   f1-score: 0.8609852194786072   accuracy: 0.9143243432044983\n",
      "Epoch:  1448 , Loss:  0.6089563369750977   f1-score: 0.8611516952514648   accuracy: 0.9144144058227539\n",
      "Epoch:  1449 , Loss:  0.6089380979537964   f1-score: 0.8611516952514648   accuracy: 0.9144144058227539\n",
      "Epoch:  1450 , Loss:  0.6089200973510742   f1-score: 0.8613181114196777   accuracy: 0.9145045280456543\n",
      "Epoch:  1451 , Loss:  0.608901858329773   f1-score: 0.8613181114196777   accuracy: 0.9145045280456543\n",
      "Epoch:  1452 , Loss:  0.608883798122406   f1-score: 0.8613181114196777   accuracy: 0.9145045280456543\n",
      "Epoch:  1453 , Loss:  0.6088656187057495   f1-score: 0.8613181114196777   accuracy: 0.9145045280456543\n",
      "Epoch:  1454 , Loss:  0.6088475584983826   f1-score: 0.8611516952514648   accuracy: 0.9144144058227539\n",
      "Epoch:  1455 , Loss:  0.6088293194770813   f1-score: 0.8614439964294434   accuracy: 0.9145945906639099\n",
      "Epoch:  1456 , Loss:  0.6088112592697144   f1-score: 0.8614845275878906   accuracy: 0.9145945906639099\n",
      "Epoch:  1457 , Loss:  0.6087930202484131   f1-score: 0.8614439964294434   accuracy: 0.9145945906639099\n",
      "Epoch:  1458 , Loss:  0.6087748408317566   f1-score: 0.8613181114196777   accuracy: 0.9145045280456543\n",
      "Epoch:  1459 , Loss:  0.6087567210197449   f1-score: 0.8614845275878906   accuracy: 0.9145945906639099\n",
      "Epoch:  1460 , Loss:  0.6087384819984436   f1-score: 0.8614845275878906   accuracy: 0.9145945906639099\n",
      "Epoch:  1461 , Loss:  0.6087204813957214   f1-score: 0.861650824546814   accuracy: 0.9146847128868103\n",
      "Epoch:  1462 , Loss:  0.6087022423744202   f1-score: 0.861650824546814   accuracy: 0.9146847128868103\n",
      "Epoch:  1463 , Loss:  0.6086840033531189   f1-score: 0.861650824546814   accuracy: 0.9146847128868103\n",
      "Epoch:  1464 , Loss:  0.6086658835411072   f1-score: 0.861650824546814   accuracy: 0.9146847128868103\n",
      "Epoch:  1465 , Loss:  0.6086477041244507   f1-score: 0.861650824546814   accuracy: 0.9146847128868103\n",
      "Epoch:  1466 , Loss:  0.6086294054985046   f1-score: 0.861650824546814   accuracy: 0.9146847128868103\n",
      "Epoch:  1467 , Loss:  0.6086112856864929   f1-score: 0.8619430065155029   accuracy: 0.9148648381233215\n",
      "Epoch:  1468 , Loss:  0.6085928678512573   f1-score: 0.8619430065155029   accuracy: 0.9148648381233215\n",
      "Epoch:  1469 , Loss:  0.6085745096206665   f1-score: 0.8622754216194153   accuracy: 0.9150450229644775\n",
      "Epoch:  1470 , Loss:  0.6085559129714966   f1-score: 0.8622754216194153   accuracy: 0.9150450229644775\n",
      "Epoch:  1471 , Loss:  0.6085377335548401   f1-score: 0.8626076579093933   accuracy: 0.9152252078056335\n",
      "Epoch:  1472 , Loss:  0.6085190773010254   f1-score: 0.8626076579093933   accuracy: 0.9152252078056335\n",
      "Epoch:  1473 , Loss:  0.6085004210472107   f1-score: 0.8627336621284485   accuracy: 0.9153153300285339\n",
      "Epoch:  1474 , Loss:  0.6084819436073303   f1-score: 0.8627336621284485   accuracy: 0.9153153300285339\n",
      "Epoch:  1475 , Loss:  0.6084632873535156   f1-score: 0.8628997206687927   accuracy: 0.9154053926467896\n",
      "Epoch:  1476 , Loss:  0.6084445714950562   f1-score: 0.8628997206687927   accuracy: 0.9154053926467896\n",
      "Epoch:  1477 , Loss:  0.6084261536598206   f1-score: 0.8632316589355469   accuracy: 0.9155855774879456\n",
      "Epoch:  1478 , Loss:  0.6084074378013611   f1-score: 0.863357663154602   accuracy: 0.915675699710846\n",
      "Epoch:  1479 , Loss:  0.6083887815475464   f1-score: 0.863357663154602   accuracy: 0.915675699710846\n",
      "Epoch:  1480 , Loss:  0.6083701252937317   f1-score: 0.8635236024856567   accuracy: 0.9157657623291016\n",
      "Epoch:  1481 , Loss:  0.6083513498306274   f1-score: 0.8636894226074219   accuracy: 0.915855884552002\n",
      "Epoch:  1482 , Loss:  0.6083327531814575   f1-score: 0.8636894226074219   accuracy: 0.915855884552002\n",
      "Epoch:  1483 , Loss:  0.6083140969276428   f1-score: 0.8635236024856567   accuracy: 0.9157657623291016\n",
      "Epoch:  1484 , Loss:  0.6082952618598938   f1-score: 0.8636894226074219   accuracy: 0.915855884552002\n",
      "Epoch:  1485 , Loss:  0.6082766056060791   f1-score: 0.863981306552887   accuracy: 0.9160360097885132\n",
      "Epoch:  1486 , Loss:  0.6082579493522644   f1-score: 0.863981306552887   accuracy: 0.9160360097885132\n",
      "Epoch:  1487 , Loss:  0.6082391142845154   f1-score: 0.8641470670700073   accuracy: 0.9161261320114136\n",
      "Epoch:  1488 , Loss:  0.6082204580307007   f1-score: 0.8641470670700073   accuracy: 0.9161261320114136\n",
      "Epoch:  1489 , Loss:  0.6082016229629517   f1-score: 0.864273190498352   accuracy: 0.9162161946296692\n",
      "Epoch:  1490 , Loss:  0.608182966709137   f1-score: 0.8644389510154724   accuracy: 0.9163063168525696\n",
      "Epoch:  1491 , Loss:  0.608164370059967   f1-score: 0.864273190498352   accuracy: 0.9162161946296692\n",
      "Epoch:  1492 , Loss:  0.6081454157829285   f1-score: 0.8644389510154724   accuracy: 0.9163063168525696\n",
      "Epoch:  1493 , Loss:  0.6081270575523376   f1-score: 0.8646045923233032   accuracy: 0.9163963794708252\n",
      "Epoch:  1494 , Loss:  0.6081081032752991   f1-score: 0.8646045923233032   accuracy: 0.9163963794708252\n",
      "Epoch:  1495 , Loss:  0.60808926820755   f1-score: 0.8648964166641235   accuracy: 0.9165765643119812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1496 , Loss:  0.6080705523490906   f1-score: 0.8648964166641235   accuracy: 0.9165765643119812\n",
      "Epoch:  1497 , Loss:  0.6080518960952759   f1-score: 0.8648964166641235   accuracy: 0.9165765643119812\n",
      "Epoch:  1498 , Loss:  0.6080331802368164   f1-score: 0.8648964166641235   accuracy: 0.9165765643119812\n",
      "Epoch:  1499 , Loss:  0.6080145835876465   f1-score: 0.8650619983673096   accuracy: 0.9166666865348816\n",
      "Epoch:  1500 , Loss:  0.607995867729187   f1-score: 0.8648964166641235   accuracy: 0.9165765643119812\n",
      "Epoch:  1501 , Loss:  0.6079774498939514   f1-score: 0.8651488423347473   accuracy: 0.9167567491531372\n",
      "Epoch:  1502 , Loss:  0.6079586744308472   f1-score: 0.8653144836425781   accuracy: 0.9168468713760376\n",
      "Epoch:  1503 , Loss:  0.6079400181770325   f1-score: 0.8653144836425781   accuracy: 0.9168468713760376\n",
      "Epoch:  1504 , Loss:  0.6079214215278625   f1-score: 0.8651488423347473   accuracy: 0.9167567491531372\n",
      "Epoch:  1505 , Loss:  0.6079028844833374   f1-score: 0.8657718300819397   accuracy: 0.9171171188354492\n",
      "Epoch:  1506 , Loss:  0.6078842878341675   f1-score: 0.8657326102256775   accuracy: 0.9171171188354492\n",
      "Epoch:  1507 , Loss:  0.6078658103942871   f1-score: 0.8657326102256775   accuracy: 0.9171171188354492\n",
      "Epoch:  1508 , Loss:  0.6078471541404724   f1-score: 0.8658981323242188   accuracy: 0.9172071814537048\n",
      "Epoch:  1509 , Loss:  0.607828676700592   f1-score: 0.8660635948181152   accuracy: 0.9172973036766052\n",
      "Epoch:  1510 , Loss:  0.607810378074646   f1-score: 0.8662290573120117   accuracy: 0.9173873662948608\n",
      "Epoch:  1511 , Loss:  0.6077918410301208   f1-score: 0.8663944005966187   accuracy: 0.9174774885177612\n",
      "Epoch:  1512 , Loss:  0.6077736616134644   f1-score: 0.8665597438812256   accuracy: 0.9175675511360168\n",
      "Epoch:  1513 , Loss:  0.6077553033828735   f1-score: 0.8665597438812256   accuracy: 0.9175675511360168\n",
      "Epoch:  1514 , Loss:  0.6077369451522827   f1-score: 0.8665597438812256   accuracy: 0.9175675511360168\n",
      "Epoch:  1515 , Loss:  0.6077187061309814   f1-score: 0.8665597438812256   accuracy: 0.9175675511360168\n",
      "Epoch:  1516 , Loss:  0.6077005863189697   f1-score: 0.8665597438812256   accuracy: 0.9175675511360168\n",
      "Epoch:  1517 , Loss:  0.6076827645301819   f1-score: 0.866724967956543   accuracy: 0.9176576733589172\n",
      "Epoch:  1518 , Loss:  0.6076641082763672   f1-score: 0.866724967956543   accuracy: 0.9176576733589172\n",
      "Epoch:  1519 , Loss:  0.6076462268829346   f1-score: 0.8665597438812256   accuracy: 0.9175675511360168\n",
      "Epoch:  1520 , Loss:  0.6076278686523438   f1-score: 0.866724967956543   accuracy: 0.9176576733589172\n",
      "Epoch:  1521 , Loss:  0.6076098680496216   f1-score: 0.8670554161071777   accuracy: 0.9178378582000732\n",
      "Epoch:  1522 , Loss:  0.6075917482376099   f1-score: 0.8670554161071777   accuracy: 0.9178378582000732\n",
      "Epoch:  1523 , Loss:  0.6075737476348877   f1-score: 0.8672205209732056   accuracy: 0.9179279208183289\n",
      "Epoch:  1524 , Loss:  0.6075558662414551   f1-score: 0.8670554161071777   accuracy: 0.9178378582000732\n",
      "Epoch:  1525 , Loss:  0.6075378656387329   f1-score: 0.8672205209732056   accuracy: 0.9179279208183289\n",
      "Epoch:  1526 , Loss:  0.6075199842453003   f1-score: 0.8673856258392334   accuracy: 0.9180180430412292\n",
      "Epoch:  1527 , Loss:  0.6075019240379333   f1-score: 0.8672205209732056   accuracy: 0.9179279208183289\n",
      "Epoch:  1528 , Loss:  0.6074841618537903   f1-score: 0.8670554161071777   accuracy: 0.9178378582000732\n",
      "Epoch:  1529 , Loss:  0.6074663400650024   f1-score: 0.8672205209732056   accuracy: 0.9179279208183289\n",
      "Epoch:  1530 , Loss:  0.6074485182762146   f1-score: 0.8672205209732056   accuracy: 0.9179279208183289\n",
      "Epoch:  1531 , Loss:  0.6074308156967163   f1-score: 0.8672205209732056   accuracy: 0.9179279208183289\n",
      "Epoch:  1532 , Loss:  0.6074133515357971   f1-score: 0.8673856258392334   accuracy: 0.9180180430412292\n",
      "Epoch:  1533 , Loss:  0.6073954701423645   f1-score: 0.8675506114959717   accuracy: 0.9181081056594849\n",
      "Epoch:  1534 , Loss:  0.6073778867721558   f1-score: 0.86771559715271   accuracy: 0.9181982278823853\n",
      "Epoch:  1535 , Loss:  0.6073602437973022   f1-score: 0.86771559715271   accuracy: 0.9181982278823853\n",
      "Epoch:  1536 , Loss:  0.607342541217804   f1-score: 0.86771559715271   accuracy: 0.9181982278823853\n",
      "Epoch:  1537 , Loss:  0.6073253154754639   f1-score: 0.86771559715271   accuracy: 0.9181982278823853\n",
      "Epoch:  1538 , Loss:  0.607307493686676   f1-score: 0.8680070042610168   accuracy: 0.9183783531188965\n",
      "Epoch:  1539 , Loss:  0.6072903275489807   f1-score: 0.8680070042610168   accuracy: 0.9183783531188965\n",
      "Epoch:  1540 , Loss:  0.607272744178772   f1-score: 0.8680070042610168   accuracy: 0.9183783531188965\n",
      "Epoch:  1541 , Loss:  0.6072555184364319   f1-score: 0.8680070042610168   accuracy: 0.9183783531188965\n",
      "Epoch:  1542 , Loss:  0.6072382926940918   f1-score: 0.8683367371559143   accuracy: 0.9185585379600525\n",
      "Epoch:  1543 , Loss:  0.6072205901145935   f1-score: 0.8683367371559143   accuracy: 0.9185585379600525\n",
      "Epoch:  1544 , Loss:  0.6072035431861877   f1-score: 0.8683367371559143   accuracy: 0.9185585379600525\n",
      "Epoch:  1545 , Loss:  0.6071860790252686   f1-score: 0.8685015439987183   accuracy: 0.9186486601829529\n",
      "Epoch:  1546 , Loss:  0.6071692109107971   f1-score: 0.8685015439987183   accuracy: 0.9186486601829529\n",
      "Epoch:  1547 , Loss:  0.607151985168457   f1-score: 0.8686662912368774   accuracy: 0.9187387228012085\n",
      "Epoch:  1548 , Loss:  0.6071346998214722   f1-score: 0.8686662912368774   accuracy: 0.9187387228012085\n",
      "Epoch:  1549 , Loss:  0.6071182489395142   f1-score: 0.8689956068992615   accuracy: 0.9189189076423645\n",
      "Epoch:  1550 , Loss:  0.6071006655693054   f1-score: 0.8691602349281311   accuracy: 0.9190090298652649\n",
      "Epoch:  1551 , Loss:  0.6070845127105713   f1-score: 0.8689956068992615   accuracy: 0.9189189076423645\n",
      "Epoch:  1552 , Loss:  0.6070672869682312   f1-score: 0.8691602349281311   accuracy: 0.9190090298652649\n",
      "Epoch:  1553 , Loss:  0.6070497632026672   f1-score: 0.8691602349281311   accuracy: 0.9190090298652649\n",
      "Epoch:  1554 , Loss:  0.6070336103439331   f1-score: 0.8691602349281311   accuracy: 0.9190090298652649\n",
      "Epoch:  1555 , Loss:  0.6070163249969482   f1-score: 0.869324803352356   accuracy: 0.9190990924835205\n",
      "Epoch:  1556 , Loss:  0.6069995760917664   f1-score: 0.869324803352356   accuracy: 0.9190990924835205\n",
      "Epoch:  1557 , Loss:  0.6069828271865845   f1-score: 0.8694513440132141   accuracy: 0.9191892147064209\n",
      "Epoch:  1558 , Loss:  0.6069658398628235   f1-score: 0.8694513440132141   accuracy: 0.9191892147064209\n",
      "Epoch:  1559 , Loss:  0.6069490313529968   f1-score: 0.8694513440132141   accuracy: 0.9191892147064209\n",
      "Epoch:  1560 , Loss:  0.6069322228431702   f1-score: 0.8694513440132141   accuracy: 0.9191892147064209\n",
      "Epoch:  1561 , Loss:  0.6069155931472778   f1-score: 0.8694513440132141   accuracy: 0.9191892147064209\n",
      "Epoch:  1562 , Loss:  0.6068987250328064   f1-score: 0.8694513440132141   accuracy: 0.9191892147064209\n",
      "Epoch:  1563 , Loss:  0.6068820357322693   f1-score: 0.8696158528327942   accuracy: 0.9192792773246765\n",
      "Epoch:  1564 , Loss:  0.6068655252456665   f1-score: 0.8696158528327942   accuracy: 0.9192792773246765\n",
      "Epoch:  1565 , Loss:  0.6068488955497742   f1-score: 0.8696158528327942   accuracy: 0.9192792773246765\n",
      "Epoch:  1566 , Loss:  0.6068322658538818   f1-score: 0.8697803020477295   accuracy: 0.9193693399429321\n",
      "Epoch:  1567 , Loss:  0.6068158745765686   f1-score: 0.8697803020477295   accuracy: 0.9193693399429321\n",
      "Epoch:  1568 , Loss:  0.6067990660667419   f1-score: 0.8697803020477295   accuracy: 0.9193693399429321\n",
      "Epoch:  1569 , Loss:  0.6067826151847839   f1-score: 0.8697803020477295   accuracy: 0.9193693399429321\n",
      "Epoch:  1570 , Loss:  0.6067659258842468   f1-score: 0.8697803020477295   accuracy: 0.9193693399429321\n",
      "Epoch:  1571 , Loss:  0.6067492961883545   f1-score: 0.8697803020477295   accuracy: 0.9193693399429321\n",
      "Epoch:  1572 , Loss:  0.6067326664924622   f1-score: 0.86994469165802   accuracy: 0.9194594621658325\n",
      "Epoch:  1573 , Loss:  0.6067162752151489   f1-score: 0.86994469165802   accuracy: 0.9194594621658325\n",
      "Epoch:  1574 , Loss:  0.6066996455192566   f1-score: 0.8702734112739563   accuracy: 0.9196396470069885\n",
      "Epoch:  1575 , Loss:  0.6066830158233643   f1-score: 0.8702734112739563   accuracy: 0.9196396470069885\n",
      "Epoch:  1576 , Loss:  0.6066665649414062   f1-score: 0.8702734112739563   accuracy: 0.9196396470069885\n",
      "Epoch:  1577 , Loss:  0.6066501140594482   f1-score: 0.8702734112739563   accuracy: 0.9196396470069885\n",
      "Epoch:  1578 , Loss:  0.6066333055496216   f1-score: 0.8702734112739563   accuracy: 0.9196396470069885\n",
      "Epoch:  1579 , Loss:  0.6066170334815979   f1-score: 0.8704376816749573   accuracy: 0.9197297096252441\n",
      "Epoch:  1580 , Loss:  0.606600284576416   f1-score: 0.8704376816749573   accuracy: 0.9197297096252441\n",
      "Epoch:  1581 , Loss:  0.606583833694458   f1-score: 0.8704376816749573   accuracy: 0.9197297096252441\n",
      "Epoch:  1582 , Loss:  0.6065673232078552   f1-score: 0.8704376816749573   accuracy: 0.9197297096252441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1583 , Loss:  0.6065506339073181   f1-score: 0.8704376816749573   accuracy: 0.9197297096252441\n",
      "Epoch:  1584 , Loss:  0.6065341830253601   f1-score: 0.8706018924713135   accuracy: 0.9198198318481445\n",
      "Epoch:  1585 , Loss:  0.6065175533294678   f1-score: 0.8706018924713135   accuracy: 0.9198198318481445\n",
      "Epoch:  1586 , Loss:  0.606501042842865   f1-score: 0.8706018924713135   accuracy: 0.9198198318481445\n",
      "Epoch:  1587 , Loss:  0.6064844727516174   f1-score: 0.8706018924713135   accuracy: 0.9198198318481445\n",
      "Epoch:  1588 , Loss:  0.6064677834510803   f1-score: 0.8706018924713135   accuracy: 0.9198198318481445\n",
      "Epoch:  1589 , Loss:  0.606451690196991   f1-score: 0.8706018924713135   accuracy: 0.9198198318481445\n",
      "Epoch:  1590 , Loss:  0.6064350605010986   f1-score: 0.8706018924713135   accuracy: 0.9198198318481445\n",
      "Epoch:  1591 , Loss:  0.6064184904098511   f1-score: 0.8707284927368164   accuracy: 0.9199098944664001\n",
      "Epoch:  1592 , Loss:  0.6064020991325378   f1-score: 0.8707284927368164   accuracy: 0.9199098944664001\n",
      "Epoch:  1593 , Loss:  0.6063855886459351   f1-score: 0.8707284927368164   accuracy: 0.9199098944664001\n",
      "Epoch:  1594 , Loss:  0.606368899345398   f1-score: 0.8707284927368164   accuracy: 0.9199098944664001\n",
      "Epoch:  1595 , Loss:  0.6063526272773743   f1-score: 0.8708927035331726   accuracy: 0.9200000166893005\n",
      "Epoch:  1596 , Loss:  0.606336236000061   f1-score: 0.871056854724884   accuracy: 0.9200900793075562\n",
      "Epoch:  1597 , Loss:  0.6063194274902344   f1-score: 0.871056854724884   accuracy: 0.9200900793075562\n",
      "Epoch:  1598 , Loss:  0.6063033938407898   f1-score: 0.871056854724884   accuracy: 0.9200900793075562\n",
      "Epoch:  1599 , Loss:  0.6062865853309631   f1-score: 0.8713849782943726   accuracy: 0.9202702641487122\n",
      "Epoch:  1600 , Loss:  0.6062700152397156   f1-score: 0.8713849782943726   accuracy: 0.9202702641487122\n",
      "Epoch:  1601 , Loss:  0.6062536835670471   f1-score: 0.8713476061820984   accuracy: 0.9202702641487122\n",
      "Epoch:  1602 , Loss:  0.6062373518943787   f1-score: 0.8715116381645203   accuracy: 0.9203603863716125\n",
      "Epoch:  1603 , Loss:  0.6062206029891968   f1-score: 0.8715116381645203   accuracy: 0.9203603863716125\n",
      "Epoch:  1604 , Loss:  0.6062043905258179   f1-score: 0.8715116381645203   accuracy: 0.9203603863716125\n",
      "Epoch:  1605 , Loss:  0.6061882376670837   f1-score: 0.8718395829200745   accuracy: 0.9205405116081238\n",
      "Epoch:  1606 , Loss:  0.6061716079711914   f1-score: 0.8719663023948669   accuracy: 0.9206306338310242\n",
      "Epoch:  1607 , Loss:  0.6061558127403259   f1-score: 0.8720930218696594   accuracy: 0.9207206964492798\n",
      "Epoch:  1608 , Loss:  0.6061393618583679   f1-score: 0.8724207878112793   accuracy: 0.9209008812904358\n",
      "Epoch:  1609 , Loss:  0.606123149394989   f1-score: 0.8724207878112793   accuracy: 0.9209008812904358\n",
      "Epoch:  1610 , Loss:  0.6061071753501892   f1-score: 0.8725846409797668   accuracy: 0.9209910035133362\n",
      "Epoch:  1611 , Loss:  0.606091320514679   f1-score: 0.8725846409797668   accuracy: 0.9209910035133362\n",
      "Epoch:  1612 , Loss:  0.6060752868652344   f1-score: 0.8727483749389648   accuracy: 0.9210810661315918\n",
      "Epoch:  1613 , Loss:  0.606059193611145   f1-score: 0.8730757832527161   accuracy: 0.9212612509727478\n",
      "Epoch:  1614 , Loss:  0.6060433387756348   f1-score: 0.8732394576072693   accuracy: 0.9213513731956482\n",
      "Epoch:  1615 , Loss:  0.6060276627540588   f1-score: 0.8732394576072693   accuracy: 0.9213513731956482\n",
      "Epoch:  1616 , Loss:  0.6060113906860352   f1-score: 0.8735665678977966   accuracy: 0.9215315580368042\n",
      "Epoch:  1617 , Loss:  0.605995774269104   f1-score: 0.8737300634384155   accuracy: 0.9216216206550598\n",
      "Epoch:  1618 , Loss:  0.6059799790382385   f1-score: 0.8737300634384155   accuracy: 0.9216216206550598\n",
      "Epoch:  1619 , Loss:  0.6059640645980835   f1-score: 0.8737300634384155   accuracy: 0.9216216206550598\n",
      "Epoch:  1620 , Loss:  0.6059483289718628   f1-score: 0.8737300634384155   accuracy: 0.9216216206550598\n",
      "Epoch:  1621 , Loss:  0.6059325933456421   f1-score: 0.8737300634384155   accuracy: 0.9216216206550598\n",
      "Epoch:  1622 , Loss:  0.6059168577194214   f1-score: 0.8737300634384155   accuracy: 0.9216216206550598\n",
      "Epoch:  1623 , Loss:  0.6059009432792664   f1-score: 0.8737300634384155   accuracy: 0.9216216206550598\n",
      "Epoch:  1624 , Loss:  0.6058854460716248   f1-score: 0.8737300634384155   accuracy: 0.9216216206550598\n",
      "Epoch:  1625 , Loss:  0.6058695912361145   f1-score: 0.874056875705719   accuracy: 0.9218018054962158\n",
      "Epoch:  1626 , Loss:  0.605853796005249   f1-score: 0.8742202520370483   accuracy: 0.9218918681144714\n",
      "Epoch:  1627 , Loss:  0.6058383584022522   f1-score: 0.8742202520370483   accuracy: 0.9218918681144714\n",
      "Epoch:  1628 , Loss:  0.6058225035667419   f1-score: 0.8743835091590881   accuracy: 0.9219819903373718\n",
      "Epoch:  1629 , Loss:  0.6058067679405212   f1-score: 0.8745467662811279   accuracy: 0.9220720529556274\n",
      "Epoch:  1630 , Loss:  0.6057910919189453   f1-score: 0.8743835091590881   accuracy: 0.9219819903373718\n",
      "Epoch:  1631 , Loss:  0.6057754755020142   f1-score: 0.874709963798523   accuracy: 0.9221621751785278\n",
      "Epoch:  1632 , Loss:  0.6057596206665039   f1-score: 0.874873161315918   accuracy: 0.9222522377967834\n",
      "Epoch:  1633 , Loss:  0.605743944644928   f1-score: 0.874873161315918   accuracy: 0.9222522377967834\n",
      "Epoch:  1634 , Loss:  0.605728268623352   f1-score: 0.874873161315918   accuracy: 0.9222522377967834\n",
      "Epoch:  1635 , Loss:  0.6057124137878418   f1-score: 0.874873161315918   accuracy: 0.9222522377967834\n",
      "Epoch:  1636 , Loss:  0.6056967973709106   f1-score: 0.874873161315918   accuracy: 0.9222522377967834\n",
      "Epoch:  1637 , Loss:  0.6056810617446899   f1-score: 0.874873161315918   accuracy: 0.9222522377967834\n",
      "Epoch:  1638 , Loss:  0.605665385723114   f1-score: 0.874873161315918   accuracy: 0.9222522377967834\n",
      "Epoch:  1639 , Loss:  0.6056498289108276   f1-score: 0.874873161315918   accuracy: 0.9222522377967834\n",
      "Epoch:  1640 , Loss:  0.6056340932846069   f1-score: 0.874873161315918   accuracy: 0.9222522377967834\n",
      "Epoch:  1641 , Loss:  0.6056182980537415   f1-score: 0.874873161315918   accuracy: 0.9222522377967834\n",
      "Epoch:  1642 , Loss:  0.6056025624275208   f1-score: 0.874873161315918   accuracy: 0.9222522377967834\n",
      "Epoch:  1643 , Loss:  0.6055868864059448   f1-score: 0.874873161315918   accuracy: 0.9222522377967834\n",
      "Epoch:  1644 , Loss:  0.6055710315704346   f1-score: 0.874873161315918   accuracy: 0.9222522377967834\n",
      "Epoch:  1645 , Loss:  0.6055553555488586   f1-score: 0.874873161315918   accuracy: 0.9222522377967834\n",
      "Epoch:  1646 , Loss:  0.6055395603179932   f1-score: 0.874873161315918   accuracy: 0.9222522377967834\n",
      "Epoch:  1647 , Loss:  0.6055237650871277   f1-score: 0.8750362396240234   accuracy: 0.9223423600196838\n",
      "Epoch:  1648 , Loss:  0.605508029460907   f1-score: 0.8750362396240234   accuracy: 0.9223423600196838\n",
      "Epoch:  1649 , Loss:  0.6054921746253967   f1-score: 0.8751993179321289   accuracy: 0.9224324226379395\n",
      "Epoch:  1650 , Loss:  0.605476438999176   f1-score: 0.8755252957344055   accuracy: 0.9226126074790955\n",
      "Epoch:  1651 , Loss:  0.6054606437683105   f1-score: 0.8755252957344055   accuracy: 0.9226126074790955\n",
      "Epoch:  1652 , Loss:  0.6054443717002869   f1-score: 0.8755252957344055   accuracy: 0.9226126074790955\n",
      "Epoch:  1653 , Loss:  0.6054290533065796   f1-score: 0.8755252957344055   accuracy: 0.9226126074790955\n",
      "Epoch:  1654 , Loss:  0.6054129004478455   f1-score: 0.8755252957344055   accuracy: 0.9226126074790955\n",
      "Epoch:  1655 , Loss:  0.6053971648216248   f1-score: 0.8756881952285767   accuracy: 0.9227027297019958\n",
      "Epoch:  1656 , Loss:  0.6053813099861145   f1-score: 0.8756881952285767   accuracy: 0.9227027297019958\n",
      "Epoch:  1657 , Loss:  0.6053652763366699   f1-score: 0.8756881952285767   accuracy: 0.9227027297019958\n",
      "Epoch:  1658 , Loss:  0.6053498983383179   f1-score: 0.8760139346122742   accuracy: 0.9228828549385071\n",
      "Epoch:  1659 , Loss:  0.6053335666656494   f1-score: 0.8758510947227478   accuracy: 0.9227927923202515\n",
      "Epoch:  1660 , Loss:  0.6053174138069153   f1-score: 0.8758510947227478   accuracy: 0.9227927923202515\n",
      "Epoch:  1661 , Loss:  0.6053014397621155   f1-score: 0.8760139346122742   accuracy: 0.9228828549385071\n",
      "Epoch:  1662 , Loss:  0.6052857041358948   f1-score: 0.876140832901001   accuracy: 0.9229729771614075\n",
      "Epoch:  1663 , Loss:  0.6052694916725159   f1-score: 0.876140832901001   accuracy: 0.9229729771614075\n",
      "Epoch:  1664 , Loss:  0.605253279209137   f1-score: 0.8764305114746094   accuracy: 0.9231531620025635\n",
      "Epoch:  1665 , Loss:  0.605237603187561   f1-score: 0.8764305114746094   accuracy: 0.9231531620025635\n",
      "Epoch:  1666 , Loss:  0.6052213907241821   f1-score: 0.8764305114746094   accuracy: 0.9231531620025635\n",
      "Epoch:  1667 , Loss:  0.6052049398422241   f1-score: 0.8764305114746094   accuracy: 0.9231531620025635\n",
      "Epoch:  1668 , Loss:  0.6051892638206482   f1-score: 0.8764305114746094   accuracy: 0.9231531620025635\n",
      "Epoch:  1669 , Loss:  0.605172872543335   f1-score: 0.8765575289726257   accuracy: 0.9232432246208191\n",
      "Epoch:  1670 , Loss:  0.6051567196846008   f1-score: 0.8766845464706421   accuracy: 0.9233333468437195\n",
      "Epoch:  1671 , Loss:  0.6051406264305115   f1-score: 0.8770099878311157   accuracy: 0.9235135316848755\n",
      "Epoch:  1672 , Loss:  0.6051245331764221   f1-score: 0.8770099878311157   accuracy: 0.9235135316848755\n",
      "Epoch:  1673 , Loss:  0.6051082611083984   f1-score: 0.8768472671508789   accuracy: 0.9234234094619751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1674 , Loss:  0.6050922870635986   f1-score: 0.8770099878311157   accuracy: 0.9235135316848755\n",
      "Epoch:  1675 , Loss:  0.6050764918327332   f1-score: 0.8771726489067078   accuracy: 0.9236035943031311\n",
      "Epoch:  1676 , Loss:  0.605060338973999   f1-score: 0.8771726489067078   accuracy: 0.9236035943031311\n",
      "Epoch:  1677 , Loss:  0.6050446033477783   f1-score: 0.8771726489067078   accuracy: 0.9236035943031311\n",
      "Epoch:  1678 , Loss:  0.6050289869308472   f1-score: 0.8771726489067078   accuracy: 0.9236035943031311\n",
      "Epoch:  1679 , Loss:  0.6050130128860474   f1-score: 0.8771726489067078   accuracy: 0.9236035943031311\n",
      "Epoch:  1680 , Loss:  0.6049976348876953   f1-score: 0.877335250377655   accuracy: 0.9236937165260315\n",
      "Epoch:  1681 , Loss:  0.6049821376800537   f1-score: 0.877335250377655   accuracy: 0.9236937165260315\n",
      "Epoch:  1682 , Loss:  0.6049665212631226   f1-score: 0.87766033411026   accuracy: 0.9238739013671875\n",
      "Epoch:  1683 , Loss:  0.6049510836601257   f1-score: 0.87766033411026   accuracy: 0.9238739013671875\n",
      "Epoch:  1684 , Loss:  0.6049355864524841   f1-score: 0.87766033411026   accuracy: 0.9238739013671875\n",
      "Epoch:  1685 , Loss:  0.6049202680587769   f1-score: 0.87766033411026   accuracy: 0.9238739013671875\n",
      "Epoch:  1686 , Loss:  0.60490483045578   f1-score: 0.87766033411026   accuracy: 0.9238739013671875\n",
      "Epoch:  1687 , Loss:  0.604889452457428   f1-score: 0.87766033411026   accuracy: 0.9238739013671875\n",
      "Epoch:  1688 , Loss:  0.604874312877655   f1-score: 0.8778228163719177   accuracy: 0.9239639639854431\n",
      "Epoch:  1689 , Loss:  0.6048588752746582   f1-score: 0.8779852390289307   accuracy: 0.9240540266036987\n",
      "Epoch:  1690 , Loss:  0.6048438549041748   f1-score: 0.8779852390289307   accuracy: 0.9240540266036987\n",
      "Epoch:  1691 , Loss:  0.6048286557197571   f1-score: 0.8779852390289307   accuracy: 0.9240540266036987\n",
      "Epoch:  1692 , Loss:  0.6048135161399841   f1-score: 0.8781476020812988   accuracy: 0.9241441488265991\n",
      "Epoch:  1693 , Loss:  0.6047985553741455   f1-score: 0.8781476020812988   accuracy: 0.9241441488265991\n",
      "Epoch:  1694 , Loss:  0.6047834753990173   f1-score: 0.878309965133667   accuracy: 0.9242342114448547\n",
      "Epoch:  1695 , Loss:  0.604768693447113   f1-score: 0.8782747387886047   accuracy: 0.9242342114448547\n",
      "Epoch:  1696 , Loss:  0.6047534942626953   f1-score: 0.8784370422363281   accuracy: 0.9243243336677551\n",
      "Epoch:  1697 , Loss:  0.6047388911247253   f1-score: 0.8784370422363281   accuracy: 0.9243243336677551\n",
      "Epoch:  1698 , Loss:  0.6047238707542419   f1-score: 0.8784370422363281   accuracy: 0.9243243336677551\n",
      "Epoch:  1699 , Loss:  0.6047089695930481   f1-score: 0.8785993456840515   accuracy: 0.9244143962860107\n",
      "Epoch:  1700 , Loss:  0.6046943068504333   f1-score: 0.8787615895271301   accuracy: 0.9245045185089111\n",
      "Epoch:  1701 , Loss:  0.6046793460845947   f1-score: 0.8787615895271301   accuracy: 0.9245045185089111\n",
      "Epoch:  1702 , Loss:  0.60466468334198   f1-score: 0.8787615895271301   accuracy: 0.9245045185089111\n",
      "Epoch:  1703 , Loss:  0.6046499609947205   f1-score: 0.8787615895271301   accuracy: 0.9245045185089111\n",
      "Epoch:  1704 , Loss:  0.6046350002288818   f1-score: 0.8787615895271301   accuracy: 0.9245045185089111\n",
      "Epoch:  1705 , Loss:  0.604620635509491   f1-score: 0.878888726234436   accuracy: 0.9245945811271667\n",
      "Epoch:  1706 , Loss:  0.6046057343482971   f1-score: 0.878888726234436   accuracy: 0.9245945811271667\n",
      "Epoch:  1707 , Loss:  0.6045913696289062   f1-score: 0.8792130947113037   accuracy: 0.9247747659683228\n",
      "Epoch:  1708 , Loss:  0.604576826095581   f1-score: 0.8790509104728699   accuracy: 0.9246847033500671\n",
      "Epoch:  1709 , Loss:  0.6045618057250977   f1-score: 0.8792130947113037   accuracy: 0.9247747659683228\n",
      "Epoch:  1710 , Loss:  0.6045475006103516   f1-score: 0.8792130947113037   accuracy: 0.9247747659683228\n",
      "Epoch:  1711 , Loss:  0.604532778263092   f1-score: 0.8792130947113037   accuracy: 0.9247747659683228\n",
      "Epoch:  1712 , Loss:  0.6045182347297668   f1-score: 0.879375159740448   accuracy: 0.9248648881912231\n",
      "Epoch:  1713 , Loss:  0.6045037508010864   f1-score: 0.8795372247695923   accuracy: 0.9249549508094788\n",
      "Epoch:  1714 , Loss:  0.6044888496398926   f1-score: 0.8795372247695923   accuracy: 0.9249549508094788\n",
      "Epoch:  1715 , Loss:  0.6044743657112122   f1-score: 0.8795372247695923   accuracy: 0.9249549508094788\n",
      "Epoch:  1716 , Loss:  0.6044596433639526   f1-score: 0.8795372247695923   accuracy: 0.9249549508094788\n",
      "Epoch:  1717 , Loss:  0.6044449806213379   f1-score: 0.8795372247695923   accuracy: 0.9249549508094788\n",
      "Epoch:  1718 , Loss:  0.6044303774833679   f1-score: 0.8796992301940918   accuracy: 0.9250450730323792\n",
      "Epoch:  1719 , Loss:  0.6044155955314636   f1-score: 0.8796992301940918   accuracy: 0.9250450730323792\n",
      "Epoch:  1720 , Loss:  0.6044009327888489   f1-score: 0.8796992301940918   accuracy: 0.9250450730323792\n",
      "Epoch:  1721 , Loss:  0.6043863892555237   f1-score: 0.8796992301940918   accuracy: 0.9250450730323792\n",
      "Epoch:  1722 , Loss:  0.6043716073036194   f1-score: 0.8796992301940918   accuracy: 0.9250450730323792\n",
      "Epoch:  1723 , Loss:  0.6043570041656494   f1-score: 0.8798612356185913   accuracy: 0.9251351356506348\n",
      "Epoch:  1724 , Loss:  0.6043423414230347   f1-score: 0.8798612356185913   accuracy: 0.9251351356506348\n",
      "Epoch:  1725 , Loss:  0.6043274998664856   f1-score: 0.8801850080490112   accuracy: 0.9253153204917908\n",
      "Epoch:  1726 , Loss:  0.6043130159378052   f1-score: 0.8801850080490112   accuracy: 0.9253153204917908\n",
      "Epoch:  1727 , Loss:  0.6042981147766113   f1-score: 0.8801850080490112   accuracy: 0.9253153204917908\n",
      "Epoch:  1728 , Loss:  0.6042837500572205   f1-score: 0.8801850080490112   accuracy: 0.9253153204917908\n",
      "Epoch:  1729 , Loss:  0.6042690277099609   f1-score: 0.8801850080490112   accuracy: 0.9253153204917908\n",
      "Epoch:  1730 , Loss:  0.6042544841766357   f1-score: 0.8801850080490112   accuracy: 0.9253153204917908\n",
      "Epoch:  1731 , Loss:  0.6042399406433105   f1-score: 0.8803468346595764   accuracy: 0.9254053831100464\n",
      "Epoch:  1732 , Loss:  0.6042255163192749   f1-score: 0.8803468346595764   accuracy: 0.9254053831100464\n",
      "Epoch:  1733 , Loss:  0.6042113304138184   f1-score: 0.8803468346595764   accuracy: 0.9254053831100464\n",
      "Epoch:  1734 , Loss:  0.6041968464851379   f1-score: 0.8803468346595764   accuracy: 0.9254053831100464\n",
      "Epoch:  1735 , Loss:  0.6041830778121948   f1-score: 0.8803468346595764   accuracy: 0.9254053831100464\n",
      "Epoch:  1736 , Loss:  0.6041685938835144   f1-score: 0.8803468346595764   accuracy: 0.9254053831100464\n",
      "Epoch:  1737 , Loss:  0.6041542887687683   f1-score: 0.8803468346595764   accuracy: 0.9254053831100464\n",
      "Epoch:  1738 , Loss:  0.6041404604911804   f1-score: 0.8803468346595764   accuracy: 0.9254053831100464\n",
      "Epoch:  1739 , Loss:  0.6041262745857239   f1-score: 0.8803468346595764   accuracy: 0.9254053831100464\n",
      "Epoch:  1740 , Loss:  0.604112446308136   f1-score: 0.8803468346595764   accuracy: 0.9254053831100464\n",
      "Epoch:  1741 , Loss:  0.6040985584259033   f1-score: 0.8803468346595764   accuracy: 0.9254053831100464\n",
      "Epoch:  1742 , Loss:  0.6040847301483154   f1-score: 0.8803468346595764   accuracy: 0.9254053831100464\n",
      "Epoch:  1743 , Loss:  0.6040709018707275   f1-score: 0.8805086016654968   accuracy: 0.9254955053329468\n",
      "Epoch:  1744 , Loss:  0.6040571928024292   f1-score: 0.8805086016654968   accuracy: 0.9254955053329468\n",
      "Epoch:  1745 , Loss:  0.6040434241294861   f1-score: 0.8805086016654968   accuracy: 0.9254955053329468\n",
      "Epoch:  1746 , Loss:  0.6040298938751221   f1-score: 0.8805086016654968   accuracy: 0.9254955053329468\n",
      "Epoch:  1747 , Loss:  0.6040160655975342   f1-score: 0.8805086016654968   accuracy: 0.9254955053329468\n",
      "Epoch:  1748 , Loss:  0.6040025353431702   f1-score: 0.8806703090667725   accuracy: 0.9255855679512024\n",
      "Epoch:  1749 , Loss:  0.6039888262748718   f1-score: 0.8805086016654968   accuracy: 0.9254955053329468\n",
      "Epoch:  1750 , Loss:  0.6039751768112183   f1-score: 0.8808320164680481   accuracy: 0.9256756901741028\n",
      "Epoch:  1751 , Loss:  0.603961706161499   f1-score: 0.8808320164680481   accuracy: 0.9256756901741028\n",
      "Epoch:  1752 , Loss:  0.6039482951164246   f1-score: 0.8808320164680481   accuracy: 0.9256756901741028\n",
      "Epoch:  1753 , Loss:  0.6039347052574158   f1-score: 0.8808320164680481   accuracy: 0.9256756901741028\n",
      "Epoch:  1754 , Loss:  0.6039211750030518   f1-score: 0.8808320164680481   accuracy: 0.9256756901741028\n",
      "Epoch:  1755 , Loss:  0.6039080023765564   f1-score: 0.8808320164680481   accuracy: 0.9256756901741028\n",
      "Epoch:  1756 , Loss:  0.6038944125175476   f1-score: 0.880993664264679   accuracy: 0.9257657527923584\n",
      "Epoch:  1757 , Loss:  0.6038811206817627   f1-score: 0.880993664264679   accuracy: 0.9257657527923584\n",
      "Epoch:  1758 , Loss:  0.6038678884506226   f1-score: 0.8808664083480835   accuracy: 0.9256756901741028\n",
      "Epoch:  1759 , Loss:  0.6038544178009033   f1-score: 0.880993664264679   accuracy: 0.9257657527923584\n",
      "Epoch:  1760 , Loss:  0.6038411855697632   f1-score: 0.881155252456665   accuracy: 0.9258558750152588\n",
      "Epoch:  1761 , Loss:  0.603827953338623   f1-score: 0.881155252456665   accuracy: 0.9258558750152588\n",
      "Epoch:  1762 , Loss:  0.6038147211074829   f1-score: 0.881155252456665   accuracy: 0.9258558750152588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1763 , Loss:  0.6038013696670532   f1-score: 0.8814440369606018   accuracy: 0.9260360598564148\n",
      "Epoch:  1764 , Loss:  0.6037881970405579   f1-score: 0.8813167810440063   accuracy: 0.9259459376335144\n",
      "Epoch:  1765 , Loss:  0.603774905204773   f1-score: 0.8814440369606018   accuracy: 0.9260360598564148\n",
      "Epoch:  1766 , Loss:  0.6037617921829224   f1-score: 0.8813167810440063   accuracy: 0.9259459376335144\n",
      "Epoch:  1767 , Loss:  0.6037484407424927   f1-score: 0.8814440369606018   accuracy: 0.9260360598564148\n",
      "Epoch:  1768 , Loss:  0.6037355065345764   f1-score: 0.8813167810440063   accuracy: 0.9259459376335144\n",
      "Epoch:  1769 , Loss:  0.6037221550941467   f1-score: 0.8814440369606018   accuracy: 0.9260360598564148\n",
      "Epoch:  1770 , Loss:  0.6037090420722961   f1-score: 0.8814440369606018   accuracy: 0.9260360598564148\n",
      "Epoch:  1771 , Loss:  0.6036959290504456   f1-score: 0.8813167810440063   accuracy: 0.9259459376335144\n",
      "Epoch:  1772 , Loss:  0.6036826372146606   f1-score: 0.8813167810440063   accuracy: 0.9259459376335144\n",
      "Epoch:  1773 , Loss:  0.6036695241928101   f1-score: 0.8814440369606018   accuracy: 0.9260360598564148\n",
      "Epoch:  1774 , Loss:  0.6036562919616699   f1-score: 0.8814440369606018   accuracy: 0.9260360598564148\n",
      "Epoch:  1775 , Loss:  0.6036431789398193   f1-score: 0.8813167810440063   accuracy: 0.9259459376335144\n",
      "Epoch:  1776 , Loss:  0.6036303043365479   f1-score: 0.8816055655479431   accuracy: 0.9261261224746704\n",
      "Epoch:  1777 , Loss:  0.6036171317100525   f1-score: 0.8814782500267029   accuracy: 0.9260360598564148\n",
      "Epoch:  1778 , Loss:  0.6036037802696228   f1-score: 0.8816055655479431   accuracy: 0.9261261224746704\n",
      "Epoch:  1779 , Loss:  0.6035909652709961   f1-score: 0.8816055655479431   accuracy: 0.9261261224746704\n",
      "Epoch:  1780 , Loss:  0.6035778522491455   f1-score: 0.8818011283874512   accuracy: 0.9262162446975708\n",
      "Epoch:  1781 , Loss:  0.6035647392272949   f1-score: 0.8822510838508606   accuracy: 0.9264864921569824\n",
      "Epoch:  1782 , Loss:  0.6035518646240234   f1-score: 0.8822510838508606   accuracy: 0.9264864921569824\n",
      "Epoch:  1783 , Loss:  0.6035386323928833   f1-score: 0.8822510838508606   accuracy: 0.9264864921569824\n",
      "Epoch:  1784 , Loss:  0.6035255789756775   f1-score: 0.8824123740196228   accuracy: 0.926576554775238\n",
      "Epoch:  1785 , Loss:  0.6035127639770508   f1-score: 0.8824123740196228   accuracy: 0.926576554775238\n",
      "Epoch:  1786 , Loss:  0.6034995317459106   f1-score: 0.8824123740196228   accuracy: 0.926576554775238\n",
      "Epoch:  1787 , Loss:  0.6034867763519287   f1-score: 0.8824462890625   accuracy: 0.926576554775238\n",
      "Epoch:  1788 , Loss:  0.6034736633300781   f1-score: 0.8827009201049805   accuracy: 0.926756739616394\n",
      "Epoch:  1789 , Loss:  0.6034605503082275   f1-score: 0.8828620910644531   accuracy: 0.9268468618392944\n",
      "Epoch:  1790 , Loss:  0.6034476161003113   f1-score: 0.8828620910644531   accuracy: 0.9268468618392944\n",
      "Epoch:  1791 , Loss:  0.6034345626831055   f1-score: 0.8828620910644531   accuracy: 0.9268468618392944\n",
      "Epoch:  1792 , Loss:  0.6034214496612549   f1-score: 0.883023202419281   accuracy: 0.92693692445755\n",
      "Epoch:  1793 , Loss:  0.6034085750579834   f1-score: 0.883023202419281   accuracy: 0.92693692445755\n",
      "Epoch:  1794 , Loss:  0.6033957004547119   f1-score: 0.8828620910644531   accuracy: 0.9268468618392944\n",
      "Epoch:  1795 , Loss:  0.6033827662467957   f1-score: 0.8828958868980408   accuracy: 0.9268468618392944\n",
      "Epoch:  1796 , Loss:  0.6033695936203003   f1-score: 0.883023202419281   accuracy: 0.92693692445755\n",
      "Epoch:  1797 , Loss:  0.6033567786216736   f1-score: 0.883023202419281   accuracy: 0.92693692445755\n",
      "Epoch:  1798 , Loss:  0.6033438444137573   f1-score: 0.8828958868980408   accuracy: 0.9268468618392944\n",
      "Epoch:  1799 , Loss:  0.6033308506011963   f1-score: 0.883150577545166   accuracy: 0.9270270466804504\n",
      "Epoch:  1800 , Loss:  0.6033177971839905   f1-score: 0.883150577545166   accuracy: 0.9270270466804504\n",
      "Epoch:  1801 , Loss:  0.6033050417900085   f1-score: 0.8833116888999939   accuracy: 0.927117109298706\n",
      "Epoch:  1802 , Loss:  0.6032921075820923   f1-score: 0.8833116888999939   accuracy: 0.927117109298706\n",
      "Epoch:  1803 , Loss:  0.6032790541648865   f1-score: 0.8833116888999939   accuracy: 0.927117109298706\n",
      "Epoch:  1804 , Loss:  0.603266179561615   f1-score: 0.8833116888999939   accuracy: 0.927117109298706\n",
      "Epoch:  1805 , Loss:  0.6032531261444092   f1-score: 0.8833116888999939   accuracy: 0.927117109298706\n",
      "Epoch:  1806 , Loss:  0.6032402515411377   f1-score: 0.883345365524292   accuracy: 0.927117109298706\n",
      "Epoch:  1807 , Loss:  0.6032271385192871   f1-score: 0.883472740650177   accuracy: 0.9272072315216064\n",
      "Epoch:  1808 , Loss:  0.6032140254974365   f1-score: 0.883472740650177   accuracy: 0.9272072315216064\n",
      "Epoch:  1809 , Loss:  0.6032009124755859   f1-score: 0.8835063576698303   accuracy: 0.9272072315216064\n",
      "Epoch:  1810 , Loss:  0.6031880974769592   f1-score: 0.8836337327957153   accuracy: 0.9272972941398621\n",
      "Epoch:  1811 , Loss:  0.6031747460365295   f1-score: 0.8836337327957153   accuracy: 0.9272972941398621\n",
      "Epoch:  1812 , Loss:  0.6031616926193237   f1-score: 0.8836337327957153   accuracy: 0.9272972941398621\n",
      "Epoch:  1813 , Loss:  0.6031485199928284   f1-score: 0.8836337327957153   accuracy: 0.9272972941398621\n",
      "Epoch:  1814 , Loss:  0.6031352281570435   f1-score: 0.8836337327957153   accuracy: 0.9272972941398621\n",
      "Epoch:  1815 , Loss:  0.6031219363212585   f1-score: 0.8836337327957153   accuracy: 0.9272972941398621\n",
      "Epoch:  1816 , Loss:  0.6031085252761841   f1-score: 0.8837611675262451   accuracy: 0.9273874163627625\n",
      "Epoch:  1817 , Loss:  0.603095293045044   f1-score: 0.8837611675262451   accuracy: 0.9273874163627625\n",
      "Epoch:  1818 , Loss:  0.6030814051628113   f1-score: 0.8837611675262451   accuracy: 0.9273874163627625\n",
      "Epoch:  1819 , Loss:  0.6030680537223816   f1-score: 0.8837611675262451   accuracy: 0.9273874163627625\n",
      "Epoch:  1820 , Loss:  0.6030542254447937   f1-score: 0.8836337327957153   accuracy: 0.9272972941398621\n",
      "Epoch:  1821 , Loss:  0.6030404567718506   f1-score: 0.8836337327957153   accuracy: 0.9272972941398621\n",
      "Epoch:  1822 , Loss:  0.603026807308197   f1-score: 0.8836337327957153   accuracy: 0.9272972941398621\n",
      "Epoch:  1823 , Loss:  0.60301274061203   f1-score: 0.8836337327957153   accuracy: 0.9272972941398621\n",
      "Epoch:  1824 , Loss:  0.6029989719390869   f1-score: 0.8836337327957153   accuracy: 0.9272972941398621\n",
      "Epoch:  1825 , Loss:  0.6029848456382751   f1-score: 0.8837946653366089   accuracy: 0.9273874163627625\n",
      "Epoch:  1826 , Loss:  0.6029711961746216   f1-score: 0.8839221596717834   accuracy: 0.9274774789810181\n",
      "Epoch:  1827 , Loss:  0.6029568910598755   f1-score: 0.8839221596717834   accuracy: 0.9274774789810181\n",
      "Epoch:  1828 , Loss:  0.6029432415962219   f1-score: 0.8839221596717834   accuracy: 0.9274774789810181\n",
      "Epoch:  1829 , Loss:  0.602929413318634   f1-score: 0.8839221596717834   accuracy: 0.9274774789810181\n",
      "Epoch:  1830 , Loss:  0.6029156446456909   f1-score: 0.8839221596717834   accuracy: 0.9274774789810181\n",
      "Epoch:  1831 , Loss:  0.6029020547866821   f1-score: 0.8840830326080322   accuracy: 0.9275675415992737\n",
      "Epoch:  1832 , Loss:  0.6028884649276733   f1-score: 0.884243905544281   accuracy: 0.9276576638221741\n",
      "Epoch:  1833 , Loss:  0.6028748750686646   f1-score: 0.884243905544281   accuracy: 0.9276576638221741\n",
      "Epoch:  1834 , Loss:  0.6028614640235901   f1-score: 0.884404718875885   accuracy: 0.9277477264404297\n",
      "Epoch:  1835 , Loss:  0.60284823179245   f1-score: 0.884404718875885   accuracy: 0.9277477264404297\n",
      "Epoch:  1836 , Loss:  0.6028347611427307   f1-score: 0.884404718875885   accuracy: 0.9277477264404297\n",
      "Epoch:  1837 , Loss:  0.6028214693069458   f1-score: 0.8845322132110596   accuracy: 0.9278378486633301\n",
      "Epoch:  1838 , Loss:  0.6028082966804504   f1-score: 0.8845322132110596   accuracy: 0.9278378486633301\n",
      "Epoch:  1839 , Loss:  0.6027951240539551   f1-score: 0.8846929669380188   accuracy: 0.9279279112815857\n",
      "Epoch:  1840 , Loss:  0.6027818322181702   f1-score: 0.8849480748176575   accuracy: 0.9281080961227417\n",
      "Epoch:  1841 , Loss:  0.6027688980102539   f1-score: 0.8849480748176575   accuracy: 0.9281080961227417\n",
      "Epoch:  1842 , Loss:  0.6027556657791138   f1-score: 0.8849480748176575   accuracy: 0.9281080961227417\n",
      "Epoch:  1843 , Loss:  0.6027424931526184   f1-score: 0.8849480748176575   accuracy: 0.9281080961227417\n",
      "Epoch:  1844 , Loss:  0.6027294397354126   f1-score: 0.8849480748176575   accuracy: 0.9281080961227417\n",
      "Epoch:  1845 , Loss:  0.602716326713562   f1-score: 0.8849480748176575   accuracy: 0.9281080961227417\n",
      "Epoch:  1846 , Loss:  0.602703332901001   f1-score: 0.8849480748176575   accuracy: 0.9281080961227417\n",
      "Epoch:  1847 , Loss:  0.6026903390884399   f1-score: 0.8848205208778381   accuracy: 0.9280180335044861\n",
      "Epoch:  1848 , Loss:  0.602677047252655   f1-score: 0.8850756883621216   accuracy: 0.9281982183456421\n",
      "Epoch:  1849 , Loss:  0.6026639342308044   f1-score: 0.8850756883621216   accuracy: 0.9281982183456421\n",
      "Epoch:  1850 , Loss:  0.6026508808135986   f1-score: 0.8849480748176575   accuracy: 0.9281080961227417\n",
      "Epoch:  1851 , Loss:  0.602637767791748   f1-score: 0.8850756883621216   accuracy: 0.9281982183456421\n",
      "Epoch:  1852 , Loss:  0.6026245355606079   f1-score: 0.8849480748176575   accuracy: 0.9281080961227417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1853 , Loss:  0.6026116013526917   f1-score: 0.8850756883621216   accuracy: 0.9281982183456421\n",
      "Epoch:  1854 , Loss:  0.6025981903076172   f1-score: 0.8850756883621216   accuracy: 0.9281982183456421\n",
      "Epoch:  1855 , Loss:  0.6025850772857666   f1-score: 0.8850756883621216   accuracy: 0.9281982183456421\n",
      "Epoch:  1856 , Loss:  0.6025717854499817   f1-score: 0.8849480748176575   accuracy: 0.9281080961227417\n",
      "Epoch:  1857 , Loss:  0.6025583148002625   f1-score: 0.8851088285446167   accuracy: 0.9281982183456421\n",
      "Epoch:  1858 , Loss:  0.602544903755188   f1-score: 0.8852695226669312   accuracy: 0.9282882809638977\n",
      "Epoch:  1859 , Loss:  0.6025314927101135   f1-score: 0.8852695226669312   accuracy: 0.9282882809638977\n",
      "Epoch:  1860 , Loss:  0.6025181412696838   f1-score: 0.8853971362113953   accuracy: 0.9283784031867981\n",
      "Epoch:  1861 , Loss:  0.6025046110153198   f1-score: 0.8852695226669312   accuracy: 0.9282882809638977\n",
      "Epoch:  1862 , Loss:  0.6024909019470215   f1-score: 0.8854301571846008   accuracy: 0.9283784031867981\n",
      "Epoch:  1863 , Loss:  0.6024774312973022   f1-score: 0.8855907917022705   accuracy: 0.9284684658050537\n",
      "Epoch:  1864 , Loss:  0.6024636626243591   f1-score: 0.8855907917022705   accuracy: 0.9284684658050537\n",
      "Epoch:  1865 , Loss:  0.6024500727653503   f1-score: 0.8855907917022705   accuracy: 0.9284684658050537\n",
      "Epoch:  1866 , Loss:  0.6024364233016968   f1-score: 0.8855907917022705   accuracy: 0.9284684658050537\n",
      "Epoch:  1867 , Loss:  0.6024225354194641   f1-score: 0.8857513070106506   accuracy: 0.9285585880279541\n",
      "Epoch:  1868 , Loss:  0.6024090051651001   f1-score: 0.8857513070106506   accuracy: 0.9285585880279541\n",
      "Epoch:  1869 , Loss:  0.6023952960968018   f1-score: 0.8859118223190308   accuracy: 0.9286486506462097\n",
      "Epoch:  1870 , Loss:  0.602381706237793   f1-score: 0.8859118223190308   accuracy: 0.9286486506462097\n",
      "Epoch:  1871 , Loss:  0.6023682951927185   f1-score: 0.8859118223190308   accuracy: 0.9286486506462097\n",
      "Epoch:  1872 , Loss:  0.6023550033569336   f1-score: 0.8860722780227661   accuracy: 0.9287387132644653\n",
      "Epoch:  1873 , Loss:  0.6023418307304382   f1-score: 0.8860722780227661   accuracy: 0.9287387132644653\n",
      "Epoch:  1874 , Loss:  0.6023287773132324   f1-score: 0.8862327337265015   accuracy: 0.9288288354873657\n",
      "Epoch:  1875 , Loss:  0.6023156046867371   f1-score: 0.8862327337265015   accuracy: 0.9288288354873657\n",
      "Epoch:  1876 , Loss:  0.6023027896881104   f1-score: 0.8862327337265015   accuracy: 0.9288288354873657\n",
      "Epoch:  1877 , Loss:  0.6022897958755493   f1-score: 0.8862327337265015   accuracy: 0.9288288354873657\n",
      "Epoch:  1878 , Loss:  0.6022769808769226   f1-score: 0.8862327337265015   accuracy: 0.9288288354873657\n",
      "Epoch:  1879 , Loss:  0.6022642254829407   f1-score: 0.8862327337265015   accuracy: 0.9288288354873657\n",
      "Epoch:  1880 , Loss:  0.602251410484314   f1-score: 0.8863930702209473   accuracy: 0.9289188981056213\n",
      "Epoch:  1881 , Loss:  0.6022388935089111   f1-score: 0.8863930702209473   accuracy: 0.9289188981056213\n",
      "Epoch:  1882 , Loss:  0.602226197719574   f1-score: 0.8863930702209473   accuracy: 0.9289188981056213\n",
      "Epoch:  1883 , Loss:  0.6022137999534607   f1-score: 0.8863930702209473   accuracy: 0.9289188981056213\n",
      "Epoch:  1884 , Loss:  0.6022012233734131   f1-score: 0.8863930702209473   accuracy: 0.9289188981056213\n",
      "Epoch:  1885 , Loss:  0.6021890044212341   f1-score: 0.8863930702209473   accuracy: 0.9289188981056213\n",
      "Epoch:  1886 , Loss:  0.6021765470504761   f1-score: 0.8865534067153931   accuracy: 0.9290090203285217\n",
      "Epoch:  1887 , Loss:  0.602164089679718   f1-score: 0.886681079864502   accuracy: 0.9290990829467773\n",
      "Epoch:  1888 , Loss:  0.6021518707275391   f1-score: 0.8865534067153931   accuracy: 0.9290090203285217\n",
      "Epoch:  1889 , Loss:  0.602139413356781   f1-score: 0.8865534067153931   accuracy: 0.9290090203285217\n",
      "Epoch:  1890 , Loss:  0.6021272540092468   f1-score: 0.886681079864502   accuracy: 0.9290990829467773\n",
      "Epoch:  1891 , Loss:  0.6021148562431335   f1-score: 0.886841356754303   accuracy: 0.9291892051696777\n",
      "Epoch:  1892 , Loss:  0.6021026372909546   f1-score: 0.886841356754303   accuracy: 0.9291892051696777\n",
      "Epoch:  1893 , Loss:  0.6020903587341309   f1-score: 0.8869690299034119   accuracy: 0.9292792677879333\n",
      "Epoch:  1894 , Loss:  0.6020780801773071   f1-score: 0.8869690299034119   accuracy: 0.9292792677879333\n",
      "Epoch:  1895 , Loss:  0.6020658612251282   f1-score: 0.8869690299034119   accuracy: 0.9292792677879333\n",
      "Epoch:  1896 , Loss:  0.6020535230636597   f1-score: 0.8869690299034119   accuracy: 0.9292792677879333\n",
      "Epoch:  1897 , Loss:  0.6020413637161255   f1-score: 0.8869690299034119   accuracy: 0.9292792677879333\n",
      "Epoch:  1898 , Loss:  0.6020291447639465   f1-score: 0.8869690299034119   accuracy: 0.9292792677879333\n",
      "Epoch:  1899 , Loss:  0.6020168662071228   f1-score: 0.8869690299034119   accuracy: 0.9292792677879333\n",
      "Epoch:  1900 , Loss:  0.602004885673523   f1-score: 0.8871293067932129   accuracy: 0.9293693900108337\n",
      "Epoch:  1901 , Loss:  0.601992666721344   f1-score: 0.8871293067932129   accuracy: 0.9293693900108337\n",
      "Epoch:  1902 , Loss:  0.6019805669784546   f1-score: 0.8872894644737244   accuracy: 0.9294594526290894\n",
      "Epoch:  1903 , Loss:  0.6019686460494995   f1-score: 0.8872894644737244   accuracy: 0.9294594526290894\n",
      "Epoch:  1904 , Loss:  0.6019563674926758   f1-score: 0.8872894644737244   accuracy: 0.9294594526290894\n",
      "Epoch:  1905 , Loss:  0.6019445061683655   f1-score: 0.8872894644737244   accuracy: 0.9294594526290894\n",
      "Epoch:  1906 , Loss:  0.6019324660301208   f1-score: 0.8872894644737244   accuracy: 0.9294594526290894\n",
      "Epoch:  1907 , Loss:  0.6019206047058105   f1-score: 0.8872894644737244   accuracy: 0.9294594526290894\n",
      "Epoch:  1908 , Loss:  0.6019085049629211   f1-score: 0.887417197227478   accuracy: 0.9295495748519897\n",
      "Epoch:  1909 , Loss:  0.6018967628479004   f1-score: 0.887417197227478   accuracy: 0.9295495748519897\n",
      "Epoch:  1910 , Loss:  0.601884663105011   f1-score: 0.887417197227478   accuracy: 0.9295495748519897\n",
      "Epoch:  1911 , Loss:  0.601872980594635   f1-score: 0.887417197227478   accuracy: 0.9295495748519897\n",
      "Epoch:  1912 , Loss:  0.6018611192703247   f1-score: 0.887417197227478   accuracy: 0.9295495748519897\n",
      "Epoch:  1913 , Loss:  0.6018491387367249   f1-score: 0.887417197227478   accuracy: 0.9295495748519897\n",
      "Epoch:  1914 , Loss:  0.6018373370170593   f1-score: 0.887417197227478   accuracy: 0.9295495748519897\n",
      "Epoch:  1915 , Loss:  0.6018254160881042   f1-score: 0.887417197227478   accuracy: 0.9295495748519897\n",
      "Epoch:  1916 , Loss:  0.6018136143684387   f1-score: 0.887417197227478   accuracy: 0.9295495748519897\n",
      "Epoch:  1917 , Loss:  0.6018017530441284   f1-score: 0.887417197227478   accuracy: 0.9295495748519897\n",
      "Epoch:  1918 , Loss:  0.6017900109291077   f1-score: 0.8875773549079895   accuracy: 0.9296396374702454\n",
      "Epoch:  1919 , Loss:  0.6017782092094421   f1-score: 0.8875773549079895   accuracy: 0.9296396374702454\n",
      "Epoch:  1920 , Loss:  0.6017664074897766   f1-score: 0.8875773549079895   accuracy: 0.9296396374702454\n",
      "Epoch:  1921 , Loss:  0.6017547249794006   f1-score: 0.8875773549079895   accuracy: 0.9296396374702454\n",
      "Epoch:  1922 , Loss:  0.6017428040504456   f1-score: 0.8875773549079895   accuracy: 0.9296396374702454\n",
      "Epoch:  1923 , Loss:  0.6017313599586487   f1-score: 0.8875773549079895   accuracy: 0.9296396374702454\n",
      "Epoch:  1924 , Loss:  0.6017196178436279   f1-score: 0.8875773549079895   accuracy: 0.9296396374702454\n",
      "Epoch:  1925 , Loss:  0.6017078757286072   f1-score: 0.8875773549079895   accuracy: 0.9296396374702454\n",
      "Epoch:  1926 , Loss:  0.601696252822876   f1-score: 0.8875773549079895   accuracy: 0.9296396374702454\n",
      "Epoch:  1927 , Loss:  0.6016842722892761   f1-score: 0.8875773549079895   accuracy: 0.9296396374702454\n",
      "Epoch:  1928 , Loss:  0.6016725301742554   f1-score: 0.8875773549079895   accuracy: 0.9296396374702454\n",
      "Epoch:  1929 , Loss:  0.6016607880592346   f1-score: 0.8875773549079895   accuracy: 0.9296396374702454\n",
      "Epoch:  1930 , Loss:  0.6016488075256348   f1-score: 0.8875773549079895   accuracy: 0.9296396374702454\n",
      "Epoch:  1931 , Loss:  0.6016371250152588   f1-score: 0.8875773549079895   accuracy: 0.9296396374702454\n",
      "Epoch:  1932 , Loss:  0.6016253232955933   f1-score: 0.8875773549079895   accuracy: 0.9296396374702454\n",
      "Epoch:  1933 , Loss:  0.6016133427619934   f1-score: 0.8878975510597229   accuracy: 0.9298198223114014\n",
      "Epoch:  1934 , Loss:  0.6016016602516174   f1-score: 0.8878975510597229   accuracy: 0.9298198223114014\n",
      "Epoch:  1935 , Loss:  0.6015896797180176   f1-score: 0.8878975510597229   accuracy: 0.9298198223114014\n",
      "Epoch:  1936 , Loss:  0.6015780568122864   f1-score: 0.8878975510597229   accuracy: 0.9298198223114014\n",
      "Epoch:  1937 , Loss:  0.6015660166740417   f1-score: 0.8880253434181213   accuracy: 0.929909884929657\n",
      "Epoch:  1938 , Loss:  0.6015542149543762   f1-score: 0.8880253434181213   accuracy: 0.929909884929657\n",
      "Epoch:  1939 , Loss:  0.6015424728393555   f1-score: 0.8880253434181213   accuracy: 0.929909884929657\n",
      "Epoch:  1940 , Loss:  0.6015307307243347   f1-score: 0.8881853222846985   accuracy: 0.9300000071525574\n",
      "Epoch:  1941 , Loss:  0.6015188097953796   f1-score: 0.8883131742477417   accuracy: 0.930090069770813\n",
      "Epoch:  1942 , Loss:  0.6015073657035828   f1-score: 0.8884410262107849   accuracy: 0.9301801919937134\n",
      "Epoch:  1943 , Loss:  0.601495623588562   f1-score: 0.8884410262107849   accuracy: 0.9301801919937134\n",
      "Epoch:  1944 , Loss:  0.6014838814735413   f1-score: 0.8884410262107849   accuracy: 0.9301801919937134\n",
      "Epoch:  1945 , Loss:  0.6014724969863892   f1-score: 0.8885689377784729   accuracy: 0.930270254611969\n",
      "Epoch:  1946 , Loss:  0.6014606356620789   f1-score: 0.8885689377784729   accuracy: 0.930270254611969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1947 , Loss:  0.6014493107795715   f1-score: 0.8885689377784729   accuracy: 0.930270254611969\n",
      "Epoch:  1948 , Loss:  0.6014379262924194   f1-score: 0.8885689377784729   accuracy: 0.930270254611969\n",
      "Epoch:  1949 , Loss:  0.6014263033866882   f1-score: 0.8885689377784729   accuracy: 0.930270254611969\n",
      "Epoch:  1950 , Loss:  0.6014151573181152   f1-score: 0.8885689377784729   accuracy: 0.930270254611969\n",
      "Epoch:  1951 , Loss:  0.601404070854187   f1-score: 0.8885689377784729   accuracy: 0.930270254611969\n",
      "Epoch:  1952 , Loss:  0.6013925671577454   f1-score: 0.8885689377784729   accuracy: 0.930270254611969\n",
      "Epoch:  1953 , Loss:  0.6013816595077515   f1-score: 0.8885689377784729   accuracy: 0.930270254611969\n",
      "Epoch:  1954 , Loss:  0.6013704538345337   f1-score: 0.8885689377784729   accuracy: 0.930270254611969\n",
      "Epoch:  1955 , Loss:  0.601359486579895   f1-score: 0.8886969089508057   accuracy: 0.9303603768348694\n",
      "Epoch:  1956 , Loss:  0.6013485789299011   f1-score: 0.8886969089508057   accuracy: 0.9303603768348694\n",
      "Epoch:  1957 , Loss:  0.6013373732566833   f1-score: 0.8886969089508057   accuracy: 0.9303603768348694\n",
      "Epoch:  1958 , Loss:  0.6013264656066895   f1-score: 0.8886969089508057   accuracy: 0.9303603768348694\n",
      "Epoch:  1959 , Loss:  0.6013156175613403   f1-score: 0.8886969089508057   accuracy: 0.9303603768348694\n",
      "Epoch:  1960 , Loss:  0.6013046503067017   f1-score: 0.8886969089508057   accuracy: 0.9303603768348694\n",
      "Epoch:  1961 , Loss:  0.6012936234474182   f1-score: 0.8886969089508057   accuracy: 0.9303603768348694\n",
      "Epoch:  1962 , Loss:  0.6012831926345825   f1-score: 0.8886969089508057   accuracy: 0.9303603768348694\n",
      "Epoch:  1963 , Loss:  0.601272463798523   f1-score: 0.8886969089508057   accuracy: 0.9303603768348694\n",
      "Epoch:  1964 , Loss:  0.6012614369392395   f1-score: 0.8888248801231384   accuracy: 0.930450439453125\n",
      "Epoch:  1965 , Loss:  0.6012506484985352   f1-score: 0.8888248801231384   accuracy: 0.930450439453125\n",
      "Epoch:  1966 , Loss:  0.6012399196624756   f1-score: 0.8888248801231384   accuracy: 0.930450439453125\n",
      "Epoch:  1967 , Loss:  0.6012293100357056   f1-score: 0.8889848589897156   accuracy: 0.9305405616760254\n",
      "Epoch:  1968 , Loss:  0.6012184023857117   f1-score: 0.8889848589897156   accuracy: 0.9305405616760254\n",
      "Epoch:  1969 , Loss:  0.6012077927589417   f1-score: 0.8889848589897156   accuracy: 0.9305405616760254\n",
      "Epoch:  1970 , Loss:  0.6011972427368164   f1-score: 0.8891448378562927   accuracy: 0.930630624294281\n",
      "Epoch:  1971 , Loss:  0.6011865735054016   f1-score: 0.8889848589897156   accuracy: 0.9305405616760254\n",
      "Epoch:  1972 , Loss:  0.6011759638786316   f1-score: 0.8893047571182251   accuracy: 0.9307207465171814\n",
      "Epoch:  1973 , Loss:  0.6011654734611511   f1-score: 0.8893047571182251   accuracy: 0.9307207465171814\n",
      "Epoch:  1974 , Loss:  0.6011548042297363   f1-score: 0.8893047571182251   accuracy: 0.9307207465171814\n",
      "Epoch:  1975 , Loss:  0.6011443734169006   f1-score: 0.8894646167755127   accuracy: 0.930810809135437\n",
      "Epoch:  1976 , Loss:  0.6011338829994202   f1-score: 0.8894646167755127   accuracy: 0.930810809135437\n",
      "Epoch:  1977 , Loss:  0.6011231541633606   f1-score: 0.8896244168281555   accuracy: 0.9309008717536926\n",
      "Epoch:  1978 , Loss:  0.6011129021644592   f1-score: 0.8896244168281555   accuracy: 0.9309008717536926\n",
      "Epoch:  1979 , Loss:  0.6011024117469788   f1-score: 0.8896244168281555   accuracy: 0.9309008717536926\n",
      "Epoch:  1980 , Loss:  0.6010918021202087   f1-score: 0.8896244168281555   accuracy: 0.9309008717536926\n",
      "Epoch:  1981 , Loss:  0.601081371307373   f1-score: 0.8896244168281555   accuracy: 0.9309008717536926\n",
      "Epoch:  1982 , Loss:  0.6010708808898926   f1-score: 0.8896244168281555   accuracy: 0.9309008717536926\n",
      "Epoch:  1983 , Loss:  0.6010605096817017   f1-score: 0.8896244168281555   accuracy: 0.9309008717536926\n",
      "Epoch:  1984 , Loss:  0.6010501384735107   f1-score: 0.8896244168281555   accuracy: 0.9309008717536926\n",
      "Epoch:  1985 , Loss:  0.6010395884513855   f1-score: 0.8896244168281555   accuracy: 0.9309008717536926\n",
      "Epoch:  1986 , Loss:  0.6010293364524841   f1-score: 0.8897841572761536   accuracy: 0.930990993976593\n",
      "Epoch:  1987 , Loss:  0.6010189652442932   f1-score: 0.8897841572761536   accuracy: 0.930990993976593\n",
      "Epoch:  1988 , Loss:  0.6010085940361023   f1-score: 0.8897841572761536   accuracy: 0.930990993976593\n",
      "Epoch:  1989 , Loss:  0.6009982824325562   f1-score: 0.8897841572761536   accuracy: 0.930990993976593\n",
      "Epoch:  1990 , Loss:  0.6009880304336548   f1-score: 0.8897841572761536   accuracy: 0.930990993976593\n",
      "Epoch:  1991 , Loss:  0.6009774804115295   f1-score: 0.8897841572761536   accuracy: 0.930990993976593\n",
      "Epoch:  1992 , Loss:  0.6009668707847595   f1-score: 0.8897841572761536   accuracy: 0.930990993976593\n",
      "Epoch:  1993 , Loss:  0.6009564995765686   f1-score: 0.8897841572761536   accuracy: 0.930990993976593\n",
      "Epoch:  1994 , Loss:  0.6009460687637329   f1-score: 0.8897841572761536   accuracy: 0.930990993976593\n",
      "Epoch:  1995 , Loss:  0.6009355187416077   f1-score: 0.8897841572761536   accuracy: 0.930990993976593\n",
      "Epoch:  1996 , Loss:  0.6009249687194824   f1-score: 0.8897841572761536   accuracy: 0.930990993976593\n",
      "Epoch:  1997 , Loss:  0.6009145379066467   f1-score: 0.8897841572761536   accuracy: 0.930990993976593\n",
      "Epoch:  1998 , Loss:  0.6009036898612976   f1-score: 0.8897841572761536   accuracy: 0.930990993976593\n",
      "Epoch:  1999 , Loss:  0.600893497467041   f1-score: 0.8897841572761536   accuracy: 0.930990993976593\n",
      "Epoch:  2000 , Loss:  0.6008827686309814   f1-score: 0.8897841572761536   accuracy: 0.930990993976593\n",
      "Epoch:  2001 , Loss:  0.6008718013763428   f1-score: 0.8897841572761536   accuracy: 0.930990993976593\n",
      "Epoch:  2002 , Loss:  0.6008613109588623   f1-score: 0.8897841572761536   accuracy: 0.930990993976593\n",
      "Epoch:  2003 , Loss:  0.6008504033088684   f1-score: 0.8899438977241516   accuracy: 0.9310810565948486\n",
      "Epoch:  2004 , Loss:  0.6008394956588745   f1-score: 0.8899438977241516   accuracy: 0.9310810565948486\n",
      "Epoch:  2005 , Loss:  0.6008284687995911   f1-score: 0.8899438977241516   accuracy: 0.9310810565948486\n",
      "Epoch:  2006 , Loss:  0.6008175611495972   f1-score: 0.8899438977241516   accuracy: 0.9310810565948486\n",
      "Epoch:  2007 , Loss:  0.6008064150810242   f1-score: 0.8899438977241516   accuracy: 0.9310810565948486\n",
      "Epoch:  2008 , Loss:  0.6007954478263855   f1-score: 0.8899438977241516   accuracy: 0.9310810565948486\n",
      "Epoch:  2009 , Loss:  0.6007843613624573   f1-score: 0.8899438977241516   accuracy: 0.9310810565948486\n",
      "Epoch:  2010 , Loss:  0.6007733345031738   f1-score: 0.8899438977241516   accuracy: 0.9310810565948486\n",
      "Epoch:  2011 , Loss:  0.6007623076438904   f1-score: 0.8899438977241516   accuracy: 0.9310810565948486\n",
      "Epoch:  2012 , Loss:  0.6007510423660278   f1-score: 0.8900719285011292   accuracy: 0.931171178817749\n",
      "Epoch:  2013 , Loss:  0.6007403135299683   f1-score: 0.8900719285011292   accuracy: 0.931171178817749\n",
      "Epoch:  2014 , Loss:  0.6007289886474609   f1-score: 0.8900719285011292   accuracy: 0.931171178817749\n",
      "Epoch:  2015 , Loss:  0.6007182002067566   f1-score: 0.8900719285011292   accuracy: 0.931171178817749\n",
      "Epoch:  2016 , Loss:  0.6007071733474731   f1-score: 0.8900719285011292   accuracy: 0.931171178817749\n",
      "Epoch:  2017 , Loss:  0.6006960868835449   f1-score: 0.8900719285011292   accuracy: 0.931171178817749\n",
      "Epoch:  2018 , Loss:  0.6006854772567749   f1-score: 0.8900719285011292   accuracy: 0.931171178817749\n",
      "Epoch:  2019 , Loss:  0.6006744503974915   f1-score: 0.8900719285011292   accuracy: 0.931171178817749\n",
      "Epoch:  2020 , Loss:  0.6006637215614319   f1-score: 0.8902000188827515   accuracy: 0.9312612414360046\n",
      "Epoch:  2021 , Loss:  0.6006530523300171   f1-score: 0.8902000188827515   accuracy: 0.9312612414360046\n",
      "Epoch:  2022 , Loss:  0.6006423830986023   f1-score: 0.8903281688690186   accuracy: 0.931351363658905\n",
      "Epoch:  2023 , Loss:  0.6006317734718323   f1-score: 0.8908070921897888   accuracy: 0.9316216111183167\n",
      "Epoch:  2024 , Loss:  0.6006211042404175   f1-score: 0.8908070921897888   accuracy: 0.9316216111183167\n",
      "Epoch:  2025 , Loss:  0.600610613822937   f1-score: 0.8909352421760559   accuracy: 0.931711733341217\n",
      "Epoch:  2026 , Loss:  0.600600004196167   f1-score: 0.8908070921897888   accuracy: 0.9316216111183167\n",
      "Epoch:  2027 , Loss:  0.6005894541740417   f1-score: 0.8909352421760559   accuracy: 0.931711733341217\n",
      "Epoch:  2028 , Loss:  0.6005789041519165   f1-score: 0.8909352421760559   accuracy: 0.931711733341217\n",
      "Epoch:  2029 , Loss:  0.6005683541297913   f1-score: 0.8909352421760559   accuracy: 0.931711733341217\n",
      "Epoch:  2030 , Loss:  0.6005580425262451   f1-score: 0.8909352421760559   accuracy: 0.931711733341217\n",
      "Epoch:  2031 , Loss:  0.6005474328994751   f1-score: 0.8909352421760559   accuracy: 0.931711733341217\n",
      "Epoch:  2032 , Loss:  0.6005370616912842   f1-score: 0.8909352421760559   accuracy: 0.931711733341217\n",
      "Epoch:  2033 , Loss:  0.6005266308784485   f1-score: 0.8909352421760559   accuracy: 0.931711733341217\n",
      "Epoch:  2034 , Loss:  0.6005160808563232   f1-score: 0.8909352421760559   accuracy: 0.931711733341217\n",
      "Epoch:  2035 , Loss:  0.6005057096481323   f1-score: 0.8909352421760559   accuracy: 0.931711733341217\n",
      "Epoch:  2036 , Loss:  0.6004953384399414   f1-score: 0.8909352421760559   accuracy: 0.931711733341217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2037 , Loss:  0.6004848480224609   f1-score: 0.8910948038101196   accuracy: 0.9318017959594727\n",
      "Epoch:  2038 , Loss:  0.6004744172096252   f1-score: 0.8910948038101196   accuracy: 0.9318017959594727\n",
      "Epoch:  2039 , Loss:  0.6004639863967896   f1-score: 0.8910948038101196   accuracy: 0.9318017959594727\n",
      "Epoch:  2040 , Loss:  0.6004536151885986   f1-score: 0.8910948038101196   accuracy: 0.9318017959594727\n",
      "Epoch:  2041 , Loss:  0.6004431843757629   f1-score: 0.8910948038101196   accuracy: 0.9318017959594727\n",
      "Epoch:  2042 , Loss:  0.6004329323768616   f1-score: 0.8910948038101196   accuracy: 0.9318017959594727\n",
      "Epoch:  2043 , Loss:  0.6004225611686707   f1-score: 0.8910948038101196   accuracy: 0.9318017959594727\n",
      "Epoch:  2044 , Loss:  0.6004121899604797   f1-score: 0.8910948038101196   accuracy: 0.9318017959594727\n",
      "Epoch:  2045 , Loss:  0.6004018783569336   f1-score: 0.8912230134010315   accuracy: 0.931891918182373\n",
      "Epoch:  2046 , Loss:  0.6003916263580322   f1-score: 0.8912230134010315   accuracy: 0.931891918182373\n",
      "Epoch:  2047 , Loss:  0.6003813743591309   f1-score: 0.8912230134010315   accuracy: 0.931891918182373\n",
      "Epoch:  2048 , Loss:  0.6003713011741638   f1-score: 0.8912230134010315   accuracy: 0.931891918182373\n",
      "Epoch:  2049 , Loss:  0.6003609299659729   f1-score: 0.8913512825965881   accuracy: 0.9319819808006287\n",
      "Epoch:  2050 , Loss:  0.6003507971763611   f1-score: 0.8913512825965881   accuracy: 0.9319819808006287\n",
      "Epoch:  2051 , Loss:  0.6003408432006836   f1-score: 0.8915107846260071   accuracy: 0.9320720434188843\n",
      "Epoch:  2052 , Loss:  0.6003305315971375   f1-score: 0.8915107846260071   accuracy: 0.9320720434188843\n",
      "Epoch:  2053 , Loss:  0.6003204584121704   f1-score: 0.8915107846260071   accuracy: 0.9320720434188843\n",
      "Epoch:  2054 , Loss:  0.6003106832504272   f1-score: 0.8919890522956848   accuracy: 0.9323423504829407\n",
      "Epoch:  2055 , Loss:  0.6003006100654602   f1-score: 0.8918296694755554   accuracy: 0.9322522282600403\n",
      "Epoch:  2056 , Loss:  0.6002905368804932   f1-score: 0.8919890522956848   accuracy: 0.9323423504829407\n",
      "Epoch:  2057 , Loss:  0.60028076171875   f1-score: 0.8918296694755554   accuracy: 0.9322522282600403\n",
      "Epoch:  2058 , Loss:  0.6002711057662964   f1-score: 0.8919890522956848   accuracy: 0.9323423504829407\n",
      "Epoch:  2059 , Loss:  0.6002610325813293   f1-score: 0.8919890522956848   accuracy: 0.9323423504829407\n",
      "Epoch:  2060 , Loss:  0.6002514958381653   f1-score: 0.8919890522956848   accuracy: 0.9323423504829407\n",
      "Epoch:  2061 , Loss:  0.6002416014671326   f1-score: 0.8919890522956848   accuracy: 0.9323423504829407\n",
      "Epoch:  2062 , Loss:  0.6002316474914551   f1-score: 0.8919890522956848   accuracy: 0.9323423504829407\n",
      "Epoch:  2063 , Loss:  0.6002220511436462   f1-score: 0.8921483755111694   accuracy: 0.9324324131011963\n",
      "Epoch:  2064 , Loss:  0.6002123355865479   f1-score: 0.8921483755111694   accuracy: 0.9324324131011963\n",
      "Epoch:  2065 , Loss:  0.600202739238739   f1-score: 0.8921483755111694   accuracy: 0.9324324131011963\n",
      "Epoch:  2066 , Loss:  0.6001930236816406   f1-score: 0.8921483755111694   accuracy: 0.9324324131011963\n",
      "Epoch:  2067 , Loss:  0.6001834273338318   f1-score: 0.892307698726654   accuracy: 0.9325225353240967\n",
      "Epoch:  2068 , Loss:  0.6001739501953125   f1-score: 0.892307698726654   accuracy: 0.9325225353240967\n",
      "Epoch:  2069 , Loss:  0.6001643538475037   f1-score: 0.892307698726654   accuracy: 0.9325225353240967\n",
      "Epoch:  2070 , Loss:  0.6001549959182739   f1-score: 0.892307698726654   accuracy: 0.9325225353240967\n",
      "Epoch:  2071 , Loss:  0.6001455187797546   f1-score: 0.892307698726654   accuracy: 0.9325225353240967\n",
      "Epoch:  2072 , Loss:  0.6001361012458801   f1-score: 0.892307698726654   accuracy: 0.9325225353240967\n",
      "Epoch:  2073 , Loss:  0.6001268625259399   f1-score: 0.892307698726654   accuracy: 0.9325225353240967\n",
      "Epoch:  2074 , Loss:  0.600117564201355   f1-score: 0.892307698726654   accuracy: 0.9325225353240967\n",
      "Epoch:  2075 , Loss:  0.6001082062721252   f1-score: 0.892307698726654   accuracy: 0.9325225353240967\n",
      "Epoch:  2076 , Loss:  0.6000989079475403   f1-score: 0.892307698726654   accuracy: 0.9325225353240967\n",
      "Epoch:  2077 , Loss:  0.6000895500183105   f1-score: 0.892307698726654   accuracy: 0.9325225353240967\n",
      "Epoch:  2078 , Loss:  0.6000803709030151   f1-score: 0.8924669623374939   accuracy: 0.9326125979423523\n",
      "Epoch:  2079 , Loss:  0.6000712513923645   f1-score: 0.8924669623374939   accuracy: 0.9326125979423523\n",
      "Epoch:  2080 , Loss:  0.6000621914863586   f1-score: 0.8927853107452393   accuracy: 0.9327927827835083\n",
      "Epoch:  2081 , Loss:  0.6000529527664185   f1-score: 0.8926261067390442   accuracy: 0.9327027201652527\n",
      "Epoch:  2082 , Loss:  0.6000440716743469   f1-score: 0.8926261067390442   accuracy: 0.9327027201652527\n",
      "Epoch:  2083 , Loss:  0.6000351905822754   f1-score: 0.8927853107452393   accuracy: 0.9327927827835083\n",
      "Epoch:  2084 , Loss:  0.6000262498855591   f1-score: 0.8926261067390442   accuracy: 0.9327027201652527\n",
      "Epoch:  2085 , Loss:  0.6000174283981323   f1-score: 0.8927853107452393   accuracy: 0.9327927827835083\n",
      "Epoch:  2086 , Loss:  0.6000086069107056   f1-score: 0.8927853107452393   accuracy: 0.9327927827835083\n",
      "Epoch:  2087 , Loss:  0.5999996066093445   f1-score: 0.8927853107452393   accuracy: 0.9327927827835083\n",
      "Epoch:  2088 , Loss:  0.5999908447265625   f1-score: 0.8927853107452393   accuracy: 0.9327927827835083\n",
      "Epoch:  2089 , Loss:  0.5999820828437805   f1-score: 0.8927853107452393   accuracy: 0.9327927827835083\n",
      "Epoch:  2090 , Loss:  0.5999734401702881   f1-score: 0.8929443955421448   accuracy: 0.9328829050064087\n",
      "Epoch:  2091 , Loss:  0.5999647974967957   f1-score: 0.8929443955421448   accuracy: 0.9328829050064087\n",
      "Epoch:  2092 , Loss:  0.5999562740325928   f1-score: 0.8929443955421448   accuracy: 0.9328829050064087\n",
      "Epoch:  2093 , Loss:  0.5999475717544556   f1-score: 0.8929443955421448   accuracy: 0.9328829050064087\n",
      "Epoch:  2094 , Loss:  0.5999389886856079   f1-score: 0.8929443955421448   accuracy: 0.9328829050064087\n",
      "Epoch:  2095 , Loss:  0.5999305248260498   f1-score: 0.8929443955421448   accuracy: 0.9328829050064087\n",
      "Epoch:  2096 , Loss:  0.5999220609664917   f1-score: 0.8929443955421448   accuracy: 0.9328829050064087\n",
      "Epoch:  2097 , Loss:  0.5999135971069336   f1-score: 0.8929443955421448   accuracy: 0.9328829050064087\n",
      "Epoch:  2098 , Loss:  0.5999051332473755   f1-score: 0.8929443955421448   accuracy: 0.9328829050064087\n",
      "Epoch:  2099 , Loss:  0.5998966693878174   f1-score: 0.8929443955421448   accuracy: 0.9328829050064087\n",
      "Epoch:  2100 , Loss:  0.5998883843421936   f1-score: 0.8929443955421448   accuracy: 0.9328829050064087\n",
      "Epoch:  2101 , Loss:  0.5998799204826355   f1-score: 0.8929443955421448   accuracy: 0.9328829050064087\n",
      "Epoch:  2102 , Loss:  0.5998715758323669   f1-score: 0.8929443955421448   accuracy: 0.9328829050064087\n",
      "Epoch:  2103 , Loss:  0.5998633503913879   f1-score: 0.8929443955421448   accuracy: 0.9328829050064087\n",
      "Epoch:  2104 , Loss:  0.5998550057411194   f1-score: 0.8931034207344055   accuracy: 0.9329729676246643\n",
      "Epoch:  2105 , Loss:  0.5998467803001404   f1-score: 0.8931034207344055   accuracy: 0.9329729676246643\n",
      "Epoch:  2106 , Loss:  0.5998387336730957   f1-score: 0.8932624459266663   accuracy: 0.9330630898475647\n",
      "Epoch:  2107 , Loss:  0.5998302102088928   f1-score: 0.8931034207344055   accuracy: 0.9329729676246643\n",
      "Epoch:  2108 , Loss:  0.5998222827911377   f1-score: 0.8932624459266663   accuracy: 0.9330630898475647\n",
      "Epoch:  2109 , Loss:  0.5998141169548035   f1-score: 0.8932624459266663   accuracy: 0.9330630898475647\n",
      "Epoch:  2110 , Loss:  0.5998058915138245   f1-score: 0.8932624459266663   accuracy: 0.9330630898475647\n",
      "Epoch:  2111 , Loss:  0.5997978448867798   f1-score: 0.8932624459266663   accuracy: 0.9330630898475647\n",
      "Epoch:  2112 , Loss:  0.5997896194458008   f1-score: 0.8932624459266663   accuracy: 0.9330630898475647\n",
      "Epoch:  2113 , Loss:  0.5997816920280457   f1-score: 0.8932624459266663   accuracy: 0.9330630898475647\n",
      "Epoch:  2114 , Loss:  0.599773645401001   f1-score: 0.8932624459266663   accuracy: 0.9330630898475647\n",
      "Epoch:  2115 , Loss:  0.599765419960022   f1-score: 0.8932624459266663   accuracy: 0.9330630898475647\n",
      "Epoch:  2116 , Loss:  0.5997576117515564   f1-score: 0.8932624459266663   accuracy: 0.9330630898475647\n",
      "Epoch:  2117 , Loss:  0.5997494459152222   f1-score: 0.8932624459266663   accuracy: 0.9330630898475647\n",
      "Epoch:  2118 , Loss:  0.5997414588928223   f1-score: 0.8932624459266663   accuracy: 0.9330630898475647\n",
      "Epoch:  2119 , Loss:  0.5997335910797119   f1-score: 0.8932624459266663   accuracy: 0.9330630898475647\n",
      "Epoch:  2120 , Loss:  0.5997255444526672   f1-score: 0.8932624459266663   accuracy: 0.9330630898475647\n",
      "Epoch:  2121 , Loss:  0.5997176170349121   f1-score: 0.8932624459266663   accuracy: 0.9330630898475647\n",
      "Epoch:  2122 , Loss:  0.5997095108032227   f1-score: 0.8932624459266663   accuracy: 0.9330630898475647\n",
      "Epoch:  2123 , Loss:  0.5997017621994019   f1-score: 0.8932624459266663   accuracy: 0.9330630898475647\n",
      "Epoch:  2124 , Loss:  0.5996937155723572   f1-score: 0.8932624459266663   accuracy: 0.9330630898475647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2125 , Loss:  0.5996857285499573   f1-score: 0.8932624459266663   accuracy: 0.9330630898475647\n",
      "Epoch:  2126 , Loss:  0.5996779799461365   f1-score: 0.8932624459266663   accuracy: 0.9330630898475647\n",
      "Epoch:  2127 , Loss:  0.5996699929237366   f1-score: 0.8932624459266663   accuracy: 0.9330630898475647\n",
      "Epoch:  2128 , Loss:  0.5996620655059814   f1-score: 0.8934214115142822   accuracy: 0.9331531524658203\n",
      "Epoch:  2129 , Loss:  0.5996543765068054   f1-score: 0.8934214115142822   accuracy: 0.9331531524658203\n",
      "Epoch:  2130 , Loss:  0.599646270275116   f1-score: 0.8934214115142822   accuracy: 0.9331531524658203\n",
      "Epoch:  2131 , Loss:  0.599638044834137   f1-score: 0.8934214115142822   accuracy: 0.9331531524658203\n",
      "Epoch:  2132 , Loss:  0.5996301770210266   f1-score: 0.8934214115142822   accuracy: 0.9331531524658203\n",
      "Epoch:  2133 , Loss:  0.5996224880218506   f1-score: 0.8934214115142822   accuracy: 0.9331531524658203\n",
      "Epoch:  2134 , Loss:  0.5996143817901611   f1-score: 0.8934214115142822   accuracy: 0.9331531524658203\n",
      "Epoch:  2135 , Loss:  0.5996063351631165   f1-score: 0.8934214115142822   accuracy: 0.9331531524658203\n",
      "Epoch:  2136 , Loss:  0.5995982885360718   f1-score: 0.8934214115142822   accuracy: 0.9331531524658203\n",
      "Epoch:  2137 , Loss:  0.5995903015136719   f1-score: 0.8934214115142822   accuracy: 0.9331531524658203\n",
      "Epoch:  2138 , Loss:  0.5995824933052063   f1-score: 0.8934214115142822   accuracy: 0.9331531524658203\n",
      "Epoch:  2139 , Loss:  0.5995744466781616   f1-score: 0.8934214115142822   accuracy: 0.9331531524658203\n",
      "Epoch:  2140 , Loss:  0.5995661020278931   f1-score: 0.8934214115142822   accuracy: 0.9331531524658203\n",
      "Epoch:  2141 , Loss:  0.5995581746101379   f1-score: 0.8934214115142822   accuracy: 0.9331531524658203\n",
      "Epoch:  2142 , Loss:  0.5995499491691589   f1-score: 0.8934214115142822   accuracy: 0.9331531524658203\n",
      "Epoch:  2143 , Loss:  0.5995417833328247   f1-score: 0.8934214115142822   accuracy: 0.9331531524658203\n",
      "Epoch:  2144 , Loss:  0.5995336174964905   f1-score: 0.8934214115142822   accuracy: 0.9331531524658203\n",
      "Epoch:  2145 , Loss:  0.5995255708694458   f1-score: 0.8935803771018982   accuracy: 0.9332432150840759\n",
      "Epoch:  2146 , Loss:  0.599517285823822   f1-score: 0.8935803771018982   accuracy: 0.9332432150840759\n",
      "Epoch:  2147 , Loss:  0.5995090007781982   f1-score: 0.8935803771018982   accuracy: 0.9332432150840759\n",
      "Epoch:  2148 , Loss:  0.5995007157325745   f1-score: 0.8935803771018982   accuracy: 0.9332432150840759\n",
      "Epoch:  2149 , Loss:  0.5994924306869507   f1-score: 0.8935803771018982   accuracy: 0.9332432150840759\n",
      "Epoch:  2150 , Loss:  0.5994839668273926   f1-score: 0.8935803771018982   accuracy: 0.9332432150840759\n",
      "Epoch:  2151 , Loss:  0.5994755625724792   f1-score: 0.8935803771018982   accuracy: 0.9332432150840759\n",
      "Epoch:  2152 , Loss:  0.5994670987129211   f1-score: 0.8935803771018982   accuracy: 0.9332432150840759\n",
      "Epoch:  2153 , Loss:  0.5994586944580078   f1-score: 0.8935803771018982   accuracy: 0.9332432150840759\n",
      "Epoch:  2154 , Loss:  0.5994500517845154   f1-score: 0.8935803771018982   accuracy: 0.9332432150840759\n",
      "Epoch:  2155 , Loss:  0.5994415879249573   f1-score: 0.8935803771018982   accuracy: 0.9332432150840759\n",
      "Epoch:  2156 , Loss:  0.599433183670044   f1-score: 0.8937087059020996   accuracy: 0.9333333373069763\n",
      "Epoch:  2157 , Loss:  0.5994243621826172   f1-score: 0.8935803771018982   accuracy: 0.9332432150840759\n",
      "Epoch:  2158 , Loss:  0.5994159579277039   f1-score: 0.8937087059020996   accuracy: 0.9333333373069763\n",
      "Epoch:  2159 , Loss:  0.5994073152542114   f1-score: 0.8938676118850708   accuracy: 0.9334233999252319\n",
      "Epoch:  2160 , Loss:  0.5993988513946533   f1-score: 0.8938676118850708   accuracy: 0.9334233999252319\n",
      "Epoch:  2161 , Loss:  0.5993903875350952   f1-score: 0.8941548466682434   accuracy: 0.9336035847663879\n",
      "Epoch:  2162 , Loss:  0.5993819236755371   f1-score: 0.8941548466682434   accuracy: 0.9336035847663879\n",
      "Epoch:  2163 , Loss:  0.5993735194206238   f1-score: 0.8941548466682434   accuracy: 0.9336035847663879\n",
      "Epoch:  2164 , Loss:  0.5993650555610657   f1-score: 0.8941548466682434   accuracy: 0.9336035847663879\n",
      "Epoch:  2165 , Loss:  0.5993566513061523   f1-score: 0.8941548466682434   accuracy: 0.9336035847663879\n",
      "Epoch:  2166 , Loss:  0.5993481874465942   f1-score: 0.8941548466682434   accuracy: 0.9336035847663879\n",
      "Epoch:  2167 , Loss:  0.59934002161026   f1-score: 0.8941548466682434   accuracy: 0.9336035847663879\n",
      "Epoch:  2168 , Loss:  0.5993317365646362   f1-score: 0.894313633441925   accuracy: 0.9336937069892883\n",
      "Epoch:  2169 , Loss:  0.599323570728302   f1-score: 0.8941548466682434   accuracy: 0.9336035847663879\n",
      "Epoch:  2170 , Loss:  0.5993152856826782   f1-score: 0.894313633441925   accuracy: 0.9336937069892883\n",
      "Epoch:  2171 , Loss:  0.5993072986602783   f1-score: 0.894313633441925   accuracy: 0.9336937069892883\n",
      "Epoch:  2172 , Loss:  0.5992990732192993   f1-score: 0.894313633441925   accuracy: 0.9336937069892883\n",
      "Epoch:  2173 , Loss:  0.5992910265922546   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2174 , Loss:  0.5992832779884338   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2175 , Loss:  0.5992750525474548   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2176 , Loss:  0.5992672443389893   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2177 , Loss:  0.5992593169212341   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2178 , Loss:  0.5992513298988342   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2179 , Loss:  0.5992436408996582   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2180 , Loss:  0.5992357730865479   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2181 , Loss:  0.5992279052734375   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2182 , Loss:  0.599220335483551   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2183 , Loss:  0.5992125272750854   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2184 , Loss:  0.5992050170898438   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2185 , Loss:  0.5991974472999573   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2186 , Loss:  0.5991897583007812   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2187 , Loss:  0.5991821885108948   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2188 , Loss:  0.5991746783256531   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2189 , Loss:  0.5991672277450562   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2190 , Loss:  0.5991598963737488   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2191 , Loss:  0.5991523861885071   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2192 , Loss:  0.5991451144218445   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2193 , Loss:  0.5991379022598267   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2194 , Loss:  0.599130392074585   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2195 , Loss:  0.5991232395172119   f1-score: 0.8944723606109619   accuracy: 0.933783769607544\n",
      "Epoch:  2196 , Loss:  0.5991158485412598   f1-score: 0.8946008086204529   accuracy: 0.9338738918304443\n",
      "Epoch:  2197 , Loss:  0.5991086363792419   f1-score: 0.8946008086204529   accuracy: 0.9338738918304443\n",
      "Epoch:  2198 , Loss:  0.5991014242172241   f1-score: 0.8946008086204529   accuracy: 0.9338738918304443\n",
      "Epoch:  2199 , Loss:  0.5990940928459167   f1-score: 0.8946008086204529   accuracy: 0.9338738918304443\n",
      "Epoch:  2200 , Loss:  0.5990870594978333   f1-score: 0.8946008086204529   accuracy: 0.9338738918304443\n",
      "Epoch:  2201 , Loss:  0.5990797877311707   f1-score: 0.8947595357894897   accuracy: 0.9339639544487\n",
      "Epoch:  2202 , Loss:  0.5990726947784424   f1-score: 0.8947595357894897   accuracy: 0.9339639544487\n",
      "Epoch:  2203 , Loss:  0.5990656018257141   f1-score: 0.8947595357894897   accuracy: 0.9339639544487\n",
      "Epoch:  2204 , Loss:  0.5990584492683411   f1-score: 0.8947595357894897   accuracy: 0.9339639544487\n",
      "Epoch:  2205 , Loss:  0.5990513563156128   f1-score: 0.8947595357894897   accuracy: 0.9339639544487\n",
      "Epoch:  2206 , Loss:  0.5990444421768188   f1-score: 0.8947595357894897   accuracy: 0.9339639544487\n",
      "Epoch:  2207 , Loss:  0.5990373492240906   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2208 , Loss:  0.5990303158760071   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2209 , Loss:  0.5990232825279236   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2210 , Loss:  0.5990163087844849   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2211 , Loss:  0.5990092754364014   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2212 , Loss:  0.5990024209022522   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2213 , Loss:  0.5989956259727478   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2214 , Loss:  0.59898841381073   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2215 , Loss:  0.5989815592765808   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2216 , Loss:  0.5989746451377869   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2217 , Loss:  0.5989676713943481   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2218 , Loss:  0.598960816860199   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2219 , Loss:  0.5989538431167603   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2220 , Loss:  0.5989471077919006   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2221 , Loss:  0.5989401936531067   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2222 , Loss:  0.5989332795143127   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2223 , Loss:  0.598926305770874   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2224 , Loss:  0.5989196300506592   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2225 , Loss:  0.5989127159118652   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2226 , Loss:  0.5989059209823608   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2227 , Loss:  0.5988990664482117   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2228 , Loss:  0.5988921523094177   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2229 , Loss:  0.5988853573799133   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2230 , Loss:  0.5988783240318298   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2231 , Loss:  0.5988715291023254   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2232 , Loss:  0.5988645553588867   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2233 , Loss:  0.5988574624061584   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2234 , Loss:  0.598850667476654   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2235 , Loss:  0.598843514919281   f1-score: 0.8949182033538818   accuracy: 0.9340540766716003\n",
      "Epoch:  2236 , Loss:  0.5988366007804871   f1-score: 0.8950768113136292   accuracy: 0.934144139289856\n",
      "Epoch:  2237 , Loss:  0.5988295078277588   f1-score: 0.8950768113136292   accuracy: 0.934144139289856\n",
      "Epoch:  2238 , Loss:  0.5988224744796753   f1-score: 0.8950768113136292   accuracy: 0.934144139289856\n",
      "Epoch:  2239 , Loss:  0.5988152027130127   f1-score: 0.8950768113136292   accuracy: 0.934144139289856\n",
      "Epoch:  2240 , Loss:  0.5988079905509949   f1-score: 0.8950768113136292   accuracy: 0.934144139289856\n",
      "Epoch:  2241 , Loss:  0.598800778388977   f1-score: 0.8950768113136292   accuracy: 0.934144139289856\n",
      "Epoch:  2242 , Loss:  0.5987935066223145   f1-score: 0.8950768113136292   accuracy: 0.934144139289856\n",
      "Epoch:  2243 , Loss:  0.5987862944602966   f1-score: 0.8950768113136292   accuracy: 0.934144139289856\n",
      "Epoch:  2244 , Loss:  0.5987788438796997   f1-score: 0.8950768113136292   accuracy: 0.934144139289856\n",
      "Epoch:  2245 , Loss:  0.5987716317176819   f1-score: 0.8950768113136292   accuracy: 0.934144139289856\n",
      "Epoch:  2246 , Loss:  0.5987641215324402   f1-score: 0.8950768113136292   accuracy: 0.934144139289856\n",
      "Epoch:  2247 , Loss:  0.5987568497657776   f1-score: 0.8950768113136292   accuracy: 0.934144139289856\n",
      "Epoch:  2248 , Loss:  0.5987492203712463   f1-score: 0.8950768113136292   accuracy: 0.934144139289856\n",
      "Epoch:  2249 , Loss:  0.5987417697906494   f1-score: 0.8950768113136292   accuracy: 0.934144139289856\n",
      "Epoch:  2250 , Loss:  0.598734438419342   f1-score: 0.8952353596687317   accuracy: 0.9342342615127563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2251 , Loss:  0.5987268090248108   f1-score: 0.8952353596687317   accuracy: 0.9342342615127563\n",
      "Epoch:  2252 , Loss:  0.5987194180488586   f1-score: 0.8952353596687317   accuracy: 0.9342342615127563\n",
      "Epoch:  2253 , Loss:  0.5987120270729065   f1-score: 0.8952353596687317   accuracy: 0.9342342615127563\n",
      "Epoch:  2254 , Loss:  0.5987043380737305   f1-score: 0.8952353596687317   accuracy: 0.9342342615127563\n",
      "Epoch:  2255 , Loss:  0.5986971259117126   f1-score: 0.8952353596687317   accuracy: 0.9342342615127563\n",
      "Epoch:  2256 , Loss:  0.5986897945404053   f1-score: 0.8952353596687317   accuracy: 0.9342342615127563\n",
      "Epoch:  2257 , Loss:  0.5986823439598083   f1-score: 0.8952353596687317   accuracy: 0.9342342615127563\n",
      "Epoch:  2258 , Loss:  0.5986751317977905   f1-score: 0.8952353596687317   accuracy: 0.9342342615127563\n",
      "Epoch:  2259 , Loss:  0.5986678600311279   f1-score: 0.8952353596687317   accuracy: 0.9342342615127563\n",
      "Epoch:  2260 , Loss:  0.5986603498458862   f1-score: 0.8953638672828674   accuracy: 0.934324324131012\n",
      "Epoch:  2261 , Loss:  0.598653256893158   f1-score: 0.8953638672828674   accuracy: 0.934324324131012\n",
      "Epoch:  2262 , Loss:  0.5986458659172058   f1-score: 0.8954923748970032   accuracy: 0.9344143867492676\n",
      "Epoch:  2263 , Loss:  0.5986385941505432   f1-score: 0.8954923748970032   accuracy: 0.9344143867492676\n",
      "Epoch:  2264 , Loss:  0.5986313223838806   f1-score: 0.8954923748970032   accuracy: 0.9344143867492676\n",
      "Epoch:  2265 , Loss:  0.5986241102218628   f1-score: 0.8954923748970032   accuracy: 0.9344143867492676\n",
      "Epoch:  2266 , Loss:  0.5986166596412659   f1-score: 0.8954923748970032   accuracy: 0.9344143867492676\n",
      "Epoch:  2267 , Loss:  0.5986093282699585   f1-score: 0.8954923748970032   accuracy: 0.9344143867492676\n",
      "Epoch:  2268 , Loss:  0.5986020565032959   f1-score: 0.8954923748970032   accuracy: 0.9344143867492676\n",
      "Epoch:  2269 , Loss:  0.5985945463180542   f1-score: 0.8954923748970032   accuracy: 0.9344143867492676\n",
      "Epoch:  2270 , Loss:  0.5985872745513916   f1-score: 0.8954923748970032   accuracy: 0.9344143867492676\n",
      "Epoch:  2271 , Loss:  0.5985797643661499   f1-score: 0.8954923748970032   accuracy: 0.9344143867492676\n",
      "Epoch:  2272 , Loss:  0.5985723733901978   f1-score: 0.8954923748970032   accuracy: 0.9344143867492676\n",
      "Epoch:  2273 , Loss:  0.5985649228096008   f1-score: 0.8954923748970032   accuracy: 0.9344143867492676\n",
      "Epoch:  2274 , Loss:  0.5985575914382935   f1-score: 0.8954923748970032   accuracy: 0.9344143867492676\n",
      "Epoch:  2275 , Loss:  0.5985501408576965   f1-score: 0.8954923748970032   accuracy: 0.9344143867492676\n",
      "Epoch:  2276 , Loss:  0.5985428094863892   f1-score: 0.8956509232521057   accuracy: 0.934504508972168\n",
      "Epoch:  2277 , Loss:  0.598535418510437   f1-score: 0.8956509232521057   accuracy: 0.934504508972168\n",
      "Epoch:  2278 , Loss:  0.5985280275344849   f1-score: 0.8956509232521057   accuracy: 0.934504508972168\n",
      "Epoch:  2279 , Loss:  0.5985206365585327   f1-score: 0.8956509232521057   accuracy: 0.934504508972168\n",
      "Epoch:  2280 , Loss:  0.5985133647918701   f1-score: 0.8958094120025635   accuracy: 0.9345945715904236\n",
      "Epoch:  2281 , Loss:  0.5985061526298523   f1-score: 0.8958094120025635   accuracy: 0.9345945715904236\n",
      "Epoch:  2282 , Loss:  0.5984987616539001   f1-score: 0.8958094120025635   accuracy: 0.9345945715904236\n",
      "Epoch:  2283 , Loss:  0.5984914302825928   f1-score: 0.8958094120025635   accuracy: 0.9345945715904236\n",
      "Epoch:  2284 , Loss:  0.598484218120575   f1-score: 0.8958094120025635   accuracy: 0.9345945715904236\n",
      "Epoch:  2285 , Loss:  0.5984768271446228   f1-score: 0.8958094120025635   accuracy: 0.9345945715904236\n",
      "Epoch:  2286 , Loss:  0.5984697341918945   f1-score: 0.8958094120025635   accuracy: 0.9345945715904236\n",
      "Epoch:  2287 , Loss:  0.5984624028205872   f1-score: 0.8958094120025635   accuracy: 0.9345945715904236\n",
      "Epoch:  2288 , Loss:  0.5984553098678589   f1-score: 0.8958094120025635   accuracy: 0.9345945715904236\n",
      "Epoch:  2289 , Loss:  0.5984480977058411   f1-score: 0.8958094120025635   accuracy: 0.9345945715904236\n",
      "Epoch:  2290 , Loss:  0.5984407663345337   f1-score: 0.8958094120025635   accuracy: 0.9345945715904236\n",
      "Epoch:  2291 , Loss:  0.5984334349632263   f1-score: 0.8959678411483765   accuracy: 0.934684693813324\n",
      "Epoch:  2292 , Loss:  0.598426103591919   f1-score: 0.8959678411483765   accuracy: 0.934684693813324\n",
      "Epoch:  2293 , Loss:  0.5984187722206116   f1-score: 0.8959678411483765   accuracy: 0.934684693813324\n",
      "Epoch:  2294 , Loss:  0.598411500453949   f1-score: 0.8959678411483765   accuracy: 0.934684693813324\n",
      "Epoch:  2295 , Loss:  0.5984041690826416   f1-score: 0.8959678411483765   accuracy: 0.934684693813324\n",
      "Epoch:  2296 , Loss:  0.5983967185020447   f1-score: 0.8959678411483765   accuracy: 0.934684693813324\n",
      "Epoch:  2297 , Loss:  0.5983893871307373   f1-score: 0.8959678411483765   accuracy: 0.934684693813324\n",
      "Epoch:  2298 , Loss:  0.5983820557594299   f1-score: 0.8959678411483765   accuracy: 0.934684693813324\n",
      "Epoch:  2299 , Loss:  0.5983745455741882   f1-score: 0.8959678411483765   accuracy: 0.934684693813324\n",
      "Epoch:  2300 , Loss:  0.5983670353889465   f1-score: 0.8962845802307129   accuracy: 0.93486487865448\n",
      "Epoch:  2301 , Loss:  0.5983596444129944   f1-score: 0.8962845802307129   accuracy: 0.93486487865448\n",
      "Epoch:  2302 , Loss:  0.5983520150184631   f1-score: 0.8962845802307129   accuracy: 0.93486487865448\n",
      "Epoch:  2303 , Loss:  0.5983444452285767   f1-score: 0.8964428901672363   accuracy: 0.9349549412727356\n",
      "Epoch:  2304 , Loss:  0.5983371138572693   f1-score: 0.8966012001037598   accuracy: 0.935045063495636\n",
      "Epoch:  2305 , Loss:  0.5983293056488037   f1-score: 0.8966012001037598   accuracy: 0.935045063495636\n",
      "Epoch:  2306 , Loss:  0.5983217358589172   f1-score: 0.8966012001037598   accuracy: 0.935045063495636\n",
      "Epoch:  2307 , Loss:  0.5983142852783203   f1-score: 0.8966012001037598   accuracy: 0.935045063495636\n",
      "Epoch:  2308 , Loss:  0.5983065366744995   f1-score: 0.8966012001037598   accuracy: 0.935045063495636\n",
      "Epoch:  2309 , Loss:  0.5982990264892578   f1-score: 0.8967297673225403   accuracy: 0.9351351261138916\n",
      "Epoch:  2310 , Loss:  0.5982912182807922   f1-score: 0.8967297673225403   accuracy: 0.9351351261138916\n",
      "Epoch:  2311 , Loss:  0.5982836484909058   f1-score: 0.896888017654419   accuracy: 0.935225248336792\n",
      "Epoch:  2312 , Loss:  0.598275899887085   f1-score: 0.896888017654419   accuracy: 0.935225248336792\n",
      "Epoch:  2313 , Loss:  0.5982680916786194   f1-score: 0.896888017654419   accuracy: 0.935225248336792\n",
      "Epoch:  2314 , Loss:  0.5982601642608643   f1-score: 0.896888017654419   accuracy: 0.935225248336792\n",
      "Epoch:  2315 , Loss:  0.5982522368431091   f1-score: 0.8970461487770081   accuracy: 0.9353153109550476\n",
      "Epoch:  2316 , Loss:  0.598244309425354   f1-score: 0.8970461487770081   accuracy: 0.9353153109550476\n",
      "Epoch:  2317 , Loss:  0.5982361435890198   f1-score: 0.8970461487770081   accuracy: 0.9353153109550476\n",
      "Epoch:  2318 , Loss:  0.5982279777526855   f1-score: 0.8972042798995972   accuracy: 0.935405433177948\n",
      "Epoch:  2319 , Loss:  0.5982195734977722   f1-score: 0.8972042798995972   accuracy: 0.935405433177948\n",
      "Epoch:  2320 , Loss:  0.5982113480567932   f1-score: 0.8972042798995972   accuracy: 0.935405433177948\n",
      "Epoch:  2321 , Loss:  0.5982028841972351   f1-score: 0.8972042798995972   accuracy: 0.935405433177948\n",
      "Epoch:  2322 , Loss:  0.5981942415237427   f1-score: 0.8973624110221863   accuracy: 0.9354954957962036\n",
      "Epoch:  2323 , Loss:  0.5981858968734741   f1-score: 0.8975204229354858   accuracy: 0.9355855584144592\n",
      "Epoch:  2324 , Loss:  0.5981773734092712   f1-score: 0.8975204229354858   accuracy: 0.9355855584144592\n",
      "Epoch:  2325 , Loss:  0.5981690883636475   f1-score: 0.8975204229354858   accuracy: 0.9355855584144592\n",
      "Epoch:  2326 , Loss:  0.5981608033180237   f1-score: 0.8975204229354858   accuracy: 0.9355855584144592\n",
      "Epoch:  2327 , Loss:  0.5981528162956238   f1-score: 0.8975204229354858   accuracy: 0.9355855584144592\n",
      "Epoch:  2328 , Loss:  0.5981448292732239   f1-score: 0.8975204229354858   accuracy: 0.9355855584144592\n",
      "Epoch:  2329 , Loss:  0.5981371402740479   f1-score: 0.8975204229354858   accuracy: 0.9355855584144592\n",
      "Epoch:  2330 , Loss:  0.5981295108795166   f1-score: 0.8975204229354858   accuracy: 0.9355855584144592\n",
      "Epoch:  2331 , Loss:  0.5981217622756958   f1-score: 0.8975204229354858   accuracy: 0.9355855584144592\n",
      "Epoch:  2332 , Loss:  0.5981143712997437   f1-score: 0.8976784348487854   accuracy: 0.9356756806373596\n",
      "Epoch:  2333 , Loss:  0.598106861114502   f1-score: 0.8976784348487854   accuracy: 0.9356756806373596\n",
      "Epoch:  2334 , Loss:  0.5980993509292603   f1-score: 0.8976784348487854   accuracy: 0.9356756806373596\n",
      "Epoch:  2335 , Loss:  0.5980919599533081   f1-score: 0.8976784348487854   accuracy: 0.9356756806373596\n",
      "Epoch:  2336 , Loss:  0.598084568977356   f1-score: 0.8976784348487854   accuracy: 0.9356756806373596\n",
      "Epoch:  2337 , Loss:  0.5980770587921143   f1-score: 0.8976784348487854   accuracy: 0.9356756806373596\n",
      "Epoch:  2338 , Loss:  0.5980697870254517   f1-score: 0.8976784348487854   accuracy: 0.9356756806373596\n",
      "Epoch:  2339 , Loss:  0.5980623960494995   f1-score: 0.8976784348487854   accuracy: 0.9356756806373596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2340 , Loss:  0.5980550646781921   f1-score: 0.8978363871574402   accuracy: 0.9357657432556152\n",
      "Epoch:  2341 , Loss:  0.5980477333068848   f1-score: 0.8978363871574402   accuracy: 0.9357657432556152\n",
      "Epoch:  2342 , Loss:  0.5980402827262878   f1-score: 0.8978363871574402   accuracy: 0.9357657432556152\n",
      "Epoch:  2343 , Loss:  0.5980330109596252   f1-score: 0.8978363871574402   accuracy: 0.9357657432556152\n",
      "Epoch:  2344 , Loss:  0.5980256199836731   f1-score: 0.8978363871574402   accuracy: 0.9357657432556152\n",
      "Epoch:  2345 , Loss:  0.598018229007721   f1-score: 0.8978363871574402   accuracy: 0.9357657432556152\n",
      "Epoch:  2346 , Loss:  0.5980108380317688   f1-score: 0.8979942798614502   accuracy: 0.9358558654785156\n",
      "Epoch:  2347 , Loss:  0.5980035662651062   f1-score: 0.8979942798614502   accuracy: 0.9358558654785156\n",
      "Epoch:  2348 , Loss:  0.5979961156845093   f1-score: 0.8979942798614502   accuracy: 0.9358558654785156\n",
      "Epoch:  2349 , Loss:  0.5979887247085571   f1-score: 0.8979942798614502   accuracy: 0.9358558654785156\n",
      "Epoch:  2350 , Loss:  0.5979813933372498   f1-score: 0.8979942798614502   accuracy: 0.9358558654785156\n",
      "Epoch:  2351 , Loss:  0.5979739427566528   f1-score: 0.8979942798614502   accuracy: 0.9358558654785156\n",
      "Epoch:  2352 , Loss:  0.597966730594635   f1-score: 0.8981521129608154   accuracy: 0.9359459280967712\n",
      "Epoch:  2353 , Loss:  0.5979593396186829   f1-score: 0.8981521129608154   accuracy: 0.9359459280967712\n",
      "Epoch:  2354 , Loss:  0.5979520082473755   f1-score: 0.8981521129608154   accuracy: 0.9359459280967712\n",
      "Epoch:  2355 , Loss:  0.5979444980621338   f1-score: 0.8981521129608154   accuracy: 0.9359459280967712\n",
      "Epoch:  2356 , Loss:  0.5979371666908264   f1-score: 0.8982807993888855   accuracy: 0.9360360503196716\n",
      "Epoch:  2357 , Loss:  0.5979297161102295   f1-score: 0.8982807993888855   accuracy: 0.9360360503196716\n",
      "Epoch:  2358 , Loss:  0.5979223847389221   f1-score: 0.8982807993888855   accuracy: 0.9360360503196716\n",
      "Epoch:  2359 , Loss:  0.5979148149490356   f1-score: 0.8982807993888855   accuracy: 0.9360360503196716\n",
      "Epoch:  2360 , Loss:  0.5979074835777283   f1-score: 0.8982807993888855   accuracy: 0.9360360503196716\n",
      "Epoch:  2361 , Loss:  0.5979000329971313   f1-score: 0.8982807993888855   accuracy: 0.9360360503196716\n",
      "Epoch:  2362 , Loss:  0.5978926420211792   f1-score: 0.8982807993888855   accuracy: 0.9360360503196716\n",
      "Epoch:  2363 , Loss:  0.5978851318359375   f1-score: 0.8984386324882507   accuracy: 0.9361261129379272\n",
      "Epoch:  2364 , Loss:  0.5978776812553406   f1-score: 0.8984386324882507   accuracy: 0.9361261129379272\n",
      "Epoch:  2365 , Loss:  0.5978703498840332   f1-score: 0.8984386324882507   accuracy: 0.9361261129379272\n",
      "Epoch:  2366 , Loss:  0.5978628396987915   f1-score: 0.8984386324882507   accuracy: 0.9361261129379272\n",
      "Epoch:  2367 , Loss:  0.5978553295135498   f1-score: 0.8984386324882507   accuracy: 0.9361261129379272\n",
      "Epoch:  2368 , Loss:  0.5978478193283081   f1-score: 0.8984386324882507   accuracy: 0.9361261129379272\n",
      "Epoch:  2369 , Loss:  0.5978403091430664   f1-score: 0.8984386324882507   accuracy: 0.9361261129379272\n",
      "Epoch:  2370 , Loss:  0.5978328585624695   f1-score: 0.8984386324882507   accuracy: 0.9361261129379272\n",
      "Epoch:  2371 , Loss:  0.597825288772583   f1-score: 0.8984386324882507   accuracy: 0.9361261129379272\n",
      "Epoch:  2372 , Loss:  0.5978179574012756   f1-score: 0.8984386324882507   accuracy: 0.9361261129379272\n",
      "Epoch:  2373 , Loss:  0.5978105068206787   f1-score: 0.8984386324882507   accuracy: 0.9361261129379272\n",
      "Epoch:  2374 , Loss:  0.597802996635437   f1-score: 0.8987541198730469   accuracy: 0.9363062977790833\n",
      "Epoch:  2375 , Loss:  0.5977956056594849   f1-score: 0.8987541198730469   accuracy: 0.9363062977790833\n",
      "Epoch:  2376 , Loss:  0.597788393497467   f1-score: 0.8987541198730469   accuracy: 0.9363062977790833\n",
      "Epoch:  2377 , Loss:  0.5977809429168701   f1-score: 0.8987541198730469   accuracy: 0.9363062977790833\n",
      "Epoch:  2378 , Loss:  0.5977736115455627   f1-score: 0.8987541198730469   accuracy: 0.9363062977790833\n",
      "Epoch:  2379 , Loss:  0.5977662205696106   f1-score: 0.8987541198730469   accuracy: 0.9363062977790833\n",
      "Epoch:  2380 , Loss:  0.597758948802948   f1-score: 0.8987541198730469   accuracy: 0.9363062977790833\n",
      "Epoch:  2381 , Loss:  0.5977516174316406   f1-score: 0.8987541198730469   accuracy: 0.9363062977790833\n",
      "Epoch:  2382 , Loss:  0.597744345664978   f1-score: 0.8989117741584778   accuracy: 0.9363964200019836\n",
      "Epoch:  2383 , Loss:  0.5977371335029602   f1-score: 0.8989117741584778   accuracy: 0.9363964200019836\n",
      "Epoch:  2384 , Loss:  0.5977298021316528   f1-score: 0.8989117741584778   accuracy: 0.9363964200019836\n",
      "Epoch:  2385 , Loss:  0.5977225303649902   f1-score: 0.8989117741584778   accuracy: 0.9363964200019836\n",
      "Epoch:  2386 , Loss:  0.5977153182029724   f1-score: 0.8990694284439087   accuracy: 0.9364864826202393\n",
      "Epoch:  2387 , Loss:  0.5977081060409546   f1-score: 0.8990694284439087   accuracy: 0.9364864826202393\n",
      "Epoch:  2388 , Loss:  0.5977008938789368   f1-score: 0.8990694284439087   accuracy: 0.9364864826202393\n",
      "Epoch:  2389 , Loss:  0.5976937413215637   f1-score: 0.8990694284439087   accuracy: 0.9364864826202393\n",
      "Epoch:  2390 , Loss:  0.5976865291595459   f1-score: 0.8990694284439087   accuracy: 0.9364864826202393\n",
      "Epoch:  2391 , Loss:  0.5976793766021729   f1-score: 0.8992270231246948   accuracy: 0.9365766048431396\n",
      "Epoch:  2392 , Loss:  0.5976724028587341   f1-score: 0.8992270231246948   accuracy: 0.9365766048431396\n",
      "Epoch:  2393 , Loss:  0.5976654291152954   f1-score: 0.8992270231246948   accuracy: 0.9365766048431396\n",
      "Epoch:  2394 , Loss:  0.5976585745811462   f1-score: 0.8992270231246948   accuracy: 0.9365766048431396\n",
      "Epoch:  2395 , Loss:  0.5976515412330627   f1-score: 0.8993845582008362   accuracy: 0.9366666674613953\n",
      "Epoch:  2396 , Loss:  0.5976446866989136   f1-score: 0.8992270231246948   accuracy: 0.9365766048431396\n",
      "Epoch:  2397 , Loss:  0.5976378917694092   f1-score: 0.8993845582008362   accuracy: 0.9366666674613953\n",
      "Epoch:  2398 , Loss:  0.5976310968399048   f1-score: 0.8993845582008362   accuracy: 0.9366666674613953\n",
      "Epoch:  2399 , Loss:  0.5976244211196899   f1-score: 0.8993845582008362   accuracy: 0.9366666674613953\n",
      "Epoch:  2400 , Loss:  0.5976177453994751   f1-score: 0.8993845582008362   accuracy: 0.9366666674613953\n",
      "Epoch:  2401 , Loss:  0.597611129283905   f1-score: 0.8993845582008362   accuracy: 0.9366666674613953\n",
      "Epoch:  2402 , Loss:  0.5976046323776245   f1-score: 0.8993845582008362   accuracy: 0.9366666674613953\n",
      "Epoch:  2403 , Loss:  0.5975980162620544   f1-score: 0.8993845582008362   accuracy: 0.9366666674613953\n",
      "Epoch:  2404 , Loss:  0.5975915789604187   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2405 , Loss:  0.5975850820541382   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2406 , Loss:  0.5975785851478577   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2407 , Loss:  0.5975722670555115   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2408 , Loss:  0.5975658297538757   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2409 , Loss:  0.59755939245224   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2410 , Loss:  0.5975529551506042   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2411 , Loss:  0.5975466966629028   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2412 , Loss:  0.5975402593612671   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2413 , Loss:  0.5975340008735657   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2414 , Loss:  0.5975276827812195   f1-score: 0.8993845582008362   accuracy: 0.9366666674613953\n",
      "Epoch:  2415 , Loss:  0.5975215435028076   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2416 , Loss:  0.5975152254104614   f1-score: 0.8993845582008362   accuracy: 0.9366666674613953\n",
      "Epoch:  2417 , Loss:  0.5975090861320496   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2418 , Loss:  0.5975027680397034   f1-score: 0.8993845582008362   accuracy: 0.9366666674613953\n",
      "Epoch:  2419 , Loss:  0.5974965691566467   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2420 , Loss:  0.5974902510643005   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2421 , Loss:  0.5974841117858887   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2422 , Loss:  0.5974780321121216   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2423 , Loss:  0.5974717140197754   f1-score: 0.8993845582008362   accuracy: 0.9366666674613953\n",
      "Epoch:  2424 , Loss:  0.5974656343460083   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2425 , Loss:  0.5974593758583069   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2426 , Loss:  0.597453236579895   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2427 , Loss:  0.5974471569061279   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2428 , Loss:  0.5974409580230713   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2429 , Loss:  0.597434937953949   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2430 , Loss:  0.5974286794662476   f1-score: 0.8995420932769775   accuracy: 0.9367567300796509\n",
      "Epoch:  2431 , Loss:  0.5974226593971252   f1-score: 0.8996708393096924   accuracy: 0.9368468523025513\n",
      "Epoch:  2432 , Loss:  0.5974166393280029   f1-score: 0.8996708393096924   accuracy: 0.9368468523025513\n",
      "Epoch:  2433 , Loss:  0.5974103808403015   f1-score: 0.8996708393096924   accuracy: 0.9368468523025513\n",
      "Epoch:  2434 , Loss:  0.5974042415618896   f1-score: 0.8996708393096924   accuracy: 0.9368468523025513\n",
      "Epoch:  2435 , Loss:  0.5973979830741882   f1-score: 0.8996708393096924   accuracy: 0.9368468523025513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2436 , Loss:  0.5973919034004211   f1-score: 0.8996708393096924   accuracy: 0.9368468523025513\n",
      "Epoch:  2437 , Loss:  0.597385823726654   f1-score: 0.8996708393096924   accuracy: 0.9368468523025513\n",
      "Epoch:  2438 , Loss:  0.5973796844482422   f1-score: 0.8996708393096924   accuracy: 0.9368468523025513\n",
      "Epoch:  2439 , Loss:  0.5973734259605408   f1-score: 0.8996708393096924   accuracy: 0.9368468523025513\n",
      "Epoch:  2440 , Loss:  0.5973671674728394   f1-score: 0.8996708393096924   accuracy: 0.9368468523025513\n",
      "Epoch:  2441 , Loss:  0.5973608493804932   f1-score: 0.8996708393096924   accuracy: 0.9368468523025513\n",
      "Epoch:  2442 , Loss:  0.5973545908927917   f1-score: 0.8998282551765442   accuracy: 0.9369369149208069\n",
      "Epoch:  2443 , Loss:  0.597348153591156   f1-score: 0.8998282551765442   accuracy: 0.9369369149208069\n",
      "Epoch:  2444 , Loss:  0.5973415374755859   f1-score: 0.8998282551765442   accuracy: 0.9369369149208069\n",
      "Epoch:  2445 , Loss:  0.5973348617553711   f1-score: 0.8998282551765442   accuracy: 0.9369369149208069\n",
      "Epoch:  2446 , Loss:  0.5973281264305115   f1-score: 0.8998282551765442   accuracy: 0.9369369149208069\n",
      "Epoch:  2447 , Loss:  0.5973211526870728   f1-score: 0.8998282551765442   accuracy: 0.9369369149208069\n",
      "Epoch:  2448 , Loss:  0.5973138809204102   f1-score: 0.8998282551765442   accuracy: 0.9369369149208069\n",
      "Epoch:  2449 , Loss:  0.5973065495491028   f1-score: 0.8998282551765442   accuracy: 0.9369369149208069\n",
      "Epoch:  2450 , Loss:  0.5972991585731506   f1-score: 0.8998282551765442   accuracy: 0.9369369149208069\n",
      "Epoch:  2451 , Loss:  0.5972915887832642   f1-score: 0.899985671043396   accuracy: 0.9370270371437073\n",
      "Epoch:  2452 , Loss:  0.597284197807312   f1-score: 0.899985671043396   accuracy: 0.9370270371437073\n",
      "Epoch:  2453 , Loss:  0.5972769260406494   f1-score: 0.899985671043396   accuracy: 0.9370270371437073\n",
      "Epoch:  2454 , Loss:  0.5972701907157898   f1-score: 0.9001430869102478   accuracy: 0.9371170997619629\n",
      "Epoch:  2455 , Loss:  0.5972633957862854   f1-score: 0.9003003835678101   accuracy: 0.9372072219848633\n",
      "Epoch:  2456 , Loss:  0.5972570776939392   f1-score: 0.9003003835678101   accuracy: 0.9372072219848633\n",
      "Epoch:  2457 , Loss:  0.5972508788108826   f1-score: 0.9003003835678101   accuracy: 0.9372072219848633\n",
      "Epoch:  2458 , Loss:  0.5972447395324707   f1-score: 0.9003003835678101   accuracy: 0.9372072219848633\n",
      "Epoch:  2459 , Loss:  0.5972387790679932   f1-score: 0.9003003835678101   accuracy: 0.9372072219848633\n",
      "Epoch:  2460 , Loss:  0.5972329378128052   f1-score: 0.9003003835678101   accuracy: 0.9372072219848633\n",
      "Epoch:  2461 , Loss:  0.5972270965576172   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2462 , Loss:  0.597221314907074   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2463 , Loss:  0.5972156524658203   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2464 , Loss:  0.5972100496292114   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2465 , Loss:  0.597204327583313   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2466 , Loss:  0.5971987843513489   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2467 , Loss:  0.5971933007240295   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2468 , Loss:  0.5971876978874207   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2469 , Loss:  0.5971822142601013   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2470 , Loss:  0.597176730632782   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2471 , Loss:  0.5971713066101074   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2472 , Loss:  0.5971659421920776   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2473 , Loss:  0.5971603989601135   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2474 , Loss:  0.5971552133560181   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2475 , Loss:  0.5971497893333435   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2476 , Loss:  0.597144603729248   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2477 , Loss:  0.5971393585205078   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2478 , Loss:  0.5971340537071228   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2479 , Loss:  0.5971286296844482   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2480 , Loss:  0.5971235632896423   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2481 , Loss:  0.5971183776855469   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2482 , Loss:  0.5971130132675171   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2483 , Loss:  0.5971078872680664   f1-score: 0.9004576802253723   accuracy: 0.9372972846031189\n",
      "Epoch:  2484 , Loss:  0.597102701663971   f1-score: 0.9006149172782898   accuracy: 0.9373874068260193\n",
      "Epoch:  2485 , Loss:  0.5970975756645203   f1-score: 0.9006149172782898   accuracy: 0.9373874068260193\n",
      "Epoch:  2486 , Loss:  0.5970923900604248   f1-score: 0.9006149172782898   accuracy: 0.9373874068260193\n",
      "Epoch:  2487 , Loss:  0.5970872044563293   f1-score: 0.9006149172782898   accuracy: 0.9373874068260193\n",
      "Epoch:  2488 , Loss:  0.5970820188522339   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2489 , Loss:  0.5970770120620728   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2490 , Loss:  0.5970718860626221   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2491 , Loss:  0.5970667004585266   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2492 , Loss:  0.5970616340637207   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2493 , Loss:  0.59705650806427   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2494 , Loss:  0.5970513820648193   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2495 , Loss:  0.5970463156700134   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2496 , Loss:  0.5970410704612732   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2497 , Loss:  0.5970361232757568   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2498 , Loss:  0.5970308780670166   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2499 , Loss:  0.5970256924629211   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2500 , Loss:  0.5970204472541809   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2501 , Loss:  0.5970153212547302   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2502 , Loss:  0.59701007604599   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2503 , Loss:  0.5970048904418945   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2504 , Loss:  0.5969996452331543   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2505 , Loss:  0.5969943404197693   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2506 , Loss:  0.596989095211029   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2507 , Loss:  0.5969838500022888   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2508 , Loss:  0.5969785451889038   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2509 , Loss:  0.5969732999801636   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2510 , Loss:  0.5969681143760681   f1-score: 0.9007720947265625   accuracy: 0.9374774694442749\n",
      "Epoch:  2511 , Loss:  0.5969628095626831   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2512 , Loss:  0.5969576835632324   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2513 , Loss:  0.5969526171684265   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2514 , Loss:  0.596947431564331   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2515 , Loss:  0.5969424247741699   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2516 , Loss:  0.5969372987747192   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2517 , Loss:  0.5969322919845581   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2518 , Loss:  0.596927285194397   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2519 , Loss:  0.5969223380088806   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2520 , Loss:  0.5969173908233643   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2521 , Loss:  0.5969125628471375   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2522 , Loss:  0.5969077348709106   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2523 , Loss:  0.5969029664993286   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2524 , Loss:  0.5968982577323914   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2525 , Loss:  0.5968934297561646   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2526 , Loss:  0.5968888401985168   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2527 , Loss:  0.5968840718269348   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2528 , Loss:  0.5968793034553528   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2529 , Loss:  0.5968747735023499   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2530 , Loss:  0.5968700647354126   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2531 , Loss:  0.5968654155731201   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2532 , Loss:  0.596860945224762   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2533 , Loss:  0.5968561768531799   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2534 , Loss:  0.596851646900177   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2535 , Loss:  0.5968471169471741   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2536 , Loss:  0.5968424677848816   f1-score: 0.9009292125701904   accuracy: 0.9375675916671753\n",
      "Epoch:  2537 , Loss:  0.5968379974365234   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2538 , Loss:  0.5968334674835205   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2539 , Loss:  0.596828818321228   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2540 , Loss:  0.5968244075775146   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2541 , Loss:  0.5968198776245117   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2542 , Loss:  0.5968153476715088   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2543 , Loss:  0.5968109369277954   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2544 , Loss:  0.5968064665794373   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2545 , Loss:  0.5968019962310791   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2546 , Loss:  0.5967977046966553   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2547 , Loss:  0.5967931747436523   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2548 , Loss:  0.5967886447906494   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2549 , Loss:  0.5967842936515808   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2550 , Loss:  0.596780002117157   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2551 , Loss:  0.596775472164154   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2552 , Loss:  0.5967711210250854   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2553 , Loss:  0.5967668294906616   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2554 , Loss:  0.5967623591423035   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2555 , Loss:  0.5967581868171692   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2556 , Loss:  0.5967537760734558   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2557 , Loss:  0.596749484539032   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2558 , Loss:  0.5967451333999634   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2559 , Loss:  0.5967410206794739   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2560 , Loss:  0.5967365503311157   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2561 , Loss:  0.5967321991920471   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2562 , Loss:  0.5967280268669128   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2563 , Loss:  0.5967236757278442   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2564 , Loss:  0.5967194437980652   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2565 , Loss:  0.5967152118682861   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2566 , Loss:  0.5967108607292175   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2567 , Loss:  0.5967065095901489   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2568 , Loss:  0.5967023372650146   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2569 , Loss:  0.5966981053352356   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2570 , Loss:  0.596693754196167   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2571 , Loss:  0.5966897010803223   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2572 , Loss:  0.5966853499412537   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2573 , Loss:  0.5966811180114746   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2574 , Loss:  0.5966769456863403   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2575 , Loss:  0.5966725945472717   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2576 , Loss:  0.5966684818267822   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2577 , Loss:  0.596664309501648   f1-score: 0.9010863304138184   accuracy: 0.9376576542854309\n",
      "Epoch:  2578 , Loss:  0.5966600179672241   f1-score: 0.9012433886528015   accuracy: 0.9377477765083313\n",
      "Epoch:  2579 , Loss:  0.5966557860374451   f1-score: 0.9012433886528015   accuracy: 0.9377477765083313\n",
      "Epoch:  2580 , Loss:  0.5966516137123108   f1-score: 0.9012433886528015   accuracy: 0.9377477765083313\n",
      "Epoch:  2581 , Loss:  0.5966474413871765   f1-score: 0.9014003872871399   accuracy: 0.9378378391265869\n",
      "Epoch:  2582 , Loss:  0.5966432094573975   f1-score: 0.9014003872871399   accuracy: 0.9378378391265869\n",
      "Epoch:  2583 , Loss:  0.5966389775276184   f1-score: 0.9014003872871399   accuracy: 0.9378378391265869\n",
      "Epoch:  2584 , Loss:  0.5966347455978394   f1-score: 0.9014003872871399   accuracy: 0.9378378391265869\n",
      "Epoch:  2585 , Loss:  0.5966305136680603   f1-score: 0.9014003872871399   accuracy: 0.9378378391265869\n",
      "Epoch:  2586 , Loss:  0.596626341342926   f1-score: 0.9014003872871399   accuracy: 0.9378378391265869\n",
      "Epoch:  2587 , Loss:  0.5966220498085022   f1-score: 0.9014003872871399   accuracy: 0.9378378391265869\n",
      "Epoch:  2588 , Loss:  0.5966179370880127   f1-score: 0.9014003872871399   accuracy: 0.9378378391265869\n",
      "Epoch:  2589 , Loss:  0.5966136455535889   f1-score: 0.9014003872871399   accuracy: 0.9378378391265869\n",
      "Epoch:  2590 , Loss:  0.5966092944145203   f1-score: 0.9014003872871399   accuracy: 0.9378378391265869\n",
      "Epoch:  2591 , Loss:  0.5966051816940308   f1-score: 0.9014003872871399   accuracy: 0.9378378391265869\n",
      "Epoch:  2592 , Loss:  0.5966008305549622   f1-score: 0.9014003872871399   accuracy: 0.9378378391265869\n",
      "Epoch:  2593 , Loss:  0.5965966582298279   f1-score: 0.9015292525291443   accuracy: 0.9379279017448425\n",
      "Epoch:  2594 , Loss:  0.5965924263000488   f1-score: 0.9014003872871399   accuracy: 0.9378378391265869\n",
      "Epoch:  2595 , Loss:  0.596588134765625   f1-score: 0.9015292525291443   accuracy: 0.9379279017448425\n",
      "Epoch:  2596 , Loss:  0.5965837836265564   f1-score: 0.9015292525291443   accuracy: 0.9379279017448425\n",
      "Epoch:  2597 , Loss:  0.5965794324874878   f1-score: 0.9015292525291443   accuracy: 0.9379279017448425\n",
      "Epoch:  2598 , Loss:  0.5965752005577087   f1-score: 0.9015292525291443   accuracy: 0.9379279017448425\n",
      "Epoch:  2599 , Loss:  0.596570611000061   f1-score: 0.9015292525291443   accuracy: 0.9379279017448425\n",
      "Epoch:  2600 , Loss:  0.5965665578842163   f1-score: 0.9015292525291443   accuracy: 0.9379279017448425\n",
      "Epoch:  2601 , Loss:  0.5965620875358582   f1-score: 0.9015292525291443   accuracy: 0.9379279017448425\n",
      "Epoch:  2602 , Loss:  0.5965576171875   f1-score: 0.9015292525291443   accuracy: 0.9379279017448425\n",
      "Epoch:  2603 , Loss:  0.5965532064437866   f1-score: 0.9015292525291443   accuracy: 0.9379279017448425\n",
      "Epoch:  2604 , Loss:  0.5965486764907837   f1-score: 0.9015292525291443   accuracy: 0.9379279017448425\n",
      "Epoch:  2605 , Loss:  0.5965441465377808   f1-score: 0.9016861915588379   accuracy: 0.9380180239677429\n",
      "Epoch:  2606 , Loss:  0.5965396761894226   f1-score: 0.9016861915588379   accuracy: 0.9380180239677429\n",
      "Epoch:  2607 , Loss:  0.5965350866317749   f1-score: 0.9016861915588379   accuracy: 0.9380180239677429\n",
      "Epoch:  2608 , Loss:  0.5965304970741272   f1-score: 0.9016861915588379   accuracy: 0.9380180239677429\n",
      "Epoch:  2609 , Loss:  0.5965258479118347   f1-score: 0.9016861915588379   accuracy: 0.9380180239677429\n",
      "Epoch:  2610 , Loss:  0.5965210795402527   f1-score: 0.9016861915588379   accuracy: 0.9380180239677429\n",
      "Epoch:  2611 , Loss:  0.5965163111686707   f1-score: 0.9016861915588379   accuracy: 0.9380180239677429\n",
      "Epoch:  2612 , Loss:  0.5965114235877991   f1-score: 0.9016861915588379   accuracy: 0.9380180239677429\n",
      "Epoch:  2613 , Loss:  0.5965065360069275   f1-score: 0.9016861915588379   accuracy: 0.9380180239677429\n",
      "Epoch:  2614 , Loss:  0.5965015292167664   f1-score: 0.9016861915588379   accuracy: 0.9380180239677429\n",
      "Epoch:  2615 , Loss:  0.5964963436126709   f1-score: 0.9016861915588379   accuracy: 0.9380180239677429\n",
      "Epoch:  2616 , Loss:  0.5964910984039307   f1-score: 0.9016861915588379   accuracy: 0.9380180239677429\n",
      "Epoch:  2617 , Loss:  0.5964857935905457   f1-score: 0.9016861915588379   accuracy: 0.9380180239677429\n",
      "Epoch:  2618 , Loss:  0.5964803695678711   f1-score: 0.9016861915588379   accuracy: 0.9380180239677429\n",
      "Epoch:  2619 , Loss:  0.5964747667312622   f1-score: 0.9016861915588379   accuracy: 0.9380180239677429\n",
      "Epoch:  2620 , Loss:  0.5964690446853638   f1-score: 0.9016861915588379   accuracy: 0.9380180239677429\n",
      "Epoch:  2621 , Loss:  0.5964633822441101   f1-score: 0.9016861915588379   accuracy: 0.9380180239677429\n",
      "Epoch:  2622 , Loss:  0.596457839012146   f1-score: 0.9018431305885315   accuracy: 0.9381080865859985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2623 , Loss:  0.596451997756958   f1-score: 0.9018431305885315   accuracy: 0.9381080865859985\n",
      "Epoch:  2624 , Loss:  0.5964462757110596   f1-score: 0.9018431305885315   accuracy: 0.9381080865859985\n",
      "Epoch:  2625 , Loss:  0.5964407324790955   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2626 , Loss:  0.5964353680610657   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2627 , Loss:  0.5964299440383911   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2628 , Loss:  0.5964244604110718   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2629 , Loss:  0.5964192152023315   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2630 , Loss:  0.5964138507843018   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2631 , Loss:  0.596408486366272   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2632 , Loss:  0.5964031219482422   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2633 , Loss:  0.5963978171348572   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2634 , Loss:  0.5963924527168274   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2635 , Loss:  0.5963869690895081   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2636 , Loss:  0.596381664276123   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2637 , Loss:  0.5963761806488037   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2638 , Loss:  0.5963706970214844   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2639 , Loss:  0.5963651537895203   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2640 , Loss:  0.5963596105575562   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2641 , Loss:  0.5963538885116577   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2642 , Loss:  0.596348226070404   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2643 , Loss:  0.5963423848152161   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2644 , Loss:  0.5963364243507385   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2645 , Loss:  0.596330463886261   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2646 , Loss:  0.5963243842124939   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2647 , Loss:  0.5963181257247925   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2648 , Loss:  0.5963117480278015   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2649 , Loss:  0.5963053703308105   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2650 , Loss:  0.5962988138198853   f1-score: 0.9019719958305359   accuracy: 0.9381982088088989\n",
      "Epoch:  2651 , Loss:  0.5962923169136047   f1-score: 0.9022856950759888   accuracy: 0.9383783936500549\n",
      "Epoch:  2652 , Loss:  0.5962856411933899   f1-score: 0.902571439743042   accuracy: 0.9385585784912109\n",
      "Epoch:  2653 , Loss:  0.5962790250778198   f1-score: 0.902571439743042   accuracy: 0.9385585784912109\n",
      "Epoch:  2654 , Loss:  0.5962727665901184   f1-score: 0.902571439743042   accuracy: 0.9385585784912109\n",
      "Epoch:  2655 , Loss:  0.5962663292884827   f1-score: 0.902571439743042   accuracy: 0.9385585784912109\n",
      "Epoch:  2656 , Loss:  0.5962598919868469   f1-score: 0.902571439743042   accuracy: 0.9385585784912109\n",
      "Epoch:  2657 , Loss:  0.5962536334991455   f1-score: 0.902571439743042   accuracy: 0.9385585784912109\n",
      "Epoch:  2658 , Loss:  0.5962476134300232   f1-score: 0.902571439743042   accuracy: 0.9385585784912109\n",
      "Epoch:  2659 , Loss:  0.5962414145469666   f1-score: 0.9027003645896912   accuracy: 0.9386486411094666\n",
      "Epoch:  2660 , Loss:  0.5962355136871338   f1-score: 0.9027003645896912   accuracy: 0.9386486411094666\n",
      "Epoch:  2661 , Loss:  0.5962296724319458   f1-score: 0.9027003645896912   accuracy: 0.9386486411094666\n",
      "Epoch:  2662 , Loss:  0.5962239503860474   f1-score: 0.9028571248054504   accuracy: 0.9387387633323669\n",
      "Epoch:  2663 , Loss:  0.5962182283401489   f1-score: 0.9028571248054504   accuracy: 0.9387387633323669\n",
      "Epoch:  2664 , Loss:  0.5962126851081848   f1-score: 0.9028571248054504   accuracy: 0.9387387633323669\n",
      "Epoch:  2665 , Loss:  0.596207320690155   f1-score: 0.9028571248054504   accuracy: 0.9387387633323669\n",
      "Epoch:  2666 , Loss:  0.5962019562721252   f1-score: 0.9028571248054504   accuracy: 0.9387387633323669\n",
      "Epoch:  2667 , Loss:  0.5961965918540955   f1-score: 0.9028571248054504   accuracy: 0.9387387633323669\n",
      "Epoch:  2668 , Loss:  0.5961915254592896   f1-score: 0.9028571248054504   accuracy: 0.9387387633323669\n",
      "Epoch:  2669 , Loss:  0.5961864590644836   f1-score: 0.9028571248054504   accuracy: 0.9387387633323669\n",
      "Epoch:  2670 , Loss:  0.5961814522743225   f1-score: 0.9028571248054504   accuracy: 0.9387387633323669\n",
      "Epoch:  2671 , Loss:  0.5961764454841614   f1-score: 0.9028571248054504   accuracy: 0.9387387633323669\n",
      "Epoch:  2672 , Loss:  0.5961715579032898   f1-score: 0.9028571248054504   accuracy: 0.9387387633323669\n",
      "Epoch:  2673 , Loss:  0.5961667895317078   f1-score: 0.9028571248054504   accuracy: 0.9387387633323669\n",
      "Epoch:  2674 , Loss:  0.596161961555481   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2675 , Loss:  0.5961571335792542   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2676 , Loss:  0.5961524248123169   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2677 , Loss:  0.5961477756500244   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2678 , Loss:  0.5961430668830872   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2679 , Loss:  0.5961386561393738   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2680 , Loss:  0.5961339473724365   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2681 , Loss:  0.5961293578147888   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2682 , Loss:  0.596125066280365   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2683 , Loss:  0.5961205363273621   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2684 , Loss:  0.5961160063743591   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2685 , Loss:  0.5961115956306458   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2686 , Loss:  0.5961072444915771   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2687 , Loss:  0.5961027145385742   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2688 , Loss:  0.5960984826087952   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2689 , Loss:  0.5960940718650818   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2690 , Loss:  0.5960897207260132   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2691 , Loss:  0.5960854887962341   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2692 , Loss:  0.5960811376571655   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2693 , Loss:  0.5960769057273865   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2694 , Loss:  0.5960726141929626   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2695 , Loss:  0.5960684418678284   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2696 , Loss:  0.5960642695426941   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2697 , Loss:  0.5960599184036255   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2698 , Loss:  0.5960556864738464   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2699 , Loss:  0.5960515141487122   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2700 , Loss:  0.5960472822189331   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2701 , Loss:  0.5960431098937988   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2702 , Loss:  0.5960389375686646   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2703 , Loss:  0.5960347056388855   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2704 , Loss:  0.5960306525230408   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2705 , Loss:  0.5960263013839722   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2706 , Loss:  0.5960222482681274   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2707 , Loss:  0.5960178971290588   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2708 , Loss:  0.5960137844085693   f1-score: 0.9030138254165649   accuracy: 0.9388288259506226\n",
      "Epoch:  2709 , Loss:  0.5960096120834351   f1-score: 0.9031705260276794   accuracy: 0.938918948173523\n",
      "Epoch:  2710 , Loss:  0.5960053205490112   f1-score: 0.9031705260276794   accuracy: 0.938918948173523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2711 , Loss:  0.596001148223877   f1-score: 0.9031705260276794   accuracy: 0.938918948173523\n",
      "Epoch:  2712 , Loss:  0.5959969162940979   f1-score: 0.9033271670341492   accuracy: 0.9390090107917786\n",
      "Epoch:  2713 , Loss:  0.5959927439689636   f1-score: 0.9031705260276794   accuracy: 0.938918948173523\n",
      "Epoch:  2714 , Loss:  0.5959884524345398   f1-score: 0.9033271670341492   accuracy: 0.9390090107917786\n",
      "Epoch:  2715 , Loss:  0.5959842205047607   f1-score: 0.9033271670341492   accuracy: 0.9390090107917786\n",
      "Epoch:  2716 , Loss:  0.5959799289703369   f1-score: 0.9033271670341492   accuracy: 0.9390090107917786\n",
      "Epoch:  2717 , Loss:  0.5959757566452026   f1-score: 0.9033271670341492   accuracy: 0.9390090107917786\n",
      "Epoch:  2718 , Loss:  0.5959714651107788   f1-score: 0.9033271670341492   accuracy: 0.9390090107917786\n",
      "Epoch:  2719 , Loss:  0.595967173576355   f1-score: 0.9033271670341492   accuracy: 0.9390090107917786\n",
      "Epoch:  2720 , Loss:  0.5959628820419312   f1-score: 0.9033271670341492   accuracy: 0.9390090107917786\n",
      "Epoch:  2721 , Loss:  0.5959586501121521   f1-score: 0.9033271670341492   accuracy: 0.9390090107917786\n",
      "Epoch:  2722 , Loss:  0.5959542393684387   f1-score: 0.9033271670341492   accuracy: 0.9390090107917786\n",
      "Epoch:  2723 , Loss:  0.5959499478340149   f1-score: 0.9033271670341492   accuracy: 0.9390090107917786\n",
      "Epoch:  2724 , Loss:  0.5959455966949463   f1-score: 0.9033271670341492   accuracy: 0.9390090107917786\n",
      "Epoch:  2725 , Loss:  0.5959413051605225   f1-score: 0.9033271670341492   accuracy: 0.9390090107917786\n",
      "Epoch:  2726 , Loss:  0.5959369540214539   f1-score: 0.9033271670341492   accuracy: 0.9390090107917786\n",
      "Epoch:  2727 , Loss:  0.5959326028823853   f1-score: 0.9033271670341492   accuracy: 0.9390090107917786\n",
      "Epoch:  2728 , Loss:  0.5959282517433167   f1-score: 0.9034837484359741   accuracy: 0.9390990734100342\n",
      "Epoch:  2729 , Loss:  0.5959237813949585   f1-score: 0.9034837484359741   accuracy: 0.9390990734100342\n",
      "Epoch:  2730 , Loss:  0.5959194898605347   f1-score: 0.9034837484359741   accuracy: 0.9390990734100342\n",
      "Epoch:  2731 , Loss:  0.5959150195121765   f1-score: 0.9034837484359741   accuracy: 0.9390990734100342\n",
      "Epoch:  2732 , Loss:  0.5959106087684631   f1-score: 0.9034837484359741   accuracy: 0.9390990734100342\n",
      "Epoch:  2733 , Loss:  0.5959061980247498   f1-score: 0.9034837484359741   accuracy: 0.9390990734100342\n",
      "Epoch:  2734 , Loss:  0.5959017276763916   f1-score: 0.9034837484359741   accuracy: 0.9390990734100342\n",
      "Epoch:  2735 , Loss:  0.5958971977233887   f1-score: 0.9034837484359741   accuracy: 0.9390990734100342\n",
      "Epoch:  2736 , Loss:  0.5958926677703857   f1-score: 0.9034837484359741   accuracy: 0.9390990734100342\n",
      "Epoch:  2737 , Loss:  0.5958882570266724   f1-score: 0.9034837484359741   accuracy: 0.9390990734100342\n",
      "Epoch:  2738 , Loss:  0.5958836078643799   f1-score: 0.9034837484359741   accuracy: 0.9390990734100342\n",
      "Epoch:  2739 , Loss:  0.595879077911377   f1-score: 0.9034837484359741   accuracy: 0.9390990734100342\n",
      "Epoch:  2740 , Loss:  0.595874547958374   f1-score: 0.9034837484359741   accuracy: 0.9390990734100342\n",
      "Epoch:  2741 , Loss:  0.5958698391914368   f1-score: 0.9034837484359741   accuracy: 0.9390990734100342\n",
      "Epoch:  2742 , Loss:  0.5958653688430786   f1-score: 0.9034837484359741   accuracy: 0.9390990734100342\n",
      "Epoch:  2743 , Loss:  0.5958606600761414   f1-score: 0.9036402702331543   accuracy: 0.9391891956329346\n",
      "Epoch:  2744 , Loss:  0.5958560705184937   f1-score: 0.9036402702331543   accuracy: 0.9391891956329346\n",
      "Epoch:  2745 , Loss:  0.5958514213562012   f1-score: 0.9036402702331543   accuracy: 0.9391891956329346\n",
      "Epoch:  2746 , Loss:  0.5958468317985535   f1-score: 0.9036402702331543   accuracy: 0.9391891956329346\n",
      "Epoch:  2747 , Loss:  0.5958421230316162   f1-score: 0.9036402702331543   accuracy: 0.9391891956329346\n",
      "Epoch:  2748 , Loss:  0.5958375930786133   f1-score: 0.9036402702331543   accuracy: 0.9391891956329346\n",
      "Epoch:  2749 , Loss:  0.595832884311676   f1-score: 0.9036402702331543   accuracy: 0.9391891956329346\n",
      "Epoch:  2750 , Loss:  0.5958281755447388   f1-score: 0.9037967324256897   accuracy: 0.9392792582511902\n",
      "Epoch:  2751 , Loss:  0.5958236455917358   f1-score: 0.9037967324256897   accuracy: 0.9392792582511902\n",
      "Epoch:  2752 , Loss:  0.5958189964294434   f1-score: 0.9037967324256897   accuracy: 0.9392792582511902\n",
      "Epoch:  2753 , Loss:  0.5958144068717957   f1-score: 0.9037967324256897   accuracy: 0.9392792582511902\n",
      "Epoch:  2754 , Loss:  0.5958098769187927   f1-score: 0.9037967324256897   accuracy: 0.9392792582511902\n",
      "Epoch:  2755 , Loss:  0.595805287361145   f1-score: 0.9037967324256897   accuracy: 0.9392792582511902\n",
      "Epoch:  2756 , Loss:  0.5958006978034973   f1-score: 0.9037967324256897   accuracy: 0.9392792582511902\n",
      "Epoch:  2757 , Loss:  0.5957960486412048   f1-score: 0.9037967324256897   accuracy: 0.9392792582511902\n",
      "Epoch:  2758 , Loss:  0.5957914590835571   f1-score: 0.9037967324256897   accuracy: 0.9392792582511902\n",
      "Epoch:  2759 , Loss:  0.5957868695259094   f1-score: 0.9037967324256897   accuracy: 0.9392792582511902\n",
      "Epoch:  2760 , Loss:  0.5957822203636169   f1-score: 0.9037967324256897   accuracy: 0.9392792582511902\n",
      "Epoch:  2761 , Loss:  0.5957775712013245   f1-score: 0.9037967324256897   accuracy: 0.9392792582511902\n",
      "Epoch:  2762 , Loss:  0.5957728028297424   f1-score: 0.9037967324256897   accuracy: 0.9392792582511902\n",
      "Epoch:  2763 , Loss:  0.5957680940628052   f1-score: 0.9037967324256897   accuracy: 0.9392792582511902\n",
      "Epoch:  2764 , Loss:  0.5957632064819336   f1-score: 0.9037967324256897   accuracy: 0.9392792582511902\n",
      "Epoch:  2765 , Loss:  0.5957584381103516   f1-score: 0.9037967324256897   accuracy: 0.9392792582511902\n",
      "Epoch:  2766 , Loss:  0.5957534313201904   f1-score: 0.9039531946182251   accuracy: 0.9393693804740906\n",
      "Epoch:  2767 , Loss:  0.5957484245300293   f1-score: 0.9039531946182251   accuracy: 0.9393693804740906\n",
      "Epoch:  2768 , Loss:  0.5957434177398682   f1-score: 0.9039531946182251   accuracy: 0.9393693804740906\n",
      "Epoch:  2769 , Loss:  0.5957383513450623   f1-score: 0.9039531946182251   accuracy: 0.9393693804740906\n",
      "Epoch:  2770 , Loss:  0.5957333445549011   f1-score: 0.9039531946182251   accuracy: 0.9393693804740906\n",
      "Epoch:  2771 , Loss:  0.5957283973693848   f1-score: 0.9041095972061157   accuracy: 0.9394594430923462\n",
      "Epoch:  2772 , Loss:  0.5957233905792236   f1-score: 0.9041095972061157   accuracy: 0.9394594430923462\n",
      "Epoch:  2773 , Loss:  0.5957186222076416   f1-score: 0.9041095972061157   accuracy: 0.9394594430923462\n",
      "Epoch:  2774 , Loss:  0.5957140326499939   f1-score: 0.9041095972061157   accuracy: 0.9394594430923462\n",
      "Epoch:  2775 , Loss:  0.595709502696991   f1-score: 0.9041095972061157   accuracy: 0.9394594430923462\n",
      "Epoch:  2776 , Loss:  0.595704972743988   f1-score: 0.9041095972061157   accuracy: 0.9394594430923462\n",
      "Epoch:  2777 , Loss:  0.5957006812095642   f1-score: 0.9041095972061157   accuracy: 0.9394594430923462\n",
      "Epoch:  2778 , Loss:  0.5956963896751404   f1-score: 0.9041095972061157   accuracy: 0.9394594430923462\n",
      "Epoch:  2779 , Loss:  0.5956921577453613   f1-score: 0.9041095972061157   accuracy: 0.9394594430923462\n",
      "Epoch:  2780 , Loss:  0.595687985420227   f1-score: 0.9041095972061157   accuracy: 0.9394594430923462\n",
      "Epoch:  2781 , Loss:  0.5956839323043823   f1-score: 0.9041095972061157   accuracy: 0.9394594430923462\n",
      "Epoch:  2782 , Loss:  0.5956798195838928   f1-score: 0.9041095972061157   accuracy: 0.9394594430923462\n",
      "Epoch:  2783 , Loss:  0.5956758856773376   f1-score: 0.9042659401893616   accuracy: 0.9395495653152466\n",
      "Epoch:  2784 , Loss:  0.5956718325614929   f1-score: 0.9042659401893616   accuracy: 0.9395495653152466\n",
      "Epoch:  2785 , Loss:  0.595667839050293   f1-score: 0.9042659401893616   accuracy: 0.9395495653152466\n",
      "Epoch:  2786 , Loss:  0.595663845539093   f1-score: 0.9042659401893616   accuracy: 0.9395495653152466\n",
      "Epoch:  2787 , Loss:  0.5956599712371826   f1-score: 0.9042659401893616   accuracy: 0.9395495653152466\n",
      "Epoch:  2788 , Loss:  0.5956559777259827   f1-score: 0.9042659401893616   accuracy: 0.9395495653152466\n",
      "Epoch:  2789 , Loss:  0.5956520438194275   f1-score: 0.9042659401893616   accuracy: 0.9395495653152466\n",
      "Epoch:  2790 , Loss:  0.5956481695175171   f1-score: 0.9042659401893616   accuracy: 0.9395495653152466\n",
      "Epoch:  2791 , Loss:  0.5956442952156067   f1-score: 0.9042659401893616   accuracy: 0.9395495653152466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2792 , Loss:  0.5956403017044067   f1-score: 0.9042659401893616   accuracy: 0.9395495653152466\n",
      "Epoch:  2793 , Loss:  0.5956364274024963   f1-score: 0.9042659401893616   accuracy: 0.9395495653152466\n",
      "Epoch:  2794 , Loss:  0.5956325531005859   f1-score: 0.9042659401893616   accuracy: 0.9395495653152466\n",
      "Epoch:  2795 , Loss:  0.5956288576126099   f1-score: 0.9042659401893616   accuracy: 0.9395495653152466\n",
      "Epoch:  2796 , Loss:  0.5956249237060547   f1-score: 0.9042659401893616   accuracy: 0.9395495653152466\n",
      "Epoch:  2797 , Loss:  0.5956210494041443   f1-score: 0.9042659401893616   accuracy: 0.9395495653152466\n",
      "Epoch:  2798 , Loss:  0.5956173539161682   f1-score: 0.9042659401893616   accuracy: 0.9395495653152466\n",
      "Epoch:  2799 , Loss:  0.5956135988235474   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2800 , Loss:  0.5956098437309265   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2801 , Loss:  0.5956061482429504   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2802 , Loss:  0.5956025123596191   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2803 , Loss:  0.5955988168716431   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2804 , Loss:  0.5955953001976013   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2805 , Loss:  0.59559166431427   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2806 , Loss:  0.5955880880355835   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2807 , Loss:  0.5955846309661865   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2808 , Loss:  0.5955810546875   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2809 , Loss:  0.5955776572227478   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2810 , Loss:  0.595574140548706   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2811 , Loss:  0.5955706834793091   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2812 , Loss:  0.5955672264099121   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2813 , Loss:  0.5955638289451599   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2814 , Loss:  0.5955603718757629   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2815 , Loss:  0.5955570340156555   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2816 , Loss:  0.5955538153648376   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2817 , Loss:  0.5955502986907959   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2818 , Loss:  0.5955469608306885   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2819 , Loss:  0.5955437421798706   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2820 , Loss:  0.5955402255058289   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2821 , Loss:  0.595537006855011   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2822 , Loss:  0.5955336689949036   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2823 , Loss:  0.5955301523208618   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2824 , Loss:  0.595526933670044   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2825 , Loss:  0.595523476600647   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2826 , Loss:  0.5955200791358948   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2827 , Loss:  0.5955168008804321   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2828 , Loss:  0.5955134630203247   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2829 , Loss:  0.5955100059509277   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2830 , Loss:  0.5955066680908203   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2831 , Loss:  0.5955032706260681   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2832 , Loss:  0.5954998135566711   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2833 , Loss:  0.5954964756965637   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2834 , Loss:  0.5954930186271667   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2835 , Loss:  0.5954896807670593   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2836 , Loss:  0.5954863429069519   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2837 , Loss:  0.5954829454421997   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2838 , Loss:  0.5954796075820923   f1-score: 0.9044222831726074   accuracy: 0.9396396279335022\n",
      "Epoch:  2839 , Loss:  0.5954762697219849   f1-score: 0.9045785069465637   accuracy: 0.9397297501564026\n",
      "Epoch:  2840 , Loss:  0.5954728126525879   f1-score: 0.9045785069465637   accuracy: 0.9397297501564026\n",
      "Epoch:  2841 , Loss:  0.5954695343971252   f1-score: 0.9045785069465637   accuracy: 0.9397297501564026\n",
      "Epoch:  2842 , Loss:  0.5954661965370178   f1-score: 0.9045785069465637   accuracy: 0.9397297501564026\n",
      "Epoch:  2843 , Loss:  0.5954628586769104   f1-score: 0.9045785069465637   accuracy: 0.9397297501564026\n",
      "Epoch:  2844 , Loss:  0.5954595804214478   f1-score: 0.9045785069465637   accuracy: 0.9397297501564026\n",
      "Epoch:  2845 , Loss:  0.5954562425613403   f1-score: 0.9045785069465637   accuracy: 0.9397297501564026\n",
      "Epoch:  2846 , Loss:  0.5954530239105225   f1-score: 0.9045785069465637   accuracy: 0.9397297501564026\n",
      "Epoch:  2847 , Loss:  0.595449686050415   f1-score: 0.9045785069465637   accuracy: 0.9397297501564026\n",
      "Epoch:  2848 , Loss:  0.5954464077949524   f1-score: 0.9045785069465637   accuracy: 0.9397297501564026\n",
      "Epoch:  2849 , Loss:  0.5954431891441345   f1-score: 0.9045785069465637   accuracy: 0.9397297501564026\n",
      "Epoch:  2850 , Loss:  0.5954399704933167   f1-score: 0.9045785069465637   accuracy: 0.9397297501564026\n",
      "Epoch:  2851 , Loss:  0.5954367518424988   f1-score: 0.9045785069465637   accuracy: 0.9397297501564026\n",
      "Epoch:  2852 , Loss:  0.5954335927963257   f1-score: 0.9045785069465637   accuracy: 0.9397297501564026\n",
      "Epoch:  2853 , Loss:  0.5954304337501526   f1-score: 0.9045785069465637   accuracy: 0.9397297501564026\n",
      "Epoch:  2854 , Loss:  0.5954273343086243   f1-score: 0.9045785069465637   accuracy: 0.9397297501564026\n",
      "Epoch:  2855 , Loss:  0.595424234867096   f1-score: 0.9045785069465637   accuracy: 0.9397297501564026\n",
      "Epoch:  2856 , Loss:  0.5954210758209229   f1-score: 0.9045785069465637   accuracy: 0.9397297501564026\n",
      "Epoch:  2857 , Loss:  0.5954180359840393   f1-score: 0.9045785069465637   accuracy: 0.9397297501564026\n",
      "Epoch:  2858 , Loss:  0.595414936542511   f1-score: 0.9045785069465637   accuracy: 0.9397297501564026\n",
      "Epoch:  2859 , Loss:  0.5954118967056274   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2860 , Loss:  0.5954089164733887   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2861 , Loss:  0.5954058766365051   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2862 , Loss:  0.5954028367996216   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2863 , Loss:  0.5953998565673828   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2864 , Loss:  0.5953968167304993   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2865 , Loss:  0.59539395570755   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2866 , Loss:  0.5953909754753113   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2867 , Loss:  0.5953879952430725   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2868 , Loss:  0.5953851342201233   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2869 , Loss:  0.5953822731971741   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2870 , Loss:  0.5953793525695801   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2871 , Loss:  0.5953764915466309   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2872 , Loss:  0.5953736901283264   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2873 , Loss:  0.595370888710022   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2874 , Loss:  0.5953680872917175   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2875 , Loss:  0.5953652858734131   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2876 , Loss:  0.5953624844551086   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2877 , Loss:  0.595359742641449   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2878 , Loss:  0.5953569412231445   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2879 , Loss:  0.5953542590141296   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2880 , Loss:  0.59535151720047   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2881 , Loss:  0.5953487157821655   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2882 , Loss:  0.5953460931777954   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2883 , Loss:  0.5953434109687805   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2884 , Loss:  0.5953406691551208   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2885 , Loss:  0.5953380465507507   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2886 , Loss:  0.5953353047370911   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2887 , Loss:  0.595332682132721   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2888 , Loss:  0.595329999923706   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2889 , Loss:  0.5953274369239807   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2890 , Loss:  0.5953248143196106   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2891 , Loss:  0.5953221321105957   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2892 , Loss:  0.5953195691108704   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2893 , Loss:  0.595317006111145   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2894 , Loss:  0.5953143835067749   f1-score: 0.90473473072052   accuracy: 0.9398198127746582\n",
      "Epoch:  2895 , Loss:  0.59531170129776   f1-score: 0.9048908948898315   accuracy: 0.9399099349975586\n",
      "Epoch:  2896 , Loss:  0.5953091382980347   f1-score: 0.9048908948898315   accuracy: 0.9399099349975586\n",
      "Epoch:  2897 , Loss:  0.5953065156936646   f1-score: 0.9048908948898315   accuracy: 0.9399099349975586\n",
      "Epoch:  2898 , Loss:  0.5953038930892944   f1-score: 0.9048908948898315   accuracy: 0.9399099349975586\n",
      "Epoch:  2899 , Loss:  0.5953012704849243   f1-score: 0.9048908948898315   accuracy: 0.9399099349975586\n",
      "Epoch:  2900 , Loss:  0.5952985882759094   f1-score: 0.9048908948898315   accuracy: 0.9399099349975586\n",
      "Epoch:  2901 , Loss:  0.5952959656715393   f1-score: 0.9048908948898315   accuracy: 0.9399099349975586\n",
      "Epoch:  2902 , Loss:  0.5952933430671692   f1-score: 0.9048908948898315   accuracy: 0.9399099349975586\n",
      "Epoch:  2903 , Loss:  0.5952906012535095   f1-score: 0.9048908948898315   accuracy: 0.9399099349975586\n",
      "Epoch:  2904 , Loss:  0.5952877998352051   f1-score: 0.9048908948898315   accuracy: 0.9399099349975586\n",
      "Epoch:  2905 , Loss:  0.5952849984169006   f1-score: 0.9048908948898315   accuracy: 0.9399099349975586\n",
      "Epoch:  2906 , Loss:  0.5952821373939514   f1-score: 0.9048908948898315   accuracy: 0.9399099349975586\n",
      "Epoch:  2907 , Loss:  0.5952792167663574   f1-score: 0.9050470590591431   accuracy: 0.9399999976158142\n",
      "Epoch:  2908 , Loss:  0.5952762365341187   f1-score: 0.9050470590591431   accuracy: 0.9399999976158142\n",
      "Epoch:  2909 , Loss:  0.5952730774879456   f1-score: 0.9050470590591431   accuracy: 0.9399999976158142\n",
      "Epoch:  2910 , Loss:  0.5952697396278381   f1-score: 0.9050470590591431   accuracy: 0.9399999976158142\n",
      "Epoch:  2911 , Loss:  0.5952662825584412   f1-score: 0.9050470590591431   accuracy: 0.9399999976158142\n",
      "Epoch:  2912 , Loss:  0.5952626466751099   f1-score: 0.9050470590591431   accuracy: 0.9399999976158142\n",
      "Epoch:  2913 , Loss:  0.5952590703964233   f1-score: 0.9050470590591431   accuracy: 0.9399999976158142\n",
      "Epoch:  2914 , Loss:  0.5952552556991577   f1-score: 0.9050470590591431   accuracy: 0.9399999976158142\n",
      "Epoch:  2915 , Loss:  0.5952512621879578   f1-score: 0.9050470590591431   accuracy: 0.9399999976158142\n",
      "Epoch:  2916 , Loss:  0.5952475666999817   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2917 , Loss:  0.5952438712120056   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2918 , Loss:  0.5952403545379639   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2919 , Loss:  0.5952370762825012   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2920 , Loss:  0.5952339768409729   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2921 , Loss:  0.5952311158180237   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2922 , Loss:  0.595228374004364   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2923 , Loss:  0.5952256917953491   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2924 , Loss:  0.595223069190979   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2925 , Loss:  0.5952203869819641   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2926 , Loss:  0.5952178835868835   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2927 , Loss:  0.5952152013778687   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2928 , Loss:  0.5952126383781433   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2929 , Loss:  0.5952101349830627   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2930 , Loss:  0.5952075719833374   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2931 , Loss:  0.5952050685882568   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2932 , Loss:  0.5952025055885315   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2933 , Loss:  0.5952000021934509   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2934 , Loss:  0.5951973795890808   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2935 , Loss:  0.5951948761940002   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2936 , Loss:  0.5951924324035645   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2937 , Loss:  0.5951898694038391   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2938 , Loss:  0.5951873660087585   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2939 , Loss:  0.595184862613678   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2940 , Loss:  0.5951822996139526   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2941 , Loss:  0.5951796770095825   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2942 , Loss:  0.5951770544052124   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2943 , Loss:  0.595174252986908   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2944 , Loss:  0.5951712131500244   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2945 , Loss:  0.595167875289917   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2946 , Loss:  0.5951639413833618   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2947 , Loss:  0.5951589345932007   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2948 , Loss:  0.5951524972915649   f1-score: 0.9052031636238098   accuracy: 0.9400901198387146\n",
      "Epoch:  2949 , Loss:  0.5951443910598755   f1-score: 0.9053592085838318   accuracy: 0.9401801824569702\n",
      "Epoch:  2950 , Loss:  0.595136284828186   f1-score: 0.9053592085838318   accuracy: 0.9401801824569702\n",
      "Epoch:  2951 , Loss:  0.595130443572998   f1-score: 0.9053592085838318   accuracy: 0.9401801824569702\n",
      "Epoch:  2952 , Loss:  0.5951266884803772   f1-score: 0.9053592085838318   accuracy: 0.9401801824569702\n",
      "Epoch:  2953 , Loss:  0.5951241254806519   f1-score: 0.9053592085838318   accuracy: 0.9401801824569702\n",
      "Epoch:  2954 , Loss:  0.5951218008995056   f1-score: 0.9053592085838318   accuracy: 0.9401801824569702\n",
      "Epoch:  2955 , Loss:  0.5951195955276489   f1-score: 0.9053592085838318   accuracy: 0.9401801824569702\n",
      "Epoch:  2956 , Loss:  0.5951172113418579   f1-score: 0.9053592085838318   accuracy: 0.9401801824569702\n",
      "Epoch:  2957 , Loss:  0.5951147675514221   f1-score: 0.9053592085838318   accuracy: 0.9401801824569702\n",
      "Epoch:  2958 , Loss:  0.5951122045516968   f1-score: 0.9053592085838318   accuracy: 0.9401801824569702\n",
      "Epoch:  2959 , Loss:  0.5951095223426819   f1-score: 0.9053592085838318   accuracy: 0.9401801824569702\n",
      "Epoch:  2960 , Loss:  0.5951067209243774   f1-score: 0.9053592085838318   accuracy: 0.9401801824569702\n",
      "Epoch:  2961 , Loss:  0.5951037406921387   f1-score: 0.9053592085838318   accuracy: 0.9401801824569702\n",
      "Epoch:  2962 , Loss:  0.5951008200645447   f1-score: 0.9053592085838318   accuracy: 0.9401801824569702\n",
      "Epoch:  2963 , Loss:  0.5950977802276611   f1-score: 0.9053592085838318   accuracy: 0.9401801824569702\n",
      "Epoch:  2964 , Loss:  0.5950946807861328   f1-score: 0.9053592085838318   accuracy: 0.9401801824569702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2965 , Loss:  0.5950916409492493   f1-score: 0.9053592085838318   accuracy: 0.9401801824569702\n",
      "Epoch:  2966 , Loss:  0.595088541507721   f1-score: 0.9053592085838318   accuracy: 0.9401801824569702\n",
      "Epoch:  2967 , Loss:  0.5950854420661926   f1-score: 0.9053592085838318   accuracy: 0.9401801824569702\n",
      "Epoch:  2968 , Loss:  0.5950823426246643   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2969 , Loss:  0.5950793623924255   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2970 , Loss:  0.5950764417648315   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2971 , Loss:  0.5950735807418823   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2972 , Loss:  0.5950707197189331   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2973 , Loss:  0.5950679779052734   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2974 , Loss:  0.5950652956962585   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2975 , Loss:  0.5950626730918884   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2976 , Loss:  0.5950601100921631   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2977 , Loss:  0.5950576066970825   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2978 , Loss:  0.595055103302002   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2979 , Loss:  0.5950525999069214   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2980 , Loss:  0.5950501561164856   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2981 , Loss:  0.5950477719306946   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2982 , Loss:  0.5950453877449036   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2983 , Loss:  0.5950430631637573   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2984 , Loss:  0.5950407981872559   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2985 , Loss:  0.5950384736061096   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2986 , Loss:  0.5950361490249634   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2987 , Loss:  0.5950338244438171   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2988 , Loss:  0.5950316190719604   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2989 , Loss:  0.5950292944908142   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2990 , Loss:  0.5950270295143127   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2991 , Loss:  0.595024824142456   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2992 , Loss:  0.5950225591659546   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2993 , Loss:  0.5950203537940979   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2994 , Loss:  0.5950181484222412   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2995 , Loss:  0.5950159430503845   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2996 , Loss:  0.5950137376785278   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2997 , Loss:  0.5950115323066711   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2998 , Loss:  0.5950093269348145   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  2999 , Loss:  0.595007061958313   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  3000 , Loss:  0.5950047373771667   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  3001 , Loss:  0.5950025916099548   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  3002 , Loss:  0.5950002670288086   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  3003 , Loss:  0.5949980020523071   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  3004 , Loss:  0.5949956774711609   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  3005 , Loss:  0.5949934124946594   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  3006 , Loss:  0.5949910283088684   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  3007 , Loss:  0.5949887633323669   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  3008 , Loss:  0.5949863791465759   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  3009 , Loss:  0.5949839949607849   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  3010 , Loss:  0.5949816107749939   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  3011 , Loss:  0.5949792265892029   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  3012 , Loss:  0.5949767827987671   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  3013 , Loss:  0.5949743986129761   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  3014 , Loss:  0.5949719548225403   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  3015 , Loss:  0.5949695110321045   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  3016 , Loss:  0.5949671268463135   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  3017 , Loss:  0.5949647426605225   f1-score: 0.905515193939209   accuracy: 0.9402702450752258\n",
      "Epoch:  3018 , Loss:  0.5949623584747314   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3019 , Loss:  0.5949599742889404   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3020 , Loss:  0.5949575901031494   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3021 , Loss:  0.594955325126648   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3022 , Loss:  0.5949530601501465   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3023 , Loss:  0.5949507355690002   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3024 , Loss:  0.5949485301971436   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3025 , Loss:  0.5949463248252869   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3026 , Loss:  0.5949441194534302   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3027 , Loss:  0.5949419736862183   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3028 , Loss:  0.5949398279190063   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3029 , Loss:  0.5949377417564392   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3030 , Loss:  0.5949357151985168   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3031 , Loss:  0.5949335694313049   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3032 , Loss:  0.5949315428733826   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3033 , Loss:  0.5949295163154602   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3034 , Loss:  0.5949275493621826   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3035 , Loss:  0.5949254631996155   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3036 , Loss:  0.5949234962463379   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3037 , Loss:  0.5949215292930603   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3038 , Loss:  0.5949195027351379   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3039 , Loss:  0.5949175953865051   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3040 , Loss:  0.5949156284332275   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3041 , Loss:  0.5949137210845947   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3042 , Loss:  0.5949117541313171   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3043 , Loss:  0.5949099063873291   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3044 , Loss:  0.5949079394340515   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3045 , Loss:  0.5949060320854187   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3046 , Loss:  0.5949041843414307   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3047 , Loss:  0.5949022769927979   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3048 , Loss:  0.594900369644165   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3049 , Loss:  0.5948984622955322   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3050 , Loss:  0.5948966145515442   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3051 , Loss:  0.5948947668075562   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3052 , Loss:  0.5948929190635681   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3053 , Loss:  0.5948910117149353   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3054 , Loss:  0.5948891639709473   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3055 , Loss:  0.594887375831604   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3056 , Loss:  0.594885528087616   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3057 , Loss:  0.5948836207389832   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3058 , Loss:  0.5948818325996399   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3059 , Loss:  0.5948799848556519   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3060 , Loss:  0.5948781371116638   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3061 , Loss:  0.5948764085769653   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3062 , Loss:  0.5948745012283325   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3063 , Loss:  0.5948727130889893   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3064 , Loss:  0.5948708653450012   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3065 , Loss:  0.594869077205658   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3066 , Loss:  0.5948672294616699   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3067 , Loss:  0.5948653221130371   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3068 , Loss:  0.5948635339736938   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3069 , Loss:  0.5948616862297058   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3070 , Loss:  0.5948598384857178   f1-score: 0.9056711196899414   accuracy: 0.9403603672981262\n",
      "Epoch:  3071 , Loss:  0.5948579907417297   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3072 , Loss:  0.5948561429977417   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3073 , Loss:  0.5948543548583984   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3074 , Loss:  0.5948524475097656   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3075 , Loss:  0.5948505997657776   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3076 , Loss:  0.5948488712310791   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3077 , Loss:  0.5948469042778015   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3078 , Loss:  0.5948451161384583   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3079 , Loss:  0.594843327999115   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3080 , Loss:  0.594841480255127   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3081 , Loss:  0.5948395729064941   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3082 , Loss:  0.5948377847671509   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3083 , Loss:  0.5948359370231628   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3084 , Loss:  0.5948339700698853   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3085 , Loss:  0.5948321223258972   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3086 , Loss:  0.5948302745819092   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3087 , Loss:  0.5948284268379211   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3088 , Loss:  0.5948265790939331   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3089 , Loss:  0.5948246717453003   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3090 , Loss:  0.5948227643966675   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3091 , Loss:  0.5948209166526794   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3092 , Loss:  0.5948190689086914   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3093 , Loss:  0.5948171615600586   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3094 , Loss:  0.5948152542114258   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3095 , Loss:  0.594813346862793   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3096 , Loss:  0.5948114991188049   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3097 , Loss:  0.5948096513748169   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3098 , Loss:  0.5948078036308289   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3099 , Loss:  0.5948059558868408   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3100 , Loss:  0.5948039889335632   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3101 , Loss:  0.5948020815849304   f1-score: 0.9058270454406738   accuracy: 0.9404504299163818\n",
      "Epoch:  3102 , Loss:  0.5948002338409424   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3103 , Loss:  0.5947983860969543   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3104 , Loss:  0.5947964787483215   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3105 , Loss:  0.5947946310043335   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3106 , Loss:  0.5947927236557007   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3107 , Loss:  0.5947908163070679   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3108 , Loss:  0.5947889685630798   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3109 , Loss:  0.594787061214447   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3110 , Loss:  0.5947851538658142   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3111 , Loss:  0.5947833061218262   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3112 , Loss:  0.5947813391685486   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3113 , Loss:  0.5947794318199158   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3114 , Loss:  0.594777524471283   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3115 , Loss:  0.5947755575180054   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3116 , Loss:  0.5947736501693726   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3117 , Loss:  0.594771683216095   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3118 , Loss:  0.5947696566581726   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3119 , Loss:  0.5947677493095398   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3120 , Loss:  0.5947657227516174   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3121 , Loss:  0.5947636365890503   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3122 , Loss:  0.5947616100311279   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3123 , Loss:  0.5947595834732056   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3124 , Loss:  0.5947574377059937   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3125 , Loss:  0.5947553515434265   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3126 , Loss:  0.5947532057762146   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3127 , Loss:  0.5947510600090027   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3128 , Loss:  0.5947489142417908   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3129 , Loss:  0.5947467088699341   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3130 , Loss:  0.5947445034980774   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3131 , Loss:  0.5947422981262207   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3132 , Loss:  0.5947400331497192   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3133 , Loss:  0.5947378277778625   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3134 , Loss:  0.5947356224060059   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3135 , Loss:  0.5947333574295044   f1-score: 0.9059829115867615   accuracy: 0.9405405521392822\n",
      "Epoch:  3136 , Loss:  0.5947311520576477   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3137 , Loss:  0.5947288870811462   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3138 , Loss:  0.5947266817092896   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3139 , Loss:  0.5947245359420776   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3140 , Loss:  0.594722330570221   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3141 , Loss:  0.5947202444076538   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3142 , Loss:  0.5947181582450867   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3143 , Loss:  0.59471595287323   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3144 , Loss:  0.5947139263153076   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3145 , Loss:  0.5947117805480957   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3146 , Loss:  0.5947097539901733   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3147 , Loss:  0.594707727432251   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3148 , Loss:  0.5947056412696838   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3149 , Loss:  0.5947036147117615   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3150 , Loss:  0.5947015881538391   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3151 , Loss:  0.5946995615959167   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3152 , Loss:  0.5946976542472839   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3153 , Loss:  0.5946956276893616   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3154 , Loss:  0.5946935415267944   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3155 , Loss:  0.5946916341781616   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3156 , Loss:  0.5946895480155945   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3157 , Loss:  0.5946876406669617   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3158 , Loss:  0.5946856141090393   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3159 , Loss:  0.5946835875511169   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3160 , Loss:  0.5946816205978394   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3161 , Loss:  0.5946795344352722   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3162 , Loss:  0.5946775078773499   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3163 , Loss:  0.5946754813194275   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3164 , Loss:  0.5946733355522156   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3165 , Loss:  0.5946713089942932   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3166 , Loss:  0.5946691632270813   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3167 , Loss:  0.5946670174598694   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3168 , Loss:  0.5946648716926575   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3169 , Loss:  0.594662606716156   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3170 , Loss:  0.5946603417396545   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3171 , Loss:  0.5946580171585083   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3172 , Loss:  0.5946556925773621   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3173 , Loss:  0.5946532487869263   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3174 , Loss:  0.5946507453918457   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3175 , Loss:  0.5946480631828308   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3176 , Loss:  0.5946452617645264   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3177 , Loss:  0.5946422815322876   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3178 , Loss:  0.5946390628814697   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3179 , Loss:  0.5946356058120728   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3180 , Loss:  0.5946318507194519   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3181 , Loss:  0.5946277379989624   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3182 , Loss:  0.5946233868598938   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3183 , Loss:  0.5946189165115356   f1-score: 0.9061387181282043   accuracy: 0.9406306147575378\n",
      "Epoch:  3184 , Loss:  0.5946143865585327   f1-score: 0.9062945246696472   accuracy: 0.9407207369804382\n",
      "Epoch:  3185 , Loss:  0.5946099758148193   f1-score: 0.9062945246696472   accuracy: 0.9407207369804382\n",
      "Epoch:  3186 , Loss:  0.5946059823036194   f1-score: 0.9062945246696472   accuracy: 0.9407207369804382\n",
      "Epoch:  3187 , Loss:  0.594602108001709   f1-score: 0.9062945246696472   accuracy: 0.9407207369804382\n",
      "Epoch:  3188 , Loss:  0.5945985317230225   f1-score: 0.9062945246696472   accuracy: 0.9407207369804382\n",
      "Epoch:  3189 , Loss:  0.5945950746536255   f1-score: 0.9062945246696472   accuracy: 0.9407207369804382\n",
      "Epoch:  3190 , Loss:  0.5945916175842285   f1-score: 0.9062945246696472   accuracy: 0.9407207369804382\n",
      "Epoch:  3191 , Loss:  0.5945882201194763   f1-score: 0.9062945246696472   accuracy: 0.9407207369804382\n",
      "Epoch:  3192 , Loss:  0.5945847630500793   f1-score: 0.9062945246696472   accuracy: 0.9407207369804382\n",
      "Epoch:  3193 , Loss:  0.5945812463760376   f1-score: 0.9064502120018005   accuracy: 0.9408107995986938\n",
      "Epoch:  3194 , Loss:  0.5945777297019958   f1-score: 0.9064502120018005   accuracy: 0.9408107995986938\n",
      "Epoch:  3195 , Loss:  0.5945741534233093   f1-score: 0.9064502120018005   accuracy: 0.9408107995986938\n",
      "Epoch:  3196 , Loss:  0.594570517539978   f1-score: 0.9064502120018005   accuracy: 0.9408107995986938\n",
      "Epoch:  3197 , Loss:  0.5945670008659363   f1-score: 0.9064502120018005   accuracy: 0.9408107995986938\n",
      "Epoch:  3198 , Loss:  0.5945634245872498   f1-score: 0.9064502120018005   accuracy: 0.9408107995986938\n",
      "Epoch:  3199 , Loss:  0.5945598483085632   f1-score: 0.9066058993339539   accuracy: 0.9409009218215942\n",
      "Epoch:  3200 , Loss:  0.594556450843811   f1-score: 0.9066058993339539   accuracy: 0.9409009218215942\n",
      "Epoch:  3201 , Loss:  0.5945529937744141   f1-score: 0.9067615866661072   accuracy: 0.9409909844398499\n",
      "Epoch:  3202 , Loss:  0.5945496559143066   f1-score: 0.9067615866661072   accuracy: 0.9409909844398499\n",
      "Epoch:  3203 , Loss:  0.5945463180541992   f1-score: 0.9067615866661072   accuracy: 0.9409909844398499\n",
      "Epoch:  3204 , Loss:  0.5945431590080261   f1-score: 0.9067615866661072   accuracy: 0.9409909844398499\n",
      "Epoch:  3205 , Loss:  0.5945400595664978   f1-score: 0.9067615866661072   accuracy: 0.9409909844398499\n",
      "Epoch:  3206 , Loss:  0.5945369601249695   f1-score: 0.9067615866661072   accuracy: 0.9409909844398499\n",
      "Epoch:  3207 , Loss:  0.5945339798927307   f1-score: 0.9067615866661072   accuracy: 0.9409909844398499\n",
      "Epoch:  3208 , Loss:  0.5945310592651367   f1-score: 0.9067615866661072   accuracy: 0.9409909844398499\n",
      "Epoch:  3209 , Loss:  0.5945281982421875   f1-score: 0.9067615866661072   accuracy: 0.9409909844398499\n",
      "Epoch:  3210 , Loss:  0.5945252776145935   f1-score: 0.9067615866661072   accuracy: 0.9409909844398499\n",
      "Epoch:  3211 , Loss:  0.5945224165916443   f1-score: 0.9067615866661072   accuracy: 0.9409909844398499\n",
      "Epoch:  3212 , Loss:  0.5945195555686951   f1-score: 0.9067615866661072   accuracy: 0.9409909844398499\n",
      "Epoch:  3213 , Loss:  0.5945166349411011   f1-score: 0.9067615866661072   accuracy: 0.9409909844398499\n",
      "Epoch:  3214 , Loss:  0.5945136547088623   f1-score: 0.9067615866661072   accuracy: 0.9409909844398499\n",
      "Epoch:  3215 , Loss:  0.5945106744766235   f1-score: 0.9068906903266907   accuracy: 0.9410811066627502\n",
      "Epoch:  3216 , Loss:  0.5945076942443848   f1-score: 0.9068906903266907   accuracy: 0.9410811066627502\n",
      "Epoch:  3217 , Loss:  0.5945046544075012   f1-score: 0.9068906903266907   accuracy: 0.9410811066627502\n",
      "Epoch:  3218 , Loss:  0.5945015549659729   f1-score: 0.9068906903266907   accuracy: 0.9410811066627502\n",
      "Epoch:  3219 , Loss:  0.5944984555244446   f1-score: 0.9068906903266907   accuracy: 0.9410811066627502\n",
      "Epoch:  3220 , Loss:  0.5944952964782715   f1-score: 0.9068906903266907   accuracy: 0.9410811066627502\n",
      "Epoch:  3221 , Loss:  0.5944921374320984   f1-score: 0.9068906903266907   accuracy: 0.9410811066627502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3222 , Loss:  0.5944889187812805   f1-score: 0.9068906903266907   accuracy: 0.9410811066627502\n",
      "Epoch:  3223 , Loss:  0.594485878944397   f1-score: 0.9070462584495544   accuracy: 0.9411711692810059\n",
      "Epoch:  3224 , Loss:  0.5944827198982239   f1-score: 0.9070462584495544   accuracy: 0.9411711692810059\n",
      "Epoch:  3225 , Loss:  0.5944796800613403   f1-score: 0.9070462584495544   accuracy: 0.9411711692810059\n",
      "Epoch:  3226 , Loss:  0.5944766402244568   f1-score: 0.9070462584495544   accuracy: 0.9411711692810059\n",
      "Epoch:  3227 , Loss:  0.594473659992218   f1-score: 0.9070462584495544   accuracy: 0.9411711692810059\n",
      "Epoch:  3228 , Loss:  0.594470739364624   f1-score: 0.9070462584495544   accuracy: 0.9411711692810059\n",
      "Epoch:  3229 , Loss:  0.59446781873703   f1-score: 0.9070462584495544   accuracy: 0.9411711692810059\n",
      "Epoch:  3230 , Loss:  0.5944650173187256   f1-score: 0.9070462584495544   accuracy: 0.9411711692810059\n",
      "Epoch:  3231 , Loss:  0.5944622755050659   f1-score: 0.9070462584495544   accuracy: 0.9411711692810059\n",
      "Epoch:  3232 , Loss:  0.5944595336914062   f1-score: 0.9070462584495544   accuracy: 0.9411711692810059\n",
      "Epoch:  3233 , Loss:  0.5944569110870361   f1-score: 0.9070462584495544   accuracy: 0.9411711692810059\n",
      "Epoch:  3234 , Loss:  0.5944542288780212   f1-score: 0.9070462584495544   accuracy: 0.9411711692810059\n",
      "Epoch:  3235 , Loss:  0.5944515466690063   f1-score: 0.9070462584495544   accuracy: 0.9411711692810059\n",
      "Epoch:  3236 , Loss:  0.594448983669281   f1-score: 0.9070462584495544   accuracy: 0.9411711692810059\n",
      "Epoch:  3237 , Loss:  0.5944464802742004   f1-score: 0.9070462584495544   accuracy: 0.9411711692810059\n",
      "Epoch:  3238 , Loss:  0.5944437980651855   f1-score: 0.9072018265724182   accuracy: 0.9412612318992615\n",
      "Epoch:  3239 , Loss:  0.5944412350654602   f1-score: 0.9072018265724182   accuracy: 0.9412612318992615\n",
      "Epoch:  3240 , Loss:  0.5944387316703796   f1-score: 0.9072018265724182   accuracy: 0.9412612318992615\n",
      "Epoch:  3241 , Loss:  0.5944361686706543   f1-score: 0.9072018265724182   accuracy: 0.9412612318992615\n",
      "Epoch:  3242 , Loss:  0.594433605670929   f1-score: 0.9072018265724182   accuracy: 0.9412612318992615\n",
      "Epoch:  3243 , Loss:  0.5944309830665588   f1-score: 0.9072018265724182   accuracy: 0.9412612318992615\n",
      "Epoch:  3244 , Loss:  0.594428300857544   f1-score: 0.9072018265724182   accuracy: 0.9412612318992615\n",
      "Epoch:  3245 , Loss:  0.5944257974624634   f1-score: 0.9072018265724182   accuracy: 0.9412612318992615\n",
      "Epoch:  3246 , Loss:  0.5944231152534485   f1-score: 0.9072018265724182   accuracy: 0.9412612318992615\n",
      "Epoch:  3247 , Loss:  0.5944204926490784   f1-score: 0.9072018265724182   accuracy: 0.9412612318992615\n",
      "Epoch:  3248 , Loss:  0.5944178104400635   f1-score: 0.9072018265724182   accuracy: 0.9412612318992615\n",
      "Epoch:  3249 , Loss:  0.5944151878356934   f1-score: 0.9072018265724182   accuracy: 0.9412612318992615\n",
      "Epoch:  3250 , Loss:  0.5944125652313232   f1-score: 0.9072018265724182   accuracy: 0.9412612318992615\n",
      "Epoch:  3251 , Loss:  0.5944098234176636   f1-score: 0.9072018265724182   accuracy: 0.9412612318992615\n",
      "Epoch:  3252 , Loss:  0.5944070816040039   f1-score: 0.9072018265724182   accuracy: 0.9412612318992615\n",
      "Epoch:  3253 , Loss:  0.5944043397903442   f1-score: 0.9072018265724182   accuracy: 0.9412612318992615\n",
      "Epoch:  3254 , Loss:  0.5944016575813293   f1-score: 0.9073573350906372   accuracy: 0.9413513541221619\n",
      "Epoch:  3255 , Loss:  0.5943987965583801   f1-score: 0.9073573350906372   accuracy: 0.9413513541221619\n",
      "Epoch:  3256 , Loss:  0.5943959355354309   f1-score: 0.9073573350906372   accuracy: 0.9413513541221619\n",
      "Epoch:  3257 , Loss:  0.5943930745124817   f1-score: 0.9073573350906372   accuracy: 0.9413513541221619\n",
      "Epoch:  3258 , Loss:  0.5943898558616638   f1-score: 0.9073573350906372   accuracy: 0.9413513541221619\n",
      "Epoch:  3259 , Loss:  0.5943865180015564   f1-score: 0.9073573350906372   accuracy: 0.9413513541221619\n",
      "Epoch:  3260 , Loss:  0.594382643699646   f1-score: 0.9073573350906372   accuracy: 0.9413513541221619\n",
      "Epoch:  3261 , Loss:  0.5943778157234192   f1-score: 0.9073573350906372   accuracy: 0.9413513541221619\n",
      "Epoch:  3262 , Loss:  0.5943712592124939   f1-score: 0.9073573350906372   accuracy: 0.9413513541221619\n",
      "Epoch:  3263 , Loss:  0.5943618416786194   f1-score: 0.9075127840042114   accuracy: 0.9414414167404175\n",
      "Epoch:  3264 , Loss:  0.5943498611450195   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3265 , Loss:  0.5943397283554077   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3266 , Loss:  0.5943340063095093   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3267 , Loss:  0.594330906867981   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3268 , Loss:  0.5943285226821899   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3269 , Loss:  0.5943260788917542   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3270 , Loss:  0.5943236351013184   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3271 , Loss:  0.5943212509155273   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3272 , Loss:  0.5943187475204468   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3273 , Loss:  0.5943161845207214   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3274 , Loss:  0.5943136215209961   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3275 , Loss:  0.5943110585212708   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3276 , Loss:  0.5943084955215454   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3277 , Loss:  0.5943058729171753   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3278 , Loss:  0.5943034291267395   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3279 , Loss:  0.5943010449409485   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3280 , Loss:  0.5942988395690918   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3281 , Loss:  0.5942966938018799   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3282 , Loss:  0.594294548034668   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3283 , Loss:  0.5942924618721008   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3284 , Loss:  0.5942903161048889   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3285 , Loss:  0.5942882895469666   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3286 , Loss:  0.5942862629890442   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3287 , Loss:  0.594284176826477   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3288 , Loss:  0.5942822098731995   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3289 , Loss:  0.5942802429199219   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3290 , Loss:  0.5942781567573547   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3291 , Loss:  0.5942761898040771   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3292 , Loss:  0.5942742824554443   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3293 , Loss:  0.5942723155021667   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3294 , Loss:  0.5942704677581787   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3295 , Loss:  0.5942686200141907   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3296 , Loss:  0.5942668318748474   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3297 , Loss:  0.5942650437355042   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3298 , Loss:  0.5942632555961609   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3299 , Loss:  0.5942615270614624   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3300 , Loss:  0.5942597389221191   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3301 , Loss:  0.5942580699920654   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3302 , Loss:  0.5942564606666565   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3303 , Loss:  0.594254732131958   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3304 , Loss:  0.5942530632019043   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3305 , Loss:  0.5942513942718506   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3306 , Loss:  0.5942497849464417   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3307 , Loss:  0.5942481756210327   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3308 , Loss:  0.5942465662956238   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3309 , Loss:  0.5942448973655701   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3310 , Loss:  0.5942432880401611   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3311 , Loss:  0.5942416787147522   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3312 , Loss:  0.5942400097846985   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3313 , Loss:  0.5942384004592896   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3314 , Loss:  0.5942367911338806   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3315 , Loss:  0.5942352414131165   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3316 , Loss:  0.5942335724830627   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3317 , Loss:  0.5942319631576538   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3318 , Loss:  0.5942303538322449   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3319 , Loss:  0.5942287445068359   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3320 , Loss:  0.594227135181427   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3321 , Loss:  0.5942254662513733   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3322 , Loss:  0.5942237973213196   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3323 , Loss:  0.5942221879959106   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3324 , Loss:  0.5942204594612122   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3325 , Loss:  0.5942187905311584   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3326 , Loss:  0.5942170023918152   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3327 , Loss:  0.5942152738571167   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3328 , Loss:  0.5942134261131287   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3329 , Loss:  0.5942115783691406   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3330 , Loss:  0.5942096710205078   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3331 , Loss:  0.594207763671875   f1-score: 0.9076419472694397   accuracy: 0.9415315389633179\n",
      "Epoch:  3332 , Loss:  0.5942056775093079   f1-score: 0.9077973961830139   accuracy: 0.9416216015815735\n",
      "Epoch:  3333 , Loss:  0.5942036509513855   f1-score: 0.9077973961830139   accuracy: 0.9416216015815735\n",
      "Epoch:  3334 , Loss:  0.5942015647888184   f1-score: 0.9077973961830139   accuracy: 0.9416216015815735\n",
      "Epoch:  3335 , Loss:  0.5941994190216064   f1-score: 0.9077973961830139   accuracy: 0.9416216015815735\n",
      "Epoch:  3336 , Loss:  0.5941972136497498   f1-score: 0.9077973961830139   accuracy: 0.9416216015815735\n",
      "Epoch:  3337 , Loss:  0.5941950082778931   f1-score: 0.9077973961830139   accuracy: 0.9416216015815735\n",
      "Epoch:  3338 , Loss:  0.5941928029060364   f1-score: 0.9077973961830139   accuracy: 0.9416216015815735\n",
      "Epoch:  3339 , Loss:  0.5941905379295349   f1-score: 0.9077973961830139   accuracy: 0.9416216015815735\n",
      "Epoch:  3340 , Loss:  0.594188392162323   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3341 , Loss:  0.5941861867904663   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3342 , Loss:  0.5941841006278992   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3343 , Loss:  0.5941820740699768   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3344 , Loss:  0.5941800475120544   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3345 , Loss:  0.5941781401634216   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3346 , Loss:  0.5941762924194336   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3347 , Loss:  0.5941744446754456   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3348 , Loss:  0.5941726565361023   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3349 , Loss:  0.5941709280014038   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3350 , Loss:  0.5941693186759949   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3351 , Loss:  0.5941675901412964   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3352 , Loss:  0.5941659808158875   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3353 , Loss:  0.5941643714904785   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3354 , Loss:  0.5941628217697144   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3355 , Loss:  0.5941612124443054   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3356 , Loss:  0.5941596627235413   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3357 , Loss:  0.5941581726074219   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3358 , Loss:  0.5941566228866577   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3359 , Loss:  0.5941551327705383   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3360 , Loss:  0.594153642654419   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3361 , Loss:  0.5941521525382996   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3362 , Loss:  0.5941507816314697   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3363 , Loss:  0.5941492319107056   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3364 , Loss:  0.5941478610038757   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3365 , Loss:  0.5941464304924011   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3366 , Loss:  0.5941449999809265   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3367 , Loss:  0.5941435694694519   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3368 , Loss:  0.5941421389579773   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3369 , Loss:  0.5941407084465027   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3370 , Loss:  0.5941393375396729   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3371 , Loss:  0.5941379070281982   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3372 , Loss:  0.5941364765167236   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3373 , Loss:  0.594135046005249   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3374 , Loss:  0.5941336154937744   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3375 , Loss:  0.5941323041915894   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3376 , Loss:  0.5941308736801147   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3377 , Loss:  0.5941295623779297   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3378 , Loss:  0.5941281318664551   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3379 , Loss:  0.5941267609596252   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3380 , Loss:  0.5941253900527954   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3381 , Loss:  0.5941240191459656   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3382 , Loss:  0.5941227078437805   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3383 , Loss:  0.5941213369369507   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3384 , Loss:  0.5941199660301208   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3385 , Loss:  0.594118595123291   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3386 , Loss:  0.5941172242164612   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3387 , Loss:  0.5941159129142761   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3388 , Loss:  0.5941145420074463   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3389 , Loss:  0.5941132307052612   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3390 , Loss:  0.5941118597984314   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3391 , Loss:  0.5941105484962463   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3392 , Loss:  0.5941092371940613   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3393 , Loss:  0.5941078662872314   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3394 , Loss:  0.5941064953804016   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3395 , Loss:  0.5941051840782166   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3396 , Loss:  0.5941038727760315   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3397 , Loss:  0.5941025018692017   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3398 , Loss:  0.5941011309623718   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3399 , Loss:  0.5940998196601868   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3400 , Loss:  0.5940984487533569   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3401 , Loss:  0.5940971970558167   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3402 , Loss:  0.5940958261489868   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3403 , Loss:  0.5940945148468018   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3404 , Loss:  0.5940931439399719   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3405 , Loss:  0.5940918326377869   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3406 , Loss:  0.5940905213356018   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3407 , Loss:  0.5940890908241272   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3408 , Loss:  0.5940878391265869   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3409 , Loss:  0.5940864682197571   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3410 , Loss:  0.5940850973129272   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3411 , Loss:  0.5940837860107422   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3412 , Loss:  0.5940824151039124   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3413 , Loss:  0.5940811038017273   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3414 , Loss:  0.5940797924995422   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3415 , Loss:  0.5940784215927124   f1-score: 0.9079527854919434   accuracy: 0.9417117238044739\n",
      "Epoch:  3416 , Loss:  0.5940770506858826   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3417 , Loss:  0.5940757393836975   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3418 , Loss:  0.5940743684768677   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3419 , Loss:  0.5940729975700378   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3420 , Loss:  0.5940715670585632   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3421 , Loss:  0.5940701961517334   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3422 , Loss:  0.5940687656402588   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3423 , Loss:  0.5940673351287842   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3424 , Loss:  0.5940659642219543   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3425 , Loss:  0.594064474105835   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3426 , Loss:  0.5940630435943604   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3427 , Loss:  0.5940614938735962   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3428 , Loss:  0.5940600037574768   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3429 , Loss:  0.5940584540367126   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3430 , Loss:  0.5940569043159485   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3431 , Loss:  0.5940552353858948   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3432 , Loss:  0.5940534472465515   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3433 , Loss:  0.5940514802932739   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3434 , Loss:  0.5940493941307068   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3435 , Loss:  0.5940470099449158   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3436 , Loss:  0.5940439701080322   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3437 , Loss:  0.5940402746200562   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3438 , Loss:  0.5940351486206055   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3439 , Loss:  0.5940287113189697   f1-score: 0.908108115196228   accuracy: 0.9418017864227295\n",
      "Epoch:  3440 , Loss:  0.5940222144126892   f1-score: 0.9082633852958679   accuracy: 0.9418919086456299\n",
      "Epoch:  3441 , Loss:  0.5940173268318176   f1-score: 0.9082633852958679   accuracy: 0.9418919086456299\n",
      "Epoch:  3442 , Loss:  0.5940144062042236   f1-score: 0.9082633852958679   accuracy: 0.9418919086456299\n",
      "Epoch:  3443 , Loss:  0.5940123796463013   f1-score: 0.9082633852958679   accuracy: 0.9418919086456299\n",
      "Epoch:  3444 , Loss:  0.594010591506958   f1-score: 0.9082633852958679   accuracy: 0.9418919086456299\n",
      "Epoch:  3445 , Loss:  0.5940088629722595   f1-score: 0.9082633852958679   accuracy: 0.9418919086456299\n",
      "Epoch:  3446 , Loss:  0.5940070152282715   f1-score: 0.9082633852958679   accuracy: 0.9418919086456299\n",
      "Epoch:  3447 , Loss:  0.594005286693573   f1-score: 0.9082633852958679   accuracy: 0.9418919086456299\n",
      "Epoch:  3448 , Loss:  0.5940036177635193   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3449 , Loss:  0.5940020084381104   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3450 , Loss:  0.5940002799034119   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3451 , Loss:  0.5939986109733582   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3452 , Loss:  0.5939969420433044   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3453 , Loss:  0.593995213508606   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3454 , Loss:  0.593993604183197   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3455 , Loss:  0.5939919352531433   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3456 , Loss:  0.5939902663230896   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3457 , Loss:  0.5939887166023254   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3458 , Loss:  0.5939870476722717   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3459 , Loss:  0.5939854979515076   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3460 , Loss:  0.5939838290214539   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3461 , Loss:  0.5939821004867554   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3462 , Loss:  0.593980610370636   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3463 , Loss:  0.593979001045227   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3464 , Loss:  0.5939775109291077   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3465 , Loss:  0.5939760804176331   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3466 , Loss:  0.5939746499061584   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3467 , Loss:  0.5939732193946838   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3468 , Loss:  0.5939717888832092   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3469 , Loss:  0.5939704179763794   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3470 , Loss:  0.5939690470695496   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3471 , Loss:  0.5939676761627197   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3472 , Loss:  0.5939663052558899   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3473 , Loss:  0.5939649343490601   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3474 , Loss:  0.593963623046875   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3475 , Loss:  0.5939623713493347   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3476 , Loss:  0.5939610600471497   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3477 , Loss:  0.5939597487449646   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3478 , Loss:  0.5939584970474243   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3479 , Loss:  0.5939571857452393   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3480 , Loss:  0.5939558744430542   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3481 , Loss:  0.5939546823501587   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3482 , Loss:  0.5939533710479736   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3483 , Loss:  0.5939521193504333   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3484 , Loss:  0.5939508676528931   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3485 , Loss:  0.5939496159553528   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3486 , Loss:  0.5939484238624573   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3487 , Loss:  0.5939471125602722   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3488 , Loss:  0.5939459204673767   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3489 , Loss:  0.5939447283744812   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3490 , Loss:  0.5939434170722961   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3491 , Loss:  0.5939421653747559   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3492 , Loss:  0.5939409136772156   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3493 , Loss:  0.5939396023750305   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3494 , Loss:  0.5939383506774902   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3495 , Loss:  0.5939370393753052   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3496 , Loss:  0.5939359068870544   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3497 , Loss:  0.5939345955848694   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3498 , Loss:  0.5939332842826843   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3499 , Loss:  0.593932032585144   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3500 , Loss:  0.593930721282959   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3501 , Loss:  0.5939293503761292   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3502 , Loss:  0.5939280986785889   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3503 , Loss:  0.5939268469810486   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3504 , Loss:  0.593925416469574   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3505 , Loss:  0.5939240455627441   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3506 , Loss:  0.5939227342605591   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3507 , Loss:  0.5939213633537292   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3508 , Loss:  0.5939200520515442   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3509 , Loss:  0.5939185619354248   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3510 , Loss:  0.593917191028595   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3511 , Loss:  0.5939158797264099   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3512 , Loss:  0.5939143300056458   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3513 , Loss:  0.5939129590988159   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3514 , Loss:  0.5939115285873413   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3515 , Loss:  0.5939099788665771   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3516 , Loss:  0.5939086675643921   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3517 , Loss:  0.5939071774482727   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3518 , Loss:  0.5939056277275085   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3519 , Loss:  0.5939042568206787   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3520 , Loss:  0.5939027667045593   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3521 , Loss:  0.5939012765884399   f1-score: 0.9084186553955078   accuracy: 0.9419819712638855\n",
      "Epoch:  3522 , Loss:  0.5938997864723206   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3523 , Loss:  0.5938982963562012   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3524 , Loss:  0.5938968658447266   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3525 , Loss:  0.593895435333252   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3526 , Loss:  0.5938939452171326   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3527 , Loss:  0.5938924551010132   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3528 , Loss:  0.5938910245895386   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3529 , Loss:  0.5938896536827087   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3530 , Loss:  0.5938881635665894   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3531 , Loss:  0.59388667345047   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3532 , Loss:  0.5938853025436401   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3533 , Loss:  0.5938838124275208   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3534 , Loss:  0.5938823819160461   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3535 , Loss:  0.5938809514045715   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3536 , Loss:  0.5938794016838074   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3537 , Loss:  0.5938780307769775   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3538 , Loss:  0.5938764810562134   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3539 , Loss:  0.593874990940094   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3540 , Loss:  0.5938734412193298   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3541 , Loss:  0.5938718914985657   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3542 , Loss:  0.5938704013824463   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3543 , Loss:  0.5938688516616821   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3544 , Loss:  0.5938671827316284   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3545 , Loss:  0.5938656330108643   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3546 , Loss:  0.5938640236854553   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3547 , Loss:  0.5938623547554016   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3548 , Loss:  0.5938606262207031   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3549 , Loss:  0.5938589572906494   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3550 , Loss:  0.5938572287559509   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3551 , Loss:  0.5938554406166077   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3552 , Loss:  0.5938537120819092   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3553 , Loss:  0.5938518643379211   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3554 , Loss:  0.5938501358032227   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3555 , Loss:  0.5938483476638794   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3556 , Loss:  0.5938465595245361   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3557 , Loss:  0.5938447713851929   f1-score: 0.9085738658905029   accuracy: 0.9420720934867859\n",
      "Epoch:  3558 , Loss:  0.5938429832458496   f1-score: 0.9087290167808533   accuracy: 0.9421621561050415\n",
      "Epoch:  3559 , Loss:  0.5938411951065063   f1-score: 0.9087290167808533   accuracy: 0.9421621561050415\n",
      "Epoch:  3560 , Loss:  0.5938394665718079   f1-score: 0.9087290167808533   accuracy: 0.9421621561050415\n",
      "Epoch:  3561 , Loss:  0.5938377380371094   f1-score: 0.9087290167808533   accuracy: 0.9421621561050415\n",
      "Epoch:  3562 , Loss:  0.5938360095024109   f1-score: 0.9087290167808533   accuracy: 0.9421621561050415\n",
      "Epoch:  3563 , Loss:  0.5938342809677124   f1-score: 0.9087290167808533   accuracy: 0.9421621561050415\n",
      "Epoch:  3564 , Loss:  0.5938326120376587   f1-score: 0.9087290167808533   accuracy: 0.9421621561050415\n",
      "Epoch:  3565 , Loss:  0.5938310027122498   f1-score: 0.9087290167808533   accuracy: 0.9421621561050415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3566 , Loss:  0.5938293933868408   f1-score: 0.9087290167808533   accuracy: 0.9421621561050415\n",
      "Epoch:  3567 , Loss:  0.5938277244567871   f1-score: 0.9087290167808533   accuracy: 0.9421621561050415\n",
      "Epoch:  3568 , Loss:  0.593826174736023   f1-score: 0.9087290167808533   accuracy: 0.9421621561050415\n",
      "Epoch:  3569 , Loss:  0.5938246250152588   f1-score: 0.9087290167808533   accuracy: 0.9421621561050415\n",
      "Epoch:  3570 , Loss:  0.5938230156898499   f1-score: 0.9087290167808533   accuracy: 0.9421621561050415\n",
      "Epoch:  3571 , Loss:  0.5938215851783752   f1-score: 0.9087290167808533   accuracy: 0.9421621561050415\n",
      "Epoch:  3572 , Loss:  0.5938200354576111   f1-score: 0.9088841676712036   accuracy: 0.9422522783279419\n",
      "Epoch:  3573 , Loss:  0.5938185453414917   f1-score: 0.9088841676712036   accuracy: 0.9422522783279419\n",
      "Epoch:  3574 , Loss:  0.5938170552253723   f1-score: 0.9088841676712036   accuracy: 0.9422522783279419\n",
      "Epoch:  3575 , Loss:  0.5938156247138977   f1-score: 0.9088841676712036   accuracy: 0.9422522783279419\n",
      "Epoch:  3576 , Loss:  0.5938141345977783   f1-score: 0.9088841676712036   accuracy: 0.9422522783279419\n",
      "Epoch:  3577 , Loss:  0.5938127040863037   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3578 , Loss:  0.5938113331794739   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3579 , Loss:  0.5938099026679993   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3580 , Loss:  0.5938085317611694   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3581 , Loss:  0.5938071608543396   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3582 , Loss:  0.5938057899475098   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3583 , Loss:  0.5938044786453247   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3584 , Loss:  0.5938030481338501   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3585 , Loss:  0.593801736831665   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3586 , Loss:  0.59380042552948   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3587 , Loss:  0.5937991738319397   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3588 , Loss:  0.5937978029251099   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3589 , Loss:  0.5937965512275696   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3590 , Loss:  0.5937952995300293   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3591 , Loss:  0.5937939882278442   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3592 , Loss:  0.5937926769256592   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3593 , Loss:  0.5937914252281189   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3594 , Loss:  0.5937901139259338   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3595 , Loss:  0.5937889218330383   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3596 , Loss:  0.593787670135498   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3597 , Loss:  0.593786358833313   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3598 , Loss:  0.5937851667404175   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3599 , Loss:  0.5937839150428772   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3600 , Loss:  0.5937827229499817   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3601 , Loss:  0.5937814116477966   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3602 , Loss:  0.5937802195549011   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3603 , Loss:  0.5937789082527161   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3604 , Loss:  0.5937776565551758   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3605 , Loss:  0.593776524066925   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3606 , Loss:  0.59377521276474   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3607 , Loss:  0.5937739610671997   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3608 , Loss:  0.5937727093696594   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3609 , Loss:  0.5937714576721191   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3610 , Loss:  0.5937701463699341   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3611 , Loss:  0.593768835067749   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3612 , Loss:  0.593767523765564   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3613 , Loss:  0.5937662124633789   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3614 , Loss:  0.5937649011611938   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3615 , Loss:  0.5937635898590088   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3616 , Loss:  0.5937621593475342   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3617 , Loss:  0.5937607288360596   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3618 , Loss:  0.5937593579292297   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3619 , Loss:  0.5937578678131104   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3620 , Loss:  0.593756377696991   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3621 , Loss:  0.5937548279762268   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3622 , Loss:  0.5937532782554626   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3623 , Loss:  0.5937516689300537   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3624 , Loss:  0.59375   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3625 , Loss:  0.5937482714653015   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3626 , Loss:  0.5937464237213135   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3627 , Loss:  0.5937445759773254   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3628 , Loss:  0.5937426090240479   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3629 , Loss:  0.5937405824661255   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3630 , Loss:  0.5937384366989136   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3631 , Loss:  0.5937362909317017   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3632 , Loss:  0.5937340259552002   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3633 , Loss:  0.593731701374054   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3634 , Loss:  0.5937293171882629   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3635 , Loss:  0.5937269926071167   f1-score: 0.9090391993522644   accuracy: 0.9423423409461975\n",
      "Epoch:  3636 , Loss:  0.5937246084213257   f1-score: 0.9091942310333252   accuracy: 0.9424324035644531\n",
      "Epoch:  3637 , Loss:  0.5937221646308899   f1-score: 0.9091942310333252   accuracy: 0.9424324035644531\n",
      "Epoch:  3638 , Loss:  0.5937197208404541   f1-score: 0.9091942310333252   accuracy: 0.9424324035644531\n",
      "Epoch:  3639 , Loss:  0.5937174558639526   f1-score: 0.9091942310333252   accuracy: 0.9424324035644531\n",
      "Epoch:  3640 , Loss:  0.5937151312828064   f1-score: 0.9091942310333252   accuracy: 0.9424324035644531\n",
      "Epoch:  3641 , Loss:  0.5937129259109497   f1-score: 0.9091942310333252   accuracy: 0.9424324035644531\n",
      "Epoch:  3642 , Loss:  0.5937107801437378   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3643 , Loss:  0.5937086939811707   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3644 , Loss:  0.5937066674232483   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3645 , Loss:  0.5937047004699707   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3646 , Loss:  0.5937027931213379   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3647 , Loss:  0.5937009453773499   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3648 , Loss:  0.5936990976333618   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3649 , Loss:  0.5936972498893738   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3650 , Loss:  0.5936954617500305   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3651 , Loss:  0.593693733215332   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3652 , Loss:  0.5936919450759888   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3653 , Loss:  0.5936902165412903   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3654 , Loss:  0.5936884880065918   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3655 , Loss:  0.5936867594718933   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3656 , Loss:  0.5936850905418396   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3657 , Loss:  0.5936834812164307   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3658 , Loss:  0.593681812286377   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3659 , Loss:  0.5936800837516785   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3660 , Loss:  0.5936785936355591   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3661 , Loss:  0.5936769247055054   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3662 , Loss:  0.5936752557754517   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3663 , Loss:  0.593673586845398   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3664 , Loss:  0.593671977519989   f1-score: 0.909349262714386   accuracy: 0.9425225257873535\n",
      "Epoch:  3665 , Loss:  0.5936703085899353   f1-score: 0.9095041751861572   accuracy: 0.9426125884056091\n",
      "Epoch:  3666 , Loss:  0.5936686396598816   f1-score: 0.9095041751861572   accuracy: 0.9426125884056091\n",
      "Epoch:  3667 , Loss:  0.5936669707298279   f1-score: 0.9095041751861572   accuracy: 0.9426125884056091\n",
      "Epoch:  3668 , Loss:  0.5936653017997742   f1-score: 0.9095041751861572   accuracy: 0.9426125884056091\n",
      "Epoch:  3669 , Loss:  0.5936635136604309   f1-score: 0.9095041751861572   accuracy: 0.9426125884056091\n",
      "Epoch:  3670 , Loss:  0.5936617851257324   f1-score: 0.9095041751861572   accuracy: 0.9426125884056091\n",
      "Epoch:  3671 , Loss:  0.5936599969863892   f1-score: 0.9095041751861572   accuracy: 0.9426125884056091\n",
      "Epoch:  3672 , Loss:  0.5936581492424011   f1-score: 0.9095041751861572   accuracy: 0.9426125884056091\n",
      "Epoch:  3673 , Loss:  0.5936562418937683   f1-score: 0.9095041751861572   accuracy: 0.9426125884056091\n",
      "Epoch:  3674 , Loss:  0.5936543345451355   f1-score: 0.9095041751861572   accuracy: 0.9426125884056091\n",
      "Epoch:  3675 , Loss:  0.5936523675918579   f1-score: 0.9095041751861572   accuracy: 0.9426125884056091\n",
      "Epoch:  3676 , Loss:  0.593650221824646   f1-score: 0.9095041751861572   accuracy: 0.9426125884056091\n",
      "Epoch:  3677 , Loss:  0.5936481356620789   f1-score: 0.9095041751861572   accuracy: 0.9426125884056091\n",
      "Epoch:  3678 , Loss:  0.5936460494995117   f1-score: 0.9095041751861572   accuracy: 0.9426125884056091\n",
      "Epoch:  3679 , Loss:  0.5936437249183655   f1-score: 0.9095041751861572   accuracy: 0.9426125884056091\n",
      "Epoch:  3680 , Loss:  0.5936413407325745   f1-score: 0.9095041751861572   accuracy: 0.9426125884056091\n",
      "Epoch:  3681 , Loss:  0.593639075756073   f1-score: 0.9095041751861572   accuracy: 0.9426125884056091\n",
      "Epoch:  3682 , Loss:  0.5936366319656372   f1-score: 0.9095041751861572   accuracy: 0.9426125884056091\n",
      "Epoch:  3683 , Loss:  0.5936342477798462   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3684 , Loss:  0.5936319231987   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3685 , Loss:  0.5936295986175537   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3686 , Loss:  0.5936272740364075   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3687 , Loss:  0.593625009059906   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3688 , Loss:  0.5936228036880493   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3689 , Loss:  0.5936205983161926   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3690 , Loss:  0.5936185121536255   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3691 , Loss:  0.5936163067817688   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3692 , Loss:  0.5936142802238464   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3693 , Loss:  0.5936121344566345   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3694 , Loss:  0.5936099886894226   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3695 , Loss:  0.5936078429222107   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3696 , Loss:  0.5936055779457092   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3697 , Loss:  0.5936033725738525   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3698 , Loss:  0.5936010479927063   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3699 , Loss:  0.5935986042022705   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3700 , Loss:  0.5935961604118347   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3701 , Loss:  0.5935935974121094   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3702 , Loss:  0.5935908555984497   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3703 , Loss:  0.5935879349708557   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3704 , Loss:  0.5935849547386169   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3705 , Loss:  0.5935817956924438   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3706 , Loss:  0.5935785174369812   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3707 , Loss:  0.5935749411582947   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3708 , Loss:  0.5935712456703186   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3709 , Loss:  0.593567430973053   f1-score: 0.9096590876579285   accuracy: 0.9427027106285095\n",
      "Epoch:  3710 , Loss:  0.5935635566711426   f1-score: 0.9098139405250549   accuracy: 0.9427927732467651\n",
      "Epoch:  3711 , Loss:  0.593559741973877   f1-score: 0.9099687337875366   accuracy: 0.9428828954696655\n",
      "Epoch:  3712 , Loss:  0.5935560464859009   f1-score: 0.9099687337875366   accuracy: 0.9428828954696655\n",
      "Epoch:  3713 , Loss:  0.5935525298118591   f1-score: 0.9099687337875366   accuracy: 0.9428828954696655\n",
      "Epoch:  3714 , Loss:  0.5935492515563965   f1-score: 0.9099687337875366   accuracy: 0.9428828954696655\n",
      "Epoch:  3715 , Loss:  0.5935462713241577   f1-score: 0.9099687337875366   accuracy: 0.9428828954696655\n",
      "Epoch:  3716 , Loss:  0.5935434103012085   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3717 , Loss:  0.5935407280921936   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3718 , Loss:  0.5935382843017578   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3719 , Loss:  0.5935359001159668   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3720 , Loss:  0.5935335755348206   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3721 , Loss:  0.5935313701629639   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3722 , Loss:  0.5935291647911072   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3723 , Loss:  0.5935270190238953   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3724 , Loss:  0.5935249328613281   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3725 , Loss:  0.593522846698761   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3726 , Loss:  0.5935208201408386   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3727 , Loss:  0.5935187935829163   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3728 , Loss:  0.5935168862342834   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3729 , Loss:  0.5935149788856506   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3730 , Loss:  0.5935130715370178   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3731 , Loss:  0.5935112237930298   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3732 , Loss:  0.5935094952583313   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3733 , Loss:  0.5935076475143433   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3734 , Loss:  0.5935059785842896   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3735 , Loss:  0.5935043096542358   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3736 , Loss:  0.5935026407241821   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3737 , Loss:  0.5935009717941284   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3738 , Loss:  0.5934994220733643   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3739 , Loss:  0.5934978723526001   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3740 , Loss:  0.5934963822364807   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3741 , Loss:  0.5934948921203613   f1-score: 0.9101235270500183   accuracy: 0.9429729580879211\n",
      "Epoch:  3742 , Loss:  0.5934934020042419   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3743 , Loss:  0.5934919118881226   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3744 , Loss:  0.5934905409812927   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3745 , Loss:  0.5934891104698181   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3746 , Loss:  0.5934876799583435   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3747 , Loss:  0.5934863686561584   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3748 , Loss:  0.5934849381446838   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3749 , Loss:  0.5934836268424988   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3750 , Loss:  0.5934823155403137   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3751 , Loss:  0.5934810042381287   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3752 , Loss:  0.5934796929359436   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3753 , Loss:  0.5934784412384033   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3754 , Loss:  0.593477189540863   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3755 , Loss:  0.5934759378433228   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3756 , Loss:  0.5934747457504272   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3757 , Loss:  0.593473494052887   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3758 , Loss:  0.5934723615646362   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3759 , Loss:  0.5934711694717407   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3760 , Loss:  0.5934699773788452   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3761 , Loss:  0.5934688448905945   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3762 , Loss:  0.5934677124023438   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3763 , Loss:  0.5934665203094482   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3764 , Loss:  0.5934654474258423   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3765 , Loss:  0.5934643745422363   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3766 , Loss:  0.5934632420539856   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3767 , Loss:  0.5934621691703796   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3768 , Loss:  0.5934610962867737   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3769 , Loss:  0.5934600234031677   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3770 , Loss:  0.5934590101242065   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3771 , Loss:  0.5934579372406006   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3772 , Loss:  0.5934569239616394   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3773 , Loss:  0.5934559106826782   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3774 , Loss:  0.5934548377990723   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3775 , Loss:  0.5934537649154663   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3776 , Loss:  0.5934528112411499   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3777 , Loss:  0.5934518575668335   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3778 , Loss:  0.5934508442878723   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3779 , Loss:  0.5934498906135559   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3780 , Loss:  0.5934489369392395   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3781 , Loss:  0.5934479236602783   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3782 , Loss:  0.5934469699859619   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3783 , Loss:  0.5934460759162903   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3784 , Loss:  0.5934450626373291   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3785 , Loss:  0.5934442281723022   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3786 , Loss:  0.5934432148933411   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3787 , Loss:  0.5934423208236694   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3788 , Loss:  0.5934414267539978   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3789 , Loss:  0.5934405326843262   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3790 , Loss:  0.5934395790100098   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3791 , Loss:  0.5934386849403381   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3792 , Loss:  0.5934377908706665   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3793 , Loss:  0.5934368968009949   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3794 , Loss:  0.5934360027313232   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3795 , Loss:  0.5934351682662964   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3796 , Loss:  0.5934342741966248   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3797 , Loss:  0.5934333801269531   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3798 , Loss:  0.5934324860572815   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3799 , Loss:  0.5934317111968994   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3800 , Loss:  0.5934308171272278   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3801 , Loss:  0.5934299826622009   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3802 , Loss:  0.5934291481971741   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3803 , Loss:  0.5934282541275024   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3804 , Loss:  0.5934274792671204   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3805 , Loss:  0.5934265851974487   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3806 , Loss:  0.5934258103370667   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3807 , Loss:  0.5934249758720398   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3808 , Loss:  0.5934241414070129   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3809 , Loss:  0.5934233665466309   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3810 , Loss:  0.593422532081604   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3811 , Loss:  0.5934216976165771   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3812 , Loss:  0.5934209823608398   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3813 , Loss:  0.5934200882911682   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3814 , Loss:  0.5934193730354309   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3815 , Loss:  0.593418538570404   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3816 , Loss:  0.5934177041053772   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3817 , Loss:  0.5934169888496399   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3818 , Loss:  0.5934162139892578   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3819 , Loss:  0.5934154391288757   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3820 , Loss:  0.5934146642684937   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3821 , Loss:  0.5934139490127563   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3822 , Loss:  0.5934131145477295   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3823 , Loss:  0.5934123992919922   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3824 , Loss:  0.5934116244316101   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3825 , Loss:  0.593410849571228   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3826 , Loss:  0.593410074710846   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3827 , Loss:  0.5934093594551086   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3828 , Loss:  0.5934085845947266   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3829 , Loss:  0.5934078693389893   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3830 , Loss:  0.5934070944786072   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3831 , Loss:  0.5934063792228699   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3832 , Loss:  0.5934056639671326   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3833 , Loss:  0.5934048891067505   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3834 , Loss:  0.5934041738510132   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3835 , Loss:  0.5934034585952759   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3836 , Loss:  0.5934026837348938   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3837 , Loss:  0.5934019684791565   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3838 , Loss:  0.5934012532234192   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3839 , Loss:  0.5934004783630371   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3840 , Loss:  0.5933998227119446   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3841 , Loss:  0.5933990478515625   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3842 , Loss:  0.59339839220047   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3843 , Loss:  0.5933976769447327   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3844 , Loss:  0.5933969616889954   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3845 , Loss:  0.5933962464332581   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3846 , Loss:  0.5933955311775208   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3847 , Loss:  0.5933948159217834   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3848 , Loss:  0.5933941602706909   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3849 , Loss:  0.5933934450149536   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3850 , Loss:  0.5933927297592163   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3851 , Loss:  0.593392014503479   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3852 , Loss:  0.5933913588523865   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3853 , Loss:  0.593390703201294   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3854 , Loss:  0.5933899879455566   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3855 , Loss:  0.5933892726898193   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3856 , Loss:  0.5933886170387268   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3857 , Loss:  0.5933879613876343   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3858 , Loss:  0.5933873057365417   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3859 , Loss:  0.5933865904808044   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3860 , Loss:  0.5933859348297119   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3861 , Loss:  0.5933852791786194   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3862 , Loss:  0.5933845639228821   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3863 , Loss:  0.5933838486671448   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3864 , Loss:  0.593383252620697   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3865 , Loss:  0.5933825373649597   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3866 , Loss:  0.5933818221092224   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3867 , Loss:  0.5933811664581299   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3868 , Loss:  0.5933805108070374   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3869 , Loss:  0.5933797955513   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3870 , Loss:  0.5933791399002075   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3871 , Loss:  0.593378484249115   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3872 , Loss:  0.5933778285980225   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3873 , Loss:  0.5933772325515747   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3874 , Loss:  0.5933765172958374   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3875 , Loss:  0.5933758616447449   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3876 , Loss:  0.5933752059936523   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3877 , Loss:  0.5933745503425598   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3878 , Loss:  0.5933738946914673   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3879 , Loss:  0.59337317943573   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3880 , Loss:  0.5933725833892822   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3881 , Loss:  0.5933719277381897   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3882 , Loss:  0.5933712720870972   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3883 , Loss:  0.5933706760406494   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3884 , Loss:  0.5933700203895569   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3885 , Loss:  0.5933693051338196   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3886 , Loss:  0.5933687090873718   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3887 , Loss:  0.5933680534362793   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3888 , Loss:  0.5933673977851868   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3889 , Loss:  0.593366801738739   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3890 , Loss:  0.5933661460876465   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3891 , Loss:  0.5933654308319092   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3892 , Loss:  0.5933648347854614   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3893 , Loss:  0.5933641791343689   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3894 , Loss:  0.5933635234832764   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3895 , Loss:  0.5933628678321838   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3896 , Loss:  0.5933622121810913   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3897 , Loss:  0.5933615565299988   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3898 , Loss:  0.5933609008789062   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3899 , Loss:  0.5933602452278137   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3900 , Loss:  0.5933595895767212   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3901 , Loss:  0.5933589339256287   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3902 , Loss:  0.5933582782745361   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3903 , Loss:  0.5933576226234436   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3904 , Loss:  0.5933570265769958   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3905 , Loss:  0.5933563709259033   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3906 , Loss:  0.5933557152748108   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3907 , Loss:  0.5933550000190735   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3908 , Loss:  0.5933544039726257   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3909 , Loss:  0.5933536887168884   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3910 , Loss:  0.5933530330657959   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3911 , Loss:  0.5933523774147034   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3912 , Loss:  0.5933516621589661   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3913 , Loss:  0.5933510065078735   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3914 , Loss:  0.593350350856781   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3915 , Loss:  0.5933496952056885   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3916 , Loss:  0.5933489799499512   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3917 , Loss:  0.5933483242988586   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3918 , Loss:  0.5933476090431213   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3919 , Loss:  0.5933469533920288   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3920 , Loss:  0.5933461785316467   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3921 , Loss:  0.5933454632759094   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3922 , Loss:  0.5933448076248169   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3923 , Loss:  0.5933440923690796   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3924 , Loss:  0.5933433771133423   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3925 , Loss:  0.5933426022529602   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3926 , Loss:  0.5933418869972229   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3927 , Loss:  0.5933411717414856   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3928 , Loss:  0.5933403968811035   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3929 , Loss:  0.5933396220207214   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3930 , Loss:  0.5933387875556946   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3931 , Loss:  0.5933380126953125   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3932 , Loss:  0.5933371782302856   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3933 , Loss:  0.5933363437652588   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3934 , Loss:  0.5933354496955872   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3935 , Loss:  0.5933346152305603   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3936 , Loss:  0.5933337211608887   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3937 , Loss:  0.593332827091217   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3938 , Loss:  0.5933318138122559   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3939 , Loss:  0.5933308005332947   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3940 , Loss:  0.5933297276496887   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3941 , Loss:  0.5933287143707275   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3942 , Loss:  0.593327522277832   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3943 , Loss:  0.5933263301849365   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3944 , Loss:  0.593325138092041   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3945 , Loss:  0.593323826789856   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3946 , Loss:  0.5933224558830261   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3947 , Loss:  0.5933211445808411   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3948 , Loss:  0.5933195948600769   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3949 , Loss:  0.5933182239532471   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3950 , Loss:  0.5933167338371277   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3951 , Loss:  0.5933152437210083   f1-score: 0.9102782607078552   accuracy: 0.9430630803108215\n",
      "Epoch:  3952 , Loss:  0.5933137536048889   f1-score: 0.9104329347610474   accuracy: 0.9431531429290771\n",
      "Epoch:  3953 , Loss:  0.5933123230934143   f1-score: 0.9104329347610474   accuracy: 0.9431531429290771\n",
      "Epoch:  3954 , Loss:  0.5933108925819397   f1-score: 0.9104329347610474   accuracy: 0.9431531429290771\n",
      "Epoch:  3955 , Loss:  0.5933095216751099   f1-score: 0.9104329347610474   accuracy: 0.9431531429290771\n",
      "Epoch:  3956 , Loss:  0.59330815076828   f1-score: 0.9104329347610474   accuracy: 0.9431531429290771\n",
      "Epoch:  3957 , Loss:  0.5933067798614502   f1-score: 0.9104329347610474   accuracy: 0.9431531429290771\n",
      "Epoch:  3958 , Loss:  0.5933055281639099   f1-score: 0.9104329347610474   accuracy: 0.9431531429290771\n",
      "Epoch:  3959 , Loss:  0.5933042764663696   f1-score: 0.9104329347610474   accuracy: 0.9431531429290771\n",
      "Epoch:  3960 , Loss:  0.5933030247688293   f1-score: 0.9104329347610474   accuracy: 0.9431531429290771\n",
      "Epoch:  3961 , Loss:  0.5933018326759338   f1-score: 0.9104329347610474   accuracy: 0.9431531429290771\n",
      "Epoch:  3962 , Loss:  0.5933007001876831   f1-score: 0.9104329347610474   accuracy: 0.9431531429290771\n",
      "Epoch:  3963 , Loss:  0.5932995080947876   f1-score: 0.9104329347610474   accuracy: 0.9431531429290771\n",
      "Epoch:  3964 , Loss:  0.5932984352111816   f1-score: 0.9104329347610474   accuracy: 0.9431531429290771\n",
      "Epoch:  3965 , Loss:  0.5932973027229309   f1-score: 0.9104329347610474   accuracy: 0.9431531429290771\n",
      "Epoch:  3966 , Loss:  0.593296229839325   f1-score: 0.9104329347610474   accuracy: 0.9431531429290771\n",
      "Epoch:  3967 , Loss:  0.593295156955719   f1-score: 0.9104329347610474   accuracy: 0.9431531429290771\n",
      "Epoch:  3968 , Loss:  0.593294084072113   f1-score: 0.9104329347610474   accuracy: 0.9431531429290771\n",
      "Epoch:  3969 , Loss:  0.5932930707931519   f1-score: 0.9104329347610474   accuracy: 0.9431531429290771\n",
      "Epoch:  3970 , Loss:  0.5932919979095459   f1-score: 0.9104329347610474   accuracy: 0.9431531429290771\n",
      "Epoch:  3971 , Loss:  0.5932909846305847   f1-score: 0.9104329347610474   accuracy: 0.9431531429290771\n",
      "Epoch:  3972 , Loss:  0.5932899117469788   f1-score: 0.9104329347610474   accuracy: 0.9431531429290771\n",
      "Epoch:  3973 , Loss:  0.5932888984680176   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3974 , Loss:  0.5932878851890564   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3975 , Loss:  0.5932868719100952   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3976 , Loss:  0.5932857990264893   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3977 , Loss:  0.5932847261428833   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3978 , Loss:  0.5932837128639221   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3979 , Loss:  0.5932826995849609   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3980 , Loss:  0.5932815074920654   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3981 , Loss:  0.5932804346084595   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3982 , Loss:  0.5932793021202087   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3983 , Loss:  0.593278169631958   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3984 , Loss:  0.5932769775390625   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3985 , Loss:  0.5932756662368774   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3986 , Loss:  0.5932744145393372   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3987 , Loss:  0.5932729244232178   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3988 , Loss:  0.5932714939117432   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3989 , Loss:  0.5932698845863342   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3990 , Loss:  0.593268096446991   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3991 , Loss:  0.5932662487030029   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3992 , Loss:  0.5932640433311462   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3993 , Loss:  0.5932616591453552   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3994 , Loss:  0.5932588577270508   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3995 , Loss:  0.5932557582855225   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3996 , Loss:  0.5932523012161255   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3997 , Loss:  0.5932484269142151   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3998 , Loss:  0.5932439565658569   f1-score: 0.9105875492095947   accuracy: 0.9432432651519775\n",
      "Epoch:  3999 , Loss:  0.5932391285896301   f1-score: 0.9107168316841125   accuracy: 0.9433333277702332\n",
      "Epoch:  4000 , Loss:  0.5932337045669556   f1-score: 0.9107168316841125   accuracy: 0.9433333277702332\n",
      "Epoch:  4001 , Loss:  0.5932278037071228   f1-score: 0.9107168316841125   accuracy: 0.9433333277702332\n",
      "Epoch:  4002 , Loss:  0.5932209491729736   f1-score: 0.9107168316841125   accuracy: 0.9433333277702332\n",
      "Epoch:  4003 , Loss:  0.5932129621505737   f1-score: 0.9107168316841125   accuracy: 0.9433333277702332\n",
      "Epoch:  4004 , Loss:  0.5932043194770813   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4005 , Loss:  0.593196451663971   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4006 , Loss:  0.5931904911994934   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4007 , Loss:  0.5931864380836487   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4008 , Loss:  0.5931832790374756   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4009 , Loss:  0.5931805968284607   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4010 , Loss:  0.5931781530380249   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4011 , Loss:  0.5931760668754578   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4012 , Loss:  0.5931740999221802   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4013 , Loss:  0.5931724309921265   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4014 , Loss:  0.5931708216667175   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4015 , Loss:  0.5931693315505981   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4016 , Loss:  0.5931676030158997   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4017 , Loss:  0.5931658148765564   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4018 , Loss:  0.5931640267372131   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4019 , Loss:  0.5931622982025146   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4020 , Loss:  0.5931606292724609   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4021 , Loss:  0.5931588411331177   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4022 , Loss:  0.5931570529937744   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4023 , Loss:  0.5931552052497864   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4024 , Loss:  0.5931532979011536   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4025 , Loss:  0.593151330947876   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4026 , Loss:  0.5931493043899536   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4027 , Loss:  0.5931470990180969   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4028 , Loss:  0.5931447148323059   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4029 , Loss:  0.5931422710418701   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4030 , Loss:  0.5931395888328552   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4031 , Loss:  0.5931367874145508   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4032 , Loss:  0.5931340456008911   f1-score: 0.9108461141586304   accuracy: 0.9434234499931335\n",
      "Epoch:  4033 , Loss:  0.5931312441825867   f1-score: 0.9110007286071777   accuracy: 0.9435135126113892\n",
      "Epoch:  4034 , Loss:  0.5931283831596375   f1-score: 0.9110007286071777   accuracy: 0.9435135126113892\n",
      "Epoch:  4035 , Loss:  0.5931256413459778   f1-score: 0.9110007286071777   accuracy: 0.9435135126113892\n",
      "Epoch:  4036 , Loss:  0.5931230187416077   f1-score: 0.9110007286071777   accuracy: 0.9435135126113892\n",
      "Epoch:  4037 , Loss:  0.5931203961372375   f1-score: 0.9110007286071777   accuracy: 0.9435135126113892\n",
      "Epoch:  4038 , Loss:  0.5931178331375122   f1-score: 0.9110007286071777   accuracy: 0.9435135126113892\n",
      "Epoch:  4039 , Loss:  0.5931152701377869   f1-score: 0.9110007286071777   accuracy: 0.9435135126113892\n",
      "Epoch:  4040 , Loss:  0.593112587928772   f1-score: 0.9110007286071777   accuracy: 0.9435135126113892\n",
      "Epoch:  4041 , Loss:  0.5931099653244019   f1-score: 0.9110007286071777   accuracy: 0.9435135126113892\n",
      "Epoch:  4042 , Loss:  0.593107283115387   f1-score: 0.9110007286071777   accuracy: 0.9435135126113892\n",
      "Epoch:  4043 , Loss:  0.5931045413017273   f1-score: 0.9110007286071777   accuracy: 0.9435135126113892\n",
      "Epoch:  4044 , Loss:  0.5931016802787781   f1-score: 0.9110007286071777   accuracy: 0.9435135126113892\n",
      "Epoch:  4045 , Loss:  0.5930989980697632   f1-score: 0.9111552834510803   accuracy: 0.9436035752296448\n",
      "Epoch:  4046 , Loss:  0.5930962562561035   f1-score: 0.9111552834510803   accuracy: 0.9436035752296448\n",
      "Epoch:  4047 , Loss:  0.5930936336517334   f1-score: 0.9111552834510803   accuracy: 0.9436035752296448\n",
      "Epoch:  4048 , Loss:  0.5930912494659424   f1-score: 0.9111552834510803   accuracy: 0.9436035752296448\n",
      "Epoch:  4049 , Loss:  0.5930889248847961   f1-score: 0.9111552834510803   accuracy: 0.9436035752296448\n",
      "Epoch:  4050 , Loss:  0.5930867195129395   f1-score: 0.9111552834510803   accuracy: 0.9436035752296448\n",
      "Epoch:  4051 , Loss:  0.5930845737457275   f1-score: 0.9111552834510803   accuracy: 0.9436035752296448\n",
      "Epoch:  4052 , Loss:  0.5930824875831604   f1-score: 0.9111552834510803   accuracy: 0.9436035752296448\n",
      "Epoch:  4053 , Loss:  0.5930804014205933   f1-score: 0.9111552834510803   accuracy: 0.9436035752296448\n",
      "Epoch:  4054 , Loss:  0.5930783748626709   f1-score: 0.9111552834510803   accuracy: 0.9436035752296448\n",
      "Epoch:  4055 , Loss:  0.5930764079093933   f1-score: 0.9111552834510803   accuracy: 0.9436035752296448\n",
      "Epoch:  4056 , Loss:  0.5930744409561157   f1-score: 0.9111552834510803   accuracy: 0.9436035752296448\n",
      "Epoch:  4057 , Loss:  0.5930723547935486   f1-score: 0.9111552834510803   accuracy: 0.9436035752296448\n",
      "Epoch:  4058 , Loss:  0.5930702686309814   f1-score: 0.9111552834510803   accuracy: 0.9436035752296448\n",
      "Epoch:  4059 , Loss:  0.5930682420730591   f1-score: 0.9111552834510803   accuracy: 0.9436035752296448\n",
      "Epoch:  4060 , Loss:  0.5930662155151367   f1-score: 0.9111552834510803   accuracy: 0.9436035752296448\n",
      "Epoch:  4061 , Loss:  0.5930642485618591   f1-score: 0.9111552834510803   accuracy: 0.9436035752296448\n",
      "Epoch:  4062 , Loss:  0.5930622220039368   f1-score: 0.9111552834510803   accuracy: 0.9436035752296448\n",
      "Epoch:  4063 , Loss:  0.5930601954460144   f1-score: 0.9111552834510803   accuracy: 0.9436035752296448\n",
      "Epoch:  4064 , Loss:  0.593058168888092   f1-score: 0.9113097786903381   accuracy: 0.9436936974525452\n",
      "Epoch:  4065 , Loss:  0.5930562019348145   f1-score: 0.9113097786903381   accuracy: 0.9436936974525452\n",
      "Epoch:  4066 , Loss:  0.5930542945861816   f1-score: 0.9113097786903381   accuracy: 0.9436936974525452\n",
      "Epoch:  4067 , Loss:  0.5930524468421936   f1-score: 0.9113097786903381   accuracy: 0.9436936974525452\n",
      "Epoch:  4068 , Loss:  0.5930505990982056   f1-score: 0.9113097786903381   accuracy: 0.9436936974525452\n",
      "Epoch:  4069 , Loss:  0.5930488705635071   f1-score: 0.9113097786903381   accuracy: 0.9436936974525452\n",
      "Epoch:  4070 , Loss:  0.5930472016334534   f1-score: 0.9113097786903381   accuracy: 0.9436936974525452\n",
      "Epoch:  4071 , Loss:  0.5930455327033997   f1-score: 0.9113097786903381   accuracy: 0.9436936974525452\n",
      "Epoch:  4072 , Loss:  0.5930439233779907   f1-score: 0.9113097786903381   accuracy: 0.9436936974525452\n",
      "Epoch:  4073 , Loss:  0.5930423736572266   f1-score: 0.9113097786903381   accuracy: 0.9436936974525452\n",
      "Epoch:  4074 , Loss:  0.5930408835411072   f1-score: 0.9113097786903381   accuracy: 0.9436936974525452\n",
      "Epoch:  4075 , Loss:  0.5930393934249878   f1-score: 0.9113097786903381   accuracy: 0.9436936974525452\n",
      "Epoch:  4076 , Loss:  0.5930379033088684   f1-score: 0.9113097786903381   accuracy: 0.9436936974525452\n",
      "Epoch:  4077 , Loss:  0.5930365324020386   f1-score: 0.9113097786903381   accuracy: 0.9436936974525452\n",
      "Epoch:  4078 , Loss:  0.5930350422859192   f1-score: 0.9113097786903381   accuracy: 0.9436936974525452\n",
      "Epoch:  4079 , Loss:  0.5930336713790894   f1-score: 0.9113097786903381   accuracy: 0.9436936974525452\n",
      "Epoch:  4080 , Loss:  0.5930323004722595   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n",
      "Epoch:  4081 , Loss:  0.5930309295654297   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n",
      "Epoch:  4082 , Loss:  0.5930294990539551   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n",
      "Epoch:  4083 , Loss:  0.5930281281471252   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n",
      "Epoch:  4084 , Loss:  0.5930267572402954   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n",
      "Epoch:  4085 , Loss:  0.5930253863334656   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n",
      "Epoch:  4086 , Loss:  0.5930240154266357   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n",
      "Epoch:  4087 , Loss:  0.5930225849151611   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n",
      "Epoch:  4088 , Loss:  0.5930211544036865   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4089 , Loss:  0.5930197238922119   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n",
      "Epoch:  4090 , Loss:  0.5930182337760925   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n",
      "Epoch:  4091 , Loss:  0.5930166840553284   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n",
      "Epoch:  4092 , Loss:  0.5930151343345642   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n",
      "Epoch:  4093 , Loss:  0.5930134654045105   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n",
      "Epoch:  4094 , Loss:  0.5930116772651672   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n",
      "Epoch:  4095 , Loss:  0.5930099487304688   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n",
      "Epoch:  4096 , Loss:  0.5930081009864807   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n",
      "Epoch:  4097 , Loss:  0.5930061340332031   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n",
      "Epoch:  4098 , Loss:  0.5930041074752808   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n",
      "Epoch:  4099 , Loss:  0.5930020213127136   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n",
      "Epoch:  4100 , Loss:  0.5929998755455017   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n",
      "Epoch:  4101 , Loss:  0.5929977297782898   f1-score: 0.911464273929596   accuracy: 0.9437837600708008\n",
      "Epoch:  4102 , Loss:  0.5929955840110779   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4103 , Loss:  0.5929935574531555   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4104 , Loss:  0.5929915308952332   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4105 , Loss:  0.5929896831512451   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4106 , Loss:  0.5929878354072571   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4107 , Loss:  0.5929861664772034   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4108 , Loss:  0.5929844975471497   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4109 , Loss:  0.592982828617096   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4110 , Loss:  0.5929813385009766   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4111 , Loss:  0.5929798483848572   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4112 , Loss:  0.5929784178733826   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4113 , Loss:  0.5929770469665527   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4114 , Loss:  0.5929756760597229   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4115 , Loss:  0.5929743647575378   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4116 , Loss:  0.5929730534553528   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4117 , Loss:  0.5929717421531677   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4118 , Loss:  0.5929704904556274   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4119 , Loss:  0.5929691791534424   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4120 , Loss:  0.5929679274559021   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4121 , Loss:  0.5929667353630066   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4122 , Loss:  0.5929654836654663   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4123 , Loss:  0.5929642915725708   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4124 , Loss:  0.5929630398750305   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4125 , Loss:  0.5929619073867798   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4126 , Loss:  0.5929606556892395   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4127 , Loss:  0.592959463596344   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4128 , Loss:  0.5929582118988037   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4129 , Loss:  0.5929570198059082   f1-score: 0.9116186499595642   accuracy: 0.9438738822937012\n",
      "Epoch:  4130 , Loss:  0.5929558277130127   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4131 , Loss:  0.5929545760154724   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4132 , Loss:  0.5929532647132874   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4133 , Loss:  0.5929520726203918   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4134 , Loss:  0.5929508209228516   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4135 , Loss:  0.5929495692253113   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4136 , Loss:  0.5929482579231262   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4137 , Loss:  0.5929470062255859   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4138 , Loss:  0.5929456949234009   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4139 , Loss:  0.592944324016571   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4140 , Loss:  0.592943012714386   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4141 , Loss:  0.5929416418075562   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4142 , Loss:  0.5929401516914368   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4143 , Loss:  0.5929387807846069   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4144 , Loss:  0.5929372906684875   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4145 , Loss:  0.5929356217384338   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4146 , Loss:  0.5929340720176697   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4147 , Loss:  0.592932403087616   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4148 , Loss:  0.5929307341575623   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4149 , Loss:  0.592928946018219   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4150 , Loss:  0.5929271578788757   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4151 , Loss:  0.5929251909255981   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4152 , Loss:  0.5929232835769653   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4153 , Loss:  0.5929213166236877   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4154 , Loss:  0.5929193496704102   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4155 , Loss:  0.5929173231124878   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4156 , Loss:  0.5929152965545654   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4157 , Loss:  0.5929132103919983   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4158 , Loss:  0.5929112434387207   f1-score: 0.9117730259895325   accuracy: 0.9439639449119568\n",
      "Epoch:  4159 , Loss:  0.5929091572761536   f1-score: 0.9119274020195007   accuracy: 0.9440540671348572\n",
      "Epoch:  4160 , Loss:  0.592907190322876   f1-score: 0.9120816588401794   accuracy: 0.9441441297531128\n",
      "Epoch:  4161 , Loss:  0.5929052233695984   f1-score: 0.9120816588401794   accuracy: 0.9441441297531128\n",
      "Epoch:  4162 , Loss:  0.592903196811676   f1-score: 0.9120816588401794   accuracy: 0.9441441297531128\n",
      "Epoch:  4163 , Loss:  0.5929012894630432   f1-score: 0.9120816588401794   accuracy: 0.9441441297531128\n",
      "Epoch:  4164 , Loss:  0.5928993225097656   f1-score: 0.9120816588401794   accuracy: 0.9441441297531128\n",
      "Epoch:  4165 , Loss:  0.5928974747657776   f1-score: 0.9120816588401794   accuracy: 0.9441441297531128\n",
      "Epoch:  4166 , Loss:  0.5928956270217896   f1-score: 0.9120816588401794   accuracy: 0.9441441297531128\n",
      "Epoch:  4167 , Loss:  0.5928937196731567   f1-score: 0.9120816588401794   accuracy: 0.9441441297531128\n",
      "Epoch:  4168 , Loss:  0.5928919315338135   f1-score: 0.9120816588401794   accuracy: 0.9441441297531128\n",
      "Epoch:  4169 , Loss:  0.5928900837898254   f1-score: 0.9120816588401794   accuracy: 0.9441441297531128\n",
      "Epoch:  4170 , Loss:  0.5928882360458374   f1-score: 0.9120816588401794   accuracy: 0.9441441297531128\n",
      "Epoch:  4171 , Loss:  0.5928863286972046   f1-score: 0.9120816588401794   accuracy: 0.9441441297531128\n",
      "Epoch:  4172 , Loss:  0.5928843021392822   f1-score: 0.9120816588401794   accuracy: 0.9441441297531128\n",
      "Epoch:  4173 , Loss:  0.5928822159767151   f1-score: 0.9120816588401794   accuracy: 0.9441441297531128\n",
      "Epoch:  4174 , Loss:  0.5928798317909241   f1-score: 0.9120816588401794   accuracy: 0.9441441297531128\n",
      "Epoch:  4175 , Loss:  0.5928770899772644   f1-score: 0.9120816588401794   accuracy: 0.9441441297531128\n",
      "Epoch:  4176 , Loss:  0.5928738117218018   f1-score: 0.9120816588401794   accuracy: 0.9441441297531128\n",
      "Epoch:  4177 , Loss:  0.5928699374198914   f1-score: 0.9120816588401794   accuracy: 0.9441441297531128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4178 , Loss:  0.5928657054901123   f1-score: 0.9120816588401794   accuracy: 0.9441441297531128\n",
      "Epoch:  4179 , Loss:  0.5928613543510437   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4180 , Loss:  0.5928577184677124   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4181 , Loss:  0.5928548574447632   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4182 , Loss:  0.5928526520729065   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4183 , Loss:  0.5928506255149841   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4184 , Loss:  0.5928486585617065   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4185 , Loss:  0.5928468704223633   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4186 , Loss:  0.5928451418876648   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4187 , Loss:  0.5928434729576111   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4188 , Loss:  0.5928419828414917   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4189 , Loss:  0.5928404927253723   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4190 , Loss:  0.5928390622138977   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4191 , Loss:  0.5928376913070679   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4192 , Loss:  0.5928363800048828   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4193 , Loss:  0.5928349494934082   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4194 , Loss:  0.5928336381912231   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4195 , Loss:  0.5928322076797485   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4196 , Loss:  0.5928308963775635   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4197 , Loss:  0.5928295850753784   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4198 , Loss:  0.5928281545639038   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4199 , Loss:  0.5928269624710083   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4200 , Loss:  0.5928256511688232   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4201 , Loss:  0.5928242802619934   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4202 , Loss:  0.5928229093551636   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4203 , Loss:  0.5928215980529785   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4204 , Loss:  0.5928201675415039   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4205 , Loss:  0.5928186774253845   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4206 , Loss:  0.5928171873092651   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4207 , Loss:  0.5928155183792114   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4208 , Loss:  0.5928137302398682   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4209 , Loss:  0.592811644077301   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4210 , Loss:  0.5928093791007996   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4211 , Loss:  0.5928066372871399   f1-score: 0.9122359156608582   accuracy: 0.9442342519760132\n",
      "Epoch:  4212 , Loss:  0.5928034782409668   f1-score: 0.9123901128768921   accuracy: 0.9443243145942688\n",
      "Epoch:  4213 , Loss:  0.5928000807762146   f1-score: 0.9123901128768921   accuracy: 0.9443243145942688\n",
      "Epoch:  4214 , Loss:  0.5927965641021729   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4215 , Loss:  0.5927931666374207   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4216 , Loss:  0.5927901864051819   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4217 , Loss:  0.5927878022193909   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4218 , Loss:  0.5927859544754028   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4219 , Loss:  0.5927843451499939   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4220 , Loss:  0.5927829146385193   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4221 , Loss:  0.592781662940979   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4222 , Loss:  0.592780351638794   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4223 , Loss:  0.5927790999412537   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4224 , Loss:  0.5927779078483582   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4225 , Loss:  0.5927767157554626   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4226 , Loss:  0.5927754640579224   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4227 , Loss:  0.5927743315696716   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4228 , Loss:  0.5927730798721313   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4229 , Loss:  0.5927718877792358   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4230 , Loss:  0.5927706956863403   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4231 , Loss:  0.5927695631980896   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4232 , Loss:  0.5927683711051941   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4233 , Loss:  0.5927671790122986   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4234 , Loss:  0.5927659869194031   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4235 , Loss:  0.5927648544311523   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4236 , Loss:  0.5927636623382568   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4237 , Loss:  0.5927625298500061   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4238 , Loss:  0.5927612781524658   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4239 , Loss:  0.5927600860595703   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4240 , Loss:  0.59275883436203   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4241 , Loss:  0.5927575826644897   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4242 , Loss:  0.5927562713623047   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4243 , Loss:  0.5927549600601196   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4244 , Loss:  0.5927535891532898   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4245 , Loss:  0.5927520990371704   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4246 , Loss:  0.5927505493164062   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4247 , Loss:  0.5927489995956421   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4248 , Loss:  0.5927473306655884   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4249 , Loss:  0.5927456617355347   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4250 , Loss:  0.5927438735961914   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4251 , Loss:  0.5927421450614929   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4252 , Loss:  0.5927403569221497   f1-score: 0.912544310092926   accuracy: 0.9444144368171692\n",
      "Epoch:  4253 , Loss:  0.5927386283874512   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4254 , Loss:  0.5927369594573975   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4255 , Loss:  0.5927352905273438   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4256 , Loss:  0.5927336812019348   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4257 , Loss:  0.5927321910858154   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4258 , Loss:  0.5927307605743408   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4259 , Loss:  0.592729389667511   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4260 , Loss:  0.5927281379699707   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4261 , Loss:  0.5927268862724304   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4262 , Loss:  0.5927256345748901   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4263 , Loss:  0.5927244424819946   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4264 , Loss:  0.5927233099937439   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4265 , Loss:  0.5927222371101379   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4266 , Loss:  0.592721164226532   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4267 , Loss:  0.5927200317382812   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4268 , Loss:  0.5927190184593201   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4269 , Loss:  0.5927180051803589   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4270 , Loss:  0.5927169919013977   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4271 , Loss:  0.5927159786224365   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4272 , Loss:  0.5927149653434753   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4273 , Loss:  0.5927139520645142   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4274 , Loss:  0.5927129983901978   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4275 , Loss:  0.5927119851112366   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4276 , Loss:  0.5927109718322754   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4277 , Loss:  0.592710018157959   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4278 , Loss:  0.592708945274353   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4279 , Loss:  0.5927079916000366   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4280 , Loss:  0.5927069187164307   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4281 , Loss:  0.5927059054374695   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4282 , Loss:  0.5927047729492188   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4283 , Loss:  0.5927035808563232   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4284 , Loss:  0.5927024483680725   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4285 , Loss:  0.5927011966705322   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4286 , Loss:  0.5926998853683472   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4287 , Loss:  0.5926985740661621   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4288 , Loss:  0.5926970839500427   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4289 , Loss:  0.5926955342292786   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4290 , Loss:  0.5926939249038696   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4291 , Loss:  0.5926920771598816   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4292 , Loss:  0.5926902294158936   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4293 , Loss:  0.5926882028579712   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4294 , Loss:  0.592686116695404   f1-score: 0.9126983880996704   accuracy: 0.9445044994354248\n",
      "Epoch:  4295 , Loss:  0.5926839113235474   f1-score: 0.9128524661064148   accuracy: 0.9445946216583252\n",
      "Epoch:  4296 , Loss:  0.5926815867424011   f1-score: 0.9128524661064148   accuracy: 0.9445946216583252\n",
      "Epoch:  4297 , Loss:  0.5926791429519653   f1-score: 0.9128524661064148   accuracy: 0.9445946216583252\n",
      "Epoch:  4298 , Loss:  0.5926763415336609   f1-score: 0.9128524661064148   accuracy: 0.9445946216583252\n",
      "Epoch:  4299 , Loss:  0.5926732420921326   f1-score: 0.9128524661064148   accuracy: 0.9445946216583252\n",
      "Epoch:  4300 , Loss:  0.5926694869995117   f1-score: 0.9128524661064148   accuracy: 0.9445946216583252\n",
      "Epoch:  4301 , Loss:  0.5926649570465088   f1-score: 0.9128524661064148   accuracy: 0.9445946216583252\n",
      "Epoch:  4302 , Loss:  0.5926599502563477   f1-score: 0.9130065441131592   accuracy: 0.9446846842765808\n",
      "Epoch:  4303 , Loss:  0.5926552414894104   f1-score: 0.9130065441131592   accuracy: 0.9446846842765808\n",
      "Epoch:  4304 , Loss:  0.5926513075828552   f1-score: 0.9130065441131592   accuracy: 0.9446846842765808\n",
      "Epoch:  4305 , Loss:  0.5926480889320374   f1-score: 0.9130065441131592   accuracy: 0.9446846842765808\n",
      "Epoch:  4306 , Loss:  0.5926449298858643   f1-score: 0.9130065441131592   accuracy: 0.9446846842765808\n",
      "Epoch:  4307 , Loss:  0.5926414728164673   f1-score: 0.9130065441131592   accuracy: 0.9446846842765808\n",
      "Epoch:  4308 , Loss:  0.5926377773284912   f1-score: 0.9130065441131592   accuracy: 0.9446846842765808\n",
      "Epoch:  4309 , Loss:  0.5926339626312256   f1-score: 0.9130065441131592   accuracy: 0.9446846842765808\n",
      "Epoch:  4310 , Loss:  0.5926305055618286   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4311 , Loss:  0.5926274657249451   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4312 , Loss:  0.5926250219345093   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4313 , Loss:  0.5926227569580078   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4314 , Loss:  0.5926205515861511   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4315 , Loss:  0.5926183462142944   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4316 , Loss:  0.5926163792610168   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4317 , Loss:  0.5926147103309631   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4318 , Loss:  0.5926132202148438   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4319 , Loss:  0.5926119089126587   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4320 , Loss:  0.5926105380058289   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4321 , Loss:  0.5926092863082886   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4322 , Loss:  0.5926080346107483   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4323 , Loss:  0.5926069617271423   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4324 , Loss:  0.5926058292388916   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4325 , Loss:  0.5926046371459961   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4326 , Loss:  0.5926035642623901   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4327 , Loss:  0.5926024913787842   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4328 , Loss:  0.5926015377044678   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4329 , Loss:  0.5926006436347961   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4330 , Loss:  0.5925996899604797   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4331 , Loss:  0.5925987958908081   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4332 , Loss:  0.5925978422164917   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4333 , Loss:  0.5925969481468201   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4334 , Loss:  0.5925959944725037   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4335 , Loss:  0.592595100402832   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4336 , Loss:  0.5925942659378052   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4337 , Loss:  0.5925934314727783   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4338 , Loss:  0.592592716217041   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4339 , Loss:  0.5925918817520142   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4340 , Loss:  0.5925912261009216   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4341 , Loss:  0.5925904512405396   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4342 , Loss:  0.5925896763801575   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4343 , Loss:  0.5925889611244202   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4344 , Loss:  0.5925882458686829   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4345 , Loss:  0.5925875306129456   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4346 , Loss:  0.592586874961853   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4347 , Loss:  0.5925861597061157   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4348 , Loss:  0.592585563659668   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4349 , Loss:  0.5925849080085754   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4350 , Loss:  0.5925842523574829   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4351 , Loss:  0.5925835967063904   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4352 , Loss:  0.5925830006599426   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4353 , Loss:  0.5925823450088501   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4354 , Loss:  0.5925816893577576   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4355 , Loss:  0.5925810933113098   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4356 , Loss:  0.5925804972648621   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4357 , Loss:  0.5925799012184143   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4358 , Loss:  0.5925793051719666   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4359 , Loss:  0.5925787091255188   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4360 , Loss:  0.592578113079071   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4361 , Loss:  0.5925775766372681   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4362 , Loss:  0.5925769805908203   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4363 , Loss:  0.5925764441490173   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4364 , Loss:  0.5925758481025696   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4365 , Loss:  0.5925753116607666   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4366 , Loss:  0.5925747156143188   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4367 , Loss:  0.5925741791725159   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4368 , Loss:  0.5925735831260681   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4369 , Loss:  0.5925731062889099   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4370 , Loss:  0.5925725698471069   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4371 , Loss:  0.592572033405304   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4372 , Loss:  0.5925714373588562   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4373 , Loss:  0.5925709009170532   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4374 , Loss:  0.592570424079895   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4375 , Loss:  0.592569887638092   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4376 , Loss:  0.5925694108009338   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4377 , Loss:  0.5925688743591309   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4378 , Loss:  0.5925683975219727   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4379 , Loss:  0.5925678014755249   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4380 , Loss:  0.5925673246383667   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4381 , Loss:  0.5925668478012085   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4382 , Loss:  0.5925663113594055   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4383 , Loss:  0.5925658345222473   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4384 , Loss:  0.5925653576850891   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4385 , Loss:  0.5925648808479309   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4386 , Loss:  0.5925644040107727   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4387 , Loss:  0.5925638675689697   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4388 , Loss:  0.5925634503364563   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4389 , Loss:  0.5925629138946533   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4390 , Loss:  0.5925624370574951   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4391 , Loss:  0.5925619602203369   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4392 , Loss:  0.5925614833831787   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4393 , Loss:  0.5925610065460205   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4394 , Loss:  0.5925605297088623   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4395 , Loss:  0.5925601124763489   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4396 , Loss:  0.5925595760345459   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4397 , Loss:  0.5925591588020325   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4398 , Loss:  0.5925586819648743   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4399 , Loss:  0.5925581455230713   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4400 , Loss:  0.5925577878952026   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4401 , Loss:  0.5925573110580444   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4402 , Loss:  0.5925568342208862   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4403 , Loss:  0.5925564169883728   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4404 , Loss:  0.5925559997558594   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4405 , Loss:  0.5925555229187012   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4406 , Loss:  0.5925551056861877   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4407 , Loss:  0.5925546288490295   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4408 , Loss:  0.5925542116165161   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4409 , Loss:  0.5925537943840027   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4410 , Loss:  0.5925533175468445   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4411 , Loss:  0.5925528407096863   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4412 , Loss:  0.5925524234771729   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4413 , Loss:  0.5925520062446594   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4414 , Loss:  0.592551589012146   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4415 , Loss:  0.5925511121749878   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4416 , Loss:  0.5925507545471191   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4417 , Loss:  0.5925503373146057   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4418 , Loss:  0.5925498604774475   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4419 , Loss:  0.5925495028495789   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4420 , Loss:  0.5925490856170654   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4421 , Loss:  0.5925486087799072   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4422 , Loss:  0.5925481915473938   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4423 , Loss:  0.5925477743148804   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4424 , Loss:  0.5925473570823669   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4425 , Loss:  0.5925469398498535   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4426 , Loss:  0.5925465822219849   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4427 , Loss:  0.5925462245941162   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4428 , Loss:  0.5925456881523132   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4429 , Loss:  0.5925453305244446   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4430 , Loss:  0.5925449132919312   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4431 , Loss:  0.5925444960594177   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4432 , Loss:  0.5925440788269043   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4433 , Loss:  0.5925437211990356   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4434 , Loss:  0.5925433039665222   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4435 , Loss:  0.5925428867340088   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4436 , Loss:  0.5925425291061401   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4437 , Loss:  0.5925421118736267   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4438 , Loss:  0.5925416946411133   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4439 , Loss:  0.5925413370132446   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4440 , Loss:  0.5925409197807312   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4441 , Loss:  0.5925405025482178   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4442 , Loss:  0.5925401449203491   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4443 , Loss:  0.5925396680831909   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4444 , Loss:  0.592539370059967   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4445 , Loss:  0.5925390124320984   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4446 , Loss:  0.5925385355949402   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4447 , Loss:  0.5925381779670715   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4448 , Loss:  0.5925378203392029   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4449 , Loss:  0.5925374627113342   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4450 , Loss:  0.5925370454788208   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4451 , Loss:  0.5925366282463074   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4452 , Loss:  0.5925363302230835   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4453 , Loss:  0.5925359129905701   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4454 , Loss:  0.5925354957580566   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4455 , Loss:  0.592535138130188   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4456 , Loss:  0.5925347805023193   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4457 , Loss:  0.5925344228744507   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4458 , Loss:  0.592534065246582   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4459 , Loss:  0.5925336480140686   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4460 , Loss:  0.5925332903862   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4461 , Loss:  0.5925329327583313   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4462 , Loss:  0.5925324559211731   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4463 , Loss:  0.5925320982933044   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4464 , Loss:  0.5925318002700806   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4465 , Loss:  0.5925314426422119   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4466 , Loss:  0.5925310254096985   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4467 , Loss:  0.5925306081771851   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4468 , Loss:  0.5925302505493164   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4469 , Loss:  0.5925299525260925   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4470 , Loss:  0.5925295948982239   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4471 , Loss:  0.5925292372703552   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4472 , Loss:  0.5925288796424866   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4473 , Loss:  0.5925284624099731   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4474 , Loss:  0.5925281047821045   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4475 , Loss:  0.5925277471542358   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4476 , Loss:  0.5925273895263672   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4477 , Loss:  0.5925270318984985   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4478 , Loss:  0.5925266742706299   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4479 , Loss:  0.5925263166427612   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4480 , Loss:  0.5925259590148926   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4481 , Loss:  0.5925256013870239   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4482 , Loss:  0.5925252437591553   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4483 , Loss:  0.5925248861312866   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4484 , Loss:  0.592524528503418   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4485 , Loss:  0.5925241708755493   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4486 , Loss:  0.5925238132476807   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4487 , Loss:  0.5925233960151672   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4488 , Loss:  0.5925230383872986   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4489 , Loss:  0.5925227403640747   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4490 , Loss:  0.592522382736206   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4491 , Loss:  0.5925220251083374   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4492 , Loss:  0.5925216674804688   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4493 , Loss:  0.5925213098526001   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4494 , Loss:  0.5925209522247314   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4495 , Loss:  0.5925205945968628   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4496 , Loss:  0.5925202369689941   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4497 , Loss:  0.5925198793411255   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4498 , Loss:  0.5925194621086121   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4499 , Loss:  0.5925191640853882   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4500 , Loss:  0.5925187468528748   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4501 , Loss:  0.5925183892250061   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4502 , Loss:  0.5925180315971375   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4503 , Loss:  0.5925176739692688   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4504 , Loss:  0.5925173163414001   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4505 , Loss:  0.5925168991088867   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4506 , Loss:  0.5925166010856628   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4507 , Loss:  0.5925161838531494   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4508 , Loss:  0.5925158262252808   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4509 , Loss:  0.5925155282020569   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4510 , Loss:  0.5925150513648987   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4511 , Loss:  0.59251469373703   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4512 , Loss:  0.5925142765045166   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4513 , Loss:  0.5925138592720032   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4514 , Loss:  0.5925135016441345   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4515 , Loss:  0.5925130248069763   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4516 , Loss:  0.5925126671791077   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4517 , Loss:  0.5925121903419495   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4518 , Loss:  0.592511773109436   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4519 , Loss:  0.5925112962722778   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4520 , Loss:  0.5925108790397644   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4521 , Loss:  0.5925104022026062   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4522 , Loss:  0.592509925365448   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4523 , Loss:  0.5925093293190002   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4524 , Loss:  0.592508852481842   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4525 , Loss:  0.5925082564353943   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4526 , Loss:  0.5925076603889465   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4527 , Loss:  0.5925070643424988   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4528 , Loss:  0.5925063490867615   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4529 , Loss:  0.5925056338310242   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4530 , Loss:  0.5925048589706421   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4531 , Loss:  0.5925039649009705   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4532 , Loss:  0.592503011226654   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4533 , Loss:  0.5925019979476929   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4534 , Loss:  0.5925008654594421   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4535 , Loss:  0.5924996733665466   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4536 , Loss:  0.5924983620643616   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4537 , Loss:  0.5924970507621765   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4538 , Loss:  0.5924956202507019   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4539 , Loss:  0.5924941897392273   f1-score: 0.913160502910614   accuracy: 0.9447747468948364\n",
      "Epoch:  4540 , Loss:  0.5924928188323975   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4541 , Loss:  0.5924915075302124   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4542 , Loss:  0.5924902558326721   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4543 , Loss:  0.5924891829490662   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4544 , Loss:  0.592488169670105   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4545 , Loss:  0.5924872756004333   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4546 , Loss:  0.5924863815307617   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4547 , Loss:  0.5924856066703796   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4548 , Loss:  0.5924847722053528   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4549 , Loss:  0.5924839973449707   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4550 , Loss:  0.5924832820892334   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4551 , Loss:  0.5924825668334961   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4552 , Loss:  0.5924819111824036   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4553 , Loss:  0.5924811959266663   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4554 , Loss:  0.5924805998802185   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4555 , Loss:  0.5924800634384155   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4556 , Loss:  0.592479407787323   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4557 , Loss:  0.59247887134552   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4558 , Loss:  0.5924783945083618   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4559 , Loss:  0.5924778580665588   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4560 , Loss:  0.5924773216247559   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4561 , Loss:  0.5924767851829529   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4562 , Loss:  0.5924763679504395   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4563 , Loss:  0.5924758315086365   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4564 , Loss:  0.5924753546714783   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4565 , Loss:  0.5924748778343201   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4566 , Loss:  0.5924744606018066   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4567 , Loss:  0.5924740433692932   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4568 , Loss:  0.5924736261367798   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4569 , Loss:  0.5924732089042664   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4570 , Loss:  0.5924727916717529   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4571 , Loss:  0.5924723744392395   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4572 , Loss:  0.5924720168113708   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4573 , Loss:  0.5924715399742126   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4574 , Loss:  0.592471182346344   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4575 , Loss:  0.5924707651138306   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4576 , Loss:  0.5924704074859619   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4577 , Loss:  0.5924699902534485   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4578 , Loss:  0.5924696326255798   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4579 , Loss:  0.5924692153930664   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4580 , Loss:  0.5924688577651978   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4581 , Loss:  0.5924685001373291   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4582 , Loss:  0.5924681425094604   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4583 , Loss:  0.5924677848815918   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4584 , Loss:  0.5924674868583679   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4585 , Loss:  0.5924671292304993   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4586 , Loss:  0.5924667119979858   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4587 , Loss:  0.592466413974762   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4588 , Loss:  0.5924659967422485   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4589 , Loss:  0.5924656391143799   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4590 , Loss:  0.592465341091156   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4591 , Loss:  0.5924649834632874   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4592 , Loss:  0.5924646258354187   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4593 , Loss:  0.5924643278121948   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4594 , Loss:  0.592464029788971   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4595 , Loss:  0.5924636721611023   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4596 , Loss:  0.5924633145332336   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4597 , Loss:  0.5924630165100098   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4598 , Loss:  0.5924627184867859   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4599 , Loss:  0.5924623608589172   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4600 , Loss:  0.5924620628356934   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4601 , Loss:  0.5924617648124695   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4602 , Loss:  0.5924614071846008   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4603 , Loss:  0.592461109161377   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4604 , Loss:  0.5924607515335083   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4605 , Loss:  0.5924604535102844   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4606 , Loss:  0.5924601554870605   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4607 , Loss:  0.5924598574638367   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4608 , Loss:  0.5924595594406128   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4609 , Loss:  0.5924592614173889   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4610 , Loss:  0.5924589037895203   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4611 , Loss:  0.5924586057662964   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4612 , Loss:  0.5924583077430725   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4613 , Loss:  0.5924580097198486   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4614 , Loss:  0.5924577116966248   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4615 , Loss:  0.5924574136734009   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4616 , Loss:  0.5924570560455322   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4617 , Loss:  0.5924568176269531   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4618 , Loss:  0.5924564599990845   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4619 , Loss:  0.5924562215805054   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4620 , Loss:  0.5924558639526367   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4621 , Loss:  0.5924555659294128   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4622 , Loss:  0.5924553275108337   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4623 , Loss:  0.5924550294876099   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4624 , Loss:  0.592454731464386   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4625 , Loss:  0.5924543738365173   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4626 , Loss:  0.5924541354179382   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4627 , Loss:  0.5924538373947144   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4628 , Loss:  0.5924534797668457   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4629 , Loss:  0.5924531817436218   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4630 , Loss:  0.5924529433250427   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4631 , Loss:  0.5924526453018188   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4632 , Loss:  0.592452347278595   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4633 , Loss:  0.5924520492553711   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4634 , Loss:  0.5924517512321472   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4635 , Loss:  0.5924514532089233   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4636 , Loss:  0.5924512147903442   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4637 , Loss:  0.5924509167671204   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4638 , Loss:  0.5924505591392517   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4639 , Loss:  0.5924503207206726   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4640 , Loss:  0.5924500226974487   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4641 , Loss:  0.5924497246742249   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4642 , Loss:  0.5924494862556458   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4643 , Loss:  0.5924491882324219   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4644 , Loss:  0.5924488306045532   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4645 , Loss:  0.5924485325813293   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4646 , Loss:  0.5924482941627502   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4647 , Loss:  0.5924479961395264   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4648 , Loss:  0.5924476981163025   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4649 , Loss:  0.5924474000930786   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4650 , Loss:  0.5924471616744995   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4651 , Loss:  0.5924468040466309   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4652 , Loss:  0.592446506023407   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4653 , Loss:  0.5924462080001831   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4654 , Loss:  0.5924459099769592   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4655 , Loss:  0.5924456119537354   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4656 , Loss:  0.5924453139305115   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4657 , Loss:  0.5924450159072876   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4658 , Loss:  0.5924447774887085   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4659 , Loss:  0.5924444794654846   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4660 , Loss:  0.592444121837616   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4661 , Loss:  0.5924438834190369   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4662 , Loss:  0.5924435257911682   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4663 , Loss:  0.5924432873725891   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4664 , Loss:  0.5924429893493652   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4665 , Loss:  0.5924426317214966   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4666 , Loss:  0.5924422740936279   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4667 , Loss:  0.5924420356750488   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4668 , Loss:  0.5924416780471802   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4669 , Loss:  0.5924413800239563   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4670 , Loss:  0.5924410820007324   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4671 , Loss:  0.5924407243728638   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4672 , Loss:  0.5924403667449951   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4673 , Loss:  0.5924400687217712   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4674 , Loss:  0.5924397110939026   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4675 , Loss:  0.5924394130706787   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4676 , Loss:  0.5924390554428101   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4677 , Loss:  0.5924386382102966   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4678 , Loss:  0.592438280582428   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4679 , Loss:  0.5924379229545593   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4680 , Loss:  0.5924375653266907   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4681 , Loss:  0.5924371480941772   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4682 , Loss:  0.5924367308616638   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4683 , Loss:  0.5924364328384399   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4684 , Loss:  0.5924359560012817   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4685 , Loss:  0.5924355387687683   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4686 , Loss:  0.5924350619316101   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4687 , Loss:  0.5924346446990967   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4688 , Loss:  0.5924341678619385   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4689 , Loss:  0.5924336910247803   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4690 , Loss:  0.5924331545829773   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4691 , Loss:  0.5924326777458191   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4692 , Loss:  0.5924322009086609   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4693 , Loss:  0.5924315452575684   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4694 , Loss:  0.5924310684204102   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4695 , Loss:  0.5924304127693176   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4696 , Loss:  0.5924298167228699   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4697 , Loss:  0.5924292206764221   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4698 , Loss:  0.5924285054206848   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4699 , Loss:  0.5924278497695923   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4700 , Loss:  0.5924271941184998   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4701 , Loss:  0.5924264788627625   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4702 , Loss:  0.5924257636070251   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4703 , Loss:  0.5924250483512878   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4704 , Loss:  0.5924243330955505   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4705 , Loss:  0.592423677444458   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4706 , Loss:  0.5924229621887207   f1-score: 0.9133144617080688   accuracy: 0.9448648691177368\n",
      "Epoch:  4707 , Loss:  0.5924223065376282   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4708 , Loss:  0.5924216508865356   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4709 , Loss:  0.5924209952354431   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4710 , Loss:  0.5924202799797058   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4711 , Loss:  0.5924196243286133   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4712 , Loss:  0.5924190878868103   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4713 , Loss:  0.5924184322357178   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4714 , Loss:  0.5924178957939148   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4715 , Loss:  0.592417299747467   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4716 , Loss:  0.5924167633056641   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4717 , Loss:  0.5924161672592163   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4718 , Loss:  0.5924155712127686   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4719 , Loss:  0.5924150943756104   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4720 , Loss:  0.5924144983291626   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4721 , Loss:  0.5924139618873596   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4722 , Loss:  0.5924134254455566   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4723 , Loss:  0.5924128890037537   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4724 , Loss:  0.5924123525619507   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4725 , Loss:  0.5924117565155029   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4726 , Loss:  0.5924112200737   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4727 , Loss:  0.592410683631897   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4728 , Loss:  0.5924100875854492   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4729 , Loss:  0.5924094915390015   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4730 , Loss:  0.5924088954925537   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4731 , Loss:  0.5924081802368164   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4732 , Loss:  0.5924075245857239   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4733 , Loss:  0.5924067497253418   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4734 , Loss:  0.5924059748649597   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4735 , Loss:  0.5924050211906433   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4736 , Loss:  0.5924040079116821   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4737 , Loss:  0.5924026966094971   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4738 , Loss:  0.5924013257026672   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4739 , Loss:  0.592399537563324   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4740 , Loss:  0.5923975706100464   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4741 , Loss:  0.5923951864242554   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4742 , Loss:  0.5923925638198853   f1-score: 0.9134683609008789   accuracy: 0.9449549317359924\n",
      "Epoch:  4743 , Loss:  0.5923900604248047   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4744 , Loss:  0.5923876762390137   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4745 , Loss:  0.5923857688903809   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4746 , Loss:  0.5923842787742615   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4747 , Loss:  0.592383086681366   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4748 , Loss:  0.5923821330070496   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4749 , Loss:  0.5923811793327332   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4750 , Loss:  0.592380166053772   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4751 , Loss:  0.5923793315887451   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4752 , Loss:  0.5923783779144287   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4753 , Loss:  0.5923774838447571   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4754 , Loss:  0.5923766493797302   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4755 , Loss:  0.5923759341239929   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4756 , Loss:  0.5923752784729004   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4757 , Loss:  0.5923745632171631   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4758 , Loss:  0.5923739671707153   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4759 , Loss:  0.5923734307289124   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4760 , Loss:  0.5923727750778198   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4761 , Loss:  0.5923722386360168   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4762 , Loss:  0.5923716425895691   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4763 , Loss:  0.5923711061477661   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4764 , Loss:  0.5923705101013184   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4765 , Loss:  0.5923699736595154   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4766 , Loss:  0.5923693776130676   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4767 , Loss:  0.5923688411712646   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4768 , Loss:  0.5923682451248169   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4769 , Loss:  0.5923675298690796   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4770 , Loss:  0.5923668742179871   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4771 , Loss:  0.5923662185668945   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4772 , Loss:  0.5923654437065125   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4773 , Loss:  0.5923646092414856   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4774 , Loss:  0.5923636555671692   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4775 , Loss:  0.5923625826835632   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4776 , Loss:  0.592361330986023   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4777 , Loss:  0.5923599600791931   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4778 , Loss:  0.5923581719398499   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4779 , Loss:  0.5923562049865723   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4780 , Loss:  0.5923539996147156   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4781 , Loss:  0.592351496219635   f1-score: 0.9136222004890442   accuracy: 0.9450450539588928\n",
      "Epoch:  4782 , Loss:  0.592349112033844   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4783 , Loss:  0.5923469066619873   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4784 , Loss:  0.5923450589179993   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4785 , Loss:  0.5923436284065247   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4786 , Loss:  0.5923423767089844   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4787 , Loss:  0.5923413038253784   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4788 , Loss:  0.592340350151062   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4789 , Loss:  0.5923394560813904   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4790 , Loss:  0.5923386216163635   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4791 , Loss:  0.5923378467559814   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4792 , Loss:  0.5923371911048889   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4793 , Loss:  0.5923364758491516   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4794 , Loss:  0.5923357009887695   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4795 , Loss:  0.5923349857330322   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4796 , Loss:  0.5923342108726501   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4797 , Loss:  0.5923333764076233   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4798 , Loss:  0.5923326015472412   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4799 , Loss:  0.5923318266868591   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4800 , Loss:  0.5923309326171875   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4801 , Loss:  0.5923300981521606   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4802 , Loss:  0.5923291444778442   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4803 , Loss:  0.5923281311988831   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4804 , Loss:  0.5923270583152771   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4805 , Loss:  0.5923259258270264   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4806 , Loss:  0.5923246741294861   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4807 , Loss:  0.5923232436180115   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4808 , Loss:  0.5923217535018921   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4809 , Loss:  0.5923202037811279   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4810 , Loss:  0.5923186540603638   f1-score: 0.9137760400772095   accuracy: 0.9451351165771484\n",
      "Epoch:  4811 , Loss:  0.5923171043395996   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4812 , Loss:  0.5923157930374146   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4813 , Loss:  0.5923144817352295   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4814 , Loss:  0.592313289642334   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4815 , Loss:  0.5923121571540833   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4816 , Loss:  0.5923111438751221   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4817 , Loss:  0.5923101305961609   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4818 , Loss:  0.5923091173171997   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4819 , Loss:  0.5923082232475281   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4820 , Loss:  0.5923073887825012   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4821 , Loss:  0.5923065543174744   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4822 , Loss:  0.5923057794570923   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4823 , Loss:  0.5923050045967102   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4824 , Loss:  0.5923042893409729   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4825 , Loss:  0.5923035740852356   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4826 , Loss:  0.5923028588294983   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4827 , Loss:  0.5923022627830505   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4828 , Loss:  0.592301607131958   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4829 , Loss:  0.592301070690155   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4830 , Loss:  0.5923004746437073   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4831 , Loss:  0.5922999382019043   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4832 , Loss:  0.5922994017601013   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4833 , Loss:  0.5922989249229431   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4834 , Loss:  0.5922983884811401   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4835 , Loss:  0.5922979116439819   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4836 , Loss:  0.592297375202179   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4837 , Loss:  0.5922969579696655   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4838 , Loss:  0.5922965407371521   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4839 , Loss:  0.5922960638999939   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4840 , Loss:  0.5922956466674805   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4841 , Loss:  0.592295229434967   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4842 , Loss:  0.5922948122024536   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4843 , Loss:  0.5922943949699402   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4844 , Loss:  0.5922939777374268   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4845 , Loss:  0.5922936201095581   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4846 , Loss:  0.5922932028770447   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4847 , Loss:  0.5922929048538208   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4848 , Loss:  0.5922924876213074   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4849 , Loss:  0.5922921299934387   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4850 , Loss:  0.5922917723655701   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4851 , Loss:  0.5922914147377014   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4852 , Loss:  0.5922910571098328   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4853 , Loss:  0.5922907590866089   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4854 , Loss:  0.5922904014587402   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4855 , Loss:  0.5922900438308716   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4856 , Loss:  0.5922897458076477   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4857 , Loss:  0.5922894477844238   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4858 , Loss:  0.5922891497612   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4859 , Loss:  0.5922887921333313   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4860 , Loss:  0.5922884941101074   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4861 , Loss:  0.5922881364822388   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4862 , Loss:  0.5922878980636597   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4863 , Loss:  0.592287540435791   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4864 , Loss:  0.5922873020172119   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4865 , Loss:  0.5922869443893433   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4866 , Loss:  0.5922866463661194   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4867 , Loss:  0.5922863483428955   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4868 , Loss:  0.5922860503196716   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4869 , Loss:  0.5922858119010925   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4870 , Loss:  0.5922855138778687   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4871 , Loss:  0.59228515625   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4872 , Loss:  0.5922849178314209   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4873 , Loss:  0.592284619808197   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4874 , Loss:  0.5922843813896179   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4875 , Loss:  0.592284083366394   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4876 , Loss:  0.5922837853431702   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4877 , Loss:  0.5922835469245911   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4878 , Loss:  0.5922832489013672   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4879 , Loss:  0.5922829508781433   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4880 , Loss:  0.5922827124595642   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4881 , Loss:  0.5922824144363403   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4882 , Loss:  0.5922821164131165   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4883 , Loss:  0.5922819375991821   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4884 , Loss:  0.5922816395759583   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4885 , Loss:  0.5922814011573792   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4886 , Loss:  0.5922811031341553   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4887 , Loss:  0.5922808051109314   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4888 , Loss:  0.5922805666923523   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4889 , Loss:  0.5922803282737732   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4890 , Loss:  0.5922800898551941   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4891 , Loss:  0.5922797918319702   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4892 , Loss:  0.5922795534133911   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4893 , Loss:  0.5922792553901672   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4894 , Loss:  0.5922789573669434   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4895 , Loss:  0.5922787189483643   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4896 , Loss:  0.5922784209251404   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4897 , Loss:  0.5922781825065613   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4898 , Loss:  0.5922778844833374   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4899 , Loss:  0.5922775864601135   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4900 , Loss:  0.5922774076461792   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4901 , Loss:  0.5922770500183105   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4902 , Loss:  0.5922768115997314   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4903 , Loss:  0.5922765135765076   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4904 , Loss:  0.5922762155532837   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4905 , Loss:  0.5922759175300598   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4906 , Loss:  0.5922756195068359   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4907 , Loss:  0.5922753214836121   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4908 , Loss:  0.5922749638557434   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4909 , Loss:  0.5922746062278748   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4910 , Loss:  0.5922741889953613   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4911 , Loss:  0.5922737717628479   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4912 , Loss:  0.5922732949256897   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4913 , Loss:  0.5922726988792419   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4914 , Loss:  0.5922720432281494   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4915 , Loss:  0.5922712087631226   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4916 , Loss:  0.5922701358795166   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4917 , Loss:  0.592268705368042   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4918 , Loss:  0.5922666788101196   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4919 , Loss:  0.5922638177871704   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4920 , Loss:  0.5922601222991943   f1-score: 0.9139297604560852   accuracy: 0.9452252388000488\n",
      "Epoch:  4921 , Loss:  0.5922560095787048   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4922 , Loss:  0.5922527313232422   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4923 , Loss:  0.592250645160675   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4924 , Loss:  0.5922494530677795   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4925 , Loss:  0.5922486782073975   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4926 , Loss:  0.5922479033470154   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4927 , Loss:  0.5922471284866333   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4928 , Loss:  0.5922463536262512   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4929 , Loss:  0.5922457575798035   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4930 , Loss:  0.5922452807426453   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4931 , Loss:  0.5922448039054871   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4932 , Loss:  0.5922443270683289   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4933 , Loss:  0.5922438502311707   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4934 , Loss:  0.5922433137893677   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4935 , Loss:  0.5922427773475647   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4936 , Loss:  0.5922421216964722   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4937 , Loss:  0.592241644859314   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4938 , Loss:  0.592241108417511   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4939 , Loss:  0.592240571975708   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4940 , Loss:  0.5922401547431946   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4941 , Loss:  0.5922397971153259   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4942 , Loss:  0.5922393798828125   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4943 , Loss:  0.5922389626502991   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4944 , Loss:  0.5922386050224304   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4945 , Loss:  0.592238187789917   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4946 , Loss:  0.5922378301620483   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4947 , Loss:  0.5922374725341797   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4948 , Loss:  0.5922372341156006   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4949 , Loss:  0.5922369360923767   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4950 , Loss:  0.5922365784645081   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4951 , Loss:  0.5922362804412842   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4952 , Loss:  0.5922359824180603   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4953 , Loss:  0.5922357439994812   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4954 , Loss:  0.5922354459762573   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4955 , Loss:  0.5922352075576782   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4956 , Loss:  0.5922349095344543   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4957 , Loss:  0.5922346711158752   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4958 , Loss:  0.5922344326972961   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4959 , Loss:  0.5922341346740723   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4960 , Loss:  0.5922338962554932   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4961 , Loss:  0.5922337174415588   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4962 , Loss:  0.592233419418335   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4963 , Loss:  0.5922331809997559   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4964 , Loss:  0.592232882976532   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4965 , Loss:  0.5922327041625977   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4966 , Loss:  0.5922324657440186   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4967 , Loss:  0.5922322273254395   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4968 , Loss:  0.5922319889068604   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4969 , Loss:  0.5922317504882812   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4970 , Loss:  0.5922315716743469   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4971 , Loss:  0.5922313332557678   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4972 , Loss:  0.5922310948371887   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4973 , Loss:  0.5922309160232544   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4974 , Loss:  0.5922306776046753   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4975 , Loss:  0.5922304391860962   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4976 , Loss:  0.5922302007675171   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4977 , Loss:  0.5922300219535828   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4978 , Loss:  0.5922298431396484   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4979 , Loss:  0.5922295451164246   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4980 , Loss:  0.5922293663024902   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4981 , Loss:  0.5922291874885559   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4982 , Loss:  0.5922289490699768   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4983 , Loss:  0.5922287702560425   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4984 , Loss:  0.5922285318374634   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4985 , Loss:  0.592228353023529   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4986 , Loss:  0.59222811460495   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4987 , Loss:  0.5922278761863708   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4988 , Loss:  0.5922276973724365   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4989 , Loss:  0.5922275185585022   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4990 , Loss:  0.5922273397445679   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4991 , Loss:  0.5922271609306335   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4992 , Loss:  0.5922269225120544   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4993 , Loss:  0.5922266840934753   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4994 , Loss:  0.5922265648841858   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4995 , Loss:  0.5922263264656067   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4996 , Loss:  0.5922262072563171   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4997 , Loss:  0.592225968837738   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4998 , Loss:  0.5922257900238037   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  4999 , Loss:  0.5922256112098694   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5000 , Loss:  0.5922253727912903   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5001 , Loss:  0.592225193977356   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5002 , Loss:  0.5922250151634216   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5003 , Loss:  0.5922248363494873   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5004 , Loss:  0.592224657535553   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5005 , Loss:  0.5922244787216187   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5006 , Loss:  0.5922242403030396   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5007 , Loss:  0.5922240018844604   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5008 , Loss:  0.5922238230705261   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5009 , Loss:  0.5922236442565918   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5010 , Loss:  0.5922235250473022   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5011 , Loss:  0.5922233462333679   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5012 , Loss:  0.5922231674194336   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5013 , Loss:  0.5922229290008545   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5014 , Loss:  0.5922228097915649   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5015 , Loss:  0.5922226309776306   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5016 , Loss:  0.5922223925590515   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5017 , Loss:  0.5922222137451172   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5018 , Loss:  0.5922220945358276   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5019 , Loss:  0.5922217965126038   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5020 , Loss:  0.5922216773033142   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5021 , Loss:  0.5922214984893799   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5022 , Loss:  0.5922213196754456   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5023 , Loss:  0.5922211408615112   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5024 , Loss:  0.5922209620475769   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5025 , Loss:  0.5922207832336426   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5026 , Loss:  0.5922206044197083   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5027 , Loss:  0.5922204256057739   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5028 , Loss:  0.5922203063964844   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5029 , Loss:  0.5922200679779053   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5030 , Loss:  0.592219889163971   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5031 , Loss:  0.5922197103500366   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5032 , Loss:  0.5922195315361023   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5033 , Loss:  0.592219352722168   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5034 , Loss:  0.5922191739082336   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5035 , Loss:  0.5922189950942993   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5036 , Loss:  0.592218816280365   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5037 , Loss:  0.5922186374664307   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5038 , Loss:  0.5922184586524963   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5039 , Loss:  0.5922183394432068   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5040 , Loss:  0.5922181606292725   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5041 , Loss:  0.5922179818153381   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5042 , Loss:  0.5922178030014038   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5043 , Loss:  0.5922176241874695   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5044 , Loss:  0.5922174453735352   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5045 , Loss:  0.5922172665596008   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5046 , Loss:  0.5922171473503113   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5047 , Loss:  0.592216968536377   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5048 , Loss:  0.5922167897224426   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5049 , Loss:  0.5922166109085083   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5050 , Loss:  0.592216432094574   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5051 , Loss:  0.5922163128852844   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5052 , Loss:  0.5922161340713501   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5053 , Loss:  0.5922159552574158   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5054 , Loss:  0.5922157764434814   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5055 , Loss:  0.5922155976295471   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5056 , Loss:  0.5922154188156128   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5057 , Loss:  0.5922152400016785   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5058 , Loss:  0.5922151207923889   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5059 , Loss:  0.5922148823738098   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5060 , Loss:  0.5922147035598755   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5061 , Loss:  0.5922145843505859   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5062 , Loss:  0.5922144055366516   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5063 , Loss:  0.5922142863273621   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5064 , Loss:  0.592214047908783   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5065 , Loss:  0.5922139286994934   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5066 , Loss:  0.5922137498855591   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5067 , Loss:  0.5922135710716248   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5068 , Loss:  0.5922133922576904   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5069 , Loss:  0.5922132134437561   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5070 , Loss:  0.5922130346298218   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5071 , Loss:  0.5922128558158875   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5072 , Loss:  0.5922126770019531   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5073 , Loss:  0.5922124981880188   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5074 , Loss:  0.5922123193740845   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5075 , Loss:  0.5922120809555054   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5076 , Loss:  0.5922119617462158   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5077 , Loss:  0.5922117829322815   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5078 , Loss:  0.5922116041183472   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5079 , Loss:  0.5922114253044128   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5080 , Loss:  0.5922111868858337   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5081 , Loss:  0.5922110080718994   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5082 , Loss:  0.5922108292579651   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5083 , Loss:  0.5922106504440308   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5084 , Loss:  0.5922104120254517   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5085 , Loss:  0.5922102332115173   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5086 , Loss:  0.592210054397583   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5087 , Loss:  0.5922098159790039   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5088 , Loss:  0.5922095775604248   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5089 , Loss:  0.5922093391418457   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5090 , Loss:  0.5922091007232666   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5091 , Loss:  0.5922088027000427   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5092 , Loss:  0.5922085642814636   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5093 , Loss:  0.592208206653595   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5094 , Loss:  0.5922079086303711   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5095 , Loss:  0.5922075510025024   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5096 , Loss:  0.592207133769989   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5097 , Loss:  0.592206597328186   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5098 , Loss:  0.5922060608863831   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5099 , Loss:  0.5922052264213562   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5100 , Loss:  0.5922043323516846   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5101 , Loss:  0.5922030210494995   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5102 , Loss:  0.5922010540962219   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5103 , Loss:  0.5921981334686279   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5104 , Loss:  0.5921934247016907   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5105 , Loss:  0.5921863913536072   f1-score: 0.9140834808349609   accuracy: 0.9453153014183044\n",
      "Epoch:  5106 , Loss:  0.5921775102615356   f1-score: 0.9142128825187683   accuracy: 0.9454054236412048\n",
      "Epoch:  5107 , Loss:  0.5921699404716492   f1-score: 0.9142128825187683   accuracy: 0.9454054236412048\n",
      "Epoch:  5108 , Loss:  0.5921661257743835   f1-score: 0.9142128825187683   accuracy: 0.9454054236412048\n",
      "Epoch:  5109 , Loss:  0.592164933681488   f1-score: 0.9142128825187683   accuracy: 0.9454054236412048\n",
      "Epoch:  5110 , Loss:  0.5921645164489746   f1-score: 0.9142128825187683   accuracy: 0.9454054236412048\n",
      "Epoch:  5111 , Loss:  0.5921639800071716   f1-score: 0.9142128825187683   accuracy: 0.9454054236412048\n",
      "Epoch:  5112 , Loss:  0.5921629667282104   f1-score: 0.9142128825187683   accuracy: 0.9454054236412048\n",
      "Epoch:  5113 , Loss:  0.5921614766120911   f1-score: 0.9142128825187683   accuracy: 0.9454054236412048\n",
      "Epoch:  5114 , Loss:  0.5921594500541687   f1-score: 0.9142128825187683   accuracy: 0.9454054236412048\n",
      "Epoch:  5115 , Loss:  0.5921568274497986   f1-score: 0.9142128825187683   accuracy: 0.9454054236412048\n",
      "Epoch:  5116 , Loss:  0.5921531319618225   f1-score: 0.9142128825187683   accuracy: 0.9454054236412048\n",
      "Epoch:  5117 , Loss:  0.5921481847763062   f1-score: 0.9142128825187683   accuracy: 0.9454054236412048\n",
      "Epoch:  5118 , Loss:  0.592143177986145   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5119 , Loss:  0.5921398401260376   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5120 , Loss:  0.5921378135681152   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5121 , Loss:  0.592136025428772   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5122 , Loss:  0.5921341776847839   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5123 , Loss:  0.5921324491500854   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5124 , Loss:  0.5921310782432556   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5125 , Loss:  0.5921301245689392   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5126 , Loss:  0.5921293497085571   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5127 , Loss:  0.5921284556388855   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5128 , Loss:  0.5921275615692139   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5129 , Loss:  0.5921266078948975   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5130 , Loss:  0.5921255946159363   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5131 , Loss:  0.592124879360199   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5132 , Loss:  0.5921242833137512   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5133 , Loss:  0.592123806476593   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5134 , Loss:  0.5921233296394348   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5135 , Loss:  0.5921229124069214   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5136 , Loss:  0.592122495174408   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5137 , Loss:  0.5921220779418945   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5138 , Loss:  0.5921216607093811   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5139 , Loss:  0.5921213030815125   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5140 , Loss:  0.592120885848999   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5141 , Loss:  0.5921205282211304   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5142 , Loss:  0.5921200513839722   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5143 , Loss:  0.5921196341514587   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5144 , Loss:  0.5921193361282349   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5145 , Loss:  0.592119038105011   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5146 , Loss:  0.5921187400817871   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5147 , Loss:  0.5921185612678528   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5148 , Loss:  0.5921182632446289   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5149 , Loss:  0.592117965221405   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5150 , Loss:  0.5921176671981812   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5151 , Loss:  0.5921173095703125   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5152 , Loss:  0.5921170711517334   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5153 , Loss:  0.5921168327331543   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5154 , Loss:  0.5921165943145752   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5155 , Loss:  0.5921163558959961   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5156 , Loss:  0.5921161770820618   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5157 , Loss:  0.5921158790588379   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5158 , Loss:  0.5921156406402588   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5159 , Loss:  0.5921154022216797   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5160 , Loss:  0.5921152234077454   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5161 , Loss:  0.5921149849891663   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5162 , Loss:  0.5921147465705872   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5163 , Loss:  0.5921145677566528   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5164 , Loss:  0.5921143293380737   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5165 , Loss:  0.5921141505241394   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5166 , Loss:  0.5921139717102051   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5167 , Loss:  0.5921137928962708   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5168 , Loss:  0.5921134948730469   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5169 , Loss:  0.5921133756637573   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5170 , Loss:  0.592113196849823   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5171 , Loss:  0.5921130180358887   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5172 , Loss:  0.5921128392219543   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5173 , Loss:  0.5921125411987305   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5174 , Loss:  0.5921124219894409   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5175 , Loss:  0.5921121835708618   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5176 , Loss:  0.5921120047569275   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5177 , Loss:  0.5921118259429932   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5178 , Loss:  0.5921116471290588   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5179 , Loss:  0.5921114683151245   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5180 , Loss:  0.5921112298965454   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5181 , Loss:  0.5921110510826111   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5182 , Loss:  0.5921108722686768   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5183 , Loss:  0.5921106934547424   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5184 , Loss:  0.5921105146408081   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5185 , Loss:  0.5921103358268738   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5186 , Loss:  0.5921101570129395   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5187 , Loss:  0.5921099781990051   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5188 , Loss:  0.592109739780426   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5189 , Loss:  0.5921095609664917   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5190 , Loss:  0.5921093225479126   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5191 , Loss:  0.5921091437339783   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5192 , Loss:  0.592108964920044   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5193 , Loss:  0.5921087861061096   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5194 , Loss:  0.5921086072921753   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5195 , Loss:  0.5921083688735962   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5196 , Loss:  0.5921081304550171   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5197 , Loss:  0.5921079516410828   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5198 , Loss:  0.5921077132225037   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5199 , Loss:  0.5921074748039246   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5200 , Loss:  0.5921072959899902   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5201 , Loss:  0.5921069979667664   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5202 , Loss:  0.5921067595481873   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5203 , Loss:  0.5921064615249634   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5204 , Loss:  0.5921061635017395   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5205 , Loss:  0.5921058654785156   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5206 , Loss:  0.592105507850647   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5207 , Loss:  0.5921051502227783   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5208 , Loss:  0.5921047925949097   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5209 , Loss:  0.5921043157577515   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5210 , Loss:  0.5921038389205933   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5211 , Loss:  0.5921032428741455   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5212 , Loss:  0.592102587223053   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5213 , Loss:  0.5921018123626709   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5214 , Loss:  0.5921007990837097   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5215 , Loss:  0.5920996069908142   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5216 , Loss:  0.5920981168746948   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5217 , Loss:  0.5920960903167725   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5218 , Loss:  0.5920935273170471   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5219 , Loss:  0.5920902490615845   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5220 , Loss:  0.592086672782898   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5221 , Loss:  0.5920827388763428   f1-score: 0.914366602897644   accuracy: 0.9454954862594604\n",
      "Epoch:  5222 , Loss:  0.5920785069465637   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5223 , Loss:  0.5920745730400085   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5224 , Loss:  0.5920712351799011   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5225 , Loss:  0.5920687913894653   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5226 , Loss:  0.5920670032501221   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5227 , Loss:  0.5920655727386475   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5228 , Loss:  0.5920643210411072   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5229 , Loss:  0.592063307762146   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5230 , Loss:  0.5920624136924744   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5231 , Loss:  0.5920616388320923   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5232 , Loss:  0.5920608043670654   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5233 , Loss:  0.5920600295066833   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5234 , Loss:  0.592059314250946   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5235 , Loss:  0.5920585989952087   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5236 , Loss:  0.5920579433441162   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5237 , Loss:  0.5920573472976685   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5238 , Loss:  0.5920568704605103   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5239 , Loss:  0.5920562744140625   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5240 , Loss:  0.5920557975769043   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5241 , Loss:  0.5920553207397461   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5242 , Loss:  0.5920549035072327   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5243 , Loss:  0.5920546054840088   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5244 , Loss:  0.5920541286468506   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5245 , Loss:  0.5920537710189819   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5246 , Loss:  0.5920534133911133   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5247 , Loss:  0.5920530557632446   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5248 , Loss:  0.5920527577400208   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5249 , Loss:  0.5920524001121521   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5250 , Loss:  0.5920521020889282   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5251 , Loss:  0.5920518636703491   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5252 , Loss:  0.5920515656471252   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5253 , Loss:  0.5920513868331909   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5254 , Loss:  0.5920511484146118   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5255 , Loss:  0.5920509099960327   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5256 , Loss:  0.5920507311820984   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5257 , Loss:  0.5920504927635193   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5258 , Loss:  0.5920502543449402   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5259 , Loss:  0.5920500159263611   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5260 , Loss:  0.5920498371124268   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5261 , Loss:  0.5920495986938477   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5262 , Loss:  0.5920493602752686   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5263 , Loss:  0.592049241065979   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5264 , Loss:  0.5920490622520447   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5265 , Loss:  0.5920488834381104   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5266 , Loss:  0.5920486450195312   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5267 , Loss:  0.5920484662055969   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5268 , Loss:  0.5920482873916626   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5269 , Loss:  0.5920481085777283   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5270 , Loss:  0.592047929763794   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5271 , Loss:  0.5920476913452148   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5272 , Loss:  0.5920475721359253   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5273 , Loss:  0.592047393321991   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5274 , Loss:  0.5920472145080566   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5275 , Loss:  0.5920470356941223   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5276 , Loss:  0.5920469164848328   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5277 , Loss:  0.5920467376708984   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5278 , Loss:  0.5920465588569641   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5279 , Loss:  0.5920463800430298   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5280 , Loss:  0.5920462608337402   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5281 , Loss:  0.5920460820198059   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5282 , Loss:  0.5920459628105164   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5283 , Loss:  0.592045783996582   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5284 , Loss:  0.5920456051826477   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5285 , Loss:  0.5920454859733582   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5286 , Loss:  0.5920453667640686   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5287 , Loss:  0.5920451879501343   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5288 , Loss:  0.5920450091362   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5289 , Loss:  0.5920448899269104   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5290 , Loss:  0.5920447111129761   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5291 , Loss:  0.5920445322990417   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5292 , Loss:  0.592044472694397   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5293 , Loss:  0.5920442938804626   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5294 , Loss:  0.5920441746711731   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5295 , Loss:  0.5920439958572388   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5296 , Loss:  0.5920438170433044   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5297 , Loss:  0.5920436978340149   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5298 , Loss:  0.5920435786247253   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5299 , Loss:  0.592043399810791   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5300 , Loss:  0.5920433402061462   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5301 , Loss:  0.5920431613922119   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5302 , Loss:  0.5920430421829224   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5303 , Loss:  0.592042863368988   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5304 , Loss:  0.5920428037643433   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5305 , Loss:  0.5920426249504089   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5306 , Loss:  0.5920425057411194   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5307 , Loss:  0.5920423269271851   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5308 , Loss:  0.5920422077178955   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5309 , Loss:  0.592042088508606   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5310 , Loss:  0.5920419692993164   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5311 , Loss:  0.5920418500900269   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5312 , Loss:  0.5920416712760925   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5313 , Loss:  0.592041552066803   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5314 , Loss:  0.5920413732528687   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5315 , Loss:  0.5920413136482239   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5316 , Loss:  0.5920411348342896   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5317 , Loss:  0.592041015625   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5318 , Loss:  0.5920408964157104   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5319 , Loss:  0.5920407772064209   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5320 , Loss:  0.5920406579971313   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5321 , Loss:  0.592040479183197   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5322 , Loss:  0.5920404195785522   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5323 , Loss:  0.5920403003692627   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5324 , Loss:  0.5920401215553284   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5325 , Loss:  0.5920400023460388   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5326 , Loss:  0.5920398831367493   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5327 , Loss:  0.5920397639274597   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5328 , Loss:  0.5920396447181702   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5329 , Loss:  0.5920394659042358   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5330 , Loss:  0.5920393466949463   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5331 , Loss:  0.5920392274856567   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5332 , Loss:  0.5920391082763672   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5333 , Loss:  0.5920389890670776   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5334 , Loss:  0.5920388698577881   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5335 , Loss:  0.5920387506484985   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5336 , Loss:  0.592038631439209   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5337 , Loss:  0.5920385122299194   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5338 , Loss:  0.5920383930206299   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5339 , Loss:  0.5920382738113403   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5340 , Loss:  0.5920381546020508   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5341 , Loss:  0.5920379757881165   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5342 , Loss:  0.5920379161834717   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5343 , Loss:  0.5920377969741821   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5344 , Loss:  0.5920376181602478   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5345 , Loss:  0.592037558555603   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5346 , Loss:  0.5920374393463135   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5347 , Loss:  0.5920373201370239   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5348 , Loss:  0.5920372009277344   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5349 , Loss:  0.5920370817184448   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5350 , Loss:  0.5920369625091553   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5351 , Loss:  0.5920368432998657   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5352 , Loss:  0.5920367240905762   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5353 , Loss:  0.5920366048812866   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5354 , Loss:  0.5920364260673523   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5355 , Loss:  0.5920363664627075   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5356 , Loss:  0.5920363068580627   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5357 , Loss:  0.5920361280441284   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5358 , Loss:  0.5920360088348389   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5359 , Loss:  0.5920358896255493   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5360 , Loss:  0.5920357704162598   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5361 , Loss:  0.5920356512069702   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5362 , Loss:  0.5920355916023254   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5363 , Loss:  0.5920354723930359   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5364 , Loss:  0.5920352935791016   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5365 , Loss:  0.5920352339744568   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5366 , Loss:  0.5920351147651672   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5367 , Loss:  0.5920349359512329   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5368 , Loss:  0.5920348763465881   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5369 , Loss:  0.5920347571372986   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5370 , Loss:  0.592034637928009   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5371 , Loss:  0.5920345783233643   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5372 , Loss:  0.5920344591140747   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5373 , Loss:  0.5920343399047852   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5374 , Loss:  0.5920342206954956   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5375 , Loss:  0.592034101486206   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5376 , Loss:  0.5920339822769165   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5377 , Loss:  0.592033863067627   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5378 , Loss:  0.5920337438583374   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5379 , Loss:  0.5920336246490479   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5380 , Loss:  0.5920335650444031   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5381 , Loss:  0.5920334458351135   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5382 , Loss:  0.592033326625824   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5383 , Loss:  0.5920332074165344   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5384 , Loss:  0.5920330882072449   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5385 , Loss:  0.5920330286026001   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5386 , Loss:  0.5920329093933105   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5387 , Loss:  0.592032790184021   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5388 , Loss:  0.5920326709747314   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5389 , Loss:  0.5920326113700867   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5390 , Loss:  0.5920324325561523   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5391 , Loss:  0.5920323133468628   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5392 , Loss:  0.592032253742218   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5393 , Loss:  0.5920321345329285   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5394 , Loss:  0.5920320153236389   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5395 , Loss:  0.5920318961143494   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5396 , Loss:  0.5920317769050598   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5397 , Loss:  0.592031717300415   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5398 , Loss:  0.5920315980911255   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5399 , Loss:  0.5920314788818359   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5400 , Loss:  0.5920313596725464   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5401 , Loss:  0.5920313000679016   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5402 , Loss:  0.5920311808586121   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5403 , Loss:  0.5920310616493225   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5404 , Loss:  0.592030942440033   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5405 , Loss:  0.5920308232307434   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5406 , Loss:  0.5920307636260986   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5407 , Loss:  0.5920306444168091   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5408 , Loss:  0.5920305848121643   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5409 , Loss:  0.5920304656028748   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5410 , Loss:  0.5920302867889404   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5411 , Loss:  0.5920302271842957   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5412 , Loss:  0.5920301079750061   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5413 , Loss:  0.5920300483703613   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5414 , Loss:  0.5920299291610718   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5415 , Loss:  0.5920298099517822   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5416 , Loss:  0.5920297503471375   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5417 , Loss:  0.5920296311378479   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5418 , Loss:  0.5920295119285583   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5419 , Loss:  0.5920293927192688   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5420 , Loss:  0.5920292735099792   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5421 , Loss:  0.5920292139053345   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5422 , Loss:  0.5920291543006897   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5423 , Loss:  0.5920289754867554   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5424 , Loss:  0.5920289158821106   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5425 , Loss:  0.592028796672821   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5426 , Loss:  0.5920287370681763   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5427 , Loss:  0.5920286178588867   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5428 , Loss:  0.5920285582542419   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5429 , Loss:  0.5920283794403076   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5430 , Loss:  0.5920283198356628   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5431 , Loss:  0.5920282006263733   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5432 , Loss:  0.5920280814170837   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5433 , Loss:  0.592028021812439   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5434 , Loss:  0.5920279026031494   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5435 , Loss:  0.5920277833938599   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5436 , Loss:  0.5920277237892151   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5437 , Loss:  0.5920276045799255   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5438 , Loss:  0.592027485370636   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5439 , Loss:  0.5920273661613464   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5440 , Loss:  0.5920273065567017   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5441 , Loss:  0.5920272469520569   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5442 , Loss:  0.5920271277427673   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5443 , Loss:  0.5920270681381226   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5444 , Loss:  0.592026948928833   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5445 , Loss:  0.5920268893241882   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5446 , Loss:  0.5920267701148987   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5447 , Loss:  0.5920265913009644   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5448 , Loss:  0.5920265316963196   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5449 , Loss:  0.59202641248703   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5450 , Loss:  0.5920263528823853   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5451 , Loss:  0.5920262336730957   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5452 , Loss:  0.5920261740684509   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5453 , Loss:  0.5920260548591614   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5454 , Loss:  0.5920259356498718   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5455 , Loss:  0.592025876045227   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5456 , Loss:  0.5920257568359375   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5457 , Loss:  0.5920256972312927   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5458 , Loss:  0.5920255780220032   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5459 , Loss:  0.5920254588127136   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5460 , Loss:  0.5920253992080688   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5461 , Loss:  0.5920252799987793   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5462 , Loss:  0.5920252203941345   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5463 , Loss:  0.592025101184845   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5464 , Loss:  0.5920250415802002   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5465 , Loss:  0.5920249223709106   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5466 , Loss:  0.5920248627662659   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5467 , Loss:  0.5920247435569763   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5468 , Loss:  0.5920246839523315   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5469 , Loss:  0.5920245051383972   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5470 , Loss:  0.5920244455337524   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5471 , Loss:  0.5920243263244629   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5472 , Loss:  0.5920242667198181   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5473 , Loss:  0.5920241475105286   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5474 , Loss:  0.592024028301239   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5475 , Loss:  0.5920239686965942   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5476 , Loss:  0.5920238494873047   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5477 , Loss:  0.5920237898826599   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5478 , Loss:  0.5920236706733704   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5479 , Loss:  0.5920236110687256   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5480 , Loss:  0.5920235514640808   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5481 , Loss:  0.5920234322547913   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5482 , Loss:  0.5920233726501465   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5483 , Loss:  0.5920232534408569   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5484 , Loss:  0.5920231938362122   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5485 , Loss:  0.5920230746269226   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5486 , Loss:  0.5920230150222778   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5487 , Loss:  0.5920228958129883   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5488 , Loss:  0.5920228362083435   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5489 , Loss:  0.592022716999054   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5490 , Loss:  0.5920226573944092   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5491 , Loss:  0.5920224785804749   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5492 , Loss:  0.5920223593711853   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5493 , Loss:  0.5920222997665405   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5494 , Loss:  0.5920222401618958   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5495 , Loss:  0.592022180557251   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5496 , Loss:  0.5920220613479614   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5497 , Loss:  0.5920220017433167   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5498 , Loss:  0.5920218825340271   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5499 , Loss:  0.5920218229293823   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5500 , Loss:  0.5920217037200928   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5501 , Loss:  0.5920215845108032   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5502 , Loss:  0.5920215249061584   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5503 , Loss:  0.5920214056968689   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5504 , Loss:  0.5920213460922241   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5505 , Loss:  0.5920212268829346   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5506 , Loss:  0.5920211672782898   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5507 , Loss:  0.5920210480690002   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5508 , Loss:  0.5920209884643555   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5509 , Loss:  0.5920208692550659   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5510 , Loss:  0.5920208096504211   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5511 , Loss:  0.5920206904411316   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5512 , Loss:  0.5920206308364868   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5513 , Loss:  0.5920205116271973   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5514 , Loss:  0.5920205116271973   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5515 , Loss:  0.5920203328132629   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5516 , Loss:  0.5920202732086182   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5517 , Loss:  0.5920202136039734   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5518 , Loss:  0.5920201539993286   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5519 , Loss:  0.5920199751853943   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5520 , Loss:  0.5920199155807495   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5521 , Loss:  0.5920198559761047   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5522 , Loss:  0.5920197367668152   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5523 , Loss:  0.5920196771621704   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5524 , Loss:  0.5920195579528809   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5525 , Loss:  0.5920194983482361   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5526 , Loss:  0.5920193791389465   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5527 , Loss:  0.5920193195343018   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5528 , Loss:  0.5920192003250122   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5529 , Loss:  0.5920191407203674   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5530 , Loss:  0.5920190215110779   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5531 , Loss:  0.5920189619064331   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5532 , Loss:  0.5920188426971436   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5533 , Loss:  0.5920187830924988   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5534 , Loss:  0.5920186638832092   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5535 , Loss:  0.5920186638832092   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5536 , Loss:  0.5920185446739197   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5537 , Loss:  0.5920184850692749   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5538 , Loss:  0.5920183658599854   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5539 , Loss:  0.5920183062553406   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5540 , Loss:  0.592018187046051   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5541 , Loss:  0.5920181274414062   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5542 , Loss:  0.5920180678367615   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5543 , Loss:  0.5920180082321167   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5544 , Loss:  0.5920178890228271   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5545 , Loss:  0.5920178294181824   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5546 , Loss:  0.5920177102088928   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5547 , Loss:  0.592017650604248   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5548 , Loss:  0.5920175313949585   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5549 , Loss:  0.5920174717903137   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5550 , Loss:  0.5920173525810242   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5551 , Loss:  0.5920172929763794   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5552 , Loss:  0.5920171737670898   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5553 , Loss:  0.5920171141624451   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5554 , Loss:  0.5920169949531555   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5555 , Loss:  0.5920169353485107   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5556 , Loss:  0.5920168161392212   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5557 , Loss:  0.5920167565345764   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5558 , Loss:  0.5920166373252869   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5559 , Loss:  0.5920165777206421   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5560 , Loss:  0.5920165181159973   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5561 , Loss:  0.5920164585113525   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5562 , Loss:  0.592016339302063   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5563 , Loss:  0.5920162796974182   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5564 , Loss:  0.5920161604881287   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5565 , Loss:  0.5920161008834839   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5566 , Loss:  0.5920160412788391   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5567 , Loss:  0.5920159816741943   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5568 , Loss:  0.5920158624649048   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5569 , Loss:  0.59201580286026   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5570 , Loss:  0.5920156836509705   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5571 , Loss:  0.5920156240463257   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5572 , Loss:  0.5920155048370361   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5573 , Loss:  0.5920154452323914   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5574 , Loss:  0.5920153260231018   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5575 , Loss:  0.592015266418457   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5576 , Loss:  0.5920152068138123   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5577 , Loss:  0.5920151472091675   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5578 , Loss:  0.5920150876045227   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5579 , Loss:  0.5920149683952332   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5580 , Loss:  0.5920149087905884   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5581 , Loss:  0.5920147895812988   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5582 , Loss:  0.592014729976654   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5583 , Loss:  0.5920146107673645   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5584 , Loss:  0.5920145511627197   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5585 , Loss:  0.5920144319534302   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5586 , Loss:  0.5920143723487854   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5587 , Loss:  0.5920143127441406   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5588 , Loss:  0.5920142531394958   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5589 , Loss:  0.5920141339302063   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5590 , Loss:  0.5920140743255615   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5591 , Loss:  0.5920140147209167   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5592 , Loss:  0.592013955116272   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5593 , Loss:  0.5920138359069824   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5594 , Loss:  0.5920137763023376   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5595 , Loss:  0.5920136570930481   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5596 , Loss:  0.5920135974884033   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5597 , Loss:  0.5920134782791138   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5598 , Loss:  0.5920134782791138   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5599 , Loss:  0.5920132994651794   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5600 , Loss:  0.5920132994651794   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5601 , Loss:  0.5920132398605347   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5602 , Loss:  0.5920131206512451   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5603 , Loss:  0.5920130610466003   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5604 , Loss:  0.5920129418373108   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5605 , Loss:  0.592012882232666   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5606 , Loss:  0.5920127630233765   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5607 , Loss:  0.5920127630233765   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5608 , Loss:  0.5920127034187317   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5609 , Loss:  0.5920125842094421   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5610 , Loss:  0.5920125246047974   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5611 , Loss:  0.5920124650001526   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5612 , Loss:  0.592012345790863   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5613 , Loss:  0.5920122861862183   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5614 , Loss:  0.5920121669769287   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5615 , Loss:  0.5920121073722839   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5616 , Loss:  0.5920121073722839   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5617 , Loss:  0.5920119285583496   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5618 , Loss:  0.5920119285583496   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5619 , Loss:  0.5920118093490601   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5620 , Loss:  0.5920117497444153   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5621 , Loss:  0.5920116901397705   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5622 , Loss:  0.5920116305351257   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5623 , Loss:  0.5920115113258362   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5624 , Loss:  0.5920114517211914   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5625 , Loss:  0.5920113921165466   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5626 , Loss:  0.5920112729072571   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5627 , Loss:  0.5920112133026123   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5628 , Loss:  0.5920110940933228   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5629 , Loss:  0.5920110940933228   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5630 , Loss:  0.5920109748840332   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5631 , Loss:  0.5920109152793884   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5632 , Loss:  0.5920108556747437   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5633 , Loss:  0.5920107364654541   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5634 , Loss:  0.5920106768608093   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5635 , Loss:  0.5920106172561646   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5636 , Loss:  0.5920105576515198   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5637 , Loss:  0.592010498046875   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5638 , Loss:  0.5920103788375854   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5639 , Loss:  0.5920102596282959   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5640 , Loss:  0.5920102596282959   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5641 , Loss:  0.5920102000236511   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5642 , Loss:  0.5920100808143616   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5643 , Loss:  0.5920100212097168   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5644 , Loss:  0.5920099020004272   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5645 , Loss:  0.5920099020004272   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5646 , Loss:  0.5920097827911377   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5647 , Loss:  0.5920097231864929   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5648 , Loss:  0.5920096039772034   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5649 , Loss:  0.5920095443725586   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5650 , Loss:  0.5920094847679138   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5651 , Loss:  0.592009425163269   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5652 , Loss:  0.5920093655586243   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5653 , Loss:  0.5920092463493347   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5654 , Loss:  0.5920091867446899   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5655 , Loss:  0.5920090675354004   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5656 , Loss:  0.5920090079307556   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5657 , Loss:  0.5920090079307556   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5658 , Loss:  0.5920088887214661   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5659 , Loss:  0.5920088291168213   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5660 , Loss:  0.5920087695121765   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5661 , Loss:  0.5920087695121765   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5662 , Loss:  0.592008650302887   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5663 , Loss:  0.5920085906982422   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5664 , Loss:  0.5920084714889526   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5665 , Loss:  0.5920084118843079   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5666 , Loss:  0.5920082926750183   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5667 , Loss:  0.5920082330703735   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5668 , Loss:  0.5920082330703735   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5669 , Loss:  0.592008113861084   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5670 , Loss:  0.5920080542564392   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5671 , Loss:  0.5920079350471497   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5672 , Loss:  0.5920078754425049   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5673 , Loss:  0.5920078158378601   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5674 , Loss:  0.5920077562332153   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5675 , Loss:  0.5920076966285706   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5676 , Loss:  0.592007577419281   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5677 , Loss:  0.592007577419281   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5678 , Loss:  0.5920074582099915   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5679 , Loss:  0.5920073986053467   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5680 , Loss:  0.5920073390007019   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5681 , Loss:  0.5920072197914124   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5682 , Loss:  0.5920071601867676   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5683 , Loss:  0.5920071005821228   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5684 , Loss:  0.592007040977478   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5685 , Loss:  0.5920069813728333   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5686 , Loss:  0.5920069217681885   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5687 , Loss:  0.5920068025588989   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5688 , Loss:  0.5920067429542542   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5689 , Loss:  0.5920067429542542   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5690 , Loss:  0.5920066237449646   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5691 , Loss:  0.5920065641403198   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5692 , Loss:  0.5920064449310303   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5693 , Loss:  0.5920063853263855   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5694 , Loss:  0.5920063853263855   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5695 , Loss:  0.592006266117096   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5696 , Loss:  0.5920062065124512   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5697 , Loss:  0.5920060873031616   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5698 , Loss:  0.5920060873031616   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5699 , Loss:  0.5920059680938721   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5700 , Loss:  0.5920059084892273   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5701 , Loss:  0.5920059084892273   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5702 , Loss:  0.5920057892799377   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5703 , Loss:  0.592005729675293   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5704 , Loss:  0.5920056104660034   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5705 , Loss:  0.5920055508613586   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5706 , Loss:  0.5920054912567139   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5707 , Loss:  0.5920054316520691   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5708 , Loss:  0.5920053720474243   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5709 , Loss:  0.5920053124427795   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5710 , Loss:  0.59200519323349   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5711 , Loss:  0.59200519323349   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5712 , Loss:  0.5920050740242004   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5713 , Loss:  0.5920050740242004   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5714 , Loss:  0.5920049548149109   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5715 , Loss:  0.5920048952102661   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5716 , Loss:  0.5920048356056213   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5717 , Loss:  0.5920047760009766   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5718 , Loss:  0.5920047163963318   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5719 , Loss:  0.5920045971870422   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5720 , Loss:  0.5920045375823975   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5721 , Loss:  0.5920044779777527   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5722 , Loss:  0.5920044183731079   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5723 , Loss:  0.5920043587684631   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5724 , Loss:  0.5920042395591736   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5725 , Loss:  0.5920041799545288   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5726 , Loss:  0.592004120349884   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5727 , Loss:  0.5920040607452393   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5728 , Loss:  0.5920040011405945   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5729 , Loss:  0.5920038819313049   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5730 , Loss:  0.5920038819313049   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5731 , Loss:  0.5920038223266602   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5732 , Loss:  0.5920037031173706   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5733 , Loss:  0.5920036435127258   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5734 , Loss:  0.5920036435127258   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5735 , Loss:  0.5920035243034363   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5736 , Loss:  0.5920034646987915   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5737 , Loss:  0.592003345489502   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5738 , Loss:  0.592003345489502   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5739 , Loss:  0.5920032262802124   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5740 , Loss:  0.5920032262802124   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5741 , Loss:  0.5920031070709229   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5742 , Loss:  0.5920030474662781   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5743 , Loss:  0.5920030474662781   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5744 , Loss:  0.5920029282569885   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5745 , Loss:  0.5920028686523438   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5746 , Loss:  0.592002809047699   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5747 , Loss:  0.5920027494430542   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5748 , Loss:  0.5920026898384094   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5749 , Loss:  0.5920025706291199   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5750 , Loss:  0.5920025110244751   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5751 , Loss:  0.5920024514198303   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5752 , Loss:  0.5920023918151855   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5753 , Loss:  0.5920023322105408   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5754 , Loss:  0.5920022130012512   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5755 , Loss:  0.5920022130012512   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5756 , Loss:  0.5920021533966064   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5757 , Loss:  0.5920020341873169   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5758 , Loss:  0.5920019745826721   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5759 , Loss:  0.5920019149780273   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5760 , Loss:  0.5920018553733826   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5761 , Loss:  0.5920017957687378   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5762 , Loss:  0.5920016765594482   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5763 , Loss:  0.5920016765594482   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5764 , Loss:  0.5920016169548035   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5765 , Loss:  0.5920015573501587   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5766 , Loss:  0.5920014381408691   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5767 , Loss:  0.5920014381408691   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5768 , Loss:  0.5920013785362244   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5769 , Loss:  0.5920012593269348   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5770 , Loss:  0.59200119972229   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5771 , Loss:  0.59200119972229   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5772 , Loss:  0.5920010805130005   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5773 , Loss:  0.5920010209083557   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5774 , Loss:  0.5920009613037109   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5775 , Loss:  0.5920009016990662   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5776 , Loss:  0.5920008420944214   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5777 , Loss:  0.5920007228851318   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5778 , Loss:  0.5920006632804871   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5779 , Loss:  0.5920006632804871   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5780 , Loss:  0.5920005440711975   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5781 , Loss:  0.5920004844665527   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5782 , Loss:  0.592000424861908   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5783 , Loss:  0.5920003652572632   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5784 , Loss:  0.5920003056526184   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5785 , Loss:  0.5920001864433289   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5786 , Loss:  0.5920001864433289   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5787 , Loss:  0.5920000672340393   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5788 , Loss:  0.5920000076293945   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5789 , Loss:  0.5919999480247498   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5790 , Loss:  0.591999888420105   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5791 , Loss:  0.5919998288154602   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5792 , Loss:  0.5919997692108154   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5793 , Loss:  0.5919997096061707   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5794 , Loss:  0.5919996500015259   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5795 , Loss:  0.5919995903968811   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5796 , Loss:  0.5919995307922363   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5797 , Loss:  0.5919994711875916   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5798 , Loss:  0.5919994115829468   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5799 , Loss:  0.591999351978302   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5800 , Loss:  0.5919992327690125   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5801 , Loss:  0.5919991731643677   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5802 , Loss:  0.5919991135597229   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5803 , Loss:  0.5919990539550781   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5804 , Loss:  0.5919989943504333   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5805 , Loss:  0.5919988751411438   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5806 , Loss:  0.591998815536499   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5807 , Loss:  0.591998815536499   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5808 , Loss:  0.5919986963272095   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5809 , Loss:  0.5919986367225647   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5810 , Loss:  0.5919985771179199   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5811 , Loss:  0.5919985175132751   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5812 , Loss:  0.5919984579086304   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5813 , Loss:  0.5919983983039856   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5814 , Loss:  0.5919983386993408   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5815 , Loss:  0.591998279094696   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5816 , Loss:  0.5919981598854065   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5817 , Loss:  0.5919981002807617   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5818 , Loss:  0.5919979810714722   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5819 , Loss:  0.5919979810714722   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5820 , Loss:  0.5919979214668274   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5821 , Loss:  0.5919978618621826   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5822 , Loss:  0.5919978022575378   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5823 , Loss:  0.5919977426528931   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5824 , Loss:  0.5919976830482483   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5825 , Loss:  0.5919975638389587   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5826 , Loss:  0.591997504234314   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5827 , Loss:  0.5919974446296692   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5828 , Loss:  0.5919973850250244   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5829 , Loss:  0.5919973254203796   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5830 , Loss:  0.5919972062110901   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5831 , Loss:  0.5919971466064453   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5832 , Loss:  0.5919970870018005   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5833 , Loss:  0.591996967792511   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5834 , Loss:  0.5919969081878662   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5835 , Loss:  0.5919968485832214   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5836 , Loss:  0.5919967889785767   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5837 , Loss:  0.5919966697692871   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5838 , Loss:  0.5919966101646423   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5839 , Loss:  0.5919964909553528   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5840 , Loss:  0.591996431350708   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5841 , Loss:  0.5919963121414185   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5842 , Loss:  0.5919962525367737   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5843 , Loss:  0.5919961333274841   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5844 , Loss:  0.5919960737228394   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5845 , Loss:  0.5919959545135498   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5846 , Loss:  0.5919958353042603   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5847 , Loss:  0.5919957160949707   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5848 , Loss:  0.5919956564903259   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5849 , Loss:  0.5919954776763916   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5850 , Loss:  0.5919952988624573   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5851 , Loss:  0.591995120048523   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5852 , Loss:  0.5919949412345886   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5853 , Loss:  0.5919947624206543   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5854 , Loss:  0.5919944047927856   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5855 , Loss:  0.5919941067695618   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5856 , Loss:  0.5919936895370483   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5857 , Loss:  0.5919931530952454   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5858 , Loss:  0.5919923186302185   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5859 , Loss:  0.591991126537323   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5860 , Loss:  0.5919891595840454   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5861 , Loss:  0.5919857025146484   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5862 , Loss:  0.591979444026947   f1-score: 0.9144960641860962   accuracy: 0.9455856084823608\n",
      "Epoch:  5863 , Loss:  0.5919700264930725   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5864 , Loss:  0.5919608473777771   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5865 , Loss:  0.591955840587616   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5866 , Loss:  0.5919552445411682   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5867 , Loss:  0.5919560194015503   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5868 , Loss:  0.5919566750526428   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5869 , Loss:  0.5919567346572876   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5870 , Loss:  0.591955840587616   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5871 , Loss:  0.5919546484947205   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5872 , Loss:  0.591952919960022   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5873 , Loss:  0.5919513702392578   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5874 , Loss:  0.5919497609138489   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5875 , Loss:  0.591948390007019   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5876 , Loss:  0.5919472575187683   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5877 , Loss:  0.5919463038444519   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5878 , Loss:  0.5919457674026489   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5879 , Loss:  0.5919454097747803   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5880 , Loss:  0.591945230960846   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5881 , Loss:  0.5919450521469116   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5882 , Loss:  0.5919449329376221   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5883 , Loss:  0.5919447541236877   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5884 , Loss:  0.5919444561004639   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5885 , Loss:  0.5919440984725952   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5886 , Loss:  0.591943621635437   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5887 , Loss:  0.591943085193634   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5888 , Loss:  0.5919426083564758   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5889 , Loss:  0.5919422507286072   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5890 , Loss:  0.5919418931007385   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5891 , Loss:  0.5919415950775146   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5892 , Loss:  0.591941237449646   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5893 , Loss:  0.5919411182403564   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5894 , Loss:  0.5919409394264221   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5895 , Loss:  0.591940701007843   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5896 , Loss:  0.5919404625892639   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5897 , Loss:  0.5919402241706848   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5898 , Loss:  0.5919398665428162   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5899 , Loss:  0.5919395685195923   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5900 , Loss:  0.5919392108917236   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5901 , Loss:  0.5919389128684998   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5902 , Loss:  0.5919385552406311   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5903 , Loss:  0.5919381380081177   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5904 , Loss:  0.5919376611709595   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5905 , Loss:  0.5919371247291565   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5906 , Loss:  0.5919364094734192   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5907 , Loss:  0.5919355154037476   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5908 , Loss:  0.5919343829154968   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5909 , Loss:  0.5919328927993774   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5910 , Loss:  0.5919310450553894   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5911 , Loss:  0.5919287800788879   f1-score: 0.9146255254745483   accuracy: 0.9456756711006165\n",
      "Epoch:  5912 , Loss:  0.5919262766838074   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5913 , Loss:  0.5919241309165955   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5914 , Loss:  0.5919223427772522   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5915 , Loss:  0.5919210314750671   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5916 , Loss:  0.591920018196106   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5917 , Loss:  0.5919189453125   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5918 , Loss:  0.5919179320335388   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5919 , Loss:  0.5919169783592224   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5920 , Loss:  0.5919162034988403   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5921 , Loss:  0.5919156670570374   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5922 , Loss:  0.5919151306152344   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5923 , Loss:  0.5919145941734314   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5924 , Loss:  0.5919139981269836   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5925 , Loss:  0.5919132232666016   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5926 , Loss:  0.5919123888015747   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5927 , Loss:  0.5919115543365479   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5928 , Loss:  0.591910719871521   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5929 , Loss:  0.5919098258018494   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5930 , Loss:  0.5919088125228882   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5931 , Loss:  0.5919075012207031   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5932 , Loss:  0.5919058918952942   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5933 , Loss:  0.5919041037559509   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5934 , Loss:  0.591901957988739   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5935 , Loss:  0.5918997526168823   f1-score: 0.9147791862487793   accuracy: 0.9457657933235168\n",
      "Epoch:  5936 , Loss:  0.5918974876403809   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5937 , Loss:  0.5918954014778137   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5938 , Loss:  0.5918936133384705   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5939 , Loss:  0.591892421245575   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5940 , Loss:  0.5918915271759033   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5941 , Loss:  0.591890811920166   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5942 , Loss:  0.5918901562690735   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5943 , Loss:  0.591889500617981   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5944 , Loss:  0.5918888449668884   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5945 , Loss:  0.5918881297111511   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5946 , Loss:  0.5918875336647034   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5947 , Loss:  0.5918868184089661   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5948 , Loss:  0.5918862819671631   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5949 , Loss:  0.5918857455253601   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5950 , Loss:  0.5918852686882019   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5951 , Loss:  0.5918847918510437   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5952 , Loss:  0.5918843746185303   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5953 , Loss:  0.5918840169906616   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5954 , Loss:  0.5918835401535034   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5955 , Loss:  0.5918831825256348   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5956 , Loss:  0.5918827652931213   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5957 , Loss:  0.5918824076652527   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5958 , Loss:  0.591882050037384   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5959 , Loss:  0.5918816924095154   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5960 , Loss:  0.5918814539909363   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5961 , Loss:  0.5918811559677124   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5962 , Loss:  0.5918807983398438   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5963 , Loss:  0.5918805599212646   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5964 , Loss:  0.5918803215026855   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5965 , Loss:  0.5918800234794617   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5966 , Loss:  0.5918797850608826   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5967 , Loss:  0.5918794870376587   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5968 , Loss:  0.5918793082237244   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5969 , Loss:  0.5918790102005005   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5970 , Loss:  0.5918787717819214   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5971 , Loss:  0.5918785929679871   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5972 , Loss:  0.591878354549408   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5973 , Loss:  0.5918781757354736   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5974 , Loss:  0.5918779373168945   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5975 , Loss:  0.5918777585029602   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5976 , Loss:  0.5918775796890259   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5977 , Loss:  0.5918774008750916   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5978 , Loss:  0.5918772220611572   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5979 , Loss:  0.5918769836425781   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5980 , Loss:  0.5918768048286438   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5981 , Loss:  0.5918766260147095   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5982 , Loss:  0.5918764472007751   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5983 , Loss:  0.5918762683868408   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5984 , Loss:  0.5918760895729065   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5985 , Loss:  0.5918759107589722   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5986 , Loss:  0.5918757319450378   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5987 , Loss:  0.5918755531311035   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5988 , Loss:  0.5918753743171692   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5989 , Loss:  0.5918751955032349   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5990 , Loss:  0.5918750762939453   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5991 , Loss:  0.5918748378753662   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5992 , Loss:  0.5918746590614319   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5993 , Loss:  0.5918744802474976   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5994 , Loss:  0.5918743014335632   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5995 , Loss:  0.5918741226196289   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5996 , Loss:  0.5918739438056946   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5997 , Loss:  0.5918737649917603   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5998 , Loss:  0.5918735861778259   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  5999 , Loss:  0.5918734073638916   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  6000 , Loss:  0.5918731689453125   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  6001 , Loss:  0.5918729901313782   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  6002 , Loss:  0.5918726325035095   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  6003 , Loss:  0.5918723940849304   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  6004 , Loss:  0.5918720960617065   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  6005 , Loss:  0.5918717384338379   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  6006 , Loss:  0.5918712019920349   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  6007 , Loss:  0.5918706059455872   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  6008 , Loss:  0.5918697118759155   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  6009 , Loss:  0.5918684005737305   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  6010 , Loss:  0.5918661952018738   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  6011 , Loss:  0.5918623208999634   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  6012 , Loss:  0.5918554067611694   f1-score: 0.9149327874183655   accuracy: 0.9458558559417725\n",
      "Epoch:  6013 , Loss:  0.5918458700180054   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6014 , Loss:  0.5918383002281189   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6015 , Loss:  0.5918357968330383   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6016 , Loss:  0.5918368101119995   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6017 , Loss:  0.5918373465538025   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6018 , Loss:  0.5918375253677368   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6019 , Loss:  0.5918359160423279   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6020 , Loss:  0.5918341875076294   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6021 , Loss:  0.5918317437171936   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6022 , Loss:  0.5918298959732056   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6023 , Loss:  0.5918281078338623   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6024 , Loss:  0.5918269157409668   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6025 , Loss:  0.5918259024620056   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6026 , Loss:  0.5918251872062683   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6027 , Loss:  0.5918246507644653   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6028 , Loss:  0.5918239951133728   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6029 , Loss:  0.5918235182762146   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6030 , Loss:  0.5918228626251221   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6031 , Loss:  0.5918222665786743   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6032 , Loss:  0.591821551322937   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6033 , Loss:  0.5918208956718445   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6034 , Loss:  0.5918203592300415   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6035 , Loss:  0.591819703578949   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6036 , Loss:  0.5918191075325012   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6037 , Loss:  0.5918183326721191   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6038 , Loss:  0.5918174982070923   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6039 , Loss:  0.5918166041374207   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6040 , Loss:  0.5918153524398804   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6041 , Loss:  0.591813862323761   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6042 , Loss:  0.591812014579773   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6043 , Loss:  0.591809868812561   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6044 , Loss:  0.5918073654174805   f1-score: 0.9150623083114624   accuracy: 0.9459459185600281\n",
      "Epoch:  6045 , Loss:  0.5918048620223999   f1-score: 0.9152158498764038   accuracy: 0.9460360407829285\n",
      "Epoch:  6046 , Loss:  0.5918025374412537   f1-score: 0.9152158498764038   accuracy: 0.9460360407829285\n",
      "Epoch:  6047 , Loss:  0.5918005704879761   f1-score: 0.9152158498764038   accuracy: 0.9460360407829285\n",
      "Epoch:  6048 , Loss:  0.5917988419532776   f1-score: 0.9152158498764038   accuracy: 0.9460360407829285\n",
      "Epoch:  6049 , Loss:  0.591796875   f1-score: 0.9152158498764038   accuracy: 0.9460360407829285\n",
      "Epoch:  6050 , Loss:  0.591794490814209   f1-score: 0.9152158498764038   accuracy: 0.9460360407829285\n",
      "Epoch:  6051 , Loss:  0.5917911529541016   f1-score: 0.9152158498764038   accuracy: 0.9460360407829285\n",
      "Epoch:  6052 , Loss:  0.5917864441871643   f1-score: 0.9152158498764038   accuracy: 0.9460360407829285\n",
      "Epoch:  6053 , Loss:  0.591780960559845   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6054 , Loss:  0.5917763710021973   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6055 , Loss:  0.5917739272117615   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6056 , Loss:  0.5917726159095764   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6057 , Loss:  0.5917714834213257   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6058 , Loss:  0.5917699933052063   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6059 , Loss:  0.5917684435844421   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6060 , Loss:  0.5917669534683228   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6061 , Loss:  0.591765820980072   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6062 , Loss:  0.5917648673057556   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6063 , Loss:  0.5917640328407288   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6064 , Loss:  0.5917632579803467   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6065 , Loss:  0.5917626023292542   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6066 , Loss:  0.5917620062828064   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6067 , Loss:  0.5917614102363586   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6068 , Loss:  0.5917609333992004   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6069 , Loss:  0.5917604565620422   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6070 , Loss:  0.5917598605155945   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6071 , Loss:  0.5917593240737915   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6072 , Loss:  0.5917587280273438   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6073 , Loss:  0.5917580723762512   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6074 , Loss:  0.5917575359344482   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6075 , Loss:  0.59175705909729   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6076 , Loss:  0.5917565822601318   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6077 , Loss:  0.5917562246322632   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6078 , Loss:  0.5917559862136841   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6079 , Loss:  0.5917556881904602   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6080 , Loss:  0.5917554497718811   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6081 , Loss:  0.5917550325393677   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6082 , Loss:  0.5917547345161438   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6083 , Loss:  0.5917543768882751   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6084 , Loss:  0.5917540192604065   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6085 , Loss:  0.5917537808418274   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6086 , Loss:  0.5917535424232483   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6087 , Loss:  0.5917532444000244   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6088 , Loss:  0.5917530059814453   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6089 , Loss:  0.5917527675628662   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6090 , Loss:  0.5917525291442871   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6091 , Loss:  0.5917521715164185   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6092 , Loss:  0.5917519927024841   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6093 , Loss:  0.5917516946792603   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6094 , Loss:  0.5917513966560364   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6095 , Loss:  0.5917511582374573   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6096 , Loss:  0.5917508602142334   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6097 , Loss:  0.5917506217956543   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6098 , Loss:  0.5917503237724304   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6099 , Loss:  0.5917500853538513   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6100 , Loss:  0.5917497277259827   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6101 , Loss:  0.591749370098114   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6102 , Loss:  0.5917490124702454   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6103 , Loss:  0.5917485952377319   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6104 , Loss:  0.5917479991912842   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6105 , Loss:  0.5917472839355469   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6106 , Loss:  0.5917463302612305   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6107 , Loss:  0.5917448997497559   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6108 , Loss:  0.5917426347732544   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6109 , Loss:  0.5917389392852783   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6110 , Loss:  0.5917336940765381   f1-score: 0.9153693914413452   accuracy: 0.9461261034011841\n",
      "Epoch:  6111 , Loss:  0.5917288064956665   f1-score: 0.9155228734016418   accuracy: 0.9462162256240845\n",
      "Epoch:  6112 , Loss:  0.5917261242866516   f1-score: 0.9155228734016418   accuracy: 0.9462162256240845\n",
      "Epoch:  6113 , Loss:  0.5917256474494934   f1-score: 0.9155228734016418   accuracy: 0.9462162256240845\n",
      "Epoch:  6114 , Loss:  0.5917256474494934   f1-score: 0.9155228734016418   accuracy: 0.9462162256240845\n",
      "Epoch:  6115 , Loss:  0.5917252898216248   f1-score: 0.9155228734016418   accuracy: 0.9462162256240845\n",
      "Epoch:  6116 , Loss:  0.5917246341705322   f1-score: 0.9155228734016418   accuracy: 0.9462162256240845\n",
      "Epoch:  6117 , Loss:  0.5917234420776367   f1-score: 0.9155228734016418   accuracy: 0.9462162256240845\n",
      "Epoch:  6118 , Loss:  0.5917220711708069   f1-score: 0.9155228734016418   accuracy: 0.9462162256240845\n",
      "Epoch:  6119 , Loss:  0.5917206406593323   f1-score: 0.9155228734016418   accuracy: 0.9462162256240845\n",
      "Epoch:  6120 , Loss:  0.5917192697525024   f1-score: 0.9155228734016418   accuracy: 0.9462162256240845\n",
      "Epoch:  6121 , Loss:  0.5917181372642517   f1-score: 0.9155228734016418   accuracy: 0.9462162256240845\n",
      "Epoch:  6122 , Loss:  0.5917172431945801   f1-score: 0.9155228734016418   accuracy: 0.9462162256240845\n",
      "Epoch:  6123 , Loss:  0.5917164087295532   f1-score: 0.9155228734016418   accuracy: 0.9462162256240845\n",
      "Epoch:  6124 , Loss:  0.5917155742645264   f1-score: 0.9155228734016418   accuracy: 0.9462162256240845\n",
      "Epoch:  6125 , Loss:  0.59171462059021   f1-score: 0.9155228734016418   accuracy: 0.9462162256240845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6126 , Loss:  0.591713547706604   f1-score: 0.9155228734016418   accuracy: 0.9462162256240845\n",
      "Epoch:  6127 , Loss:  0.5917122960090637   f1-score: 0.9155228734016418   accuracy: 0.9462162256240845\n",
      "Epoch:  6128 , Loss:  0.5917107462882996   f1-score: 0.9155228734016418   accuracy: 0.9462162256240845\n",
      "Epoch:  6129 , Loss:  0.5917088985443115   f1-score: 0.9155228734016418   accuracy: 0.9462162256240845\n",
      "Epoch:  6130 , Loss:  0.5917068719863892   f1-score: 0.9155228734016418   accuracy: 0.9462162256240845\n",
      "Epoch:  6131 , Loss:  0.591704785823822   f1-score: 0.9155228734016418   accuracy: 0.9462162256240845\n",
      "Epoch:  6132 , Loss:  0.5917027592658997   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6133 , Loss:  0.591701090335846   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6134 , Loss:  0.5916996598243713   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6135 , Loss:  0.5916987061500549   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6136 , Loss:  0.5916978120803833   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6137 , Loss:  0.591697096824646   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6138 , Loss:  0.5916962623596191   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6139 , Loss:  0.5916953682899475   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6140 , Loss:  0.5916944742202759   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6141 , Loss:  0.5916936993598938   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6142 , Loss:  0.5916929841041565   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6143 , Loss:  0.591692328453064   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6144 , Loss:  0.5916917324066162   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6145 , Loss:  0.591691255569458   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6146 , Loss:  0.5916907787322998   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6147 , Loss:  0.5916903614997864   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6148 , Loss:  0.5916898846626282   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6149 , Loss:  0.59168940782547   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6150 , Loss:  0.591688871383667   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6151 , Loss:  0.5916885137557983   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6152 , Loss:  0.5916880369186401   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6153 , Loss:  0.5916876792907715   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6154 , Loss:  0.5916873812675476   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6155 , Loss:  0.591687023639679   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6156 , Loss:  0.5916867256164551   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6157 , Loss:  0.5916863679885864   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6158 , Loss:  0.5916860699653625   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6159 , Loss:  0.5916857719421387   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6160 , Loss:  0.5916855335235596   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6161 , Loss:  0.5916851758956909   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6162 , Loss:  0.591684877872467   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6163 , Loss:  0.5916846394538879   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6164 , Loss:  0.5916843414306641   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6165 , Loss:  0.5916841626167297   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6166 , Loss:  0.5916839241981506   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6167 , Loss:  0.5916836857795715   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6168 , Loss:  0.5916835069656372   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6169 , Loss:  0.5916832089424133   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6170 , Loss:  0.591683030128479   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6171 , Loss:  0.5916828513145447   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6172 , Loss:  0.5916826725006104   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6173 , Loss:  0.591682493686676   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6174 , Loss:  0.5916822552680969   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6175 , Loss:  0.5916820764541626   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6176 , Loss:  0.5916818976402283   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6177 , Loss:  0.591681718826294   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6178 , Loss:  0.5916815400123596   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6179 , Loss:  0.5916813611984253   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6180 , Loss:  0.591681182384491   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6181 , Loss:  0.5916810631752014   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6182 , Loss:  0.5916809439659119   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6183 , Loss:  0.5916807651519775   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6184 , Loss:  0.5916805863380432   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6185 , Loss:  0.5916804075241089   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6186 , Loss:  0.5916802883148193   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6187 , Loss:  0.5916801691055298   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6188 , Loss:  0.5916799902915955   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6189 , Loss:  0.5916798114776611   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6190 , Loss:  0.5916796922683716   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6191 , Loss:  0.5916795134544373   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6192 , Loss:  0.5916794538497925   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6193 , Loss:  0.5916793346405029   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6194 , Loss:  0.5916791558265686   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6195 , Loss:  0.591679036617279   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6196 , Loss:  0.5916789174079895   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6197 , Loss:  0.5916787981987   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6198 , Loss:  0.5916786193847656   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6199 , Loss:  0.5916785001754761   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6200 , Loss:  0.5916783809661865   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6201 , Loss:  0.591678261756897   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6202 , Loss:  0.5916781425476074   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6203 , Loss:  0.5916780233383179   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6204 , Loss:  0.5916779041290283   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6205 , Loss:  0.5916777849197388   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6206 , Loss:  0.5916776657104492   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6207 , Loss:  0.5916775465011597   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6208 , Loss:  0.5916774272918701   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6209 , Loss:  0.5916773080825806   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6210 , Loss:  0.591677188873291   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6211 , Loss:  0.5916770696640015   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6212 , Loss:  0.5916769504547119   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6213 , Loss:  0.5916768908500671   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6214 , Loss:  0.5916767120361328   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6215 , Loss:  0.5916765928268433   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6216 , Loss:  0.5916765332221985   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6217 , Loss:  0.5916764140129089   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6218 , Loss:  0.5916762948036194   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6219 , Loss:  0.5916762351989746   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6220 , Loss:  0.5916761159896851   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6221 , Loss:  0.5916759967803955   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6222 , Loss:  0.591675877571106   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6223 , Loss:  0.5916757583618164   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6224 , Loss:  0.5916756987571716   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6225 , Loss:  0.5916755795478821   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6226 , Loss:  0.5916754603385925   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6227 , Loss:  0.5916754007339478   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6228 , Loss:  0.5916752815246582   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6229 , Loss:  0.5916751623153687   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6230 , Loss:  0.5916751027107239   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6231 , Loss:  0.5916749238967896   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6232 , Loss:  0.5916748642921448   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6233 , Loss:  0.5916748046875   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6234 , Loss:  0.5916746854782104   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6235 , Loss:  0.5916746258735657   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6236 , Loss:  0.5916745066642761   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6237 , Loss:  0.5916744470596313   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6238 , Loss:  0.5916743278503418   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6239 , Loss:  0.5916742086410522   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6240 , Loss:  0.5916740894317627   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6241 , Loss:  0.5916740894317627   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6242 , Loss:  0.5916739702224731   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6243 , Loss:  0.5916738510131836   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6244 , Loss:  0.5916737914085388   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6245 , Loss:  0.5916736125946045   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6246 , Loss:  0.5916736125946045   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6247 , Loss:  0.5916734337806702   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6248 , Loss:  0.5916733741760254   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6249 , Loss:  0.5916732549667358   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6250 , Loss:  0.5916731953620911   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6251 , Loss:  0.5916730761528015   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6252 , Loss:  0.5916730165481567   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6253 , Loss:  0.591672956943512   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6254 , Loss:  0.5916728973388672   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6255 , Loss:  0.5916727781295776   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6256 , Loss:  0.5916727185249329   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6257 , Loss:  0.5916726589202881   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6258 , Loss:  0.5916725397109985   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6259 , Loss:  0.591672420501709   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6260 , Loss:  0.591672420501709   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6261 , Loss:  0.5916723012924194   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6262 , Loss:  0.5916722416877747   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6263 , Loss:  0.5916720628738403   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6264 , Loss:  0.5916720628738403   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6265 , Loss:  0.5916719436645508   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6266 , Loss:  0.591671884059906   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6267 , Loss:  0.5916717648506165   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6268 , Loss:  0.5916717052459717   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6269 , Loss:  0.5916716456413269   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6270 , Loss:  0.5916715860366821   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6271 , Loss:  0.5916714668273926   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6272 , Loss:  0.5916714072227478   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6273 , Loss:  0.5916712284088135   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6274 , Loss:  0.5916711688041687   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6275 , Loss:  0.5916711688041687   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6276 , Loss:  0.5916711091995239   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6277 , Loss:  0.5916709899902344   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6278 , Loss:  0.5916709303855896   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6279 , Loss:  0.5916708111763   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6280 , Loss:  0.5916707515716553   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6281 , Loss:  0.5916706323623657   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6282 , Loss:  0.591670572757721   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6283 , Loss:  0.591670572757721   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6284 , Loss:  0.5916704535484314   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6285 , Loss:  0.5916703939437866   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6286 , Loss:  0.5916702747344971   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6287 , Loss:  0.5916702151298523   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6288 , Loss:  0.5916701555252075   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6289 , Loss:  0.5916700959205627   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6290 , Loss:  0.591670036315918   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6291 , Loss:  0.5916699171066284   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6292 , Loss:  0.5916698575019836   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6293 , Loss:  0.5916697382926941   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6294 , Loss:  0.5916697382926941   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6295 , Loss:  0.5916696786880493   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6296 , Loss:  0.5916695594787598   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6297 , Loss:  0.591669499874115   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6298 , Loss:  0.5916693806648254   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6299 , Loss:  0.5916693806648254   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6300 , Loss:  0.5916692614555359   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6301 , Loss:  0.5916692018508911   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6302 , Loss:  0.5916690826416016   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6303 , Loss:  0.5916690826416016   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6304 , Loss:  0.5916690230369568   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6305 , Loss:  0.5916689038276672   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6306 , Loss:  0.5916688442230225   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6307 , Loss:  0.5916687846183777   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6308 , Loss:  0.5916687250137329   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6309 , Loss:  0.5916686654090881   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6310 , Loss:  0.5916685461997986   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6311 , Loss:  0.5916684865951538   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6312 , Loss:  0.591668426990509   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6313 , Loss:  0.5916683673858643   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6314 , Loss:  0.5916683077812195   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6315 , Loss:  0.5916682481765747   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6316 , Loss:  0.5916681885719299   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6317 , Loss:  0.5916680693626404   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6318 , Loss:  0.5916680097579956   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6319 , Loss:  0.5916680097579956   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6320 , Loss:  0.591667890548706   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6321 , Loss:  0.5916678309440613   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6322 , Loss:  0.5916677117347717   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6323 , Loss:  0.591667652130127   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6324 , Loss:  0.591667652130127   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6325 , Loss:  0.5916675329208374   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6326 , Loss:  0.5916674733161926   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6327 , Loss:  0.5916674137115479   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6328 , Loss:  0.5916672945022583   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6329 , Loss:  0.5916672945022583   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6330 , Loss:  0.5916672348976135   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6331 , Loss:  0.591667115688324   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6332 , Loss:  0.5916670560836792   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6333 , Loss:  0.5916670560836792   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6334 , Loss:  0.5916669368743896   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6335 , Loss:  0.5916668772697449   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6336 , Loss:  0.5916668772697449   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6337 , Loss:  0.5916667580604553   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6338 , Loss:  0.5916666984558105   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6339 , Loss:  0.591666579246521   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6340 , Loss:  0.591666579246521   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6341 , Loss:  0.5916665196418762   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6342 , Loss:  0.5916664004325867   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6343 , Loss:  0.5916664004325867   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6344 , Loss:  0.5916663408279419   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6345 , Loss:  0.5916662216186523   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6346 , Loss:  0.5916662216186523   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6347 , Loss:  0.5916661620140076   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6348 , Loss:  0.591666042804718   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6349 , Loss:  0.5916659832000732   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6350 , Loss:  0.5916659235954285   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6351 , Loss:  0.5916658639907837   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6352 , Loss:  0.5916658043861389   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6353 , Loss:  0.5916657447814941   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6354 , Loss:  0.5916656851768494   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6355 , Loss:  0.5916656255722046   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6356 , Loss:  0.5916655659675598   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6357 , Loss:  0.5916655659675598   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6358 , Loss:  0.5916654467582703   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6359 , Loss:  0.5916653871536255   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6360 , Loss:  0.5916653871536255   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6361 , Loss:  0.5916652679443359   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6362 , Loss:  0.5916652083396912   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6363 , Loss:  0.5916652083396912   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6364 , Loss:  0.5916650891304016   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6365 , Loss:  0.5916650295257568   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6366 , Loss:  0.5916649699211121   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6367 , Loss:  0.5916649103164673   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6368 , Loss:  0.5916648507118225   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6369 , Loss:  0.5916647911071777   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6370 , Loss:  0.591664731502533   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6371 , Loss:  0.5916646718978882   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6372 , Loss:  0.5916646122932434   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6373 , Loss:  0.5916645526885986   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6374 , Loss:  0.5916644930839539   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6375 , Loss:  0.5916644334793091   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6376 , Loss:  0.5916643738746643   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6377 , Loss:  0.5916643738746643   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6378 , Loss:  0.5916642546653748   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6379 , Loss:  0.59166419506073   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6380 , Loss:  0.5916641354560852   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6381 , Loss:  0.5916641354560852   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6382 , Loss:  0.5916640162467957   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6383 , Loss:  0.5916639566421509   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6384 , Loss:  0.5916639566421509   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6385 , Loss:  0.5916638374328613   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6386 , Loss:  0.5916637778282166   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6387 , Loss:  0.5916637778282166   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6388 , Loss:  0.5916637182235718   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6389 , Loss:  0.591663658618927   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6390 , Loss:  0.5916635990142822   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6391 , Loss:  0.5916635394096375   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6392 , Loss:  0.5916634798049927   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6393 , Loss:  0.5916634202003479   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6394 , Loss:  0.5916633605957031   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6395 , Loss:  0.5916633605957031   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6396 , Loss:  0.5916632413864136   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6397 , Loss:  0.5916631817817688   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6398 , Loss:  0.5916631817817688   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6399 , Loss:  0.5916630625724792   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6400 , Loss:  0.5916630029678345   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6401 , Loss:  0.5916630029678345   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6402 , Loss:  0.5916629433631897   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6403 , Loss:  0.5916628241539001   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6404 , Loss:  0.5916628241539001   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6405 , Loss:  0.5916627645492554   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6406 , Loss:  0.5916627049446106   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6407 , Loss:  0.5916627049446106   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6408 , Loss:  0.591662585735321   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6409 , Loss:  0.5916625261306763   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6410 , Loss:  0.5916625261306763   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6411 , Loss:  0.5916624069213867   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6412 , Loss:  0.5916623473167419   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6413 , Loss:  0.5916623473167419   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6414 , Loss:  0.5916622877120972   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6415 , Loss:  0.5916622281074524   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6416 , Loss:  0.5916621685028076   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6417 , Loss:  0.5916621088981628   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6418 , Loss:  0.5916620492935181   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6419 , Loss:  0.5916619896888733   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6420 , Loss:  0.5916619896888733   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6421 , Loss:  0.5916618704795837   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6422 , Loss:  0.5916618704795837   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6423 , Loss:  0.591661810874939   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6424 , Loss:  0.5916617512702942   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6425 , Loss:  0.5916616916656494   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6426 , Loss:  0.5916616916656494   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6427 , Loss:  0.5916616320610046   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6428 , Loss:  0.5916615724563599   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6429 , Loss:  0.5916615128517151   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6430 , Loss:  0.5916614532470703   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6431 , Loss:  0.5916613936424255   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6432 , Loss:  0.5916613340377808   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6433 , Loss:  0.5916613340377808   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6434 , Loss:  0.5916612148284912   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6435 , Loss:  0.5916611552238464   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6436 , Loss:  0.5916611552238464   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6437 , Loss:  0.5916610956192017   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6438 , Loss:  0.5916610360145569   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6439 , Loss:  0.5916609764099121   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6440 , Loss:  0.5916609764099121   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6441 , Loss:  0.5916608572006226   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6442 , Loss:  0.5916608572006226   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6443 , Loss:  0.5916607975959778   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6444 , Loss:  0.5916606783866882   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6445 , Loss:  0.5916606783866882   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6446 , Loss:  0.5916606187820435   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6447 , Loss:  0.5916606187820435   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6448 , Loss:  0.5916604995727539   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6449 , Loss:  0.5916604995727539   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6450 , Loss:  0.5916604399681091   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6451 , Loss:  0.5916603803634644   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6452 , Loss:  0.5916603207588196   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6453 , Loss:  0.5916602611541748   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6454 , Loss:  0.5916602611541748   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6455 , Loss:  0.5916601419448853   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6456 , Loss:  0.5916601419448853   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6457 , Loss:  0.5916600823402405   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6458 , Loss:  0.5916600227355957   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6459 , Loss:  0.5916600227355957   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6460 , Loss:  0.5916599631309509   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6461 , Loss:  0.5916598439216614   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6462 , Loss:  0.5916598439216614   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6463 , Loss:  0.5916598439216614   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6464 , Loss:  0.5916597247123718   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6465 , Loss:  0.5916597247123718   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6466 , Loss:  0.591659665107727   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6467 , Loss:  0.5916596055030823   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6468 , Loss:  0.5916595458984375   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6469 , Loss:  0.5916594862937927   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6470 , Loss:  0.5916594862937927   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6471 , Loss:  0.591659426689148   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6472 , Loss:  0.5916593670845032   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6473 , Loss:  0.5916593074798584   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6474 , Loss:  0.5916593074798584   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6475 , Loss:  0.5916591882705688   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6476 , Loss:  0.5916591882705688   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6477 , Loss:  0.5916591286659241   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6478 , Loss:  0.5916591286659241   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6479 , Loss:  0.5916590094566345   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6480 , Loss:  0.5916590094566345   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6481 , Loss:  0.5916589498519897   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6482 , Loss:  0.5916588306427002   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6483 , Loss:  0.5916588306427002   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6484 , Loss:  0.5916587710380554   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6485 , Loss:  0.5916587710380554   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6486 , Loss:  0.5916586518287659   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6487 , Loss:  0.5916586518287659   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6488 , Loss:  0.5916585922241211   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6489 , Loss:  0.5916585922241211   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6490 , Loss:  0.5916584730148315   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6491 , Loss:  0.5916584134101868   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6492 , Loss:  0.5916584134101868   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6493 , Loss:  0.591658353805542   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6494 , Loss:  0.5916582942008972   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6495 , Loss:  0.5916582345962524   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6496 , Loss:  0.5916582345962524   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6497 , Loss:  0.5916581749916077   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6498 , Loss:  0.5916581749916077   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6499 , Loss:  0.5916580557823181   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6500 , Loss:  0.5916580557823181   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6501 , Loss:  0.5916579961776733   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6502 , Loss:  0.5916579961776733   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6503 , Loss:  0.5916578769683838   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6504 , Loss:  0.5916578769683838   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6505 , Loss:  0.591657817363739   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6506 , Loss:  0.591657817363739   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6507 , Loss:  0.5916576981544495   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6508 , Loss:  0.5916576981544495   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6509 , Loss:  0.5916576385498047   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6510 , Loss:  0.5916576385498047   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6511 , Loss:  0.5916575193405151   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6512 , Loss:  0.5916574597358704   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6513 , Loss:  0.5916574597358704   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6514 , Loss:  0.5916574001312256   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6515 , Loss:  0.5916573405265808   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6516 , Loss:  0.5916573405265808   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6517 , Loss:  0.591657280921936   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6518 , Loss:  0.5916572213172913   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6519 , Loss:  0.5916571617126465   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6520 , Loss:  0.5916571617126465   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6521 , Loss:  0.5916571021080017   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6522 , Loss:  0.5916570425033569   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6523 , Loss:  0.5916569828987122   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6524 , Loss:  0.5916569828987122   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6525 , Loss:  0.5916569232940674   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6526 , Loss:  0.5916568636894226   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6527 , Loss:  0.5916568040847778   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6528 , Loss:  0.5916568040847778   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6529 , Loss:  0.5916567444801331   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6530 , Loss:  0.5916566848754883   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6531 , Loss:  0.5916566252708435   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6532 , Loss:  0.5916566252708435   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6533 , Loss:  0.5916565656661987   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6534 , Loss:  0.591656506061554   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6535 , Loss:  0.5916564464569092   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6536 , Loss:  0.5916564464569092   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6537 , Loss:  0.5916563868522644   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6538 , Loss:  0.5916563272476196   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6539 , Loss:  0.5916563272476196   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6540 , Loss:  0.5916562676429749   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6541 , Loss:  0.5916562080383301   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6542 , Loss:  0.5916561484336853   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6543 , Loss:  0.5916561484336853   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6544 , Loss:  0.5916560888290405   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6545 , Loss:  0.5916560292243958   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6546 , Loss:  0.5916560292243958   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6547 , Loss:  0.591655969619751   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6548 , Loss:  0.5916559100151062   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6549 , Loss:  0.5916558504104614   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6550 , Loss:  0.5916558504104614   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6551 , Loss:  0.5916557908058167   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6552 , Loss:  0.5916557312011719   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6553 , Loss:  0.5916556715965271   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6554 , Loss:  0.5916556715965271   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6555 , Loss:  0.5916556119918823   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6556 , Loss:  0.5916556119918823   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6557 , Loss:  0.5916555523872375   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6558 , Loss:  0.5916554927825928   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6559 , Loss:  0.591655433177948   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6560 , Loss:  0.5916553735733032   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6561 , Loss:  0.5916553735733032   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6562 , Loss:  0.5916553139686584   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6563 , Loss:  0.5916552543640137   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6564 , Loss:  0.5916552543640137   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6565 , Loss:  0.5916551947593689   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6566 , Loss:  0.5916551351547241   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6567 , Loss:  0.5916551351547241   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6568 , Loss:  0.5916551351547241   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6569 , Loss:  0.5916550159454346   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6570 , Loss:  0.5916549563407898   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6571 , Loss:  0.5916549563407898   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6572 , Loss:  0.5916549563407898   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6573 , Loss:  0.5916548371315002   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6574 , Loss:  0.5916547775268555   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6575 , Loss:  0.5916547775268555   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6576 , Loss:  0.5916547179222107   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6577 , Loss:  0.5916546583175659   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6578 , Loss:  0.5916546583175659   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6579 , Loss:  0.5916545987129211   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6580 , Loss:  0.5916545987129211   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6581 , Loss:  0.5916545391082764   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6582 , Loss:  0.5916544795036316   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6583 , Loss:  0.5916544795036316   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6584 , Loss:  0.5916544198989868   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6585 , Loss:  0.591654360294342   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6586 , Loss:  0.591654360294342   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6587 , Loss:  0.5916543006896973   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6588 , Loss:  0.5916543006896973   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6589 , Loss:  0.5916541814804077   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6590 , Loss:  0.5916541218757629   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6591 , Loss:  0.5916541218757629   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6592 , Loss:  0.5916541218757629   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6593 , Loss:  0.5916540026664734   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6594 , Loss:  0.5916540026664734   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6595 , Loss:  0.5916539430618286   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6596 , Loss:  0.5916539430618286   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6597 , Loss:  0.5916538238525391   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6598 , Loss:  0.5916538238525391   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6599 , Loss:  0.5916537642478943   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6600 , Loss:  0.5916537642478943   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6601 , Loss:  0.5916536450386047   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6602 , Loss:  0.5916536450386047   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6603 , Loss:  0.5916536450386047   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6604 , Loss:  0.59165358543396   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6605 , Loss:  0.5916535258293152   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6606 , Loss:  0.5916534662246704   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6607 , Loss:  0.5916534662246704   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6608 , Loss:  0.5916534066200256   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6609 , Loss:  0.5916533470153809   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6610 , Loss:  0.5916532874107361   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6611 , Loss:  0.5916532874107361   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6612 , Loss:  0.5916532874107361   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6613 , Loss:  0.5916531682014465   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6614 , Loss:  0.5916531682014465   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6615 , Loss:  0.5916531085968018   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6616 , Loss:  0.5916531085968018   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6617 , Loss:  0.591653048992157   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6618 , Loss:  0.5916529893875122   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6619 , Loss:  0.5916529297828674   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6620 , Loss:  0.5916529297828674   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6621 , Loss:  0.5916528701782227   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6622 , Loss:  0.5916527509689331   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6623 , Loss:  0.5916527509689331   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6624 , Loss:  0.5916527509689331   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6625 , Loss:  0.5916526913642883   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6626 , Loss:  0.5916526913642883   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6627 , Loss:  0.5916526317596436   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6628 , Loss:  0.5916526317596436   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6629 , Loss:  0.5916525721549988   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6630 , Loss:  0.5916524529457092   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6631 , Loss:  0.5916524529457092   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6632 , Loss:  0.5916523933410645   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6633 , Loss:  0.5916523337364197   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6634 , Loss:  0.5916523337364197   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6635 , Loss:  0.5916522741317749   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6636 , Loss:  0.5916522145271301   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6637 , Loss:  0.5916521549224854   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6638 , Loss:  0.5916521549224854   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6639 , Loss:  0.5916520953178406   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6640 , Loss:  0.5916520953178406   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6641 , Loss:  0.591651976108551   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6642 , Loss:  0.5916519165039062   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6643 , Loss:  0.5916519165039062   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6644 , Loss:  0.5916517972946167   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6645 , Loss:  0.5916517972946167   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6646 , Loss:  0.5916517376899719   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6647 , Loss:  0.5916517376899719   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6648 , Loss:  0.5916516780853271   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6649 , Loss:  0.5916516184806824   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6650 , Loss:  0.5916515588760376   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6651 , Loss:  0.591651439666748   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6652 , Loss:  0.591651439666748   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6653 , Loss:  0.5916513800621033   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6654 , Loss:  0.5916513800621033   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6655 , Loss:  0.5916512608528137   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6656 , Loss:  0.591651201248169   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6657 , Loss:  0.5916510820388794   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6658 , Loss:  0.5916510820388794   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6659 , Loss:  0.5916510224342346   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6660 , Loss:  0.5916509032249451   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6661 , Loss:  0.5916508436203003   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6662 , Loss:  0.5916507840156555   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6663 , Loss:  0.591650664806366   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6664 , Loss:  0.5916506052017212   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6665 , Loss:  0.5916504859924316   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6666 , Loss:  0.5916504263877869   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6667 , Loss:  0.5916502475738525   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6668 , Loss:  0.5916500687599182   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6669 , Loss:  0.5916499495506287   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6670 , Loss:  0.5916497707366943   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6671 , Loss:  0.5916495323181152   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6672 , Loss:  0.5916492342948914   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6673 , Loss:  0.5916489362716675   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6674 , Loss:  0.5916483998298645   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6675 , Loss:  0.591647744178772   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6676 , Loss:  0.5916467905044556   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6677 , Loss:  0.5916452407836914   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6678 , Loss:  0.5916428565979004   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6679 , Loss:  0.5916386842727661   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6680 , Loss:  0.5916323065757751   f1-score: 0.9156762957572937   accuracy: 0.9463062882423401\n",
      "Epoch:  6681 , Loss:  0.5916247367858887   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6682 , Loss:  0.5916190147399902   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6683 , Loss:  0.5916169881820679   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6684 , Loss:  0.5916169881820679   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6685 , Loss:  0.5916163921356201   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6686 , Loss:  0.5916150212287903   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6687 , Loss:  0.5916129350662231   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6688 , Loss:  0.5916112065315247   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6689 , Loss:  0.5916098356246948   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6690 , Loss:  0.5916090607643127   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6691 , Loss:  0.5916083455085754   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6692 , Loss:  0.5916077494621277   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6693 , Loss:  0.5916070342063904   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6694 , Loss:  0.5916062593460083   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6695 , Loss:  0.591605544090271   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6696 , Loss:  0.5916048884391785   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6697 , Loss:  0.5916044116020203   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6698 , Loss:  0.5916039347648621   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6699 , Loss:  0.5916035175323486   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6700 , Loss:  0.59160315990448   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6701 , Loss:  0.5916027426719666   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6702 , Loss:  0.5916024446487427   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6703 , Loss:  0.591602087020874   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6704 , Loss:  0.5916018486022949   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6705 , Loss:  0.5916016101837158   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6706 , Loss:  0.5916013717651367   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6707 , Loss:  0.5916011929512024   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6708 , Loss:  0.5916008949279785   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6709 , Loss:  0.5916005969047546   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6710 , Loss:  0.5916002988815308   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6711 , Loss:  0.5916000604629517   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6712 , Loss:  0.5915998816490173   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6713 , Loss:  0.591599702835083   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6714 , Loss:  0.5915996432304382   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6715 , Loss:  0.5915995240211487   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6716 , Loss:  0.5915994048118591   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6717 , Loss:  0.5915992259979248   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6718 , Loss:  0.5915989279747009   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6719 , Loss:  0.5915986895561218   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6720 , Loss:  0.5915984511375427   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6721 , Loss:  0.5915982127189636   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6722 , Loss:  0.5915979743003845   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6723 , Loss:  0.5915976762771606   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6724 , Loss:  0.591597318649292   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6725 , Loss:  0.5915967226028442   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6726 , Loss:  0.5915956497192383   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6727 , Loss:  0.5915935039520264   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n",
      "Epoch:  6728 , Loss:  0.5915887951850891   f1-score: 0.9158058762550354   accuracy: 0.9463964104652405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6729 , Loss:  0.5915803909301758   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6730 , Loss:  0.5915743708610535   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6731 , Loss:  0.5915729999542236   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6732 , Loss:  0.5915745496749878   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6733 , Loss:  0.5915741920471191   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6734 , Loss:  0.59157395362854   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6735 , Loss:  0.5915725231170654   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6736 , Loss:  0.5915712118148804   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6737 , Loss:  0.5915703773498535   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6738 , Loss:  0.5915693640708923   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6739 , Loss:  0.591569185256958   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6740 , Loss:  0.5915685892105103   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6741 , Loss:  0.5915682911872864   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6742 , Loss:  0.5915679931640625   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6743 , Loss:  0.5915676355361938   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6744 , Loss:  0.5915674567222595   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6745 , Loss:  0.5915668606758118   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6746 , Loss:  0.5915665626525879   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6747 , Loss:  0.5915662050247192   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6748 , Loss:  0.5915657877922058   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6749 , Loss:  0.5915655493736267   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6750 , Loss:  0.5915653109550476   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6751 , Loss:  0.5915651321411133   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6752 , Loss:  0.5915650725364685   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6753 , Loss:  0.591564953327179   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6754 , Loss:  0.5915648937225342   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6755 , Loss:  0.5915647149085999   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6756 , Loss:  0.5915645956993103   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6757 , Loss:  0.5915644764900208   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6758 , Loss:  0.5915641784667969   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6759 , Loss:  0.5915639996528625   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6760 , Loss:  0.5915637612342834   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6761 , Loss:  0.5915636420249939   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6762 , Loss:  0.5915635824203491   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6763 , Loss:  0.5915634632110596   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6764 , Loss:  0.5915634036064148   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6765 , Loss:  0.5915632247924805   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6766 , Loss:  0.5915631055831909   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6767 , Loss:  0.5915630459785461   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6768 , Loss:  0.5915628671646118   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6769 , Loss:  0.591562807559967   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6770 , Loss:  0.5915626883506775   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6771 , Loss:  0.5915626287460327   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6772 , Loss:  0.5915625095367432   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6773 , Loss:  0.5915624499320984   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6774 , Loss:  0.5915623307228088   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6775 , Loss:  0.5915622711181641   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6776 , Loss:  0.5915622711181641   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6777 , Loss:  0.5915621519088745   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6778 , Loss:  0.5915620923042297   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6779 , Loss:  0.5915619730949402   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6780 , Loss:  0.5915619134902954   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6781 , Loss:  0.5915617942810059   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6782 , Loss:  0.5915617942810059   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6783 , Loss:  0.5915617346763611   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6784 , Loss:  0.5915616154670715   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6785 , Loss:  0.5915615558624268   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6786 , Loss:  0.591561496257782   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6787 , Loss:  0.5915614366531372   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6788 , Loss:  0.5915613770484924   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6789 , Loss:  0.5915612578392029   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6790 , Loss:  0.5915612578392029   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6791 , Loss:  0.5915611982345581   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6792 , Loss:  0.5915610790252686   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6793 , Loss:  0.5915610790252686   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6794 , Loss:  0.5915610194206238   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6795 , Loss:  0.591560959815979   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6796 , Loss:  0.5915609002113342   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6797 , Loss:  0.5915608406066895   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6798 , Loss:  0.5915607810020447   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6799 , Loss:  0.5915606617927551   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6800 , Loss:  0.5915606617927551   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6801 , Loss:  0.5915606021881104   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6802 , Loss:  0.5915605425834656   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6803 , Loss:  0.5915604829788208   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6804 , Loss:  0.591560423374176   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6805 , Loss:  0.5915603637695312   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6806 , Loss:  0.5915603041648865   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6807 , Loss:  0.5915602445602417   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6808 , Loss:  0.5915601849555969   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6809 , Loss:  0.5915601253509521   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6810 , Loss:  0.5915600657463074   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6811 , Loss:  0.5915600061416626   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6812 , Loss:  0.5915599465370178   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6813 , Loss:  0.5915599465370178   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6814 , Loss:  0.5915598273277283   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6815 , Loss:  0.5915597677230835   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6816 , Loss:  0.5915597677230835   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6817 , Loss:  0.5915597081184387   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6818 , Loss:  0.5915595889091492   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6819 , Loss:  0.5915595293045044   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6820 , Loss:  0.5915595293045044   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6821 , Loss:  0.5915594100952148   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6822 , Loss:  0.5915593504905701   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6823 , Loss:  0.5915593504905701   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6824 , Loss:  0.5915592312812805   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6825 , Loss:  0.5915592312812805   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6826 , Loss:  0.591559112071991   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6827 , Loss:  0.591559112071991   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6828 , Loss:  0.5915590524673462   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6829 , Loss:  0.5915589332580566   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6830 , Loss:  0.5915589332580566   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6831 , Loss:  0.5915588736534119   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6832 , Loss:  0.5915587544441223   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6833 , Loss:  0.5915587544441223   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6834 , Loss:  0.5915586352348328   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6835 , Loss:  0.5915586352348328   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6836 , Loss:  0.5915585160255432   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6837 , Loss:  0.5915584564208984   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6838 , Loss:  0.5915583968162537   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6839 , Loss:  0.5915582776069641   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6840 , Loss:  0.5915582180023193   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6841 , Loss:  0.5915581583976746   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6842 , Loss:  0.591558039188385   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6843 , Loss:  0.5915579199790955   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6844 , Loss:  0.5915578007698059   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6845 , Loss:  0.5915576815605164   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6846 , Loss:  0.5915575623512268   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6847 , Loss:  0.5915573835372925   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6848 , Loss:  0.5915571451187134   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6849 , Loss:  0.5915568470954895   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6850 , Loss:  0.5915564298629761   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6851 , Loss:  0.5915558934211731   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6852 , Loss:  0.5915550589561462   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6853 , Loss:  0.5915536284446716   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6854 , Loss:  0.5915511846542358   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6855 , Loss:  0.5915470719337463   f1-score: 0.9159592390060425   accuracy: 0.9464864730834961\n",
      "Epoch:  6856 , Loss:  0.5915418863296509   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6857 , Loss:  0.5915378928184509   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6858 , Loss:  0.5915365815162659   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6859 , Loss:  0.5915372371673584   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6860 , Loss:  0.5915377140045166   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6861 , Loss:  0.5915380120277405   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6862 , Loss:  0.591537356376648   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6863 , Loss:  0.5915362238883972   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6864 , Loss:  0.5915347933769226   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6865 , Loss:  0.5915333032608032   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6866 , Loss:  0.5915322303771973   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6867 , Loss:  0.5915313363075256   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6868 , Loss:  0.5915308594703674   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6869 , Loss:  0.5915307402610779   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6870 , Loss:  0.5915307402610779   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6871 , Loss:  0.5915307402610779   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6872 , Loss:  0.5915305018424988   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6873 , Loss:  0.5915302038192749   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6874 , Loss:  0.5915297269821167   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6875 , Loss:  0.5915291905403137   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6876 , Loss:  0.5915287137031555   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6877 , Loss:  0.5915283560752869   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6878 , Loss:  0.591528058052063   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6879 , Loss:  0.5915278792381287   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6880 , Loss:  0.5915277004241943   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6881 , Loss:  0.5915275812149048   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6882 , Loss:  0.5915274024009705   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6883 , Loss:  0.5915272235870361   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6884 , Loss:  0.591526985168457   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6885 , Loss:  0.5915268063545227   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6886 , Loss:  0.5915266275405884   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6887 , Loss:  0.5915263295173645   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6888 , Loss:  0.5915261507034302   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6889 , Loss:  0.5915260314941406   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6890 , Loss:  0.5915258526802063   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6891 , Loss:  0.591525673866272   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6892 , Loss:  0.5915254950523376   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6893 , Loss:  0.5915253162384033   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6894 , Loss:  0.5915250778198242   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6895 , Loss:  0.5915248394012451   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6896 , Loss:  0.591524600982666   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6897 , Loss:  0.5915243029594421   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6898 , Loss:  0.5915239453315735   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6899 , Loss:  0.5915234684944153   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6900 , Loss:  0.5915228128433228   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6901 , Loss:  0.5915219783782959   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6902 , Loss:  0.5915206074714661   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6903 , Loss:  0.5915185213088989   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6904 , Loss:  0.5915154814720154   f1-score: 0.9161126017570496   accuracy: 0.9465765953063965\n",
      "Epoch:  6905 , Loss:  0.5915116667747498   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6906 , Loss:  0.5915082097053528   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6907 , Loss:  0.5915060043334961   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6908 , Loss:  0.5915053486824036   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6909 , Loss:  0.5915049910545349   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6910 , Loss:  0.5915047526359558   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6911 , Loss:  0.5915040969848633   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6912 , Loss:  0.5915032029151917   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6913 , Loss:  0.5915020704269409   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6914 , Loss:  0.5915011167526245   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6915 , Loss:  0.5915002226829529   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6916 , Loss:  0.5914995074272156   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6917 , Loss:  0.5914989709854126   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6918 , Loss:  0.5914985537528992   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6919 , Loss:  0.5914981961250305   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6920 , Loss:  0.5914978981018066   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6921 , Loss:  0.5914974808692932   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6922 , Loss:  0.5914972424507141   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6923 , Loss:  0.5914968848228455   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6924 , Loss:  0.5914965271949768   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6925 , Loss:  0.5914962887763977   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6926 , Loss:  0.5914960503578186   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6927 , Loss:  0.5914958119392395   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6928 , Loss:  0.5914955735206604   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6929 , Loss:  0.5914953351020813   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6930 , Loss:  0.5914950966835022   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6931 , Loss:  0.5914949178695679   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6932 , Loss:  0.5914947986602783   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6933 , Loss:  0.5914945602416992   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6934 , Loss:  0.5914944410324097   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6935 , Loss:  0.5914942026138306   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6936 , Loss:  0.591494083404541   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6937 , Loss:  0.5914939045906067   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6938 , Loss:  0.5914936661720276   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6939 , Loss:  0.591493546962738   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6940 , Loss:  0.5914934277534485   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6941 , Loss:  0.5914932489395142   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6942 , Loss:  0.5914930701255798   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6943 , Loss:  0.5914930105209351   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6944 , Loss:  0.5914928317070007   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6945 , Loss:  0.591492772102356   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6946 , Loss:  0.5914926528930664   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6947 , Loss:  0.5914924740791321   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6948 , Loss:  0.5914924144744873   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6949 , Loss:  0.591492235660553   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6950 , Loss:  0.5914921760559082   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6951 , Loss:  0.5914920568466187   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6952 , Loss:  0.5914919376373291   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6953 , Loss:  0.5914918184280396   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6954 , Loss:  0.5914917588233948   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6955 , Loss:  0.5914915800094604   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6956 , Loss:  0.5914915204048157   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6957 , Loss:  0.5914914011955261   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6958 , Loss:  0.5914913415908813   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6959 , Loss:  0.5914912223815918   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6960 , Loss:  0.5914911031723022   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6961 , Loss:  0.5914910435676575   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6962 , Loss:  0.5914909243583679   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6963 , Loss:  0.5914908647537231   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6964 , Loss:  0.5914907455444336   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6965 , Loss:  0.5914905667304993   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6966 , Loss:  0.5914905071258545   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6967 , Loss:  0.5914903879165649   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6968 , Loss:  0.5914902687072754   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6969 , Loss:  0.5914902091026306   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6970 , Loss:  0.5914900302886963   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6971 , Loss:  0.5914899110794067   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6972 , Loss:  0.5914897918701172   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6973 , Loss:  0.5914896726608276   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6974 , Loss:  0.5914894938468933   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6975 , Loss:  0.591489315032959   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6976 , Loss:  0.5914891362190247   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6977 , Loss:  0.5914888978004456   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6978 , Loss:  0.5914885997772217   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6979 , Loss:  0.5914883017539978   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6980 , Loss:  0.5914878845214844   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6981 , Loss:  0.5914874076843262   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6982 , Loss:  0.5914866924285889   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6983 , Loss:  0.5914856195449829   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6984 , Loss:  0.5914840698242188   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6985 , Loss:  0.5914819836616516   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6986 , Loss:  0.591479480266571   f1-score: 0.9162659049034119   accuracy: 0.9466666579246521\n",
      "Epoch:  6987 , Loss:  0.5914767980575562   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  6988 , Loss:  0.5914744734764099   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  6989 , Loss:  0.5914733409881592   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  6990 , Loss:  0.5914729237556458   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  6991 , Loss:  0.5914728045463562   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  6992 , Loss:  0.5914726257324219   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  6993 , Loss:  0.5914719104766846   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  6994 , Loss:  0.5914709568023682   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  6995 , Loss:  0.5914698839187622   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  6996 , Loss:  0.5914689302444458   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  6997 , Loss:  0.5914682745933533   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  6998 , Loss:  0.5914677381515503   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  6999 , Loss:  0.5914672613143921   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7000 , Loss:  0.5914669036865234   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7001 , Loss:  0.5914665460586548   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7002 , Loss:  0.5914661884307861   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7003 , Loss:  0.5914657711982727   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7004 , Loss:  0.591465413570404   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7005 , Loss:  0.5914648771286011   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7006 , Loss:  0.5914644598960876   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7007 , Loss:  0.5914641618728638   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7008 , Loss:  0.5914638042449951   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7009 , Loss:  0.591463565826416   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7010 , Loss:  0.5914632678031921   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7011 , Loss:  0.591463029384613   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7012 , Loss:  0.5914627313613892   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7013 , Loss:  0.5914625525474548   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7014 , Loss:  0.5914623141288757   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7015 , Loss:  0.5914620161056519   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7016 , Loss:  0.5914618372917175   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7017 , Loss:  0.5914615988731384   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7018 , Loss:  0.5914614200592041   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7019 , Loss:  0.591461181640625   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7020 , Loss:  0.5914610624313354   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7021 , Loss:  0.5914608836174011   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7022 , Loss:  0.5914607048034668   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7023 , Loss:  0.5914605259895325   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7024 , Loss:  0.5914603471755981   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7025 , Loss:  0.5914601683616638   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7026 , Loss:  0.5914599895477295   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7027 , Loss:  0.5914598703384399   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7028 , Loss:  0.5914596915245056   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7029 , Loss:  0.5914595723152161   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7030 , Loss:  0.5914593935012817   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7031 , Loss:  0.591459333896637   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7032 , Loss:  0.5914591550827026   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7033 , Loss:  0.5914590358734131   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7034 , Loss:  0.5914589166641235   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7035 , Loss:  0.5914588570594788   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7036 , Loss:  0.5914586782455444   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7037 , Loss:  0.5914585590362549   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7038 , Loss:  0.5914584398269653   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7039 , Loss:  0.5914583206176758   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7040 , Loss:  0.591458261013031   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7041 , Loss:  0.5914581418037415   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7042 , Loss:  0.5914580225944519   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7043 , Loss:  0.5914579033851624   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7044 , Loss:  0.5914578437805176   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7045 , Loss:  0.5914576649665833   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7046 , Loss:  0.5914576649665833   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7047 , Loss:  0.5914574861526489   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7048 , Loss:  0.5914574265480042   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7049 , Loss:  0.5914573073387146   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7050 , Loss:  0.5914573073387146   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7051 , Loss:  0.591457188129425   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7052 , Loss:  0.5914571285247803   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7053 , Loss:  0.5914570093154907   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7054 , Loss:  0.5914568901062012   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7055 , Loss:  0.5914568305015564   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7056 , Loss:  0.5914567112922668   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7057 , Loss:  0.5914566516876221   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7058 , Loss:  0.5914565920829773   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7059 , Loss:  0.5914564728736877   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7060 , Loss:  0.591456413269043   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7061 , Loss:  0.5914563536643982   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7062 , Loss:  0.5914562940597534   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7063 , Loss:  0.5914561748504639   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7064 , Loss:  0.5914561748504639   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7065 , Loss:  0.5914560556411743   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7066 , Loss:  0.5914559960365295   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7067 , Loss:  0.59145587682724   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7068 , Loss:  0.5914558172225952   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7069 , Loss:  0.5914558172225952   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7070 , Loss:  0.5914556980133057   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7071 , Loss:  0.5914556384086609   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7072 , Loss:  0.5914555191993713   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7073 , Loss:  0.5914554595947266   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7074 , Loss:  0.5914554595947266   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7075 , Loss:  0.591455340385437   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7076 , Loss:  0.5914552807807922   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7077 , Loss:  0.5914552211761475   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7078 , Loss:  0.5914551615715027   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7079 , Loss:  0.5914551019668579   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7080 , Loss:  0.5914549827575684   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7081 , Loss:  0.5914549827575684   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7082 , Loss:  0.5914549231529236   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7083 , Loss:  0.591454803943634   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7084 , Loss:  0.591454803943634   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7085 , Loss:  0.5914547443389893   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7086 , Loss:  0.5914546251296997   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7087 , Loss:  0.5914546251296997   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7088 , Loss:  0.5914545655250549   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7089 , Loss:  0.5914545059204102   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7090 , Loss:  0.5914544463157654   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7091 , Loss:  0.5914543867111206   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7092 , Loss:  0.5914543271064758   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7093 , Loss:  0.591454267501831   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7094 , Loss:  0.5914542078971863   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7095 , Loss:  0.5914541482925415   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7096 , Loss:  0.5914540886878967   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7097 , Loss:  0.591454029083252   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7098 , Loss:  0.5914539694786072   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7099 , Loss:  0.5914539694786072   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7100 , Loss:  0.5914538502693176   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7101 , Loss:  0.5914537906646729   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7102 , Loss:  0.5914537906646729   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7103 , Loss:  0.5914536714553833   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7104 , Loss:  0.5914536118507385   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7105 , Loss:  0.5914536118507385   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7106 , Loss:  0.5914536118507385   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7107 , Loss:  0.591453492641449   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7108 , Loss:  0.5914534330368042   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7109 , Loss:  0.5914534330368042   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7110 , Loss:  0.5914533734321594   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7111 , Loss:  0.5914533138275146   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7112 , Loss:  0.5914532542228699   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7113 , Loss:  0.5914531946182251   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7114 , Loss:  0.5914531350135803   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7115 , Loss:  0.5914530754089355   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7116 , Loss:  0.5914530754089355   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7117 , Loss:  0.591452956199646   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7118 , Loss:  0.591452956199646   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7119 , Loss:  0.5914528965950012   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7120 , Loss:  0.5914528369903564   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7121 , Loss:  0.5914527773857117   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7122 , Loss:  0.5914527773857117   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7123 , Loss:  0.5914527177810669   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7124 , Loss:  0.5914526581764221   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7125 , Loss:  0.5914526581764221   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7126 , Loss:  0.5914525985717773   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7127 , Loss:  0.5914525389671326   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7128 , Loss:  0.5914524793624878   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7129 , Loss:  0.5914524793624878   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7130 , Loss:  0.591452419757843   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7131 , Loss:  0.5914523601531982   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7132 , Loss:  0.5914523005485535   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7133 , Loss:  0.5914522409439087   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7134 , Loss:  0.5914522409439087   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7135 , Loss:  0.5914521813392639   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7136 , Loss:  0.5914521217346191   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7137 , Loss:  0.5914520621299744   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7138 , Loss:  0.5914520025253296   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7139 , Loss:  0.5914520025253296   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7140 , Loss:  0.5914519429206848   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7141 , Loss:  0.59145188331604   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7142 , Loss:  0.5914518237113953   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7143 , Loss:  0.5914518237113953   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7144 , Loss:  0.5914517641067505   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7145 , Loss:  0.5914517045021057   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7146 , Loss:  0.5914516448974609   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7147 , Loss:  0.5914516448974609   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7148 , Loss:  0.5914515852928162   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7149 , Loss:  0.5914515852928162   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7150 , Loss:  0.5914515256881714   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7151 , Loss:  0.5914514660835266   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7152 , Loss:  0.5914514660835266   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7153 , Loss:  0.5914514064788818   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7154 , Loss:  0.5914513468742371   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7155 , Loss:  0.5914512872695923   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7156 , Loss:  0.5914512276649475   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7157 , Loss:  0.5914512276649475   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7158 , Loss:  0.5914511680603027   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7159 , Loss:  0.591451108455658   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7160 , Loss:  0.591451108455658   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7161 , Loss:  0.5914510488510132   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7162 , Loss:  0.5914510488510132   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7163 , Loss:  0.5914509296417236   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7164 , Loss:  0.5914509296417236   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7165 , Loss:  0.5914508700370789   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7166 , Loss:  0.5914508700370789   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7167 , Loss:  0.5914508104324341   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7168 , Loss:  0.5914508104324341   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7169 , Loss:  0.5914507508277893   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7170 , Loss:  0.5914506912231445   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7171 , Loss:  0.5914506316184998   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7172 , Loss:  0.5914506316184998   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7173 , Loss:  0.5914506316184998   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7174 , Loss:  0.591450572013855   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7175 , Loss:  0.5914505124092102   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7176 , Loss:  0.5914504528045654   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7177 , Loss:  0.5914504528045654   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7178 , Loss:  0.5914503931999207   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7179 , Loss:  0.5914503335952759   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7180 , Loss:  0.5914503335952759   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7181 , Loss:  0.5914502739906311   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7182 , Loss:  0.5914502739906311   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7183 , Loss:  0.5914501547813416   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7184 , Loss:  0.5914501547813416   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7185 , Loss:  0.5914501547813416   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7186 , Loss:  0.5914500951766968   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7187 , Loss:  0.5914500951766968   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7188 , Loss:  0.5914499759674072   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7189 , Loss:  0.5914499759674072   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7190 , Loss:  0.5914499163627625   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7191 , Loss:  0.5914499163627625   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7192 , Loss:  0.5914498567581177   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7193 , Loss:  0.5914498567581177   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7194 , Loss:  0.5914497971534729   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7195 , Loss:  0.5914497375488281   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7196 , Loss:  0.5914497375488281   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7197 , Loss:  0.5914496779441833   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7198 , Loss:  0.5914496183395386   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7199 , Loss:  0.5914496183395386   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7200 , Loss:  0.5914496183395386   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7201 , Loss:  0.5914495587348938   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7202 , Loss:  0.591449499130249   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7203 , Loss:  0.5914494395256042   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7204 , Loss:  0.5914494395256042   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7205 , Loss:  0.5914493799209595   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7206 , Loss:  0.5914493799209595   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7207 , Loss:  0.5914492607116699   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7208 , Loss:  0.5914492607116699   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7209 , Loss:  0.5914492607116699   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7210 , Loss:  0.5914492011070251   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7211 , Loss:  0.5914492011070251   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7212 , Loss:  0.5914490818977356   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7213 , Loss:  0.5914490818977356   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7214 , Loss:  0.5914490818977356   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7215 , Loss:  0.5914490818977356   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7216 , Loss:  0.5914490222930908   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7217 , Loss:  0.591448962688446   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7218 , Loss:  0.591448962688446   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7219 , Loss:  0.5914489030838013   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7220 , Loss:  0.5914488434791565   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7221 , Loss:  0.5914488434791565   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7222 , Loss:  0.5914487838745117   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7223 , Loss:  0.5914487838745117   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7224 , Loss:  0.5914487838745117   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7225 , Loss:  0.5914486646652222   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7226 , Loss:  0.5914486646652222   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7227 , Loss:  0.5914486050605774   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7228 , Loss:  0.5914486050605774   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7229 , Loss:  0.5914486050605774   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7230 , Loss:  0.5914485454559326   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7231 , Loss:  0.5914484858512878   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7232 , Loss:  0.5914484262466431   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7233 , Loss:  0.5914484262466431   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7234 , Loss:  0.5914484262466431   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7235 , Loss:  0.5914483666419983   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7236 , Loss:  0.5914483070373535   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7237 , Loss:  0.5914482474327087   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7238 , Loss:  0.5914482474327087   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7239 , Loss:  0.591448187828064   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7240 , Loss:  0.5914481282234192   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7241 , Loss:  0.5914481282234192   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7242 , Loss:  0.5914480686187744   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7243 , Loss:  0.5914480686187744   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7244 , Loss:  0.5914480090141296   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7245 , Loss:  0.5914479494094849   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7246 , Loss:  0.5914479494094849   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7247 , Loss:  0.5914478898048401   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7248 , Loss:  0.5914478302001953   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7249 , Loss:  0.5914477705955505   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7250 , Loss:  0.5914477705955505   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7251 , Loss:  0.5914477109909058   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7252 , Loss:  0.5914475917816162   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7253 , Loss:  0.5914475917816162   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7254 , Loss:  0.5914475321769714   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7255 , Loss:  0.5914474129676819   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7256 , Loss:  0.5914472937583923   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7257 , Loss:  0.5914471745491028   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7258 , Loss:  0.5914469957351685   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7259 , Loss:  0.5914467573165894   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7260 , Loss:  0.5914462208747864   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7261 , Loss:  0.59144526720047   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7262 , Loss:  0.5914427638053894   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7263 , Loss:  0.5914353132247925   f1-score: 0.9164191484451294   accuracy: 0.9467567801475525\n",
      "Epoch:  7264 , Loss:  0.5914231538772583   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7265 , Loss:  0.5914186835289001   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7266 , Loss:  0.591418981552124   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7267 , Loss:  0.5914214849472046   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7268 , Loss:  0.5914205312728882   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7269 , Loss:  0.5914222002029419   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7270 , Loss:  0.5914205312728882   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7271 , Loss:  0.5914202332496643   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7272 , Loss:  0.5914195775985718   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7273 , Loss:  0.5914182066917419   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7274 , Loss:  0.5914185047149658   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7275 , Loss:  0.5914174318313599   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7276 , Loss:  0.5914174914360046   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7277 , Loss:  0.5914174318313599   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7278 , Loss:  0.5914168953895569   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7279 , Loss:  0.591417133808136   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7280 , Loss:  0.591416597366333   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7281 , Loss:  0.5914163589477539   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7282 , Loss:  0.5914162397384644   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7283 , Loss:  0.5914157032966614   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7284 , Loss:  0.5914157032966614   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7285 , Loss:  0.5914153456687927   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7286 , Loss:  0.5914150476455688   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7287 , Loss:  0.5914150476455688   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7288 , Loss:  0.5914146900177002   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7289 , Loss:  0.5914146900177002   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7290 , Loss:  0.5914145112037659   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7291 , Loss:  0.5914143323898315   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7292 , Loss:  0.5914143323898315   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7293 , Loss:  0.5914141535758972   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7294 , Loss:  0.5914140343666077   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7295 , Loss:  0.5914139151573181   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7296 , Loss:  0.5914137363433838   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7297 , Loss:  0.591413676738739   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7298 , Loss:  0.5914135575294495   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7299 , Loss:  0.5914133787155151   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7300 , Loss:  0.5914133191108704   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7301 , Loss:  0.5914131999015808   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7302 , Loss:  0.591413140296936   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7303 , Loss:  0.591413140296936   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7304 , Loss:  0.5914130210876465   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7305 , Loss:  0.5914130210876465   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7306 , Loss:  0.5914129614830017   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7307 , Loss:  0.5914128422737122   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7308 , Loss:  0.5914128422737122   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7309 , Loss:  0.5914127826690674   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7310 , Loss:  0.5914126634597778   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7311 , Loss:  0.5914126634597778   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7312 , Loss:  0.5914126038551331   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7313 , Loss:  0.5914126038551331   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7314 , Loss:  0.5914125442504883   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7315 , Loss:  0.5914124846458435   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7316 , Loss:  0.5914124250411987   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7317 , Loss:  0.5914124250411987   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7318 , Loss:  0.591412365436554   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7319 , Loss:  0.591412365436554   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7320 , Loss:  0.5914123058319092   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7321 , Loss:  0.5914122462272644   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7322 , Loss:  0.5914122462272644   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7323 , Loss:  0.5914121866226196   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7324 , Loss:  0.5914121270179749   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7325 , Loss:  0.5914121866226196   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7326 , Loss:  0.5914120674133301   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7327 , Loss:  0.5914120674133301   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7328 , Loss:  0.5914120078086853   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7329 , Loss:  0.5914120078086853   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7330 , Loss:  0.5914120078086853   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7331 , Loss:  0.5914118885993958   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7332 , Loss:  0.5914118885993958   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7333 , Loss:  0.591411828994751   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7334 , Loss:  0.591411828994751   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7335 , Loss:  0.5914117693901062   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7336 , Loss:  0.5914117097854614   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7337 , Loss:  0.5914117097854614   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7338 , Loss:  0.5914116501808167   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7339 , Loss:  0.5914116501808167   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7340 , Loss:  0.5914116501808167   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7341 , Loss:  0.5914115905761719   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7342 , Loss:  0.5914115309715271   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7343 , Loss:  0.5914115309715271   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7344 , Loss:  0.5914114713668823   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7345 , Loss:  0.5914114713668823   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7346 , Loss:  0.5914114713668823   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7347 , Loss:  0.5914114117622375   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7348 , Loss:  0.5914113521575928   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7349 , Loss:  0.5914113521575928   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7350 , Loss:  0.591411292552948   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7351 , Loss:  0.591411292552948   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7352 , Loss:  0.5914112329483032   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7353 , Loss:  0.5914112329483032   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7354 , Loss:  0.5914111733436584   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7355 , Loss:  0.5914111733436584   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7356 , Loss:  0.5914111733436584   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7357 , Loss:  0.5914111137390137   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7358 , Loss:  0.5914110541343689   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7359 , Loss:  0.5914110541343689   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7360 , Loss:  0.5914109945297241   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7361 , Loss:  0.5914109945297241   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7362 , Loss:  0.5914109945297241   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7363 , Loss:  0.5914109349250793   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7364 , Loss:  0.5914108753204346   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7365 , Loss:  0.5914108753204346   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7366 , Loss:  0.5914108157157898   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7367 , Loss:  0.5914108157157898   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7368 , Loss:  0.5914108157157898   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7369 , Loss:  0.591410756111145   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7370 , Loss:  0.5914106965065002   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7371 , Loss:  0.5914106369018555   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7372 , Loss:  0.5914106369018555   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7373 , Loss:  0.5914106369018555   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7374 , Loss:  0.5914106369018555   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7375 , Loss:  0.5914106369018555   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7376 , Loss:  0.5914105176925659   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7377 , Loss:  0.5914105176925659   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7378 , Loss:  0.5914104580879211   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7379 , Loss:  0.5914104580879211   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7380 , Loss:  0.5914104580879211   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7381 , Loss:  0.5914103984832764   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7382 , Loss:  0.5914103984832764   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7383 , Loss:  0.5914103388786316   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7384 , Loss:  0.5914103388786316   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7385 , Loss:  0.5914103388786316   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7386 , Loss:  0.5914102792739868   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7387 , Loss:  0.591410219669342   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7388 , Loss:  0.591410219669342   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7389 , Loss:  0.5914101600646973   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7390 , Loss:  0.5914101600646973   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7391 , Loss:  0.5914101600646973   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7392 , Loss:  0.5914101600646973   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7393 , Loss:  0.5914100408554077   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7394 , Loss:  0.5914100408554077   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7395 , Loss:  0.5914099812507629   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7396 , Loss:  0.5914099812507629   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7397 , Loss:  0.5914099812507629   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7398 , Loss:  0.5914098620414734   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7399 , Loss:  0.5914098620414734   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7400 , Loss:  0.5914098024368286   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7401 , Loss:  0.5914098024368286   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7402 , Loss:  0.5914098024368286   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7403 , Loss:  0.5914097428321838   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7404 , Loss:  0.5914096832275391   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7405 , Loss:  0.5914096832275391   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7406 , Loss:  0.5914096236228943   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7407 , Loss:  0.5914096236228943   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7408 , Loss:  0.5914095640182495   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7409 , Loss:  0.5914095044136047   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7410 , Loss:  0.5914095044136047   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7411 , Loss:  0.59140944480896   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7412 , Loss:  0.5914093852043152   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7413 , Loss:  0.5914093255996704   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7414 , Loss:  0.5914093255996704   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7415 , Loss:  0.5914092063903809   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7416 , Loss:  0.5914091467857361   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7417 , Loss:  0.5914090871810913   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7418 , Loss:  0.5914089679718018   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7419 , Loss:  0.591408908367157   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7420 , Loss:  0.5914087891578674   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7421 , Loss:  0.5914086103439331   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7422 , Loss:  0.5914084315299988   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7423 , Loss:  0.5914081335067749   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7424 , Loss:  0.5914077758789062   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7425 , Loss:  0.5914071202278137   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7426 , Loss:  0.5914059281349182   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7427 , Loss:  0.5914036631584167   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7428 , Loss:  0.5913982391357422   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7429 , Loss:  0.5913858413696289   f1-score: 0.9165723919868469   accuracy: 0.9468468427658081\n",
      "Epoch:  7430 , Loss:  0.5913740396499634   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7431 , Loss:  0.5913659334182739   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7432 , Loss:  0.5913689136505127   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7433 , Loss:  0.5913693308830261   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7434 , Loss:  0.5913704633712769   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7435 , Loss:  0.5913705229759216   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7436 , Loss:  0.5913683176040649   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7437 , Loss:  0.5913684368133545   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7438 , Loss:  0.5913655757904053   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7439 , Loss:  0.5913660526275635   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7440 , Loss:  0.5913640260696411   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7441 , Loss:  0.5913636088371277   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7442 , Loss:  0.5913629531860352   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7443 , Loss:  0.591361403465271   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7444 , Loss:  0.5913614630699158   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7445 , Loss:  0.5913601517677307   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7446 , Loss:  0.5913596749305725   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7447 , Loss:  0.5913594961166382   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7448 , Loss:  0.5913586616516113   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7449 , Loss:  0.5913587212562561   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7450 , Loss:  0.5913583040237427   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7451 , Loss:  0.5913578867912292   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7452 , Loss:  0.591357946395874   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7453 , Loss:  0.5913574695587158   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7454 , Loss:  0.5913572311401367   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7455 , Loss:  0.5913571715354919   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7456 , Loss:  0.5913568139076233   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7457 , Loss:  0.5913567543029785   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7458 , Loss:  0.591356635093689   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7459 , Loss:  0.5913563966751099   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7460 , Loss:  0.5913563370704651   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7461 , Loss:  0.5913561582565308   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7462 , Loss:  0.5913559198379517   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7463 , Loss:  0.5913558602333069   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7464 , Loss:  0.5913556814193726   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7465 , Loss:  0.591355562210083   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7466 , Loss:  0.5913555026054382   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7467 , Loss:  0.5913552641868591   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7468 , Loss:  0.5913552641868591   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7469 , Loss:  0.5913551449775696   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7470 , Loss:  0.5913550853729248   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7471 , Loss:  0.5913549661636353   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7472 , Loss:  0.5913549065589905   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7473 , Loss:  0.5913547873497009   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7474 , Loss:  0.5913547873497009   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7475 , Loss:  0.5913547277450562   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7476 , Loss:  0.5913546085357666   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7477 , Loss:  0.5913545489311218   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7478 , Loss:  0.591354489326477   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7479 , Loss:  0.5913544297218323   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7480 , Loss:  0.5913544297218323   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7481 , Loss:  0.5913543701171875   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7482 , Loss:  0.591354250907898   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7483 , Loss:  0.591354250907898   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7484 , Loss:  0.5913541913032532   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7485 , Loss:  0.5913540720939636   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7486 , Loss:  0.5913540720939636   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7487 , Loss:  0.5913540124893188   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7488 , Loss:  0.5913540124893188   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7489 , Loss:  0.5913538932800293   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7490 , Loss:  0.5913538932800293   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7491 , Loss:  0.5913538932800293   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7492 , Loss:  0.5913538336753845   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7493 , Loss:  0.5913537740707397   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7494 , Loss:  0.591353714466095   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7495 , Loss:  0.5913536548614502   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7496 , Loss:  0.5913535952568054   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7497 , Loss:  0.5913535356521606   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7498 , Loss:  0.5913535356521606   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7499 , Loss:  0.5913535356521606   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7500 , Loss:  0.5913534760475159   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7501 , Loss:  0.5913534760475159   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7502 , Loss:  0.5913534164428711   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7503 , Loss:  0.5913534164428711   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7504 , Loss:  0.5913533568382263   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7505 , Loss:  0.5913532972335815   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7506 , Loss:  0.5913532376289368   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7507 , Loss:  0.5913532376289368   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7508 , Loss:  0.5913532376289368   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7509 , Loss:  0.591353178024292   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7510 , Loss:  0.5913531184196472   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7511 , Loss:  0.5913530588150024   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7512 , Loss:  0.5913530588150024   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7513 , Loss:  0.5913530588150024   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7514 , Loss:  0.5913529992103577   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7515 , Loss:  0.5913529396057129   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7516 , Loss:  0.5913529396057129   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7517 , Loss:  0.5913528800010681   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7518 , Loss:  0.5913528800010681   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7519 , Loss:  0.5913528203964233   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7520 , Loss:  0.5913527607917786   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7521 , Loss:  0.5913527607917786   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7522 , Loss:  0.5913527011871338   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7523 , Loss:  0.5913527011871338   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7524 , Loss:  0.5913527011871338   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7525 , Loss:  0.5913525819778442   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7526 , Loss:  0.5913525819778442   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7527 , Loss:  0.5913525819778442   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7528 , Loss:  0.5913525223731995   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7529 , Loss:  0.5913525223731995   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7530 , Loss:  0.5913525223731995   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7531 , Loss:  0.5913524627685547   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7532 , Loss:  0.5913524031639099   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7533 , Loss:  0.5913524031639099   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7534 , Loss:  0.5913524031639099   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7535 , Loss:  0.5913523435592651   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7536 , Loss:  0.5913523435592651   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7537 , Loss:  0.5913523435592651   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7538 , Loss:  0.5913522243499756   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7539 , Loss:  0.5913522243499756   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7540 , Loss:  0.5913522243499756   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7541 , Loss:  0.5913521647453308   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7542 , Loss:  0.5913521647453308   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7543 , Loss:  0.5913520455360413   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7544 , Loss:  0.5913520455360413   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7545 , Loss:  0.5913520455360413   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7546 , Loss:  0.5913520455360413   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7547 , Loss:  0.5913519859313965   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7548 , Loss:  0.5913519263267517   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7549 , Loss:  0.5913519263267517   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7550 , Loss:  0.5913518667221069   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7551 , Loss:  0.5913518667221069   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7552 , Loss:  0.5913518667221069   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7553 , Loss:  0.5913518667221069   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7554 , Loss:  0.5913518071174622   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7555 , Loss:  0.5913517475128174   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7556 , Loss:  0.5913516879081726   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7557 , Loss:  0.5913516879081726   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7558 , Loss:  0.5913516879081726   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7559 , Loss:  0.5913516879081726   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7560 , Loss:  0.5913516283035278   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7561 , Loss:  0.5913516283035278   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7562 , Loss:  0.5913515686988831   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7563 , Loss:  0.5913515686988831   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7564 , Loss:  0.5913515686988831   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7565 , Loss:  0.5913515686988831   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7566 , Loss:  0.5913515090942383   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7567 , Loss:  0.5913514494895935   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7568 , Loss:  0.5913514494895935   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7569 , Loss:  0.5913513898849487   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7570 , Loss:  0.5913513898849487   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7571 , Loss:  0.591351330280304   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7572 , Loss:  0.591351330280304   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7573 , Loss:  0.5913512706756592   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7574 , Loss:  0.5913512706756592   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7575 , Loss:  0.5913512706756592   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7576 , Loss:  0.5913512110710144   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7577 , Loss:  0.5913512110710144   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7578 , Loss:  0.5913511514663696   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7579 , Loss:  0.5913511514663696   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7580 , Loss:  0.5913510918617249   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7581 , Loss:  0.5913510918617249   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7582 , Loss:  0.5913510322570801   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7583 , Loss:  0.5913510322570801   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7584 , Loss:  0.5913510322570801   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7585 , Loss:  0.5913509726524353   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7586 , Loss:  0.5913509726524353   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7587 , Loss:  0.5913509130477905   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7588 , Loss:  0.5913508534431458   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7589 , Loss:  0.5913508534431458   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7590 , Loss:  0.5913508534431458   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7591 , Loss:  0.591350793838501   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7592 , Loss:  0.5913507342338562   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7593 , Loss:  0.5913507342338562   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7594 , Loss:  0.5913507342338562   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7595 , Loss:  0.5913506746292114   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7596 , Loss:  0.5913506746292114   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7597 , Loss:  0.5913506746292114   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7598 , Loss:  0.5913505554199219   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7599 , Loss:  0.5913505554199219   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7600 , Loss:  0.5913505554199219   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7601 , Loss:  0.5913505554199219   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7602 , Loss:  0.5913504958152771   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7603 , Loss:  0.5913504362106323   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7604 , Loss:  0.5913503766059875   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7605 , Loss:  0.5913503766059875   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7606 , Loss:  0.5913503170013428   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7607 , Loss:  0.5913503170013428   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7608 , Loss:  0.5913501977920532   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7609 , Loss:  0.5913501977920532   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7610 , Loss:  0.5913501381874084   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7611 , Loss:  0.5913501381874084   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7612 , Loss:  0.5913500189781189   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7613 , Loss:  0.5913499593734741   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7614 , Loss:  0.5913498997688293   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7615 , Loss:  0.5913497805595398   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7616 , Loss:  0.591349720954895   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7617 , Loss:  0.5913495421409607   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7618 , Loss:  0.5913494229316711   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7619 , Loss:  0.591349184513092   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7620 , Loss:  0.5913488268852234   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7621 , Loss:  0.5913483500480652   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7622 , Loss:  0.5913475751876831   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7623 , Loss:  0.5913461446762085   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7624 , Loss:  0.591343343257904   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7625 , Loss:  0.5913383364677429   f1-score: 0.9167020320892334   accuracy: 0.9469369649887085\n",
      "Epoch:  7626 , Loss:  0.5913321375846863   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7627 , Loss:  0.5913278460502625   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7628 , Loss:  0.5913261771202087   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7629 , Loss:  0.5913275480270386   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7630 , Loss:  0.5913277864456177   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7631 , Loss:  0.5913283824920654   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7632 , Loss:  0.5913282036781311   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7633 , Loss:  0.5913270115852356   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7634 , Loss:  0.5913262963294983   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7635 , Loss:  0.5913248062133789   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7636 , Loss:  0.5913240313529968   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7637 , Loss:  0.59132319688797   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7638 , Loss:  0.5913224816322327   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7639 , Loss:  0.5913224220275879   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7640 , Loss:  0.5913220643997192   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7641 , Loss:  0.5913220047950745   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7642 , Loss:  0.5913220047950745   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7643 , Loss:  0.5913216471672058   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7644 , Loss:  0.5913215279579163   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7645 , Loss:  0.5913211703300476   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7646 , Loss:  0.5913206338882446   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7647 , Loss:  0.5913203358650208   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7648 , Loss:  0.5913199782371521   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7649 , Loss:  0.5913196802139282   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7650 , Loss:  0.5913195013999939   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7651 , Loss:  0.5913193225860596   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7652 , Loss:  0.5913192629814148   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7653 , Loss:  0.5913191437721252   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7654 , Loss:  0.5913189649581909   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7655 , Loss:  0.5913189053535461   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7656 , Loss:  0.5913187861442566   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7657 , Loss:  0.591318666934967   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7658 , Loss:  0.5913185477256775   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7659 , Loss:  0.5913183689117432   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7660 , Loss:  0.5913181900978088   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7661 , Loss:  0.5913181304931641   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7662 , Loss:  0.5913180112838745   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7663 , Loss:  0.5913178324699402   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7664 , Loss:  0.5913177728652954   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7665 , Loss:  0.5913176536560059   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7666 , Loss:  0.5913176536560059   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7667 , Loss:  0.5913175344467163   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7668 , Loss:  0.5913174748420715   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7669 , Loss:  0.591317355632782   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7670 , Loss:  0.5913172960281372   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7671 , Loss:  0.5913171172142029   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7672 , Loss:  0.5913171172142029   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7673 , Loss:  0.5913169384002686   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7674 , Loss:  0.5913168787956238   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7675 , Loss:  0.591316819190979   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7676 , Loss:  0.5913166999816895   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7677 , Loss:  0.5913166403770447   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7678 , Loss:  0.5913165211677551   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7679 , Loss:  0.5913164615631104   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7680 , Loss:  0.591316282749176   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7681 , Loss:  0.5913161635398865   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7682 , Loss:  0.5913159847259521   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7683 , Loss:  0.5913158059120178   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7684 , Loss:  0.5913156270980835   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7685 , Loss:  0.5913153886795044   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7686 , Loss:  0.591314971446991   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7687 , Loss:  0.5913145542144775   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7688 , Loss:  0.591313898563385   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7689 , Loss:  0.591312825679779   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7690 , Loss:  0.5913113355636597   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7691 , Loss:  0.5913087129592896   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7692 , Loss:  0.5913048386573792   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7693 , Loss:  0.5912986397743225   f1-score: 0.9168552160263062   accuracy: 0.9470270276069641\n",
      "Epoch:  7694 , Loss:  0.5912914872169495   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7695 , Loss:  0.5912849307060242   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7696 , Loss:  0.5912821292877197   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7697 , Loss:  0.591282308101654   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7698 , Loss:  0.5912824869155884   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7699 , Loss:  0.5912821888923645   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7700 , Loss:  0.591280460357666   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7701 , Loss:  0.5912784934043884   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7702 , Loss:  0.591276228427887   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7703 , Loss:  0.591274619102478   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7704 , Loss:  0.5912733674049377   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7705 , Loss:  0.5912727117538452   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7706 , Loss:  0.5912724137306213   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7707 , Loss:  0.5912721753120422   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7708 , Loss:  0.5912719964981079   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7709 , Loss:  0.5912715792655945   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7710 , Loss:  0.5912709832191467   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7711 , Loss:  0.5912703275680542   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7712 , Loss:  0.5912695527076721   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7713 , Loss:  0.5912689566612244   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7714 , Loss:  0.5912682414054871   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7715 , Loss:  0.5912677645683289   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7716 , Loss:  0.5912672877311707   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7717 , Loss:  0.591266930103302   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7718 , Loss:  0.5912667512893677   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7719 , Loss:  0.5912664532661438   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7720 , Loss:  0.5912662744522095   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7721 , Loss:  0.5912660956382751   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7722 , Loss:  0.5912657380104065   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7723 , Loss:  0.5912654399871826   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7724 , Loss:  0.5912649631500244   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7725 , Loss:  0.591264545917511   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7726 , Loss:  0.5912640690803528   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7727 , Loss:  0.5912635922431946   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7728 , Loss:  0.5912628769874573   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7729 , Loss:  0.5912620425224304   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7730 , Loss:  0.5912609100341797   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7731 , Loss:  0.5912590622901917   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7732 , Loss:  0.5912562608718872   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7733 , Loss:  0.5912521481513977   f1-score: 0.9169848561286926   accuracy: 0.9471170902252197\n",
      "Epoch:  7734 , Loss:  0.5912476181983948   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7735 , Loss:  0.5912443995475769   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7736 , Loss:  0.5912431478500366   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7737 , Loss:  0.5912431478500366   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7738 , Loss:  0.5912434458732605   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7739 , Loss:  0.59124356508255   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7740 , Loss:  0.5912431478500366   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7741 , Loss:  0.5912424325942993   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7742 , Loss:  0.5912414193153381   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7743 , Loss:  0.5912402868270874   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7744 , Loss:  0.5912392735481262   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7745 , Loss:  0.5912383794784546   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7746 , Loss:  0.5912377238273621   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7747 , Loss:  0.5912371873855591   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7748 , Loss:  0.5912367105484009   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7749 , Loss:  0.591236412525177   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7750 , Loss:  0.5912361145019531   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7751 , Loss:  0.5912358164787292   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7752 , Loss:  0.5912355184555054   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7753 , Loss:  0.5912351608276367   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7754 , Loss:  0.5912347435951233   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7755 , Loss:  0.5912343859672546   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7756 , Loss:  0.591234028339386   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7757 , Loss:  0.5912337303161621   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7758 , Loss:  0.591233491897583   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7759 , Loss:  0.5912333130836487   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7760 , Loss:  0.5912330746650696   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7761 , Loss:  0.59123295545578   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7762 , Loss:  0.5912326574325562   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7763 , Loss:  0.5912325382232666   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7764 , Loss:  0.5912323594093323   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7765 , Loss:  0.591232180595398   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7766 , Loss:  0.5912320017814636   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7767 , Loss:  0.5912318229675293   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7768 , Loss:  0.5912315845489502   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7769 , Loss:  0.5912314653396606   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7770 , Loss:  0.5912312865257263   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7771 , Loss:  0.591231107711792   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7772 , Loss:  0.5912309288978577   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7773 , Loss:  0.5912307500839233   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7774 , Loss:  0.5912305116653442   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7775 , Loss:  0.5912302732467651   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7776 , Loss:  0.591230034828186   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7777 , Loss:  0.5912297368049622   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7778 , Loss:  0.5912293791770935   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7779 , Loss:  0.5912289023399353   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7780 , Loss:  0.5912282466888428   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7781 , Loss:  0.591227114200592   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7782 , Loss:  0.5912253260612488   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7783 , Loss:  0.5912222266197205   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7784 , Loss:  0.591217577457428   f1-score: 0.9171379804611206   accuracy: 0.9472072124481201\n",
      "Epoch:  7785 , Loss:  0.5912124514579773   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7786 , Loss:  0.5912091135978699   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7787 , Loss:  0.5912087559700012   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7788 , Loss:  0.5912089943885803   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7789 , Loss:  0.5912091732025146   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7790 , Loss:  0.591208815574646   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7791 , Loss:  0.5912078619003296   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7792 , Loss:  0.5912069082260132   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7793 , Loss:  0.5912057757377625   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7794 , Loss:  0.5912049412727356   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7795 , Loss:  0.5912041664123535   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7796 , Loss:  0.5912036299705505   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7797 , Loss:  0.5912032127380371   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7798 , Loss:  0.5912027955055237   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7799 , Loss:  0.591202437877655   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7800 , Loss:  0.5912019610404968   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7801 , Loss:  0.5912016034126282   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7802 , Loss:  0.5912011861801147   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7803 , Loss:  0.5912008285522461   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7804 , Loss:  0.5912004709243774   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7805 , Loss:  0.5912001132965088   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7806 , Loss:  0.5911999344825745   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7807 , Loss:  0.5911995768547058   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7808 , Loss:  0.5911993384361267   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7809 , Loss:  0.5911991000175476   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7810 , Loss:  0.5911988615989685   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7811 , Loss:  0.591198742389679   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7812 , Loss:  0.5911985635757446   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7813 , Loss:  0.5911984443664551   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7814 , Loss:  0.5911982655525208   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7815 , Loss:  0.5911980867385864   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7816 , Loss:  0.5911979079246521   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7817 , Loss:  0.5911977291107178   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7818 , Loss:  0.5911975502967834   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7819 , Loss:  0.5911974906921387   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7820 , Loss:  0.5911973118782043   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7821 , Loss:  0.5911972522735596   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7822 , Loss:  0.59119713306427   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7823 , Loss:  0.5911970734596252   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7824 , Loss:  0.5911969542503357   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7825 , Loss:  0.5911967754364014   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7826 , Loss:  0.5911967158317566   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7827 , Loss:  0.591196596622467   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7828 , Loss:  0.5911965370178223   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7829 , Loss:  0.5911964178085327   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7830 , Loss:  0.5911963582038879   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7831 , Loss:  0.5911962389945984   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7832 , Loss:  0.5911961793899536   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7833 , Loss:  0.5911960601806641   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7834 , Loss:  0.5911960005760193   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7835 , Loss:  0.5911958813667297   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7836 , Loss:  0.5911958813667297   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7837 , Loss:  0.5911957025527954   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7838 , Loss:  0.5911957025527954   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7839 , Loss:  0.5911955833435059   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7840 , Loss:  0.5911955833435059   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7841 , Loss:  0.5911954641342163   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7842 , Loss:  0.5911954045295715   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7843 , Loss:  0.5911953449249268   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7844 , Loss:  0.591195285320282   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7845 , Loss:  0.5911952257156372   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7846 , Loss:  0.5911951065063477   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7847 , Loss:  0.5911950469017029   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7848 , Loss:  0.5911950469017029   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7849 , Loss:  0.5911949276924133   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7850 , Loss:  0.5911948680877686   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7851 , Loss:  0.5911948084831238   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7852 , Loss:  0.591194748878479   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7853 , Loss:  0.5911946892738342   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7854 , Loss:  0.5911946296691895   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7855 , Loss:  0.5911945700645447   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7856 , Loss:  0.5911945700645447   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7857 , Loss:  0.5911945104598999   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7858 , Loss:  0.5911943912506104   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7859 , Loss:  0.5911943912506104   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7860 , Loss:  0.5911943316459656   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7861 , Loss:  0.5911943316459656   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7862 , Loss:  0.591194212436676   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7863 , Loss:  0.5911941528320312   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7864 , Loss:  0.5911940932273865   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7865 , Loss:  0.5911940336227417   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7866 , Loss:  0.5911939740180969   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7867 , Loss:  0.5911939740180969   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7868 , Loss:  0.5911938548088074   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7869 , Loss:  0.5911938548088074   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7870 , Loss:  0.5911937952041626   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7871 , Loss:  0.5911937952041626   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7872 , Loss:  0.5911937355995178   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7873 , Loss:  0.591193675994873   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7874 , Loss:  0.591193675994873   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7875 , Loss:  0.5911936163902283   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7876 , Loss:  0.5911935567855835   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7877 , Loss:  0.5911934971809387   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7878 , Loss:  0.591193437576294   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7879 , Loss:  0.591193437576294   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7880 , Loss:  0.5911933779716492   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7881 , Loss:  0.5911933779716492   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7882 , Loss:  0.5911933183670044   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7883 , Loss:  0.5911931991577148   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7884 , Loss:  0.5911931991577148   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7885 , Loss:  0.5911931991577148   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7886 , Loss:  0.5911930799484253   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7887 , Loss:  0.5911930799484253   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7888 , Loss:  0.5911930203437805   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7889 , Loss:  0.5911930203437805   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7890 , Loss:  0.5911929607391357   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7891 , Loss:  0.591192901134491   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7892 , Loss:  0.591192901134491   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7893 , Loss:  0.5911928415298462   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7894 , Loss:  0.5911928415298462   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7895 , Loss:  0.5911927223205566   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7896 , Loss:  0.5911927223205566   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7897 , Loss:  0.5911926627159119   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7898 , Loss:  0.5911926627159119   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7899 , Loss:  0.5911926031112671   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7900 , Loss:  0.5911925435066223   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7901 , Loss:  0.5911925435066223   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7902 , Loss:  0.5911924839019775   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7903 , Loss:  0.5911924839019775   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7904 , Loss:  0.5911924242973328   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7905 , Loss:  0.591192364692688   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7906 , Loss:  0.591192364692688   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7907 , Loss:  0.5911923050880432   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7908 , Loss:  0.5911923050880432   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7909 , Loss:  0.5911921858787537   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7910 , Loss:  0.5911921858787537   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7911 , Loss:  0.5911921858787537   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7912 , Loss:  0.5911921262741089   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7913 , Loss:  0.5911921262741089   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7914 , Loss:  0.5911920070648193   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7915 , Loss:  0.5911920070648193   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7916 , Loss:  0.5911920070648193   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7917 , Loss:  0.5911919474601746   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7918 , Loss:  0.5911919474601746   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7919 , Loss:  0.5911918878555298   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7920 , Loss:  0.5911918878555298   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7921 , Loss:  0.591191828250885   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7922 , Loss:  0.5911917686462402   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7923 , Loss:  0.5911917090415955   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7924 , Loss:  0.5911917090415955   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7925 , Loss:  0.5911917090415955   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7926 , Loss:  0.5911917090415955   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7927 , Loss:  0.5911916494369507   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7928 , Loss:  0.5911915898323059   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7929 , Loss:  0.5911915302276611   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7930 , Loss:  0.5911915302276611   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7931 , Loss:  0.5911915302276611   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7932 , Loss:  0.5911914706230164   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7933 , Loss:  0.5911914110183716   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7934 , Loss:  0.5911913514137268   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7935 , Loss:  0.5911913514137268   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7936 , Loss:  0.5911913514137268   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7937 , Loss:  0.5911913514137268   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7938 , Loss:  0.5911912322044373   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7939 , Loss:  0.5911912322044373   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7940 , Loss:  0.5911912322044373   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7941 , Loss:  0.5911911725997925   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7942 , Loss:  0.5911911725997925   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7943 , Loss:  0.5911911725997925   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7944 , Loss:  0.5911911129951477   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7945 , Loss:  0.5911910533905029   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7946 , Loss:  0.5911910533905029   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7947 , Loss:  0.5911910533905029   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7948 , Loss:  0.5911909937858582   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7949 , Loss:  0.5911909341812134   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7950 , Loss:  0.5911909341812134   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7951 , Loss:  0.5911908745765686   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7952 , Loss:  0.5911908745765686   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7953 , Loss:  0.5911908745765686   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7954 , Loss:  0.5911908149719238   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7955 , Loss:  0.591190755367279   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7956 , Loss:  0.591190755367279   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7957 , Loss:  0.5911906957626343   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7958 , Loss:  0.5911906957626343   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7959 , Loss:  0.5911906957626343   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7960 , Loss:  0.5911906361579895   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7961 , Loss:  0.5911905765533447   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7962 , Loss:  0.5911905765533447   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7963 , Loss:  0.5911905169487   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7964 , Loss:  0.5911905169487   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7965 , Loss:  0.5911904573440552   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7966 , Loss:  0.5911904573440552   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7967 , Loss:  0.5911904573440552   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7968 , Loss:  0.5911903977394104   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7969 , Loss:  0.5911903381347656   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7970 , Loss:  0.5911903381347656   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7971 , Loss:  0.5911903381347656   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7972 , Loss:  0.5911903381347656   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7973 , Loss:  0.5911902785301208   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7974 , Loss:  0.5911902189254761   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7975 , Loss:  0.5911902189254761   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7976 , Loss:  0.5911901593208313   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7977 , Loss:  0.5911901593208313   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7978 , Loss:  0.5911901593208313   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7979 , Loss:  0.5911900997161865   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7980 , Loss:  0.5911900997161865   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7981 , Loss:  0.5911900997161865   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7982 , Loss:  0.5911900401115417   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7983 , Loss:  0.5911900401115417   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7984 , Loss:  0.5911900401115417   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7985 , Loss:  0.591189980506897   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7986 , Loss:  0.5911899209022522   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7987 , Loss:  0.5911899209022522   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7988 , Loss:  0.5911898612976074   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7989 , Loss:  0.5911898612976074   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7990 , Loss:  0.5911898612976074   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7991 , Loss:  0.5911898612976074   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7992 , Loss:  0.5911897420883179   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7993 , Loss:  0.5911897420883179   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7994 , Loss:  0.5911897420883179   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7995 , Loss:  0.5911896824836731   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7996 , Loss:  0.5911896824836731   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7997 , Loss:  0.5911896824836731   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7998 , Loss:  0.5911896824836731   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  7999 , Loss:  0.5911896228790283   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8000 , Loss:  0.5911895632743835   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8001 , Loss:  0.5911895632743835   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8002 , Loss:  0.5911895036697388   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8003 , Loss:  0.5911895036697388   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8004 , Loss:  0.5911895036697388   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8005 , Loss:  0.5911895036697388   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8006 , Loss:  0.5911893844604492   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8007 , Loss:  0.5911893844604492   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8008 , Loss:  0.5911893844604492   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8009 , Loss:  0.5911893248558044   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8010 , Loss:  0.5911893248558044   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8011 , Loss:  0.5911893248558044   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8012 , Loss:  0.5911893248558044   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8013 , Loss:  0.5911893248558044   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8014 , Loss:  0.5911892652511597   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8015 , Loss:  0.5911892056465149   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8016 , Loss:  0.5911892056465149   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8017 , Loss:  0.5911892056465149   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8018 , Loss:  0.5911891460418701   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8019 , Loss:  0.5911891460418701   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8020 , Loss:  0.5911891460418701   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8021 , Loss:  0.5911890864372253   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8022 , Loss:  0.5911890268325806   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8023 , Loss:  0.5911890268325806   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8024 , Loss:  0.5911890268325806   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8025 , Loss:  0.5911890268325806   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8026 , Loss:  0.5911889672279358   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8027 , Loss:  0.5911889672279358   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8028 , Loss:  0.5911889672279358   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8029 , Loss:  0.5911889672279358   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8030 , Loss:  0.5911888480186462   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8031 , Loss:  0.5911888480186462   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8032 , Loss:  0.5911888480186462   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8033 , Loss:  0.5911888480186462   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8034 , Loss:  0.5911888480186462   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8035 , Loss:  0.5911887884140015   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8036 , Loss:  0.5911887884140015   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8037 , Loss:  0.5911887288093567   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8038 , Loss:  0.5911887288093567   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8039 , Loss:  0.5911886692047119   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8040 , Loss:  0.5911886692047119   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8041 , Loss:  0.5911886692047119   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8042 , Loss:  0.5911886692047119   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8043 , Loss:  0.5911886096000671   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8044 , Loss:  0.5911886096000671   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8045 , Loss:  0.5911885499954224   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8046 , Loss:  0.5911885499954224   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8047 , Loss:  0.5911884903907776   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8048 , Loss:  0.5911884903907776   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8049 , Loss:  0.5911884903907776   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8050 , Loss:  0.5911884903907776   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8051 , Loss:  0.5911884307861328   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8052 , Loss:  0.5911884307861328   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8053 , Loss:  0.591188371181488   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8054 , Loss:  0.591188371181488   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8055 , Loss:  0.5911883115768433   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8056 , Loss:  0.5911883115768433   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8057 , Loss:  0.5911883115768433   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8058 , Loss:  0.5911883115768433   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8059 , Loss:  0.5911882519721985   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8060 , Loss:  0.5911882519721985   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8061 , Loss:  0.5911882519721985   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8062 , Loss:  0.5911881923675537   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8063 , Loss:  0.5911881923675537   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8064 , Loss:  0.5911881923675537   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8065 , Loss:  0.5911881923675537   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8066 , Loss:  0.5911881923675537   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8067 , Loss:  0.5911880731582642   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8068 , Loss:  0.5911880731582642   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8069 , Loss:  0.5911880731582642   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8070 , Loss:  0.5911880731582642   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8071 , Loss:  0.5911880135536194   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8072 , Loss:  0.5911880135536194   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8073 , Loss:  0.5911880135536194   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8074 , Loss:  0.5911880135536194   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8075 , Loss:  0.5911879539489746   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8076 , Loss:  0.5911878943443298   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8077 , Loss:  0.5911878943443298   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8078 , Loss:  0.5911878943443298   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8079 , Loss:  0.5911878943443298   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8080 , Loss:  0.5911878347396851   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8081 , Loss:  0.5911878347396851   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8082 , Loss:  0.5911878347396851   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8083 , Loss:  0.5911878347396851   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8084 , Loss:  0.5911877155303955   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8085 , Loss:  0.5911877155303955   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8086 , Loss:  0.5911877155303955   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8087 , Loss:  0.5911877155303955   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8088 , Loss:  0.5911877155303955   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8089 , Loss:  0.5911876559257507   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8090 , Loss:  0.5911876559257507   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8091 , Loss:  0.5911876559257507   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8092 , Loss:  0.5911876559257507   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8093 , Loss:  0.591187596321106   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8094 , Loss:  0.5911875367164612   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8095 , Loss:  0.5911875367164612   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8096 , Loss:  0.5911875367164612   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8097 , Loss:  0.5911875367164612   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8098 , Loss:  0.5911874771118164   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8099 , Loss:  0.5911874771118164   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8100 , Loss:  0.5911874771118164   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8101 , Loss:  0.5911874175071716   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8102 , Loss:  0.5911874175071716   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8103 , Loss:  0.5911873579025269   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8104 , Loss:  0.5911873579025269   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8105 , Loss:  0.5911873579025269   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8106 , Loss:  0.5911872982978821   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8107 , Loss:  0.5911872982978821   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8108 , Loss:  0.5911872982978821   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8109 , Loss:  0.5911872982978821   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8110 , Loss:  0.5911872982978821   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8111 , Loss:  0.5911871790885925   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8112 , Loss:  0.5911871790885925   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8113 , Loss:  0.5911871790885925   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8114 , Loss:  0.5911871790885925   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8115 , Loss:  0.5911871194839478   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8116 , Loss:  0.5911871194839478   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8117 , Loss:  0.5911871194839478   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8118 , Loss:  0.591187059879303   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8119 , Loss:  0.591187059879303   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8120 , Loss:  0.5911870002746582   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8121 , Loss:  0.5911870002746582   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8122 , Loss:  0.5911870002746582   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8123 , Loss:  0.5911869406700134   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8124 , Loss:  0.5911868214607239   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8125 , Loss:  0.5911868214607239   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8126 , Loss:  0.5911868214607239   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8127 , Loss:  0.5911867618560791   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8128 , Loss:  0.5911866426467896   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8129 , Loss:  0.5911865830421448   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8130 , Loss:  0.5911864042282104   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8131 , Loss:  0.5911862254142761   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8132 , Loss:  0.5911856889724731   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8133 , Loss:  0.5911845564842224   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8134 , Loss:  0.5911806225776672   f1-score: 0.9172911047935486   accuracy: 0.9472972750663757\n",
      "Epoch:  8135 , Loss:  0.591166079044342   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8136 , Loss:  0.5911592841148376   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8137 , Loss:  0.5911573767662048   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8138 , Loss:  0.5911603569984436   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8139 , Loss:  0.5911619067192078   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8140 , Loss:  0.5911601781845093   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8141 , Loss:  0.5911613702774048   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8142 , Loss:  0.5911585092544556   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8143 , Loss:  0.591157853603363   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8144 , Loss:  0.5911575555801392   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8145 , Loss:  0.5911559462547302   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8146 , Loss:  0.5911564230918884   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8147 , Loss:  0.5911562442779541   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8148 , Loss:  0.5911554098129272   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8149 , Loss:  0.5911559462547302   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8150 , Loss:  0.5911555886268616   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8151 , Loss:  0.5911549925804138   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8152 , Loss:  0.5911552906036377   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8153 , Loss:  0.5911548137664795   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8154 , Loss:  0.5911543965339661   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8155 , Loss:  0.5911546349525452   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8156 , Loss:  0.5911542773246765   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8157 , Loss:  0.5911540985107422   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8158 , Loss:  0.5911542177200317   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8159 , Loss:  0.5911539196968079   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8160 , Loss:  0.5911537408828735   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8161 , Loss:  0.5911538600921631   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8162 , Loss:  0.5911535620689392   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8163 , Loss:  0.5911534428596497   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8164 , Loss:  0.5911534428596497   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8165 , Loss:  0.5911533236503601   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8166 , Loss:  0.5911531448364258   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8167 , Loss:  0.5911531448364258   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8168 , Loss:  0.591153085231781   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8169 , Loss:  0.5911529660224915   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8170 , Loss:  0.5911529660224915   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8171 , Loss:  0.5911529064178467   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8172 , Loss:  0.5911527872085571   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8173 , Loss:  0.5911527872085571   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8174 , Loss:  0.5911527276039124   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8175 , Loss:  0.5911526083946228   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8176 , Loss:  0.5911526083946228   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8177 , Loss:  0.591152548789978   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8178 , Loss:  0.591152548789978   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8179 , Loss:  0.5911524891853333   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8180 , Loss:  0.5911524891853333   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8181 , Loss:  0.5911524295806885   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8182 , Loss:  0.5911523699760437   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8183 , Loss:  0.5911523699760437   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8184 , Loss:  0.5911523103713989   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8185 , Loss:  0.5911522507667542   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8186 , Loss:  0.5911522507667542   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8187 , Loss:  0.5911522507667542   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8188 , Loss:  0.5911522507667542   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8189 , Loss:  0.5911521911621094   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8190 , Loss:  0.5911520719528198   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8191 , Loss:  0.5911520719528198   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8192 , Loss:  0.5911520719528198   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8193 , Loss:  0.5911520719528198   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8194 , Loss:  0.591152012348175   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8195 , Loss:  0.591152012348175   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8196 , Loss:  0.591152012348175   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8197 , Loss:  0.591152012348175   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8198 , Loss:  0.5911518931388855   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8199 , Loss:  0.5911518931388855   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8200 , Loss:  0.5911518931388855   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8201 , Loss:  0.5911518931388855   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8202 , Loss:  0.5911518335342407   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8203 , Loss:  0.5911518335342407   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8204 , Loss:  0.5911518335342407   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8205 , Loss:  0.5911518335342407   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8206 , Loss:  0.5911517143249512   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8207 , Loss:  0.5911517143249512   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8208 , Loss:  0.5911517143249512   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8209 , Loss:  0.5911517143249512   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8210 , Loss:  0.5911516547203064   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8211 , Loss:  0.5911516547203064   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8212 , Loss:  0.5911516547203064   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8213 , Loss:  0.5911516547203064   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8214 , Loss:  0.5911516547203064   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8215 , Loss:  0.5911515951156616   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8216 , Loss:  0.5911515951156616   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8217 , Loss:  0.5911515951156616   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8218 , Loss:  0.5911515951156616   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8219 , Loss:  0.5911515951156616   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8220 , Loss:  0.5911515355110168   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8221 , Loss:  0.5911514759063721   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8222 , Loss:  0.5911514759063721   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8223 , Loss:  0.5911514759063721   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8224 , Loss:  0.5911514163017273   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8225 , Loss:  0.5911514163017273   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8226 , Loss:  0.5911514163017273   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8227 , Loss:  0.5911514163017273   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8228 , Loss:  0.5911514163017273   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8229 , Loss:  0.5911514163017273   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8230 , Loss:  0.5911513566970825   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8231 , Loss:  0.5911512970924377   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8232 , Loss:  0.5911512970924377   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8233 , Loss:  0.5911512970924377   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8234 , Loss:  0.5911512970924377   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8235 , Loss:  0.591151237487793   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8236 , Loss:  0.591151237487793   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8237 , Loss:  0.591151237487793   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8238 , Loss:  0.591151237487793   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8239 , Loss:  0.591151237487793   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8240 , Loss:  0.591151237487793   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8241 , Loss:  0.5911511778831482   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8242 , Loss:  0.5911511182785034   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8243 , Loss:  0.5911511182785034   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8244 , Loss:  0.5911511182785034   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8245 , Loss:  0.5911511182785034   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8246 , Loss:  0.5911510586738586   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8247 , Loss:  0.5911510586738586   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8248 , Loss:  0.5911510586738586   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8249 , Loss:  0.5911510586738586   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8250 , Loss:  0.5911510586738586   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8251 , Loss:  0.5911509990692139   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8252 , Loss:  0.5911509990692139   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8253 , Loss:  0.5911509990692139   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8254 , Loss:  0.5911509990692139   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8255 , Loss:  0.5911509990692139   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8256 , Loss:  0.5911509394645691   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8257 , Loss:  0.5911508798599243   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8258 , Loss:  0.5911508798599243   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8259 , Loss:  0.5911508798599243   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8260 , Loss:  0.5911508798599243   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8261 , Loss:  0.5911508798599243   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8262 , Loss:  0.5911508798599243   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8263 , Loss:  0.5911508798599243   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8264 , Loss:  0.5911507606506348   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8265 , Loss:  0.5911508202552795   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8266 , Loss:  0.5911507606506348   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8267 , Loss:  0.5911507606506348   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8268 , Loss:  0.5911507606506348   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8269 , Loss:  0.5911507606506348   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8270 , Loss:  0.5911507606506348   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8271 , Loss:  0.59115070104599   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8272 , Loss:  0.59115070104599   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8273 , Loss:  0.59115070104599   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8274 , Loss:  0.59115070104599   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8275 , Loss:  0.59115070104599   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8276 , Loss:  0.59115070104599   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8277 , Loss:  0.5911506414413452   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8278 , Loss:  0.5911505818367004   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8279 , Loss:  0.5911505818367004   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8280 , Loss:  0.5911505818367004   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8281 , Loss:  0.5911505818367004   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8282 , Loss:  0.5911505818367004   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8283 , Loss:  0.5911505222320557   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8284 , Loss:  0.5911505222320557   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8285 , Loss:  0.5911505222320557   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8286 , Loss:  0.5911505222320557   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8287 , Loss:  0.5911505222320557   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8288 , Loss:  0.5911505222320557   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8289 , Loss:  0.5911504626274109   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8290 , Loss:  0.5911504626274109   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8291 , Loss:  0.5911504030227661   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8292 , Loss:  0.5911504030227661   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8293 , Loss:  0.5911504030227661   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8294 , Loss:  0.5911504030227661   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8295 , Loss:  0.5911504030227661   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8296 , Loss:  0.5911504030227661   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8297 , Loss:  0.5911503434181213   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8298 , Loss:  0.5911502838134766   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8299 , Loss:  0.5911502838134766   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8300 , Loss:  0.5911502838134766   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8301 , Loss:  0.5911502838134766   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8302 , Loss:  0.5911502838134766   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8303 , Loss:  0.5911502838134766   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8304 , Loss:  0.5911502242088318   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8305 , Loss:  0.5911502242088318   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8306 , Loss:  0.5911502242088318   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8307 , Loss:  0.5911502242088318   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8308 , Loss:  0.5911502242088318   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8309 , Loss:  0.5911502242088318   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8310 , Loss:  0.591150164604187   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8311 , Loss:  0.5911501049995422   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8312 , Loss:  0.5911501049995422   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8313 , Loss:  0.5911501049995422   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8314 , Loss:  0.591150164604187   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8315 , Loss:  0.5911500453948975   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8316 , Loss:  0.5911500453948975   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8317 , Loss:  0.5911500453948975   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8318 , Loss:  0.5911500453948975   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8319 , Loss:  0.5911500453948975   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8320 , Loss:  0.5911500453948975   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8321 , Loss:  0.5911499857902527   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8322 , Loss:  0.5911499857902527   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8323 , Loss:  0.5911499857902527   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8324 , Loss:  0.5911499857902527   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8325 , Loss:  0.5911499857902527   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8326 , Loss:  0.5911499857902527   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8327 , Loss:  0.5911498665809631   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8328 , Loss:  0.5911498665809631   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8329 , Loss:  0.5911498665809631   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8330 , Loss:  0.5911498665809631   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8331 , Loss:  0.5911498665809631   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8332 , Loss:  0.5911498665809631   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8333 , Loss:  0.5911498665809631   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8334 , Loss:  0.5911498665809631   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8335 , Loss:  0.5911498069763184   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8336 , Loss:  0.5911498069763184   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8337 , Loss:  0.5911498069763184   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8338 , Loss:  0.5911497473716736   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8339 , Loss:  0.5911497473716736   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8340 , Loss:  0.5911497473716736   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8341 , Loss:  0.5911497473716736   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8342 , Loss:  0.5911497473716736   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8343 , Loss:  0.5911497473716736   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8344 , Loss:  0.5911497473716736   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8345 , Loss:  0.5911496877670288   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8346 , Loss:  0.5911496877670288   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8347 , Loss:  0.591149628162384   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8348 , Loss:  0.591149628162384   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8349 , Loss:  0.591149628162384   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8350 , Loss:  0.591149628162384   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8351 , Loss:  0.591149628162384   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8352 , Loss:  0.5911495685577393   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8353 , Loss:  0.5911495685577393   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8354 , Loss:  0.5911495685577393   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8355 , Loss:  0.5911495685577393   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8356 , Loss:  0.5911495685577393   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8357 , Loss:  0.5911495685577393   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8358 , Loss:  0.5911495089530945   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8359 , Loss:  0.5911494493484497   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8360 , Loss:  0.5911495089530945   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8361 , Loss:  0.5911494493484497   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8362 , Loss:  0.5911494493484497   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8363 , Loss:  0.5911494493484497   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8364 , Loss:  0.5911494493484497   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8365 , Loss:  0.5911494493484497   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8366 , Loss:  0.5911493897438049   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8367 , Loss:  0.5911493897438049   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8368 , Loss:  0.5911493897438049   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8369 , Loss:  0.5911493897438049   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8370 , Loss:  0.5911493897438049   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8371 , Loss:  0.5911493897438049   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8372 , Loss:  0.5911492705345154   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8373 , Loss:  0.5911492705345154   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8374 , Loss:  0.5911492705345154   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8375 , Loss:  0.5911492705345154   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8376 , Loss:  0.5911492705345154   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8377 , Loss:  0.5911492109298706   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8378 , Loss:  0.5911492109298706   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8379 , Loss:  0.5911492109298706   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8380 , Loss:  0.5911492109298706   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8381 , Loss:  0.5911492109298706   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8382 , Loss:  0.5911492109298706   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8383 , Loss:  0.5911491513252258   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8384 , Loss:  0.591149091720581   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8385 , Loss:  0.591149091720581   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8386 , Loss:  0.591149091720581   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8387 , Loss:  0.591149091720581   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8388 , Loss:  0.591149091720581   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8389 , Loss:  0.5911490321159363   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8390 , Loss:  0.5911490321159363   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8391 , Loss:  0.5911490321159363   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8392 , Loss:  0.5911490321159363   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8393 , Loss:  0.5911489725112915   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8394 , Loss:  0.5911489725112915   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8395 , Loss:  0.5911489129066467   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8396 , Loss:  0.5911489129066467   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8397 , Loss:  0.5911489129066467   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8398 , Loss:  0.5911489129066467   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8399 , Loss:  0.591148853302002   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8400 , Loss:  0.591148853302002   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8401 , Loss:  0.591148853302002   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8402 , Loss:  0.5911487936973572   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8403 , Loss:  0.5911487936973572   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8404 , Loss:  0.5911487340927124   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8405 , Loss:  0.5911487340927124   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8406 , Loss:  0.5911487340927124   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8407 , Loss:  0.5911486744880676   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8408 , Loss:  0.5911486744880676   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8409 , Loss:  0.5911486148834229   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8410 , Loss:  0.5911485552787781   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8411 , Loss:  0.5911485552787781   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8412 , Loss:  0.5911484956741333   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8413 , Loss:  0.5911484360694885   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8414 , Loss:  0.591148316860199   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8415 , Loss:  0.5911481976509094   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8416 , Loss:  0.5911481380462646   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8417 , Loss:  0.5911479592323303   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8418 , Loss:  0.591147780418396   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8419 , Loss:  0.5911474823951721   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8420 , Loss:  0.5911470055580139   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8421 , Loss:  0.5911461710929871   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8422 , Loss:  0.5911446213722229   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8423 , Loss:  0.5911415219306946   f1-score: 0.9174441695213318   accuracy: 0.9473873972892761\n",
      "Epoch:  8424 , Loss:  0.5911363363265991   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8425 , Loss:  0.5911319255828857   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8426 , Loss:  0.5911281704902649   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8427 , Loss:  0.5911281704902649   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8428 , Loss:  0.5911275148391724   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8429 , Loss:  0.591127872467041   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8430 , Loss:  0.5911272168159485   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8431 , Loss:  0.5911263227462769   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8432 , Loss:  0.5911254286766052   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8433 , Loss:  0.5911244750022888   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8434 , Loss:  0.5911243557929993   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8435 , Loss:  0.5911238789558411   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8436 , Loss:  0.5911238789558411   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8437 , Loss:  0.5911235213279724   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8438 , Loss:  0.5911229848861694   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8439 , Loss:  0.5911224484443665   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8440 , Loss:  0.5911216735839844   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8441 , Loss:  0.591121256351471   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8442 , Loss:  0.5911208391189575   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8443 , Loss:  0.5911204814910889   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8444 , Loss:  0.5911204218864441   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8445 , Loss:  0.5911202430725098   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8446 , Loss:  0.591120183467865   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8447 , Loss:  0.5911200642585754   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8448 , Loss:  0.5911197662353516   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8449 , Loss:  0.5911195278167725   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8450 , Loss:  0.5911193490028381   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8451 , Loss:  0.5911191701889038   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8452 , Loss:  0.5911189913749695   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8453 , Loss:  0.5911189317703247   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8454 , Loss:  0.5911188125610352   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8455 , Loss:  0.5911188125610352   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8456 , Loss:  0.5911186337471008   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8457 , Loss:  0.591118574142456   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8458 , Loss:  0.5911185145378113   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8459 , Loss:  0.591118335723877   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8460 , Loss:  0.5911182165145874   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8461 , Loss:  0.5911181569099426   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8462 , Loss:  0.5911180377006531   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8463 , Loss:  0.5911179780960083   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8464 , Loss:  0.5911179780960083   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8465 , Loss:  0.5911178588867188   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8466 , Loss:  0.591117799282074   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8467 , Loss:  0.5911176800727844   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8468 , Loss:  0.5911176800727844   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8469 , Loss:  0.5911175608634949   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8470 , Loss:  0.5911175012588501   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8471 , Loss:  0.5911174416542053   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8472 , Loss:  0.5911174416542053   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8473 , Loss:  0.5911173224449158   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8474 , Loss:  0.5911173224449158   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8475 , Loss:  0.591117262840271   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8476 , Loss:  0.5911171436309814   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8477 , Loss:  0.5911171436309814   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8478 , Loss:  0.5911171436309814   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8479 , Loss:  0.5911170840263367   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8480 , Loss:  0.5911170244216919   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8481 , Loss:  0.5911169648170471   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8482 , Loss:  0.5911169648170471   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8483 , Loss:  0.5911169052124023   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8484 , Loss:  0.5911169052124023   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8485 , Loss:  0.5911168456077576   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8486 , Loss:  0.5911167860031128   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8487 , Loss:  0.5911167860031128   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8488 , Loss:  0.591116726398468   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8489 , Loss:  0.591116726398468   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8490 , Loss:  0.5911166667938232   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8491 , Loss:  0.5911166667938232   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8492 , Loss:  0.5911166667938232   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8493 , Loss:  0.5911165475845337   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8494 , Loss:  0.5911164879798889   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8495 , Loss:  0.5911164879798889   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8496 , Loss:  0.5911164879798889   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8497 , Loss:  0.5911164283752441   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8498 , Loss:  0.5911163687705994   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8499 , Loss:  0.5911163687705994   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8500 , Loss:  0.5911163091659546   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8501 , Loss:  0.5911163091659546   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8502 , Loss:  0.5911163091659546   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8503 , Loss:  0.5911162495613098   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8504 , Loss:  0.5911162495613098   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8505 , Loss:  0.591116189956665   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8506 , Loss:  0.591116189956665   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8507 , Loss:  0.5911161303520203   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8508 , Loss:  0.5911161303520203   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8509 , Loss:  0.5911161303520203   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8510 , Loss:  0.5911160707473755   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8511 , Loss:  0.5911160707473755   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8512 , Loss:  0.5911160111427307   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8513 , Loss:  0.5911159515380859   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8514 , Loss:  0.5911159515380859   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8515 , Loss:  0.5911159515380859   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8516 , Loss:  0.5911159515380859   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8517 , Loss:  0.5911158919334412   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8518 , Loss:  0.5911158323287964   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8519 , Loss:  0.5911158323287964   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8520 , Loss:  0.5911158323287964   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8521 , Loss:  0.5911157727241516   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8522 , Loss:  0.5911157727241516   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8523 , Loss:  0.5911157727241516   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8524 , Loss:  0.5911157131195068   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8525 , Loss:  0.5911156535148621   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8526 , Loss:  0.5911156535148621   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8527 , Loss:  0.5911156535148621   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8528 , Loss:  0.5911156535148621   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8529 , Loss:  0.5911155939102173   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8530 , Loss:  0.5911155939102173   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8531 , Loss:  0.5911155343055725   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8532 , Loss:  0.5911154747009277   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8533 , Loss:  0.5911154747009277   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8534 , Loss:  0.5911154747009277   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8535 , Loss:  0.5911154747009277   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8536 , Loss:  0.5911154747009277   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8537 , Loss:  0.591115415096283   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8538 , Loss:  0.591115415096283   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8539 , Loss:  0.591115415096283   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8540 , Loss:  0.5911152958869934   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8541 , Loss:  0.5911152958869934   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8542 , Loss:  0.5911152958869934   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8543 , Loss:  0.5911152958869934   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8544 , Loss:  0.5911152362823486   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8545 , Loss:  0.5911152362823486   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8546 , Loss:  0.5911152362823486   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8547 , Loss:  0.5911151766777039   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8548 , Loss:  0.5911151170730591   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8549 , Loss:  0.5911151170730591   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8550 , Loss:  0.5911151170730591   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8551 , Loss:  0.5911151170730591   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8552 , Loss:  0.5911150574684143   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8553 , Loss:  0.5911149978637695   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8554 , Loss:  0.5911149382591248   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8555 , Loss:  0.5911149382591248   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8556 , Loss:  0.59111487865448   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8557 , Loss:  0.5911148190498352   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8558 , Loss:  0.5911147594451904   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8559 , Loss:  0.5911146402359009   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8560 , Loss:  0.5911144614219666   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8561 , Loss:  0.5911141037940979   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8562 , Loss:  0.5911133885383606   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8563 , Loss:  0.5911110043525696   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8564 , Loss:  0.5911003351211548   f1-score: 0.9175971746444702   accuracy: 0.9474774599075317\n",
      "Epoch:  8565 , Loss:  0.591088593006134   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8566 , Loss:  0.5910857319831848   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8567 , Loss:  0.5910872220993042   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8568 , Loss:  0.5910906195640564   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8569 , Loss:  0.5910876393318176   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8570 , Loss:  0.5910899043083191   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8571 , Loss:  0.5910869836807251   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8572 , Loss:  0.5910860300064087   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8573 , Loss:  0.5910864472389221   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8574 , Loss:  0.591084361076355   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8575 , Loss:  0.5910847187042236   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8576 , Loss:  0.5910846590995789   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8577 , Loss:  0.5910834074020386   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8578 , Loss:  0.5910838842391968   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8579 , Loss:  0.5910837054252625   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8580 , Loss:  0.5910828709602356   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8581 , Loss:  0.591083288192749   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8582 , Loss:  0.5910830497741699   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8583 , Loss:  0.5910825133323669   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8584 , Loss:  0.591082751750946   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8585 , Loss:  0.5910825729370117   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8586 , Loss:  0.5910821557044983   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8587 , Loss:  0.5910822749137878   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8588 , Loss:  0.5910820960998535   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8589 , Loss:  0.5910817384719849   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8590 , Loss:  0.5910817980766296   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8591 , Loss:  0.5910817384719849   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8592 , Loss:  0.591081440448761   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8593 , Loss:  0.591081440448761   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8594 , Loss:  0.591081440448761   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8595 , Loss:  0.5910812020301819   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8596 , Loss:  0.5910812020301819   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8597 , Loss:  0.5910812020301819   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8598 , Loss:  0.5910810232162476   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8599 , Loss:  0.5910810232162476   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8600 , Loss:  0.5910810232162476   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8601 , Loss:  0.591080904006958   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8602 , Loss:  0.5910808444023132   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8603 , Loss:  0.5910808444023132   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8604 , Loss:  0.5910807251930237   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8605 , Loss:  0.5910807251930237   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8606 , Loss:  0.5910807251930237   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8607 , Loss:  0.5910806655883789   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8608 , Loss:  0.5910805463790894   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8609 , Loss:  0.5910805463790894   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8610 , Loss:  0.5910805463790894   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8611 , Loss:  0.5910804867744446   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8612 , Loss:  0.5910804271697998   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8613 , Loss:  0.5910804271697998   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8614 , Loss:  0.591080367565155   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8615 , Loss:  0.591080367565155   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8616 , Loss:  0.591080367565155   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8617 , Loss:  0.5910803079605103   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8618 , Loss:  0.5910803079605103   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8619 , Loss:  0.5910802483558655   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8620 , Loss:  0.5910802483558655   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8621 , Loss:  0.5910801887512207   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8622 , Loss:  0.5910801887512207   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8623 , Loss:  0.5910801887512207   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8624 , Loss:  0.5910801291465759   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8625 , Loss:  0.5910801291465759   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8626 , Loss:  0.5910801291465759   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8627 , Loss:  0.5910800099372864   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8628 , Loss:  0.5910800099372864   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8629 , Loss:  0.5910800099372864   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8630 , Loss:  0.5910800099372864   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8631 , Loss:  0.5910800099372864   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8632 , Loss:  0.5910799503326416   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8633 , Loss:  0.5910799503326416   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8634 , Loss:  0.5910799503326416   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8635 , Loss:  0.5910799503326416   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8636 , Loss:  0.5910798907279968   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8637 , Loss:  0.5910798907279968   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8638 , Loss:  0.5910798907279968   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8639 , Loss:  0.5910798907279968   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8640 , Loss:  0.591079831123352   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8641 , Loss:  0.5910797715187073   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8642 , Loss:  0.591079831123352   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8643 , Loss:  0.5910797715187073   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8644 , Loss:  0.5910797715187073   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8645 , Loss:  0.5910797119140625   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8646 , Loss:  0.5910797119140625   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8647 , Loss:  0.5910797119140625   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8648 , Loss:  0.5910797119140625   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8649 , Loss:  0.5910797119140625   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8650 , Loss:  0.5910797119140625   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8651 , Loss:  0.5910797119140625   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8652 , Loss:  0.5910796523094177   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8653 , Loss:  0.591079592704773   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8654 , Loss:  0.591079592704773   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8655 , Loss:  0.591079592704773   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8656 , Loss:  0.591079592704773   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8657 , Loss:  0.591079592704773   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8658 , Loss:  0.591079592704773   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8659 , Loss:  0.5910795331001282   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8660 , Loss:  0.5910795331001282   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8661 , Loss:  0.5910795331001282   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8662 , Loss:  0.5910795331001282   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8663 , Loss:  0.5910795331001282   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8664 , Loss:  0.5910795331001282   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8665 , Loss:  0.5910794734954834   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8666 , Loss:  0.5910794734954834   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8667 , Loss:  0.5910794138908386   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8668 , Loss:  0.5910794138908386   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8669 , Loss:  0.5910793542861938   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8670 , Loss:  0.5910793542861938   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8671 , Loss:  0.5910793542861938   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8672 , Loss:  0.5910793542861938   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8673 , Loss:  0.5910793542861938   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8674 , Loss:  0.5910793542861938   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8675 , Loss:  0.5910793542861938   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8676 , Loss:  0.5910792946815491   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8677 , Loss:  0.5910793542861938   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8678 , Loss:  0.5910792946815491   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8679 , Loss:  0.5910792946815491   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8680 , Loss:  0.5910792946815491   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8681 , Loss:  0.5910792946815491   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8682 , Loss:  0.5910792350769043   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8683 , Loss:  0.5910792350769043   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8684 , Loss:  0.5910791754722595   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8685 , Loss:  0.5910791754722595   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8686 , Loss:  0.5910791754722595   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8687 , Loss:  0.5910791754722595   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8688 , Loss:  0.5910791754722595   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8689 , Loss:  0.5910791754722595   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8690 , Loss:  0.5910791158676147   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8691 , Loss:  0.5910791158676147   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8692 , Loss:  0.5910791158676147   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8693 , Loss:  0.59107905626297   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8694 , Loss:  0.59107905626297   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8695 , Loss:  0.59107905626297   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8696 , Loss:  0.59107905626297   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8697 , Loss:  0.59107905626297   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8698 , Loss:  0.59107905626297   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8699 , Loss:  0.59107905626297   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8700 , Loss:  0.5910789966583252   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8701 , Loss:  0.5910789966583252   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8702 , Loss:  0.5910789966583252   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8703 , Loss:  0.5910789966583252   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8704 , Loss:  0.5910789966583252   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8705 , Loss:  0.5910789370536804   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8706 , Loss:  0.5910789370536804   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8707 , Loss:  0.5910788774490356   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8708 , Loss:  0.5910788774490356   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8709 , Loss:  0.5910788774490356   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8710 , Loss:  0.5910788774490356   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8711 , Loss:  0.5910788774490356   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8712 , Loss:  0.5910788774490356   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8713 , Loss:  0.5910788774490356   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8714 , Loss:  0.5910788774490356   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8715 , Loss:  0.5910788178443909   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8716 , Loss:  0.5910788178443909   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8717 , Loss:  0.5910788178443909   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8718 , Loss:  0.5910788178443909   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8719 , Loss:  0.5910788178443909   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8720 , Loss:  0.5910788178443909   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8721 , Loss:  0.5910787582397461   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8722 , Loss:  0.5910786986351013   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8723 , Loss:  0.5910786986351013   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8724 , Loss:  0.5910786986351013   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8725 , Loss:  0.5910786986351013   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8726 , Loss:  0.5910786986351013   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8727 , Loss:  0.5910786986351013   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8728 , Loss:  0.5910786986351013   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8729 , Loss:  0.5910786986351013   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8730 , Loss:  0.5910786390304565   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8731 , Loss:  0.5910786390304565   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8732 , Loss:  0.5910786390304565   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8733 , Loss:  0.5910786390304565   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8734 , Loss:  0.5910786390304565   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8735 , Loss:  0.5910786390304565   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8736 , Loss:  0.591078519821167   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8737 , Loss:  0.591078519821167   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8738 , Loss:  0.591078519821167   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8739 , Loss:  0.591078519821167   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8740 , Loss:  0.591078519821167   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8741 , Loss:  0.591078519821167   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8742 , Loss:  0.591078519821167   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8743 , Loss:  0.591078519821167   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8744 , Loss:  0.591078519821167   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8745 , Loss:  0.591078519821167   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8746 , Loss:  0.5910784602165222   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8747 , Loss:  0.5910784602165222   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8748 , Loss:  0.5910784602165222   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8749 , Loss:  0.5910784602165222   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8750 , Loss:  0.5910784602165222   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8751 , Loss:  0.5910784602165222   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8752 , Loss:  0.5910784602165222   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8753 , Loss:  0.5910784602165222   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8754 , Loss:  0.5910783410072327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8755 , Loss:  0.5910783410072327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8756 , Loss:  0.5910783410072327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8757 , Loss:  0.5910783410072327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8758 , Loss:  0.5910783410072327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8759 , Loss:  0.5910783410072327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8760 , Loss:  0.5910783410072327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8761 , Loss:  0.5910783410072327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8762 , Loss:  0.5910783410072327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8763 , Loss:  0.5910782814025879   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8764 , Loss:  0.5910782814025879   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8765 , Loss:  0.5910782814025879   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8766 , Loss:  0.5910782814025879   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8767 , Loss:  0.5910782814025879   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8768 , Loss:  0.5910782814025879   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8769 , Loss:  0.5910782814025879   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8770 , Loss:  0.5910782814025879   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8771 , Loss:  0.5910782217979431   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8772 , Loss:  0.5910782217979431   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8773 , Loss:  0.5910782217979431   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8774 , Loss:  0.5910782217979431   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8775 , Loss:  0.5910782217979431   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8776 , Loss:  0.5910782217979431   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8777 , Loss:  0.5910782217979431   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8778 , Loss:  0.5910781025886536   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8779 , Loss:  0.5910781025886536   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8780 , Loss:  0.5910781025886536   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8781 , Loss:  0.5910781025886536   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8782 , Loss:  0.5910781025886536   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8783 , Loss:  0.5910781025886536   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8784 , Loss:  0.5910781025886536   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8785 , Loss:  0.5910780429840088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8786 , Loss:  0.5910780429840088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8787 , Loss:  0.5910780429840088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8788 , Loss:  0.5910780429840088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8789 , Loss:  0.5910780429840088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8790 , Loss:  0.5910780429840088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8791 , Loss:  0.5910780429840088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8792 , Loss:  0.5910780429840088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8793 , Loss:  0.5910780429840088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8794 , Loss:  0.5910780429840088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8795 , Loss:  0.591077983379364   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8796 , Loss:  0.591077983379364   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8797 , Loss:  0.591077983379364   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8798 , Loss:  0.5910779237747192   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8799 , Loss:  0.5910779237747192   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8800 , Loss:  0.5910779237747192   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8801 , Loss:  0.5910779237747192   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8802 , Loss:  0.5910778641700745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8803 , Loss:  0.5910778641700745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8804 , Loss:  0.5910778641700745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8805 , Loss:  0.5910778641700745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8806 , Loss:  0.5910778641700745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8807 , Loss:  0.5910778641700745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8808 , Loss:  0.5910778641700745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8809 , Loss:  0.5910778641700745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8810 , Loss:  0.5910778641700745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8811 , Loss:  0.5910778641700745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8812 , Loss:  0.5910778641700745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8813 , Loss:  0.5910778045654297   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8814 , Loss:  0.5910778045654297   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8815 , Loss:  0.5910778045654297   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8816 , Loss:  0.5910777449607849   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8817 , Loss:  0.5910777449607849   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8818 , Loss:  0.5910777449607849   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8819 , Loss:  0.5910777449607849   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8820 , Loss:  0.5910777449607849   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8821 , Loss:  0.5910777449607849   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8822 , Loss:  0.5910777449607849   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8823 , Loss:  0.5910776853561401   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8824 , Loss:  0.5910776853561401   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8825 , Loss:  0.5910776853561401   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8826 , Loss:  0.5910776853561401   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8827 , Loss:  0.5910776853561401   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8828 , Loss:  0.5910776853561401   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8829 , Loss:  0.5910776853561401   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8830 , Loss:  0.5910776257514954   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8831 , Loss:  0.5910776257514954   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8832 , Loss:  0.5910776257514954   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8833 , Loss:  0.5910776257514954   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8834 , Loss:  0.5910776257514954   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8835 , Loss:  0.5910775661468506   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8836 , Loss:  0.5910775661468506   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8837 , Loss:  0.5910775661468506   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8838 , Loss:  0.5910775661468506   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8839 , Loss:  0.5910775065422058   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8840 , Loss:  0.5910775065422058   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8841 , Loss:  0.5910775065422058   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8842 , Loss:  0.5910775065422058   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8843 , Loss:  0.5910775065422058   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8844 , Loss:  0.5910775065422058   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8845 , Loss:  0.5910775065422058   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8846 , Loss:  0.5910775065422058   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8847 , Loss:  0.5910775065422058   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8848 , Loss:  0.5910775065422058   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8849 , Loss:  0.5910775065422058   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8850 , Loss:  0.5910775065422058   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8851 , Loss:  0.591077446937561   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8852 , Loss:  0.591077446937561   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8853 , Loss:  0.591077446937561   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8854 , Loss:  0.5910773873329163   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8855 , Loss:  0.5910773873329163   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8856 , Loss:  0.5910773873329163   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8857 , Loss:  0.5910773873329163   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8858 , Loss:  0.5910773873329163   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8859 , Loss:  0.5910773277282715   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8860 , Loss:  0.5910773277282715   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8861 , Loss:  0.5910773277282715   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8862 , Loss:  0.5910773277282715   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8863 , Loss:  0.5910773277282715   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8864 , Loss:  0.5910773277282715   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8865 , Loss:  0.5910773277282715   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8866 , Loss:  0.5910773277282715   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8867 , Loss:  0.5910773277282715   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8868 , Loss:  0.5910773277282715   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8869 , Loss:  0.5910772681236267   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8870 , Loss:  0.5910773277282715   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8871 , Loss:  0.5910773277282715   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8872 , Loss:  0.5910772681236267   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8873 , Loss:  0.5910772681236267   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8874 , Loss:  0.5910772085189819   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8875 , Loss:  0.5910772085189819   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8876 , Loss:  0.5910772085189819   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8877 , Loss:  0.5910772085189819   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8878 , Loss:  0.5910772085189819   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8879 , Loss:  0.5910772085189819   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8880 , Loss:  0.5910772085189819   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8881 , Loss:  0.5910772085189819   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8882 , Loss:  0.5910772085189819   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8883 , Loss:  0.5910772085189819   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8884 , Loss:  0.5910771489143372   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8885 , Loss:  0.5910771489143372   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8886 , Loss:  0.5910771489143372   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8887 , Loss:  0.5910771489143372   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8888 , Loss:  0.5910770893096924   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8889 , Loss:  0.5910771489143372   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8890 , Loss:  0.5910770893096924   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8891 , Loss:  0.5910770893096924   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8892 , Loss:  0.5910770297050476   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8893 , Loss:  0.5910770297050476   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8894 , Loss:  0.5910770297050476   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8895 , Loss:  0.5910770297050476   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8896 , Loss:  0.5910770297050476   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8897 , Loss:  0.5910770297050476   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8898 , Loss:  0.5910770297050476   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8899 , Loss:  0.5910770297050476   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8900 , Loss:  0.5910770297050476   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8901 , Loss:  0.5910770297050476   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8902 , Loss:  0.5910770297050476   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8903 , Loss:  0.5910770297050476   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8904 , Loss:  0.5910769701004028   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8905 , Loss:  0.5910769701004028   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8906 , Loss:  0.5910769701004028   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8907 , Loss:  0.5910769701004028   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8908 , Loss:  0.5910769701004028   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8909 , Loss:  0.5910769104957581   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8910 , Loss:  0.5910769104957581   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8911 , Loss:  0.5910769104957581   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8912 , Loss:  0.5910769104957581   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8913 , Loss:  0.5910769104957581   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8914 , Loss:  0.5910769104957581   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8915 , Loss:  0.5910769104957581   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8916 , Loss:  0.5910768508911133   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8917 , Loss:  0.5910768508911133   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8918 , Loss:  0.5910768508911133   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8919 , Loss:  0.5910768508911133   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8920 , Loss:  0.5910768508911133   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8921 , Loss:  0.5910768508911133   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8922 , Loss:  0.5910768508911133   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8923 , Loss:  0.5910768508911133   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8924 , Loss:  0.5910768508911133   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8925 , Loss:  0.5910768508911133   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8926 , Loss:  0.5910767912864685   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8927 , Loss:  0.5910767912864685   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8928 , Loss:  0.5910767912864685   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8929 , Loss:  0.5910767912864685   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8930 , Loss:  0.5910767912864685   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8931 , Loss:  0.5910767316818237   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8932 , Loss:  0.5910767316818237   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8933 , Loss:  0.5910767316818237   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8934 , Loss:  0.5910767316818237   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8935 , Loss:  0.5910767316818237   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8936 , Loss:  0.591076672077179   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8937 , Loss:  0.591076672077179   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8938 , Loss:  0.591076672077179   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8939 , Loss:  0.591076672077179   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8940 , Loss:  0.591076672077179   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8941 , Loss:  0.591076672077179   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8942 , Loss:  0.591076672077179   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8943 , Loss:  0.591076672077179   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8944 , Loss:  0.591076672077179   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8945 , Loss:  0.5910766124725342   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8946 , Loss:  0.5910766124725342   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8947 , Loss:  0.5910766124725342   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8948 , Loss:  0.5910766124725342   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8949 , Loss:  0.5910766124725342   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8950 , Loss:  0.5910766124725342   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8951 , Loss:  0.5910766124725342   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8952 , Loss:  0.5910765528678894   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8953 , Loss:  0.5910765528678894   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8954 , Loss:  0.5910765528678894   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8955 , Loss:  0.5910765528678894   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8956 , Loss:  0.5910764932632446   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8957 , Loss:  0.5910765528678894   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8958 , Loss:  0.5910764932632446   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8959 , Loss:  0.5910764932632446   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8960 , Loss:  0.5910764932632446   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8961 , Loss:  0.5910764932632446   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8962 , Loss:  0.5910764932632446   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8963 , Loss:  0.5910764932632446   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8964 , Loss:  0.5910764932632446   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8965 , Loss:  0.5910764932632446   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8966 , Loss:  0.5910764932632446   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8967 , Loss:  0.5910764336585999   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8968 , Loss:  0.5910764336585999   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8969 , Loss:  0.5910764336585999   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8970 , Loss:  0.5910764336585999   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8971 , Loss:  0.5910764336585999   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8972 , Loss:  0.5910764336585999   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8973 , Loss:  0.5910763740539551   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8974 , Loss:  0.5910763740539551   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8975 , Loss:  0.5910763740539551   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8976 , Loss:  0.5910763740539551   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8977 , Loss:  0.5910763740539551   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8978 , Loss:  0.5910763740539551   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8979 , Loss:  0.5910763740539551   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8980 , Loss:  0.5910763740539551   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8981 , Loss:  0.5910763740539551   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8982 , Loss:  0.5910763740539551   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8983 , Loss:  0.5910763740539551   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8984 , Loss:  0.5910763144493103   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8985 , Loss:  0.5910763144493103   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8986 , Loss:  0.5910763144493103   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8987 , Loss:  0.5910763144493103   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8988 , Loss:  0.5910763144493103   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8989 , Loss:  0.5910762548446655   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8990 , Loss:  0.5910762548446655   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8991 , Loss:  0.5910762548446655   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8992 , Loss:  0.5910762548446655   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8993 , Loss:  0.5910762548446655   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8994 , Loss:  0.5910762548446655   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8995 , Loss:  0.5910762548446655   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8996 , Loss:  0.5910762548446655   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8997 , Loss:  0.5910761952400208   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8998 , Loss:  0.5910761952400208   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  8999 , Loss:  0.5910761952400208   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9000 , Loss:  0.5910761952400208   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9001 , Loss:  0.5910761952400208   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9002 , Loss:  0.5910761952400208   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9003 , Loss:  0.5910761952400208   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9004 , Loss:  0.5910761952400208   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9005 , Loss:  0.5910761952400208   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9006 , Loss:  0.5910761952400208   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9007 , Loss:  0.591076135635376   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9008 , Loss:  0.591076135635376   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9009 , Loss:  0.591076135635376   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9010 , Loss:  0.591076135635376   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9011 , Loss:  0.591076135635376   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9012 , Loss:  0.591076135635376   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9013 , Loss:  0.591076135635376   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9014 , Loss:  0.5910760760307312   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9015 , Loss:  0.5910760760307312   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9016 , Loss:  0.5910760760307312   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9017 , Loss:  0.5910760760307312   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9018 , Loss:  0.5910760164260864   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9019 , Loss:  0.5910760760307312   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9020 , Loss:  0.5910760760307312   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9021 , Loss:  0.5910760164260864   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9022 , Loss:  0.5910760164260864   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9023 , Loss:  0.5910760164260864   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9024 , Loss:  0.5910760164260864   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9025 , Loss:  0.5910760164260864   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9026 , Loss:  0.5910760164260864   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9027 , Loss:  0.5910760164260864   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9028 , Loss:  0.5910760164260864   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9029 , Loss:  0.5910760164260864   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9030 , Loss:  0.5910760164260864   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9031 , Loss:  0.5910760164260864   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9032 , Loss:  0.5910759568214417   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9033 , Loss:  0.5910759568214417   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9034 , Loss:  0.5910759568214417   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9035 , Loss:  0.5910759568214417   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9036 , Loss:  0.5910759568214417   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9037 , Loss:  0.5910759568214417   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9038 , Loss:  0.5910759568214417   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9039 , Loss:  0.5910759568214417   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9040 , Loss:  0.5910758972167969   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9041 , Loss:  0.5910758972167969   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9042 , Loss:  0.5910758376121521   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9043 , Loss:  0.5910758376121521   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9044 , Loss:  0.5910758376121521   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9045 , Loss:  0.5910758376121521   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9046 , Loss:  0.5910758376121521   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9047 , Loss:  0.5910758376121521   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9048 , Loss:  0.5910758376121521   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9049 , Loss:  0.5910758376121521   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9050 , Loss:  0.5910758376121521   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9051 , Loss:  0.5910758376121521   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9052 , Loss:  0.5910758376121521   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9053 , Loss:  0.5910758376121521   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9054 , Loss:  0.5910758376121521   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9055 , Loss:  0.5910757780075073   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9056 , Loss:  0.5910758376121521   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9057 , Loss:  0.5910758376121521   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9058 , Loss:  0.5910757780075073   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9059 , Loss:  0.5910757780075073   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9060 , Loss:  0.5910757780075073   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9061 , Loss:  0.5910757780075073   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9062 , Loss:  0.5910757780075073   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9063 , Loss:  0.5910757780075073   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9064 , Loss:  0.5910757184028625   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9065 , Loss:  0.5910757184028625   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9066 , Loss:  0.5910757184028625   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9067 , Loss:  0.5910757184028625   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9068 , Loss:  0.5910757184028625   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9069 , Loss:  0.5910756587982178   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9070 , Loss:  0.5910756587982178   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9071 , Loss:  0.5910756587982178   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9072 , Loss:  0.5910756587982178   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9073 , Loss:  0.5910756587982178   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9074 , Loss:  0.5910756587982178   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9075 , Loss:  0.5910756587982178   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9076 , Loss:  0.5910756587982178   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9077 , Loss:  0.5910756587982178   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9078 , Loss:  0.5910756587982178   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9079 , Loss:  0.5910756587982178   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9080 , Loss:  0.591075599193573   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9081 , Loss:  0.591075599193573   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9082 , Loss:  0.591075599193573   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9083 , Loss:  0.591075599193573   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9084 , Loss:  0.591075599193573   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9085 , Loss:  0.591075599193573   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9086 , Loss:  0.591075599193573   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9087 , Loss:  0.5910755395889282   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9088 , Loss:  0.5910755395889282   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9089 , Loss:  0.5910755395889282   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9090 , Loss:  0.5910755395889282   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9091 , Loss:  0.5910755395889282   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9092 , Loss:  0.5910755395889282   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9093 , Loss:  0.5910755395889282   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9094 , Loss:  0.5910755395889282   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9095 , Loss:  0.5910754799842834   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9096 , Loss:  0.5910754799842834   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9097 , Loss:  0.5910754799842834   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9098 , Loss:  0.5910754799842834   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9099 , Loss:  0.5910754799842834   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9100 , Loss:  0.5910754799842834   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9101 , Loss:  0.5910754799842834   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9102 , Loss:  0.5910754799842834   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9103 , Loss:  0.5910754799842834   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9104 , Loss:  0.5910754799842834   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9105 , Loss:  0.5910754799842834   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9106 , Loss:  0.5910754799842834   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9107 , Loss:  0.5910754799842834   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9108 , Loss:  0.5910754203796387   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9109 , Loss:  0.5910754799842834   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9110 , Loss:  0.5910754203796387   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9111 , Loss:  0.5910754203796387   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9112 , Loss:  0.5910754203796387   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9113 , Loss:  0.5910754203796387   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9114 , Loss:  0.5910753607749939   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9115 , Loss:  0.5910753607749939   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9116 , Loss:  0.5910753607749939   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9117 , Loss:  0.5910753607749939   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9118 , Loss:  0.5910753607749939   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9119 , Loss:  0.5910753607749939   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9120 , Loss:  0.5910753607749939   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9121 , Loss:  0.5910753607749939   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9122 , Loss:  0.5910753607749939   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9123 , Loss:  0.5910753607749939   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9124 , Loss:  0.5910753607749939   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9125 , Loss:  0.5910753607749939   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9126 , Loss:  0.5910753011703491   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9127 , Loss:  0.5910753011703491   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9128 , Loss:  0.5910753011703491   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9129 , Loss:  0.5910753011703491   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9130 , Loss:  0.5910753011703491   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9131 , Loss:  0.5910753011703491   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9132 , Loss:  0.5910753011703491   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9133 , Loss:  0.5910753011703491   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9134 , Loss:  0.5910752415657043   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9135 , Loss:  0.5910752415657043   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9136 , Loss:  0.5910752415657043   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9137 , Loss:  0.5910752415657043   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9138 , Loss:  0.5910751819610596   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9139 , Loss:  0.5910751819610596   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9140 , Loss:  0.5910751819610596   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9141 , Loss:  0.5910751819610596   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9142 , Loss:  0.5910751819610596   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9143 , Loss:  0.5910751819610596   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9144 , Loss:  0.5910751819610596   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9145 , Loss:  0.5910751819610596   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9146 , Loss:  0.5910751819610596   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9147 , Loss:  0.5910751819610596   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9148 , Loss:  0.5910751819610596   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9149 , Loss:  0.5910751819610596   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9150 , Loss:  0.5910751819610596   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9151 , Loss:  0.5910751223564148   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9152 , Loss:  0.5910751223564148   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9153 , Loss:  0.5910751223564148   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9154 , Loss:  0.5910751223564148   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9155 , Loss:  0.5910751223564148   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9156 , Loss:  0.5910751223564148   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9157 , Loss:  0.5910751223564148   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9158 , Loss:  0.5910751223564148   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9159 , Loss:  0.5910751223564148   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9160 , Loss:  0.5910751223564148   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9161 , Loss:  0.5910751223564148   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9162 , Loss:  0.59107506275177   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9163 , Loss:  0.5910750031471252   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9164 , Loss:  0.5910750031471252   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9165 , Loss:  0.5910750031471252   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9166 , Loss:  0.59107506275177   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9167 , Loss:  0.59107506275177   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9168 , Loss:  0.5910750031471252   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9169 , Loss:  0.5910750031471252   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9170 , Loss:  0.5910750031471252   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9171 , Loss:  0.5910750031471252   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9172 , Loss:  0.5910750031471252   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9173 , Loss:  0.5910750031471252   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9174 , Loss:  0.5910750031471252   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9175 , Loss:  0.5910750031471252   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9176 , Loss:  0.5910750031471252   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9177 , Loss:  0.5910750031471252   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9178 , Loss:  0.5910749435424805   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9179 , Loss:  0.5910750031471252   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9180 , Loss:  0.5910750031471252   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9181 , Loss:  0.5910750031471252   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9182 , Loss:  0.5910749435424805   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9183 , Loss:  0.5910749435424805   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9184 , Loss:  0.5910749435424805   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9185 , Loss:  0.5910749435424805   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9186 , Loss:  0.5910749435424805   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9187 , Loss:  0.5910748839378357   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9188 , Loss:  0.5910748839378357   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9189 , Loss:  0.5910748839378357   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9190 , Loss:  0.5910748839378357   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9191 , Loss:  0.5910748243331909   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9192 , Loss:  0.5910748839378357   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9193 , Loss:  0.5910748839378357   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9194 , Loss:  0.5910748839378357   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9195 , Loss:  0.5910748243331909   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9196 , Loss:  0.5910748243331909   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9197 , Loss:  0.5910748243331909   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9198 , Loss:  0.5910748243331909   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9199 , Loss:  0.5910748243331909   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9200 , Loss:  0.5910748243331909   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9201 , Loss:  0.5910748243331909   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9202 , Loss:  0.5910748243331909   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9203 , Loss:  0.5910748243331909   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9204 , Loss:  0.5910748243331909   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9205 , Loss:  0.5910748243331909   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9206 , Loss:  0.5910748243331909   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9207 , Loss:  0.5910747647285461   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9208 , Loss:  0.5910747647285461   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9209 , Loss:  0.5910747647285461   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9210 , Loss:  0.5910747647285461   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9211 , Loss:  0.5910747647285461   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9212 , Loss:  0.5910747647285461   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9213 , Loss:  0.5910747647285461   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9214 , Loss:  0.5910747647285461   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9215 , Loss:  0.5910747647285461   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9216 , Loss:  0.5910747051239014   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9217 , Loss:  0.5910747051239014   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9218 , Loss:  0.5910747051239014   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9219 , Loss:  0.5910747051239014   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9220 , Loss:  0.5910746455192566   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9221 , Loss:  0.5910746455192566   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9222 , Loss:  0.5910746455192566   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9223 , Loss:  0.5910746455192566   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9224 , Loss:  0.5910746455192566   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9225 , Loss:  0.5910746455192566   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9226 , Loss:  0.5910746455192566   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9227 , Loss:  0.5910746455192566   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9228 , Loss:  0.5910746455192566   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9229 , Loss:  0.5910746455192566   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9230 , Loss:  0.5910746455192566   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9231 , Loss:  0.5910746455192566   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9232 , Loss:  0.5910746455192566   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9233 , Loss:  0.5910746455192566   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9234 , Loss:  0.5910745859146118   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9235 , Loss:  0.5910745859146118   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9236 , Loss:  0.5910745859146118   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9237 , Loss:  0.5910745859146118   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9238 , Loss:  0.5910745859146118   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9239 , Loss:  0.5910745859146118   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9240 , Loss:  0.5910745859146118   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9241 , Loss:  0.5910745859146118   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9242 , Loss:  0.5910745859146118   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9243 , Loss:  0.5910745859146118   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9244 , Loss:  0.5910745859146118   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9245 , Loss:  0.5910745859146118   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9246 , Loss:  0.5910745859146118   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9247 , Loss:  0.5910745859146118   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9248 , Loss:  0.591074526309967   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9249 , Loss:  0.591074526309967   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9250 , Loss:  0.591074526309967   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9251 , Loss:  0.591074526309967   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9252 , Loss:  0.591074526309967   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9253 , Loss:  0.591074526309967   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9254 , Loss:  0.591074526309967   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9255 , Loss:  0.591074526309967   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9256 , Loss:  0.591074526309967   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9257 , Loss:  0.591074526309967   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9258 , Loss:  0.591074526309967   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9259 , Loss:  0.5910744667053223   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9260 , Loss:  0.591074526309967   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9261 , Loss:  0.591074526309967   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9262 , Loss:  0.5910744667053223   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9263 , Loss:  0.5910744667053223   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9264 , Loss:  0.5910744667053223   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9265 , Loss:  0.5910744667053223   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9266 , Loss:  0.5910744667053223   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9267 , Loss:  0.5910744667053223   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9268 , Loss:  0.5910744071006775   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9269 , Loss:  0.5910744071006775   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9270 , Loss:  0.5910744071006775   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9271 , Loss:  0.5910744071006775   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9272 , Loss:  0.5910744071006775   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9273 , Loss:  0.5910744071006775   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9274 , Loss:  0.5910744071006775   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9275 , Loss:  0.5910744071006775   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9276 , Loss:  0.5910743474960327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9277 , Loss:  0.5910743474960327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9278 , Loss:  0.5910743474960327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9279 , Loss:  0.5910743474960327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9280 , Loss:  0.5910743474960327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9281 , Loss:  0.5910743474960327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9282 , Loss:  0.5910743474960327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9283 , Loss:  0.5910743474960327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9284 , Loss:  0.5910743474960327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9285 , Loss:  0.5910743474960327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9286 , Loss:  0.5910743474960327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9287 , Loss:  0.5910743474960327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9288 , Loss:  0.5910743474960327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9289 , Loss:  0.5910743474960327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9290 , Loss:  0.5910743474960327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9291 , Loss:  0.5910743474960327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9292 , Loss:  0.5910743474960327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9293 , Loss:  0.5910743474960327   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9294 , Loss:  0.5910742878913879   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9295 , Loss:  0.5910742282867432   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9296 , Loss:  0.5910742282867432   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9297 , Loss:  0.5910742282867432   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9298 , Loss:  0.5910742282867432   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9299 , Loss:  0.5910742282867432   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9300 , Loss:  0.5910742282867432   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9301 , Loss:  0.5910742282867432   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9302 , Loss:  0.5910742282867432   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9303 , Loss:  0.5910742282867432   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9304 , Loss:  0.5910742282867432   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9305 , Loss:  0.5910742282867432   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9306 , Loss:  0.5910742282867432   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9307 , Loss:  0.5910742282867432   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9308 , Loss:  0.5910742282867432   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9309 , Loss:  0.5910742282867432   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9310 , Loss:  0.5910741686820984   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9311 , Loss:  0.5910741686820984   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9312 , Loss:  0.5910741686820984   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9313 , Loss:  0.5910741686820984   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9314 , Loss:  0.5910741686820984   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9315 , Loss:  0.5910741686820984   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9316 , Loss:  0.5910741686820984   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9317 , Loss:  0.5910741686820984   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9318 , Loss:  0.5910741686820984   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9319 , Loss:  0.5910741686820984   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9320 , Loss:  0.5910741686820984   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9321 , Loss:  0.5910741090774536   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9322 , Loss:  0.5910741090774536   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9323 , Loss:  0.5910741090774536   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9324 , Loss:  0.5910740494728088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9325 , Loss:  0.5910740494728088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9326 , Loss:  0.5910740494728088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9327 , Loss:  0.5910740494728088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9328 , Loss:  0.5910740494728088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9329 , Loss:  0.5910740494728088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9330 , Loss:  0.5910740494728088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9331 , Loss:  0.5910740494728088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9332 , Loss:  0.5910740494728088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9333 , Loss:  0.5910740494728088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9334 , Loss:  0.5910740494728088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9335 , Loss:  0.5910740494728088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9336 , Loss:  0.5910740494728088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9337 , Loss:  0.5910740494728088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9338 , Loss:  0.5910740494728088   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9339 , Loss:  0.5910739898681641   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9340 , Loss:  0.5910739898681641   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9341 , Loss:  0.5910739898681641   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9342 , Loss:  0.5910739898681641   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9343 , Loss:  0.5910739898681641   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9344 , Loss:  0.5910739898681641   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9345 , Loss:  0.5910739898681641   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9346 , Loss:  0.5910739898681641   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9347 , Loss:  0.5910739898681641   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9348 , Loss:  0.5910739898681641   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9349 , Loss:  0.5910739898681641   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9350 , Loss:  0.5910739898681641   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9351 , Loss:  0.5910739898681641   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9352 , Loss:  0.5910739302635193   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9353 , Loss:  0.5910739898681641   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9354 , Loss:  0.5910738706588745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9355 , Loss:  0.5910738706588745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9356 , Loss:  0.5910738706588745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9357 , Loss:  0.5910738706588745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9358 , Loss:  0.5910738706588745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9359 , Loss:  0.5910738706588745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9360 , Loss:  0.5910738706588745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9361 , Loss:  0.5910738706588745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9362 , Loss:  0.5910738706588745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9363 , Loss:  0.5910738706588745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9364 , Loss:  0.5910738706588745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9365 , Loss:  0.5910738706588745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9366 , Loss:  0.5910738706588745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9367 , Loss:  0.5910738706588745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9368 , Loss:  0.5910738706588745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9369 , Loss:  0.5910738706588745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9370 , Loss:  0.5910738706588745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9371 , Loss:  0.5910738706588745   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9372 , Loss:  0.5910738110542297   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9373 , Loss:  0.5910738110542297   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9374 , Loss:  0.5910738110542297   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9375 , Loss:  0.5910738110542297   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9376 , Loss:  0.5910738110542297   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9377 , Loss:  0.5910738110542297   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9378 , Loss:  0.5910738110542297   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9379 , Loss:  0.5910738110542297   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9380 , Loss:  0.5910738110542297   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9381 , Loss:  0.591073751449585   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9382 , Loss:  0.5910738110542297   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9383 , Loss:  0.591073751449585   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9384 , Loss:  0.5910736918449402   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9385 , Loss:  0.5910736918449402   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9386 , Loss:  0.591073751449585   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9387 , Loss:  0.591073751449585   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9388 , Loss:  0.591073751449585   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9389 , Loss:  0.591073751449585   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9390 , Loss:  0.5910736918449402   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9391 , Loss:  0.5910736918449402   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9392 , Loss:  0.5910736918449402   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9393 , Loss:  0.5910736918449402   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9394 , Loss:  0.5910736918449402   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9395 , Loss:  0.5910736918449402   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9396 , Loss:  0.5910736322402954   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9397 , Loss:  0.5910736918449402   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9398 , Loss:  0.5910736918449402   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9399 , Loss:  0.5910736918449402   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9400 , Loss:  0.5910736918449402   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9401 , Loss:  0.5910736322402954   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9402 , Loss:  0.5910736322402954   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9403 , Loss:  0.5910736322402954   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9404 , Loss:  0.5910736322402954   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9405 , Loss:  0.5910736322402954   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9406 , Loss:  0.5910736322402954   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9407 , Loss:  0.5910736322402954   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9408 , Loss:  0.5910736322402954   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9409 , Loss:  0.5910736322402954   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9410 , Loss:  0.5910735726356506   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9411 , Loss:  0.5910735726356506   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9412 , Loss:  0.5910735726356506   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9413 , Loss:  0.5910735726356506   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9414 , Loss:  0.5910735726356506   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9415 , Loss:  0.5910735726356506   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9416 , Loss:  0.5910735130310059   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9417 , Loss:  0.5910735726356506   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9418 , Loss:  0.5910735130310059   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9419 , Loss:  0.5910735130310059   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9420 , Loss:  0.5910735130310059   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9421 , Loss:  0.5910735130310059   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9422 , Loss:  0.5910735130310059   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9423 , Loss:  0.5910735130310059   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9424 , Loss:  0.5910735130310059   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9425 , Loss:  0.5910734534263611   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9426 , Loss:  0.5910734534263611   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9427 , Loss:  0.5910734534263611   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9428 , Loss:  0.5910734534263611   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9429 , Loss:  0.5910734534263611   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9430 , Loss:  0.5910734534263611   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9431 , Loss:  0.5910734534263611   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9432 , Loss:  0.5910734534263611   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9433 , Loss:  0.5910734534263611   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9434 , Loss:  0.5910733342170715   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9435 , Loss:  0.5910733938217163   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9436 , Loss:  0.5910733938217163   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9437 , Loss:  0.5910733938217163   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9438 , Loss:  0.5910733938217163   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9439 , Loss:  0.5910733342170715   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9440 , Loss:  0.5910733342170715   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9441 , Loss:  0.5910733342170715   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9442 , Loss:  0.5910733342170715   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9443 , Loss:  0.5910732746124268   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9444 , Loss:  0.5910732746124268   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9445 , Loss:  0.5910732746124268   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9446 , Loss:  0.591073215007782   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9447 , Loss:  0.5910731554031372   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9448 , Loss:  0.5910731554031372   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9449 , Loss:  0.5910730957984924   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9450 , Loss:  0.5910730957984924   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9451 , Loss:  0.5910729765892029   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9452 , Loss:  0.5910728573799133   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9453 , Loss:  0.5910727381706238   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9454 , Loss:  0.5910724997520447   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9455 , Loss:  0.591072142124176   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9456 , Loss:  0.591071367263794   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9457 , Loss:  0.591069757938385   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9458 , Loss:  0.5910656452178955   f1-score: 0.9177501201629639   accuracy: 0.9475675821304321\n",
      "Epoch:  9459 , Loss:  0.5910593867301941   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9460 , Loss:  0.5910540223121643   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9461 , Loss:  0.5910507440567017   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9462 , Loss:  0.5910516381263733   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9463 , Loss:  0.5910508036613464   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9464 , Loss:  0.5910528302192688   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9465 , Loss:  0.5910512208938599   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9466 , Loss:  0.5910511612892151   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9467 , Loss:  0.5910486578941345   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9468 , Loss:  0.5910484790802002   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9469 , Loss:  0.5910467505455017   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9470 , Loss:  0.5910465717315674   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9471 , Loss:  0.5910462737083435   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9472 , Loss:  0.5910457968711853   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9473 , Loss:  0.5910462737083435   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9474 , Loss:  0.5910457372665405   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9475 , Loss:  0.5910457372665405   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9476 , Loss:  0.5910453200340271   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9477 , Loss:  0.5910447239875793   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9478 , Loss:  0.5910446047782898   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9479 , Loss:  0.5910440683364868   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9480 , Loss:  0.5910437703132629   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9481 , Loss:  0.5910437703132629   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9482 , Loss:  0.5910434126853943   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9483 , Loss:  0.5910434126853943   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9484 , Loss:  0.5910433530807495   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9485 , Loss:  0.5910431742668152   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9486 , Loss:  0.59104323387146   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9487 , Loss:  0.5910431146621704   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9488 , Loss:  0.5910429358482361   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9489 , Loss:  0.5910429358482361   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9490 , Loss:  0.5910427570343018   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9491 , Loss:  0.5910425782203674   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9492 , Loss:  0.5910425782203674   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9493 , Loss:  0.5910423994064331   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9494 , Loss:  0.5910423398017883   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9495 , Loss:  0.5910422801971436   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9496 , Loss:  0.5910422205924988   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9497 , Loss:  0.5910422205924988   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9498 , Loss:  0.5910421013832092   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9499 , Loss:  0.5910421013832092   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9500 , Loss:  0.5910420417785645   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9501 , Loss:  0.5910419225692749   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9502 , Loss:  0.5910419225692749   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9503 , Loss:  0.5910418629646301   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9504 , Loss:  0.5910418033599854   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9505 , Loss:  0.5910417437553406   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9506 , Loss:  0.5910417437553406   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9507 , Loss:  0.5910416841506958   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9508 , Loss:  0.591041624546051   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9509 , Loss:  0.5910415649414062   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9510 , Loss:  0.5910415649414062   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9511 , Loss:  0.5910415053367615   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9512 , Loss:  0.5910415053367615   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9513 , Loss:  0.5910414457321167   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9514 , Loss:  0.5910414457321167   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9515 , Loss:  0.5910414457321167   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9516 , Loss:  0.5910413861274719   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9517 , Loss:  0.5910413265228271   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9518 , Loss:  0.5910413265228271   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9519 , Loss:  0.5910412669181824   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9520 , Loss:  0.5910412669181824   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9521 , Loss:  0.5910412669181824   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9522 , Loss:  0.5910412073135376   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9523 , Loss:  0.5910411477088928   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9524 , Loss:  0.5910411477088928   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9525 , Loss:  0.5910411477088928   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9526 , Loss:  0.591041088104248   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9527 , Loss:  0.591041088104248   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9528 , Loss:  0.591041088104248   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9529 , Loss:  0.5910410284996033   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9530 , Loss:  0.5910409688949585   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9531 , Loss:  0.5910409688949585   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9532 , Loss:  0.5910409688949585   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9533 , Loss:  0.5910409092903137   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9534 , Loss:  0.5910409092903137   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9535 , Loss:  0.5910409092903137   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9536 , Loss:  0.5910409092903137   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9537 , Loss:  0.591040849685669   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9538 , Loss:  0.5910407900810242   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9539 , Loss:  0.591040849685669   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9540 , Loss:  0.5910407900810242   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9541 , Loss:  0.5910407900810242   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9542 , Loss:  0.5910407304763794   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9543 , Loss:  0.5910407304763794   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9544 , Loss:  0.5910407304763794   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9545 , Loss:  0.5910406708717346   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9546 , Loss:  0.5910406708717346   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9547 , Loss:  0.5910406708717346   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9548 , Loss:  0.5910406112670898   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9549 , Loss:  0.5910406112670898   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9550 , Loss:  0.5910405516624451   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9551 , Loss:  0.5910405516624451   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9552 , Loss:  0.5910405516624451   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9553 , Loss:  0.5910405516624451   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9554 , Loss:  0.5910405516624451   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9555 , Loss:  0.5910404920578003   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9556 , Loss:  0.5910404324531555   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9557 , Loss:  0.5910404324531555   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9558 , Loss:  0.5910404324531555   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9559 , Loss:  0.5910404324531555   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9560 , Loss:  0.5910404324531555   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9561 , Loss:  0.5910403728485107   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9562 , Loss:  0.5910403728485107   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9563 , Loss:  0.5910403728485107   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9564 , Loss:  0.591040313243866   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9565 , Loss:  0.591040313243866   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9566 , Loss:  0.591040313243866   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9567 , Loss:  0.5910402536392212   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9568 , Loss:  0.5910402536392212   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9569 , Loss:  0.5910402536392212   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9570 , Loss:  0.5910401940345764   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9571 , Loss:  0.5910401940345764   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9572 , Loss:  0.5910401940345764   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9573 , Loss:  0.5910401344299316   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9574 , Loss:  0.5910401344299316   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9575 , Loss:  0.5910400748252869   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9576 , Loss:  0.5910400748252869   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9577 , Loss:  0.5910400152206421   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9578 , Loss:  0.5910400152206421   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9579 , Loss:  0.5910398960113525   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9580 , Loss:  0.5910398960113525   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9581 , Loss:  0.5910398364067078   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9582 , Loss:  0.5910397171974182   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9583 , Loss:  0.5910397171974182   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9584 , Loss:  0.5910395979881287   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9585 , Loss:  0.5910394191741943   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9586 , Loss:  0.59103924036026   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9587 , Loss:  0.5910388827323914   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9588 , Loss:  0.5910382866859436   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9589 , Loss:  0.5910370349884033   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9590 , Loss:  0.5910336375236511   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9591 , Loss:  0.5910206437110901   f1-score: 0.9179030656814575   accuracy: 0.9476576447486877\n",
      "Epoch:  9592 , Loss:  0.5910055041313171   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9593 , Loss:  0.5909854769706726   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9594 , Loss:  0.5909923315048218   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9595 , Loss:  0.5909853577613831   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9596 , Loss:  0.5909938812255859   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9597 , Loss:  0.5909853577613831   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9598 , Loss:  0.5909883379936218   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9599 , Loss:  0.5909814238548279   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9600 , Loss:  0.5909824967384338   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9601 , Loss:  0.5909802913665771   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9602 , Loss:  0.5909783244132996   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9603 , Loss:  0.5909798741340637   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9604 , Loss:  0.5909780263900757   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9605 , Loss:  0.5909777283668518   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9606 , Loss:  0.5909785628318787   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9607 , Loss:  0.5909769535064697   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9608 , Loss:  0.5909767746925354   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9609 , Loss:  0.5909770131111145   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9610 , Loss:  0.5909757614135742   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9611 , Loss:  0.5909754037857056   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9612 , Loss:  0.5909756422042847   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9613 , Loss:  0.5909749269485474   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9614 , Loss:  0.5909745693206787   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9615 , Loss:  0.5909748077392578   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9616 , Loss:  0.5909745693206787   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9617 , Loss:  0.5909740924835205   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9618 , Loss:  0.5909742712974548   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9619 , Loss:  0.5909742116928101   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9620 , Loss:  0.5909739136695862   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9621 , Loss:  0.5909738540649414   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9622 , Loss:  0.5909738540649414   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9623 , Loss:  0.5909736156463623   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9624 , Loss:  0.590973436832428   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9625 , Loss:  0.590973436832428   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9626 , Loss:  0.5909733772277832   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9627 , Loss:  0.5909731388092041   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9628 , Loss:  0.5909730792045593   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9629 , Loss:  0.5909730792045593   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9630 , Loss:  0.5909729599952698   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9631 , Loss:  0.590972900390625   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9632 , Loss:  0.590972900390625   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9633 , Loss:  0.5909728407859802   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9634 , Loss:  0.5909727215766907   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9635 , Loss:  0.5909727215766907   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9636 , Loss:  0.5909727215766907   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9637 , Loss:  0.5909726023674011   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9638 , Loss:  0.5909726023674011   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9639 , Loss:  0.5909725427627563   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9640 , Loss:  0.5909725427627563   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9641 , Loss:  0.5909724235534668   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9642 , Loss:  0.5909724235534668   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9643 , Loss:  0.5909724235534668   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9644 , Loss:  0.5909724235534668   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9645 , Loss:  0.590972363948822   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9646 , Loss:  0.590972363948822   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9647 , Loss:  0.590972363948822   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9648 , Loss:  0.5909722447395325   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9649 , Loss:  0.5909722447395325   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9650 , Loss:  0.5909722447395325   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9651 , Loss:  0.5909722447395325   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9652 , Loss:  0.5909721851348877   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9653 , Loss:  0.5909721851348877   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9654 , Loss:  0.5909721255302429   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9655 , Loss:  0.5909721255302429   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9656 , Loss:  0.5909720659255981   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9657 , Loss:  0.5909720659255981   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9658 , Loss:  0.5909720659255981   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9659 , Loss:  0.5909720659255981   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9660 , Loss:  0.5909720659255981   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9661 , Loss:  0.5909720659255981   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9662 , Loss:  0.5909720659255981   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9663 , Loss:  0.5909720063209534   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9664 , Loss:  0.5909720063209534   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9665 , Loss:  0.5909719467163086   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9666 , Loss:  0.5909718871116638   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9667 , Loss:  0.5909718871116638   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9668 , Loss:  0.5909718871116638   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9669 , Loss:  0.5909718871116638   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9670 , Loss:  0.5909718871116638   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9671 , Loss:  0.5909718871116638   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9672 , Loss:  0.5909718871116638   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9673 , Loss:  0.590971827507019   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9674 , Loss:  0.590971827507019   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9675 , Loss:  0.5909717679023743   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9676 , Loss:  0.5909717679023743   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9677 , Loss:  0.5909717679023743   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9678 , Loss:  0.5909717082977295   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9679 , Loss:  0.5909717082977295   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9680 , Loss:  0.5909717082977295   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9681 , Loss:  0.5909717082977295   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9682 , Loss:  0.5909717082977295   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9683 , Loss:  0.5909717082977295   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9684 , Loss:  0.5909717082977295   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9685 , Loss:  0.5909717082977295   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9686 , Loss:  0.5909716486930847   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9687 , Loss:  0.5909716486930847   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9688 , Loss:  0.5909716486930847   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9689 , Loss:  0.5909715890884399   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9690 , Loss:  0.5909715890884399   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9691 , Loss:  0.5909715890884399   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9692 , Loss:  0.5909715890884399   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9693 , Loss:  0.5909715890884399   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9694 , Loss:  0.5909715890884399   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9695 , Loss:  0.5909715890884399   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9696 , Loss:  0.5909715890884399   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9697 , Loss:  0.5909715294837952   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9698 , Loss:  0.5909715890884399   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9699 , Loss:  0.5909715294837952   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9700 , Loss:  0.5909715294837952   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9701 , Loss:  0.5909714698791504   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9702 , Loss:  0.5909714698791504   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9703 , Loss:  0.5909714698791504   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9704 , Loss:  0.5909714698791504   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9705 , Loss:  0.5909714698791504   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9706 , Loss:  0.5909714102745056   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9707 , Loss:  0.5909714102745056   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9708 , Loss:  0.5909714102745056   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9709 , Loss:  0.5909714102745056   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9710 , Loss:  0.5909714102745056   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9711 , Loss:  0.5909714102745056   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9712 , Loss:  0.5909714102745056   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9713 , Loss:  0.5909713506698608   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9714 , Loss:  0.5909713506698608   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9715 , Loss:  0.5909712910652161   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9716 , Loss:  0.5909712910652161   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9717 , Loss:  0.5909712910652161   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9718 , Loss:  0.5909712910652161   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9719 , Loss:  0.5909712910652161   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9720 , Loss:  0.5909712910652161   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9721 , Loss:  0.5909712910652161   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9722 , Loss:  0.5909712314605713   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9723 , Loss:  0.5909712910652161   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9724 , Loss:  0.5909712314605713   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9725 , Loss:  0.5909712314605713   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9726 , Loss:  0.5909712314605713   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9727 , Loss:  0.5909712314605713   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9728 , Loss:  0.5909712314605713   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9729 , Loss:  0.5909712314605713   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9730 , Loss:  0.5909712314605713   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9731 , Loss:  0.5909712314605713   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9732 , Loss:  0.5909711718559265   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9733 , Loss:  0.5909711718559265   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9734 , Loss:  0.5909711718559265   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9735 , Loss:  0.5909711718559265   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9736 , Loss:  0.5909711122512817   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9737 , Loss:  0.5909711122512817   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9738 , Loss:  0.5909711122512817   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9739 , Loss:  0.5909711122512817   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9740 , Loss:  0.590971052646637   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9741 , Loss:  0.590971052646637   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9742 , Loss:  0.590971052646637   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9743 , Loss:  0.590971052646637   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9744 , Loss:  0.590971052646637   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9745 , Loss:  0.590971052646637   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9746 , Loss:  0.590971052646637   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9747 , Loss:  0.590971052646637   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9748 , Loss:  0.590971052646637   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9749 , Loss:  0.590971052646637   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9750 , Loss:  0.590971052646637   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9751 , Loss:  0.590971052646637   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9752 , Loss:  0.590971052646637   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9753 , Loss:  0.590971052646637   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9754 , Loss:  0.5909709930419922   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9755 , Loss:  0.5909709334373474   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9756 , Loss:  0.5909709334373474   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9757 , Loss:  0.5909709334373474   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9758 , Loss:  0.5909709334373474   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9759 , Loss:  0.5909709334373474   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9760 , Loss:  0.5909709334373474   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9761 , Loss:  0.5909708738327026   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9762 , Loss:  0.5909709334373474   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9763 , Loss:  0.5909708738327026   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9764 , Loss:  0.5909708738327026   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9765 , Loss:  0.5909708738327026   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9766 , Loss:  0.5909708738327026   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9767 , Loss:  0.5909708738327026   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9768 , Loss:  0.5909708738327026   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9769 , Loss:  0.5909708738327026   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9770 , Loss:  0.5909708738327026   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9771 , Loss:  0.5909708738327026   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9772 , Loss:  0.5909708738327026   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9773 , Loss:  0.5909708738327026   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9774 , Loss:  0.5909708738327026   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9775 , Loss:  0.5909708142280579   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9776 , Loss:  0.5909708738327026   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9777 , Loss:  0.5909707546234131   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9778 , Loss:  0.5909707546234131   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9779 , Loss:  0.5909707546234131   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9780 , Loss:  0.5909707546234131   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9781 , Loss:  0.5909707546234131   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9782 , Loss:  0.5909707546234131   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9783 , Loss:  0.5909707546234131   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9784 , Loss:  0.5909707546234131   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9785 , Loss:  0.5909707546234131   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9786 , Loss:  0.5909707546234131   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9787 , Loss:  0.5909707546234131   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9788 , Loss:  0.5909707546234131   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9789 , Loss:  0.5909706950187683   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9790 , Loss:  0.5909706950187683   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9791 , Loss:  0.5909706950187683   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9792 , Loss:  0.5909706950187683   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9793 , Loss:  0.5909706950187683   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9794 , Loss:  0.5909706950187683   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9795 , Loss:  0.5909706950187683   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9796 , Loss:  0.5909706950187683   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9797 , Loss:  0.5909706354141235   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9798 , Loss:  0.5909706354141235   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9799 , Loss:  0.5909706354141235   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9800 , Loss:  0.5909706354141235   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9801 , Loss:  0.5909705758094788   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9802 , Loss:  0.5909705758094788   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9803 , Loss:  0.5909705758094788   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9804 , Loss:  0.5909705758094788   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9805 , Loss:  0.5909705758094788   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9806 , Loss:  0.5909705758094788   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9807 , Loss:  0.5909705758094788   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9808 , Loss:  0.5909705758094788   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9809 , Loss:  0.5909705758094788   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9810 , Loss:  0.5909705758094788   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9811 , Loss:  0.5909705758094788   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9812 , Loss:  0.5909705758094788   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9813 , Loss:  0.5909705758094788   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9814 , Loss:  0.590970516204834   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9815 , Loss:  0.590970516204834   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9816 , Loss:  0.590970516204834   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9817 , Loss:  0.590970516204834   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9818 , Loss:  0.590970516204834   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9819 , Loss:  0.5909704566001892   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9820 , Loss:  0.590970516204834   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9821 , Loss:  0.590970516204834   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9822 , Loss:  0.590970516204834   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9823 , Loss:  0.590970516204834   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9824 , Loss:  0.590970516204834   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9825 , Loss:  0.5909703969955444   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9826 , Loss:  0.5909703969955444   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9827 , Loss:  0.5909703969955444   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9828 , Loss:  0.5909703969955444   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9829 , Loss:  0.5909703969955444   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9830 , Loss:  0.5909703969955444   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9831 , Loss:  0.5909703969955444   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9832 , Loss:  0.5909703969955444   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9833 , Loss:  0.5909703969955444   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9834 , Loss:  0.5909703969955444   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9835 , Loss:  0.5909703969955444   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9836 , Loss:  0.5909703969955444   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9837 , Loss:  0.5909703969955444   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9838 , Loss:  0.5909703969955444   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9839 , Loss:  0.5909703969955444   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9840 , Loss:  0.5909703969955444   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9841 , Loss:  0.5909703373908997   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9842 , Loss:  0.5909703373908997   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9843 , Loss:  0.5909703373908997   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9844 , Loss:  0.5909703373908997   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9845 , Loss:  0.5909703373908997   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9846 , Loss:  0.5909703373908997   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9847 , Loss:  0.5909703373908997   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9848 , Loss:  0.5909703373908997   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9849 , Loss:  0.5909703373908997   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9850 , Loss:  0.5909703373908997   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9851 , Loss:  0.5909703373908997   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9852 , Loss:  0.5909702777862549   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9853 , Loss:  0.5909702777862549   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9854 , Loss:  0.5909702181816101   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9855 , Loss:  0.5909702181816101   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9856 , Loss:  0.5909702181816101   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9857 , Loss:  0.5909702181816101   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9858 , Loss:  0.5909702181816101   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9859 , Loss:  0.5909702181816101   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9860 , Loss:  0.5909702181816101   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9861 , Loss:  0.5909702181816101   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9862 , Loss:  0.5909702181816101   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9863 , Loss:  0.5909702181816101   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9864 , Loss:  0.5909702181816101   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9865 , Loss:  0.5909702181816101   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9866 , Loss:  0.5909702181816101   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9867 , Loss:  0.5909702181816101   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9868 , Loss:  0.5909702181816101   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9869 , Loss:  0.5909702181816101   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9870 , Loss:  0.5909702181816101   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9871 , Loss:  0.5909702181816101   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9872 , Loss:  0.5909701585769653   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9873 , Loss:  0.5909700989723206   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9874 , Loss:  0.5909700989723206   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9875 , Loss:  0.5909700989723206   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9876 , Loss:  0.5909700989723206   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9877 , Loss:  0.5909700989723206   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9878 , Loss:  0.5909700989723206   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9879 , Loss:  0.5909700989723206   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9880 , Loss:  0.5909700989723206   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9881 , Loss:  0.5909700989723206   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9882 , Loss:  0.5909700989723206   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9883 , Loss:  0.5909700989723206   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9884 , Loss:  0.5909700989723206   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9885 , Loss:  0.5909700989723206   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9886 , Loss:  0.5909700989723206   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9887 , Loss:  0.5909700989723206   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9888 , Loss:  0.5909700393676758   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9889 , Loss:  0.5909700393676758   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9890 , Loss:  0.5909700393676758   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9891 , Loss:  0.5909700393676758   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9892 , Loss:  0.5909700393676758   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9893 , Loss:  0.5909700393676758   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9894 , Loss:  0.5909700393676758   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9895 , Loss:  0.5909700393676758   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9896 , Loss:  0.5909700393676758   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9897 , Loss:  0.5909700393676758   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9898 , Loss:  0.5909700393676758   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9899 , Loss:  0.590969979763031   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9900 , Loss:  0.590969979763031   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9901 , Loss:  0.590969979763031   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9902 , Loss:  0.590969979763031   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9903 , Loss:  0.590969979763031   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9904 , Loss:  0.590969979763031   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9905 , Loss:  0.590969979763031   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9906 , Loss:  0.590969979763031   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9907 , Loss:  0.590969979763031   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9908 , Loss:  0.590969979763031   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9909 , Loss:  0.590969979763031   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9910 , Loss:  0.590969979763031   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9911 , Loss:  0.5909699201583862   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9912 , Loss:  0.5909699201583862   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9913 , Loss:  0.5909699201583862   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9914 , Loss:  0.5909699201583862   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9915 , Loss:  0.5909699201583862   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9916 , Loss:  0.5909699201583862   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9917 , Loss:  0.5909699201583862   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9918 , Loss:  0.5909699201583862   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9919 , Loss:  0.5909699201583862   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9920 , Loss:  0.5909699201583862   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9921 , Loss:  0.5909699201583862   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9922 , Loss:  0.5909699201583862   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9923 , Loss:  0.5909699201583862   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9924 , Loss:  0.5909699201583862   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9925 , Loss:  0.5909699201583862   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9926 , Loss:  0.5909699201583862   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9927 , Loss:  0.5909699201583862   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9928 , Loss:  0.5909699201583862   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9929 , Loss:  0.5909698605537415   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9930 , Loss:  0.5909698605537415   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9931 , Loss:  0.5909698009490967   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9932 , Loss:  0.5909698009490967   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9933 , Loss:  0.5909698009490967   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9934 , Loss:  0.5909698009490967   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9935 , Loss:  0.5909698009490967   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9936 , Loss:  0.5909698009490967   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9937 , Loss:  0.5909698009490967   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9938 , Loss:  0.5909698009490967   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9939 , Loss:  0.5909698009490967   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9940 , Loss:  0.5909698009490967   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9941 , Loss:  0.5909698009490967   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9942 , Loss:  0.5909697413444519   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9943 , Loss:  0.5909697413444519   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9944 , Loss:  0.5909697413444519   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9945 , Loss:  0.5909697413444519   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9946 , Loss:  0.5909697413444519   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9947 , Loss:  0.5909697413444519   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9948 , Loss:  0.5909697413444519   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9949 , Loss:  0.5909697413444519   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9950 , Loss:  0.5909697413444519   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9951 , Loss:  0.5909697413444519   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9952 , Loss:  0.5909697413444519   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9953 , Loss:  0.5909697413444519   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9954 , Loss:  0.5909697413444519   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9955 , Loss:  0.5909697413444519   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9956 , Loss:  0.5909697413444519   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9957 , Loss:  0.5909697413444519   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9958 , Loss:  0.5909696817398071   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9959 , Loss:  0.5909697413444519   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9960 , Loss:  0.5909696817398071   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9961 , Loss:  0.5909696817398071   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9962 , Loss:  0.5909696817398071   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9963 , Loss:  0.5909696817398071   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9964 , Loss:  0.5909696817398071   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9965 , Loss:  0.5909696817398071   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9966 , Loss:  0.5909696817398071   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9967 , Loss:  0.5909696221351624   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9968 , Loss:  0.5909696221351624   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9969 , Loss:  0.5909696221351624   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9970 , Loss:  0.5909696221351624   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9971 , Loss:  0.5909696221351624   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9972 , Loss:  0.5909696221351624   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9973 , Loss:  0.5909696221351624   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9974 , Loss:  0.5909696221351624   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9975 , Loss:  0.5909696221351624   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9976 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9977 , Loss:  0.5909696221351624   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9978 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9979 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9980 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9981 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9982 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9983 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9984 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9985 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9986 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9987 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9988 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9989 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9990 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9991 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9992 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9993 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9994 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9995 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9996 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9997 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9998 , Loss:  0.5909695029258728   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  9999 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n",
      "Epoch:  10000 , Loss:  0.5909695625305176   f1-score: 0.9182087779045105   accuracy: 0.9478378295898438\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(Mk1.parameters(), lr=0.001)\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "f1_score = torchmetrics.functional.f1_score\n",
    "accuracy = torchmetrics.functional.accuracy\n",
    "diagdf=pd.DataFrame(columns=['Epoch','loss','F1-score','accuracy'])\n",
    "for epoch in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    pred = Mk1.forward(x_train.float())\n",
    "    l = loss(pred, y_train) # squeeze the predicted tensor\n",
    "    l.backward()\n",
    "    f1= f1_score(pred, y_train, task='binary')\n",
    "    acc=accuracy(pred, y_train, task='binary')\n",
    "    data={'Epoch':epoch,'loss':l.item(),'F1-score':f1.item(),'accuracy':acc.item()}\n",
    "    diagdf = pd.concat([diagdf, pd.DataFrame(data, index=[epoch])], ignore_index=True)\n",
    "    optimizer.step()\n",
    "    print('Epoch: ', epoch+1, ', Loss: ', l.item(),'  f1-score:', f1.item(),\"  accuracy:\", acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# построение графика loss\n",
    "plt.plot(diagdf['Epoch'], diagdf['loss'], label='loss')\n",
    "\n",
    "# построение графика F1-score\n",
    "plt.plot(diagdf['Epoch'], diagdf['F1-score'], label='F1-score')\n",
    "\n",
    "# построение графика accuracy\n",
    "plt.plot(diagdf['Epoch'], diagdf['accuracy'], label='accuracy')\n",
    "\n",
    "# добавление заголовка графика\n",
    "plt.title('Графики loss, F1-score и accuracy')\n",
    "\n",
    "# добавление подписей к осям\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Значение')\n",
    "\n",
    "# добавление легенды\n",
    "plt.legend()\n",
    "\n",
    "# отображение графика\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test=Mk1.forward(x_test.float())\n",
    "pred_test_binarized = (pred_test > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.91      0.89      3216\n",
      "         1.0       0.79      0.75      0.77      1542\n",
      "\n",
      "    accuracy                           0.85      4758\n",
      "   macro avg       0.84      0.83      0.83      4758\n",
      "weighted avg       0.85      0.85      0.85      4758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.to('cpu'), pred_test_binarized.to('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
